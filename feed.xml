<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://mrifkikurniawan.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://mrifkikurniawan.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-02-15T10:47:01+00:00</updated><id>https://mrifkikurniawan.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Evolving Parameterized Prompt Memory for Continual Learning</title><link href="https://mrifkikurniawan.github.io/blog/2024/EvoPrompt/" rel="alternate" type="text/html" title="Evolving Parameterized Prompt Memory for Continual Learning"/><published>2024-01-13T15:53:00+00:00</published><updated>2024-01-13T15:53:00+00:00</updated><id>https://mrifkikurniawan.github.io/blog/2024/EvoPrompt</id><content type="html" xml:base="https://mrifkikurniawan.github.io/blog/2024/EvoPrompt/"><![CDATA[<meta property="og:title" content="Evolving Parameterized Prompt Memory for Continual Learning. AAAI2024"/> <meta property="og:image" content="https://mrifkikurniawan.github.io/assets/img/evoprompt/evoprompt_arch.svg"/> <meta property="og:description" content="Non-expandable Prompt-based Continual Learning Via Continuous Prompting and Incremental Evolution. AAAI2024"/> <meta property="og:url" content="https://mrifkikurniawan.github.io/EvoPrompt/"/> <meta property="og:image:width" content="1200"/> <meta property="og:image:height" content="663"/> <meta property="og:type" content="website"/> <head> <script async="" src="https://www.googletagmanager.com/gtag/js?id=G-9VZKE74FPW"></script> <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-9VZKE74FPW');
</script> <meta charset="utf-8"/> <meta name="description" content="Evolving Parameterized Prompt Memory for Continual Learning"/> <meta name="keywords" content="Continual Learning, Incremental Learning, Prompt, Transformer, Pre-trained, Transfer Learning"/> <meta name="viewport" content="width=device-width, initial-scale=1"/> <title>Evolving Parameterized Prompt Memory for Continual Learning</title> <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet"/> <link rel="stylesheet" href="/assets/static/css/bulma.min.css"/> <link rel="stylesheet" href="/assets/static/css/bulma-carousel.min.css"/> <link rel="stylesheet" href="/assets/static/css/bulma-slider.min.css"/> <link rel="stylesheet" href="/assets/static/css/tab_gallery.css"/> <link rel="stylesheet" href="/assets/static/css/fontawesome.all.min.css"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"/> <link rel="stylesheet" href="/assets/static/css/index.css"/> <link rel="icon" href="/assets/static/images/favicon.svg"/> <link rel="stylesheet" href="/assets/juxtapose/css/juxtapose.css"/> <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script> <script defer="" src="/assets/static/js/fontawesome.all.min.js"></script> <script src="/assets/static/js/bulma-carousel.min.js"></script> <script src="/assets/static/js/bulma-slider.min.js"></script> <script src="/assets/static/js/index.js"></script> <script src="/assets/static/js/magnifier.js"></script> <link href="https://fonts.cdnfonts.com/css/menlo" rel="stylesheet"/> <link rel="stylesheet" href="/assets/static/css/image_card_fader.css"/> <link rel="stylesheet" href="/assets/static/css/image_card_slider.css"/> </head> <style>@import url('https://fonts.cdnfonts.com/css/menlo');</style> <body> <section class="hero"> <div class="hero-body"> <div class="container is-max-desktop"> <div class="columns is-centered"> <div class="column has-text-centered"> <h1 class="title is-2 publication-title">Evolving Parameterized Prompt Memory for Continual Learning</h1> <div class="is-size-5 publication-authors"> <span class="author-block"> <a href="https://mrifkikurniawan.github.io/">Muhammad Rifki Kurniawan</a><sup>1</sup>,</span> <span class="author-block"> <a href="https://scholar.google.com/citations?user=DnNdGckAAAAJ&amp;hl=zh-CN">Xiang Song</a><sup>1</sup>,</span> <span class="author-block"> <a href="https://scholar.google.com/citations?user=y6ijVukAAAAJ&amp;hl=en">Zhiheng Ma</a><sup>2</sup>, </span> <span class="author-block"> <a href="https://gehenhe.github.io/">Yuhang He</a><sup>1</sup>, </span> <span class="author-block"> <a href="https://gr.xjtu.edu.cn/web/ygong">Yihong Gong</a><sup>1</sup>, </span> <span class="author-block"> <a href="https://gr.xjtu.edu.cn/web/yangqi">Yang Qi</a><sup>1</sup>, </span> <span class="author-block"> <a href="https://gr.xjtu.edu.cn/web/weixing">Xing Wei</a><sup>1</sup> </span> </div> <div class="is-size-5 publication-authors"> <span class="author-block"><sup>1</sup>Xi'an Jiaotong University,</span> <span class="author-block"><sup>2</sup>Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences</span> </div> <div class="is-size-5 publication-venue"> in AAAI 2024 (Oral, Top 2.3%) </div> <div class="column has-text-centered"> <div class="publication-links"> <span class="link-block"> <a href="https://ojs.aaai.org/index.php/AAAI/article/view/29231" class="external-link button is-normal is-rounded is-dark"> <span class="icon"> <i class="fas fa-file-pdf"></i> </span> <span>Paper</span> </a> </span> <span class="link-block"> <a href="https://github.com/MIV-XJTU/EvoPrompt" class="external-link button is-normal is-rounded is-dark"> <span class="icon"> <i class="fab fa-github"></i> </span> <span>Code</span> </a> </span> <span class="link-block"> <a href="https://github.com/MIV-XJTU/EvoPrompt/assets/slides.pdf" class="external-link button is-normal is-rounded is-dark"> <svg style="width:16px;height:16px;margin-left:-0px;margin-right:6px" width="16px" height="16px" viewBox="0 0 44 44"><path fill="currentColor" d="M10,26h8a2,2,0,0,0,2-2V14a2,2,0,0,0-2-2H10a2,2,0,0,0-2,2V24A2,2,0,0,0,10,26Zm0-12h8V24H10Zm15,4H35a1,1,0,0,0,0-2H25a1,1,0,0,0,0,2Zm0-4h6a1,1,0,0,0,0-2H25a1,1,0,0,0,0,2Zm0,8h4a1,1,0,0,0,0-2H25a1,1,0,0,0,0,2ZM42,2H24a2,2,0,0,0-4,0H2A2,2,0,0,0,0,4V6A2,2,0,0,0,2,8V32a2,2,0,0,0,2,2H21v2.59l-5.71,5.71a1,1,0,1,0,1.41,1.41L22,38.41l5.29,5.29a1,1,0,1,0,1.41-1.41L23,36.59V34H40a2,2,0,0,0,2-2V8a2,2,0,0,0,2-2V4A2,2,0,0,0,42,2ZM40,32H4V8H40ZM42,6H2V4H42ZM25,26H35a1,1,0,0,0,0-2H25a1,1,0,0,0,0,2Z"></path> </svg> <span>Slides</span> </a> </span> <span class="link-block"> <a href="https://github.com/MIV-XJTU/EvoPrompt/assets/poster.pdf" class="external-link button is-normal is-rounded is-dark"> <span class="icon"> <i class="far fa-image"></i> </span> <span>Poster</span> </a> </span> <span class="link-block"> <a href="#bibtex" class="external-link button is-normal is-rounded is-dark"> <span class="icon"> <i class="ai ai-obp"></i> </span> <span>BibTex</span> </a> </span> </div> </div> </div> </div> </div> </div> </section> <section class="hero is-light is-small"> <div class="hero-body"> <div class="container is-max-desktop has-text-centered"> <h2 class="title is-3">Evolving Parameterized Prompt Memory for Continual Learning</h2> <div class="content has-text-justified"> <p> <b>Delving into prompt-based continual learning, we are interested in scenarios with non-expandable prompt pools and end-to-end training devoid of discrete selection</b>. Our solution, <b>EvoPrompt</b> (<b>Evo</b>lving Parameterized <b>Prompt</b>), leverages a multi-layer perceptron (MLP) bottleneck for formulating prompting function. These prompts are stored in the weight space of the network, <b>gradually evolving</b> as new tasks are learned, all without expansion. Additionally, we present a novel method for synthesizing future classifiers from previously acquired knowledge. Remarkably, our approach employs minimal parameters, being <b>5X</b> and <b>13X</b> smaller than CODA-P, while exhibiting superior performance. <br/> </p> </div> </div> </div> </section> <section class="section"> <div class="container is-max-desktop"> <div class="columns is-centered has-text-centered"> <div class="column is-four-fifths"> <h2 class="title is-3">Abstract</h2> <div class="content has-text-justified"> <p> Recent studies have demonstrated the potency of leveraging prompts in Transformers for continual learning (CL). Nevertheless, employing a discrete key-prompt bottleneck can lead to selection mismatches and inappropriate prompt associations during testing. Furthermore, this approach hampers adaptive prompting due to the lack of shareability among nearly identical instances at a more granular level. To address these challenges, we introduce the Evolving Parameterized Prompt Memory (EvoPrompt), a novel method involving adaptive and continuous prompting attached to pre-trained Vision Transformer (ViT), conditioned on specific instance. We formulate a continuous prompt function as a neural bottleneck and encode the collection of prompts on network weights. We establish a paired prompt memory system consisting of a stable reference and a flexible working prompt memory. Inspired by linear mode connectivity, we progressively fuse the working prompt memory and reference prompt memory during inter-task periods, resulting in continually evolved prompt memory. This fusion involves aligning functionally equivalent prompts using optimal transport and aggregating them in parameter space with an adjustable bias based on prompt node attribution. Additionally, to enhance backward compatibility, we propose compositional classifier initialization, which leverages prior prototypes from pre-trained models to guide the initialization of new classifiers in a subspace-aware manner. Comprehensive experiments validate that our approach achieves state-of-the-art performance in both class and domain incremental learning scenarios. </p> </div> </div> </div> </div> </section> <section class="section"> <div class="container is-max-desktop"> <div class="columns is-centered"> <div class="column is-full-width"> <h2 class="title is-3 has-text-centered">Evolving Parameterized Prompt Memory</h2> <h3 class="title is-4">Proposed Components</h3> <div class="content has-text-justified"> <p> <ol> <li> <b>Reformulating Incremental Prompt Tuning: </b> We use a Feedforward Neural Networks (FFNs) to shift from discrete to continuous prompting, employing a Multilayer Perceptron (MLP) bottleneck for prompt encoding in the neural weight space, called <b>prompt memory</b>.</li> <li><b>Prompt Memory Evolution via Incremental Fusion: </b> We adopt a dual memory approach, combining plastic <b>working prompt memory</b> (WPM) and stable <b>reference prompt memory</b> (RPM). These memories are integrated with alignment and attribution-dependent momentum, instead of appended.</li> <li><b>Compositional Classifier Initialization: </b>Leveraging insights from the <i>anchoring-and-adjustment heuristic</i> in psychology, we predict future classifiers by referencing current classifiers and the prototype relationships between classes.</li> </ol> </p> </div> <h3 class="title is-4">Prompt Memory Architecture and Its Evolution</h3> <div class="content has-text-centered"> <img src="/assets/img/evoprompt/evoprompt_arch.svg"/> </div> <div class="content has-text-justified"> <p> The parameterization of memory prompts through <b>Feedforward Neural Networks (FFN)</b> and a training routine that involves step-by-step merging with <b>alignment</b> and <b>attribution-aware</b> momentum. When given input, the linear key memory identifies patterns to calculate a positive memory coefficient. This coefficient is then employed to allocate weights to the value memory, resulting in the ultimate prompt. We introduce a dual-functional prompt memory consisting of <b>Reference Prompt Memory</b> (RPM) and <b>Working Prompt Memory</b> (WPM). The RPM encompasses all prompts encountered so far, while the WPM is task-specific and adjusts swiftly to emerging tasks. </p> <p> To address <i>catastrophic forgetting</i>, we adopt ideas from <i>linear mode connectivity</i>, featuring a singular basin with a low error landscape amid different task solutions. Concretely, we introduce <b>incremental fusion</b> during inter-task periods to align the functionality of WPM with RPM, and subsequently fuse them in parameter space. We formulate the alignment as an <b>Optimal Transport</b> (OT) problem and the fusion as a linearly weighted aggregation adjusted by <b>neuron attribution</b>. </p> </div> <h3 class="title is-4">Compositional Classifier Initialization</h3> <div class="content has-text-centered"> <img src="/assets/img/evoprompt/compositional_initialization.svg" width="50%"/> </div> <div class="content has-text-justified"> <p> The introduction of Compositional Classifier Initialization (CCI) is based on the <b>bias adjustment heuristic</b>. It entails estimating the unknown, such as a <b>future classifiers</b>, by leveraging <b>relevant existing information</b>. We compute class mean embeddings, or prototypes, from pre-trained models. Through attention mechanisms, we establish inter-class relationships among these prototypes, forming a <b>foundational relation</b> between past and target tasks. The resulting probability simplex from multihead attention is then used to linearly combine previous classifiers, facilitating the initialization of future classifiers and <b>introducing implicit bias</b>. </p> </div> </div> </div> <div class="container is-max-desktop"> <div class="columns is-centered"> <div class="column is-full-width"> <h2 class="title is-3 has-text-centered">Empirical Benchmark Results</h2> <h3 class="title is-4">Class Incremental Learning</h3> <div class="content has-text-justified"> <p> Methods evaluated on <b>Split CIFAR-100</b>. </p> </div> <center> <style>table{border-collapse:collapse}tr{border-top:1px solid black;border-bottom:1px solid black}td{border:0}</style> <table border="0" style="width: 100%"> <tr> <th>Method</th> <th colspan="2">5 Steps</th> <th colspan="2">10 Steps</th> <th colspan="2">20 Steps</th> <th colspan="2">Avg</th> </tr> <tr> <td></td> <td>Acc(↑)</td> <td>Forget(↓)</td> <td>Acc(↑)</td> <td>Forget(↓)</td> <td>Acc(↑)</td> <td>Forget(↓)</td> <td>Acc(↑)</td> <td>Forget(↓)</td> </tr> <tr> <td>FT-seq</td> <td>73.17</td> <td>2.95</td> <td>62.77</td> <td>20.73</td> <td>55.97</td> <td>32.74</td> <td>63.97 <span style="color: red;">(+0.00)</span></td> <td>18.81 <span style="color: red;">(-0.00)</span></td> </tr> <tr> <td>L2P</td> <td>86.53</td> <td>7.67</td> <td>84.97</td> <td>8.21</td> <td>83.39</td> <td>10.18</td> <td>84.96 <span style="color:teal;">(+20.99)</span></td> <td>8.69 <span style="color:teal;">(-10.12)</span></td> </tr> <tr> <td>DualPrompt</td> <td>88.26</td> <td><u>5.72</u></td> <td>86.83</td> <td>6.21</td> <td>84.11</td> <td>8.75</td> <td>86.40 <span style="color:teal;">(+22.43)</span></td> <td>6.89 <span style="color:teal;">(-11.92)</span></td> </tr> <tr> <td>ESN</td> <td>88.09</td> <td><b>5.18</b></td> <td>85.96</td> <td>4.54</td> <td>82.71</td> <td>6.44</td> <td>85.59 <span style="color:teal;">(+21.62)</span></td> <td>5.39 <span style="color:teal;">(-13.42)</span></td> </tr> <tr> <td>CODA-P-S</td> <td>88.90</td> <td>6.29</td> <td>86.33</td> <td>6.29</td> <td>81.71</td> <td>9.41</td> <td>85.65 <span style="color:teal;">(+21.68)</span></td> <td>7.33 <span style="color:teal;">(-11.48)</span></td> </tr> <tr> <td>CODA-P</td> <td><b>89.16</b></td> <td>6.08</td> <td>87.31</td> <td>5.95</td> <td>81.69</td> <td>9.85</td> <td>86.05 <span style="color:teal;">(+22.08)</span></td> <td>7.29 <span style="color:teal;">(-11.52)</span></td> </tr> <tr> <td><b>EvoPrompt-S</b></td> <td>88.69</td> <td>9.93</td> <td><u>87.95</u></td> <td><u>2.38</u></td> <td><b>84.98</b></td> <td><b>3.42</b></td> <td><b>87.20 <span style="color:teal;">(+23.23)</span></b></td> <td><b>5.24 <span style="color:teal;">(-13.57)</span></b></td> </tr> <tr> <td><b>EvoPrompt</b></td> <td><u>88.97</u></td> <td>10.12</td> <td><b>87.97</b></td> <td><b>2.60</b></td> <td><u>84.64</u></td> <td><u>3.98</u></td> <td><u>87.19 <span style="color:teal;">(+23.22)</span></u></td> <td><u>5.57 <span style="color:teal;">(-13.24)</span></u></td> </tr> </table> </center> <br/> <div class="content has-text-justified"> <p> Methods evaluated on <b>Split ImageNet-R</b>. </p> </div> <center> <table border="0" style="width: 100%"> <tr> <th>Method</th> <th colspan="2">5 Steps</th> <th colspan="2">10 Steps</th> <th colspan="2">20 Steps</th> <th colspan="2">Avg</th> </tr> <tr> <td></td> <td>Acc(↑)</td> <td>Forget(↓)</td> <td>Acc(↑)</td> <td>Forget(↓)</td> <td>Acc(↑)</td> <td>Forget(↓)</td> <td>Acc(↑)</td> <td>Forget(↓)</td> </tr> <tr> <td>FT-seq</td> <td>61.41</td> <td>5.76</td> <td>50.28</td> <td>24.28</td> <td>39.25</td> <td>40.38</td> <td>50.31 <span style="color:red;">(+0.00)</span></td> <td>23.48 <span style="color:red;">(-0.00)</span></td> </tr> <tr> <td>L2P</td> <td>66.63</td> <td>6.65</td> <td>64.05</td> <td>10.05</td> <td>60.34</td> <td>14.44</td> <td>63.67 <span style="color:teal;">(+13.36)</span></td> <td>10.38 <span style="color:teal;">(-13.10)</span></td> </tr> <tr> <td>DualPrompt</td> <td>71.06</td> <td><u>4.19</u></td> <td>69.71</td> <td>5.44</td> <td>66.26</td> <td>8.74</td> <td>69.01 <span style="color:teal;">(+18.70)</span></td> <td>6.12 <span style="color:teal;">(-17.36)</span></td> </tr> <tr> <td>ESN</td> <td>73.42</td> <td><b>3.79</b></td> <td>71.07</td> <td>4.99</td> <td>64.77</td> <td>6.65</td> <td>69.75 <span style="color:teal;">(+19.44)</span></td> <td>5.14 <span style="color:teal;">(-18.34)</span></td> </tr> <tr> <td>CODA-P-S</td> <td>73.80</td> <td>5.56</td> <td>71.95</td> <td>5.92</td> <td>69.67</td> <td>6.23</td> <td>71.81 <span style="color:teal;">(+21.50)</span></td> <td>5.90 <span style="color:teal;">(-17.58)</span></td> </tr> <tr> <td>CODA-P</td> <td>73.77</td> <td>6.60</td> <td>72.42</td> <td>6.26</td> <td>70.18</td> <td>5.53</td> <td>72.12 <span style="color:teal;">(+21.81)</span></td> <td>6.13 <span style="color:teal;">(-17.35)</span></td> </tr> <tr> <td><b>EvoPrompt-S</b></td> <td><u>76.79</u></td> <td>9.84</td> <td><u>76.22</u></td> <td><b>2.33</b></td> <td><b>74.68</b></td> <td><u>2.70</u></td> <td><u>75.90 <span style="color:teal;">(+25.59)</span></u></td> <td><b>4.96 <span style="color:teal;">(-18.52)</span></b></td> </tr> <tr> <td><b>EvoPrompt</b></td> <td><b>77.16</b></td> <td>9.89</td> <td><b>76.83</b></td> <td><u>2.78</u></td> <td><u>74.41</u></td> <td><b>2.56</b></td> <td><b>76.13 <span style="color:teal;">(+25.82)</span></b></td> <td><u>5.08 <span style="color:teal;">(-18.40)</span></u></td> </tr> </table> </center> <br/> <h3 class="title is-4">Domain Incremental Learning</h3> <div class="content has-text-justified"> <p> Benchmark results evaluated on <b>CORe50</b> dataset. </p> </div> <center> <table border="0" style="width: 50%"> <tr> <th>Method</th> <th>Test Acc. (%)</th> <th>Δ Acc. (%)</th> </tr> <tr> <td>NME-seq</td> <td>78.20</td> <td style="color:red;">+00.00</td> </tr> <tr> <td>L2P</td> <td>78.33</td> <td style="color:teal;">+0.13</td> </tr> <tr> <td>S-iPrompts</td> <td>83.13</td> <td style="color:teal;">+4.93</td> </tr> <tr> <td>S-liPrompts</td> <td>89.06</td> <td style="color:teal;">+10.86</td> </tr> <tr> <td>ESN</td> <td>91.80</td> <td style="color:teal;">+13.60</td> </tr> <tr> <td><b>EvoPrompt-S</b></td> <td><u>94.77</u></td> <td style="color:teal;">+16.57</td> </tr> <tr> <td><b>EvoPrompt</b></td> <td><b>95.27</b></td> <td style="color:teal;">+17.07</td> </tr> </table> </center> <br/> <h3 class="title is-4">Online Learning</h3> <div class="content has-text-justified"> <p> Benchmark results evaluated on online setting on both <b>Split CIFAR-100</b> and <b>Split ImageNet-R</b>. </p> </div> <center> <table border="0" style="width: 60%"> <tr> <th>Method</th> <th colspan="2">Split CIFAR-100</th> <th colspan="2">Split ImageNet-R</th> </tr> <tr> <td></td> <td>Acc.(↑)</td> <td>Forget.(↓)</td> <td>Acc.(↑)</td> <td>Forget.(↓)</td> </tr> <tr> <td>L2P</td> <td>80.49</td> <td>8.74</td> <td>57.52</td> <td>6.54</td> </tr> <tr> <td>DualPrompt</td> <td>82.17</td> <td>7.52</td> <td>61.09</td> <td>4.40</td> </tr> <tr> <td>ESN</td> <td>74.17</td> <td>10.59</td> <td>-</td> <td>-</td> </tr> <tr> <td>CODA-P-S</td> <td>79.46</td> <td>11.92</td> <td>64.60</td> <td>6.09</td> </tr> <tr> <td>CODA-P</td> <td>81.07</td> <td>10.10</td> <td>66.47</td> <td>5.42</td> </tr> <tr> <td><b>EvoPrompt-S</b></td> <td style="text-decoration: underline;">84.23</td> <td style="text-decoration: underline;">1.64</td> <td style="text-decoration: underline;">73.56</td> <td style="text-decoration: underline;">3.82</td> </tr> <tr> <td><b>EvoPrompt</b></td> <td style="font-weight: bold;">84.72</td> <td style="font-weight: bold;">0.89</td> <td style="font-weight: bold;">74.05</td> <td style="font-weight: bold;">3.66</td> </tr> </table> </center> <div class="content has-text-justified"> </div> </div> </div> <div class="columns is-centered"> <div class="column is-full-width"> <h2 class="title is-3 has-text-centered">Further Analysis</h2> <h3 class="title is-4">Stability Gap</h3> <div class="content has-text-centered"> <img src="/assets/img/evoprompt/stability_gap.svg" width="75%"/> </div> <div class="content has-text-justified"> <p> There is <b>no observable</b> stability gap in both random and compositional classifier initialization. Despite this, our compositional initialization displays <b>stability</b> in its performance, <b>smooth transitions</b> between tasks, and <b>rapid acquisition</b> of current knowledge. </p> </div> <h3 class="title is-4">Separability and Backward-compatibility</h3> <div class="content has-text-centered"> <img src="/assets/img/evoprompt/separability.svg" width="75%"/> </div> <div class="content has-text-justified"> <p> Through our initialization method, we <b>minimize the distances</b> among points within the same class, illustrating <b>increased compactness</b> within classes. Simultaneously, we maintain <b>balanced margins</b> between different classes, resulting in smaller inter-class distances compared to random initialization, thus improving backward compatibility. </p> </div> <div class="content has-text-justified"> </div> </div> </div> <div class="columns is-centered"> <div class="column is-full-width"> <h2 class="title is-3 has-text-centered">Conclusion</h2> <div class="content has-text-justified"> <p>This paper presents EvoPrompt, a prompt-based approach that employs continually evolved parameterized memory prompt with continuous bottleneck using FFN and attribution-aware incremental prompt fusion, which facilitates the sharing and adaptability during prompting. Maximizing learned knowledge is achieved through the introduction of compositional classifier initialization, enhancing both learning stability and backward compatibility. Our framework scales to multiple steps scenarios and datasets with high intra-diversity, such as Split ImageNet-R and CORe50, proving the generalization capability introduced by our proposed method. Comprehensive experiments exhibit superior performance compared to the state-of-the-art. </p> </div> </div> </div> </div> <section class="section" id="BibTeX"> <div class="container is-max-desktop content"> <h2 class="title"><a id="bibtex">BibTeX</a></h2> <pre><code>@article{kurniawan2024evoprompt,
      title = {Evolving Parameterized Prompt Memory for Continual Learning},
      author = {Kurniawan, Muhammad Rifki and Song, Xiang and Ma, Zhiheng and He, Yuhang and Gong, Yihong and Yang, Qi and Wei, Xing},
      year = {2024},
      booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
}</code></pre> </div> </section> <footer class="footer"> <div class="columns is-centered"> <div class="column is-8"> <div class="content"> <p> This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>. </p> <p> Website adapted from the following <a href="https://github.com/nerfies/nerfies.github.io">source code</a>. </p> </div> </div> </div> </footer> <script src="/assets/juxtapose/js/juxtapose.js"></script> <script>
var slider;
let origImages = [
  {"src": "/assets/static/images/iguana_input.jpg", "label": "Input Photos or Artworks (128px)",},
  {"src": "/assets/static/images/iguana_output.jpg", "label": "Upsampled by GigaGAN (4K)",}
];
let origOptions = {
    "makeResponsive": true,
    "showLabels": true,
    "mode": "horizontal",
    "showCredits": true,
    "animate": true,
    "startingPosition": "50"
};

const juxtaposeSelector = "#juxtapose-embed";
const transientSelector = "#juxtapose-hidden";


function tab_gallery_click(name) {
  // Get the expanded image
  let inputImage = {
    label: "Input Photos or Artworks (128px)",
  };
  let outputImage = {
    label: "Upsampled by GigaGAN (4K)",
  };

  inputImage.src = "/assets/static/images/".concat(name, "_input.jpg")
  outputImage.src = "/assets/static/images/".concat(name, "_output.jpg")

  let images = [inputImage, outputImage];
  let options = slider.options;
  options.callback = function(obj) {
      var newNode = document.getElementById(obj.selector.substring(1));
      var oldNode = document.getElementById(juxtaposeSelector.substring(1));
      console.log(obj.selector.substring(1));
      console.log(newNode.children[0]);
      oldNode.replaceChild(newNode.children[0], oldNode.children[0]);
      //newNode.removeChild(newNode.children[0]);
      
  };
  
  slider = new juxtapose.JXSlider(transientSelector, images, options);
};



(function() {
    slider = new juxtapose.JXSlider(
        juxtaposeSelector, origImages, origOptions);
    //document.getElementById("left-button").onclick = replaceLeft;
    //document.getElementById("right-button").onclick = replaceRight;
})();
  // Get the image text
  var imgText = document.getElementById("imgtext");
  // Use the same src in the expanded image as the image being clicked on from the grid
  // expandImg.src = imgs.src;
  // Use the value of the alt attribute of the clickable image as text inside the expanded image
  imgText.innerHTML = name;
  // Show the container element (hidden with CSS)
  // expandImg.parentElement.style.display = "block";

$(".flip-card").click(function() {
            console.log("fading in")
            div_back = $(this).children().children()[1]
            div_front = $(this).children().children()[0]
            // console.log($(this).children("div.flip-card-back"))
            console.log(div_back)
            $(div_front).addClass("out");
            $(div_front).removeClass("in");

            $(div_back).addClass("in");
            $(div_back).removeClass("out");

});

$(".flip-card").mouseleave(function() {
            console.log("fading in")
            div_back = $(this).children().children()[1]
            div_front = $(this).children().children()[0]
            // console.log($(this).children("div.flip-card-back"))
            console.log(div_back)
            $(div_front).addClass("in");
            $(div_front).removeClass("out");

            $(div_back).addClass("out");
            $(div_back).removeClass("in");

});

</script> <script src="https://cdn.jsdelivr.net/npm/popper.js@1.12.9/dist/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/js/bootstrap.min.js"></script> </div></section></body>]]></content><author><name></name></author><summary type="html"><![CDATA[Evolving Parameterized Prompt Memory for Continual Learning Evolving Parameterized Prompt Memory for Continual Learning Muhammad Rifki Kurniawan1, Xiang Song1, Zhiheng Ma2, Yuhang He1, Yihong Gong1, Yang Qi1, Xing Wei1 1Xi'an Jiaotong University, 2Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences in AAAI 2024 (Oral, Top 2.3%) Paper Code Slides Poster BibTex Evolving Parameterized Prompt Memory for Continual Learning Delving into prompt-based continual learning, we are interested in scenarios with non-expandable prompt pools and end-to-end training devoid of discrete selection. Our solution, EvoPrompt (Evolving Parameterized Prompt), leverages a multi-layer perceptron (MLP) bottleneck for formulating prompting function. These prompts are stored in the weight space of the network, gradually evolving as new tasks are learned, all without expansion. Additionally, we present a novel method for synthesizing future classifiers from previously acquired knowledge. Remarkably, our approach employs minimal parameters, being 5X and 13X smaller than CODA-P, while exhibiting superior performance. Abstract Recent studies have demonstrated the potency of leveraging prompts in Transformers for continual learning (CL). Nevertheless, employing a discrete key-prompt bottleneck can lead to selection mismatches and inappropriate prompt associations during testing. Furthermore, this approach hampers adaptive prompting due to the lack of shareability among nearly identical instances at a more granular level. To address these challenges, we introduce the Evolving Parameterized Prompt Memory (EvoPrompt), a novel method involving adaptive and continuous prompting attached to pre-trained Vision Transformer (ViT), conditioned on specific instance. We formulate a continuous prompt function as a neural bottleneck and encode the collection of prompts on network weights. We establish a paired prompt memory system consisting of a stable reference and a flexible working prompt memory. Inspired by linear mode connectivity, we progressively fuse the working prompt memory and reference prompt memory during inter-task periods, resulting in continually evolved prompt memory. This fusion involves aligning functionally equivalent prompts using optimal transport and aggregating them in parameter space with an adjustable bias based on prompt node attribution. Additionally, to enhance backward compatibility, we propose compositional classifier initialization, which leverages prior prototypes from pre-trained models to guide the initialization of new classifiers in a subspace-aware manner. Comprehensive experiments validate that our approach achieves state-of-the-art performance in both class and domain incremental learning scenarios. Evolving Parameterized Prompt Memory Proposed Components Reformulating Incremental Prompt Tuning: We use a Feedforward Neural Networks (FFNs) to shift from discrete to continuous prompting, employing a Multilayer Perceptron (MLP) bottleneck for prompt encoding in the neural weight space, called prompt memory. Prompt Memory Evolution via Incremental Fusion: We adopt a dual memory approach, combining plastic working prompt memory (WPM) and stable reference prompt memory (RPM). These memories are integrated with alignment and attribution-dependent momentum, instead of appended. Compositional Classifier Initialization: Leveraging insights from the anchoring-and-adjustment heuristic in psychology, we predict future classifiers by referencing current classifiers and the prototype relationships between classes. Prompt Memory Architecture and Its Evolution The parameterization of memory prompts through Feedforward Neural Networks (FFN) and a training routine that involves step-by-step merging with alignment and attribution-aware momentum. When given input, the linear key memory identifies patterns to calculate a positive memory coefficient. This coefficient is then employed to allocate weights to the value memory, resulting in the ultimate prompt. We introduce a dual-functional prompt memory consisting of Reference Prompt Memory (RPM) and Working Prompt Memory (WPM). The RPM encompasses all prompts encountered so far, while the WPM is task-specific and adjusts swiftly to emerging tasks. To address catastrophic forgetting, we adopt ideas from linear mode connectivity, featuring a singular basin with a low error landscape amid different task solutions. Concretely, we introduce incremental fusion during inter-task periods to align the functionality of WPM with RPM, and subsequently fuse them in parameter space. We formulate the alignment as an Optimal Transport (OT) problem and the fusion as a linearly weighted aggregation adjusted by neuron attribution. Compositional Classifier Initialization The introduction of Compositional Classifier Initialization (CCI) is based on the bias adjustment heuristic. It entails estimating the unknown, such as a future classifiers, by leveraging relevant existing information. We compute class mean embeddings, or prototypes, from pre-trained models. Through attention mechanisms, we establish inter-class relationships among these prototypes, forming a foundational relation between past and target tasks. The resulting probability simplex from multihead attention is then used to linearly combine previous classifiers, facilitating the initialization of future classifiers and introducing implicit bias. Empirical Benchmark Results Class Incremental Learning Methods evaluated on Split CIFAR-100. Method 5 Steps 10 Steps 20 Steps Avg Acc(↑) Forget(↓) Acc(↑) Forget(↓) Acc(↑) Forget(↓) Acc(↑) Forget(↓) FT-seq 73.17 2.95 62.77 20.73 55.97 32.74 63.97 (+0.00) 18.81 (-0.00) L2P 86.53 7.67 84.97 8.21 83.39 10.18 84.96 (+20.99) 8.69 (-10.12) DualPrompt 88.26 5.72 86.83 6.21 84.11 8.75 86.40 (+22.43) 6.89 (-11.92) ESN 88.09 5.18 85.96 4.54 82.71 6.44 85.59 (+21.62) 5.39 (-13.42) CODA-P-S 88.90 6.29 86.33 6.29 81.71 9.41 85.65 (+21.68) 7.33 (-11.48) CODA-P 89.16 6.08 87.31 5.95 81.69 9.85 86.05 (+22.08) 7.29 (-11.52) EvoPrompt-S 88.69 9.93 87.95 2.38 84.98 3.42 87.20 (+23.23) 5.24 (-13.57) EvoPrompt 88.97 10.12 87.97 2.60 84.64 3.98 87.19 (+23.22) 5.57 (-13.24) Methods evaluated on Split ImageNet-R. Method 5 Steps 10 Steps 20 Steps Avg Acc(↑) Forget(↓) Acc(↑) Forget(↓) Acc(↑) Forget(↓) Acc(↑) Forget(↓) FT-seq 61.41 5.76 50.28 24.28 39.25 40.38 50.31 (+0.00) 23.48 (-0.00) L2P 66.63 6.65 64.05 10.05 60.34 14.44 63.67 (+13.36) 10.38 (-13.10) DualPrompt 71.06 4.19 69.71 5.44 66.26 8.74 69.01 (+18.70) 6.12 (-17.36) ESN 73.42 3.79 71.07 4.99 64.77 6.65 69.75 (+19.44) 5.14 (-18.34) CODA-P-S 73.80 5.56 71.95 5.92 69.67 6.23 71.81 (+21.50) 5.90 (-17.58) CODA-P 73.77 6.60 72.42 6.26 70.18 5.53 72.12 (+21.81) 6.13 (-17.35) EvoPrompt-S 76.79 9.84 76.22 2.33 74.68 2.70 75.90 (+25.59) 4.96 (-18.52) EvoPrompt 77.16 9.89 76.83 2.78 74.41 2.56 76.13 (+25.82) 5.08 (-18.40) Domain Incremental Learning Benchmark results evaluated on CORe50 dataset. Method Test Acc. (%) Δ Acc. (%) NME-seq 78.20 +00.00 L2P 78.33 +0.13 S-iPrompts 83.13 +4.93 S-liPrompts 89.06 +10.86 ESN 91.80 +13.60 EvoPrompt-S 94.77 +16.57 EvoPrompt 95.27 +17.07 Online Learning Benchmark results evaluated on online setting on both Split CIFAR-100 and Split ImageNet-R. Method Split CIFAR-100 Split ImageNet-R Acc.(↑) Forget.(↓) Acc.(↑) Forget.(↓) L2P 80.49 8.74 57.52 6.54 DualPrompt 82.17 7.52 61.09 4.40 ESN 74.17 10.59 - - CODA-P-S 79.46 11.92 64.60 6.09 CODA-P 81.07 10.10 66.47 5.42 EvoPrompt-S 84.23 1.64 73.56 3.82 EvoPrompt 84.72 0.89 74.05 3.66 Further Analysis Stability Gap There is no observable stability gap in both random and compositional classifier initialization. Despite this, our compositional initialization displays stability in its performance, smooth transitions between tasks, and rapid acquisition of current knowledge. Separability and Backward-compatibility Through our initialization method, we minimize the distances among points within the same class, illustrating increased compactness within classes. Simultaneously, we maintain balanced margins between different classes, resulting in smaller inter-class distances compared to random initialization, thus improving backward compatibility. Conclusion This paper presents EvoPrompt, a prompt-based approach that employs continually evolved parameterized memory prompt with continuous bottleneck using FFN and attribution-aware incremental prompt fusion, which facilitates the sharing and adaptability during prompting. Maximizing learned knowledge is achieved through the introduction of compositional classifier initialization, enhancing both learning stability and backward compatibility. Our framework scales to multiple steps scenarios and datasets with high intra-diversity, such as Split ImageNet-R and CORe50, proving the generalization capability introduced by our proposed method. Comprehensive experiments exhibit superior performance compared to the state-of-the-art. BibTeX @article{kurniawan2024evoprompt, title={Evolving Parameterized Prompt Memory for Continual Learning}, author={Kurniawan, Muhammad Rifki and Song, Xiang and Ma, Zhiheng and He, Yuhang and Gong, Yihong and Yang, Qi and Wei, Xing}, year={2024}, booktitle={Proceedings of the AAAI Conference on Artificial Intelligence}, } This website is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License. Website adapted from the following source code.]]></summary></entry><entry><title type="html">Catastrophic Forgetting in Neural Networks Explained</title><link href="https://mrifkikurniawan.github.io/blog/2021/Catastrophic_Forgetting_in_Neural_Networks_Explained/" rel="alternate" type="text/html" title="Catastrophic Forgetting in Neural Networks Explained"/><published>2021-05-06T15:53:00+00:00</published><updated>2021-05-06T15:53:00+00:00</updated><id>https://mrifkikurniawan.github.io/blog/2021/Catastrophic_Forgetting_in_Neural_Networks_Explained</id><content type="html" xml:base="https://mrifkikurniawan.github.io/blog/2021/Catastrophic_Forgetting_in_Neural_Networks_Explained/"><![CDATA[<blockquote style="text-align: justify;"> <p>The existing neural networks is trained on top of a useful assumption of i.i.d setting while contrasting with sequential continual learning problem setting. As a result, the neural networks trained on continual tasks setting will suffer from catastrophic interference which means the networks forget how to do previously learned tasks when they encounter new tasks. This article will dig deep into the reason for forgetting, how to measure this problem, and introduced some available approaches proposed to reducing the abandoning of prior knowledge.</p> </blockquote> <blockquote> <p>[Updates]<br/> <span style="color:#8B0000">06-05-2021</span>: <span style="color:#1E90FF">Initial article publication</span></p> </blockquote> <hr/> <h1 id="what-is-catastrophic-forgetting">What is Catastrophic Forgetting?</h1> <p style="text-align: justify;">How humans learn is both extremely fascinating and mysterious especially when it comes to the capability to continuously learn new knowledge and skills without forgetting the past experiences. As an example, while we observe the physics phenomena such as the gravitation mechanism and, afterward, acquire new knowledge how the chemistry works, we are able to remember what gravitation is about and explain it effortlessly. In contrast, from the learning intelligence machine perspective, deep learning scientists highly struggle to incorporate the lifelong learning ability into machine learning architecture such as neural networks.</p> <p style="text-align: justify;">The catastrophic forgetting or alternatively called catastrophic interference was observed initially by McColskey and Cohen <d-cite key="McCloskey1989"></d-cite> in 1898 on shallow 3-layers neural networks who realized that connectionist networks — a common term in 19’s substituting ‘neural networks’ — trained on sequential learning prone to erase the past learned knowledge. They concluded that adjusting networks weights representing the old knowledge while training caused catastrophic interference and it was precipitated and compounded by distributed representation as the recognized useful properties of Multi-layer Perceptrons.</p> <p style="text-align: justify;">Later, this is considered as a more expanded discipline of ‘plasticity-stability dilemma’ <d-cite key="French1999"></d-cite>. As a means of the study of tuning the parameters by discovering the most optimum learning algorithm to let the neural networks acquire new knowledge and be sensitive to distributional shifting — known as plasticity — but maintaining the past knowledge to reduce the forgetting — known as stability. Highly plastic networks potentially suffer from forgetting the past encoded knowledge and oppositely very stable networks could be trouble with efficient information encoding at synapse level <d-cite key="Mermillod2013"></d-cite>.</p> <p style="text-align: justify;">In contrast, cognitive sciences see beyond the field as studying determining whether the earlier acquired knowledge in life is more memorized than the knowledge acquired in the coming age or called ‘The Entrenchment Effect’ <d-cite key="Mermillod2013"></d-cite>. Therefore, it seems a little bit different between what plasticity-stability stands for in deep learning and the cognitive science community.</p> <p style="text-align: justify;">While the neural networks adapt flexibly to the new incoming knowledge, it will serendipitously experience catastrophic forgetting. Conversely, networks that are prone to being unable to discriminate the new incoming inputs if the networks are extremely stable or commonly known as catastrophic remembering <d-cite key="Kaushik2021"></d-cite>.</p> <p style="text-align: justify;">Contemporarily, deep learning is trained on top of a weak but useful assumption of <a href="https://deepai.org/machine-learning-glossary-and-terms/independent-and-identically-distributed-random-variables">i.i.d (independent and identically distributed)</a> setting which means that the data points are supposed to be mutually independent  — single data is unrelated to other data point — and having similar distribution e.g. training data is assumed to have equivalent distribution to test data. Therefore, the common training setting takes the batch of samples and updates the model parameters with respect to the loss value on this batch. However, the assumption is not applicable for real-time application such as sequentially data stream training settings just like continual learning and accidentally leads to catastrophic forgetting.</p> <p style="text-align: justify;">Shortly, catastrophic forgetting is the radical performance drops of the model $f(X;\theta)$ which parameterized by $\theta$ with input $X$ — mostly neural networks exhibit distributed representation <d-cite key="McCloskey1989"></d-cite> — that map $X \rightarrow Y$ performing on previously learned tasks $t_{t}$ after learning on task $t_{n}$ where <em>t</em> &lt; <em>n</em>.</p> <div class="fake-img l-body"> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/catastrophic_forgetting/forgetting_cl_task-480.webp 480w,/assets/img/catastrophic_forgetting/forgetting_cl_task-800.webp 800w,/assets/img/catastrophic_forgetting/forgetting_cl_task-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/catastrophic_forgetting/forgetting_cl_task.jpg" class="img-fluid rounded z-depth-1 center" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Continual learning task setting is designed for the model to learning multiple tasks incrementally which each individual task encompass a set of some classes. </div> <p style="text-align: justify;">Consider as an illustration on figure 1 above, our neural networks train to discriminate between two classes of cat and dog. Therefore, the network is trained on bunches of datasets containing any variants of cat and dog for some epochs. Thereafter we want our model to recognize 2 additional classes of tiger and elephant in task 2. Hence, we should train the model with task 2 dataset holding batches of samples of tiger and elephant. In the continual learning setting, we are not allowed to train the model on both task datasets and getting access to the existing dataset only — cluster of tigers and elephants images in this case. As a result, the model will update the parameters to optimizely perform good at present task or task 2 and forget how to predict the task 1 classes given task 1 dataset; therefore, reducing the performance on task 1 or called catastrophic forgetting.</p> <h1 id="how-do-neural-networks-forget">How Do Neural Networks Forget?</h1> <p style="text-align: justify;">Mostly the standard approach for training the neural networks model is using standard backpropagation with gradient-based optimization in particular stochastic gradient descent (SGD) <d-cite key="Robbins1951"></d-cite> or more sophisticated one like Adam <d-cite key="Kingma2015"></d-cite>. Updating parameters via SGD as below</p> \[\theta \leftarrow \theta - \eta\frac{\partial\mathcal{L}}{\partial\theta},\] <p style="text-align: justify;">require $\eta$ for tuning the updating magnitude or called learning rate on the parameters gradient $\frac{\partial\mathcal{L}}{\partial\theta}$. However, these networks trained by gradient-based optimization algorithms are prone to encounter catastrophic forgetting. The common reason is coming from the primary factor of parameters drift while the neural networks train by taking steps to updating parameters aiming to minimize the loss on task $t$. Thanks to Masana et al <d-cite key="Masana2020"></d-cite> briefly summarize the factors of forgetting, those are including parameters shifting, logits shifting, and Inter-domain/inter-task confusion.</p> <h2 id="parameters-shifting">Parameters shifting</h2> <p style="text-align: justify;">While the networks are being trained on the current task, the parameters will be tuned with respect to loss value in the current training dataset task. It means that the networks are optimized to perform maximum on the current task by changing the parameters. As a result, the optimization and parameters update will not consider previous task distribution which lead to forgetting how to do preceding tasks.</p> <h2 id="logits-shifting">Logits shifting</h2> <p style="text-align: justify;">The direct ramification of parameters shifting outputs distribution deviation of the logits given the certain input e.g., image of the previous task. In the effort to alleviate this detriment, distilling the knowledge <d-cite key="Hinton2015"></d-cite> of the previous model parameters respecting the old inputs squeezes the logits outputs of the current model to be equal to the previous model logits while allowing the parameters inconsistent to the old model.</p> <h2 id="inter-domain-and-inter-task-confusion">Inter-domain and inter-task confusion</h2> <div class="fake-img l-body"> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/catastrophic_forgetting/forgetting_inter_task.svg" sizes="95vw"/> <img src="/assets/img/catastrophic_forgetting/forgetting_inter_task.svg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The networks are susceptible to misclassify task 3 (right) classes due to the model having not trained to create discriminative decision boundary for 4 classes in task 3 because of sequential learning on task 1 and task 2 separately. Source: <a href="https://arxiv.org/abs/2010.15277">Masana, M. et al.</a> </div> <p style="text-align: justify;">The decision boundary adjustment leading to inter-task or inter-domain misclassification due to sequential learning setting on continual learning.</p> <div class="fake-img l-body"> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/catastrophic_forgetting/forgetting_forgetting.svg" sizes="95vw"/> <img src="/assets/img/catastrophic_forgetting/forgetting_forgetting.svg" class="img-fluid rounded z-depth-1 center" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Catastrophic forgetting in binary classification while the networks are trained on task 2 suffering from distributional shift which leads to forgetting to do discrimination on task 1. Source: <a href="https://www.semanticscholar.org/paper/Attention-Based-Selective-Plasticity-Kolouri-Ketz/fd45befff6852def1ba78ef0d2cd18f5e0f62f68">Kolouri, S. et al</a> </div> <p style="text-align: justify;">Take an example of a binary classification task — predicting whether given input <em>X</em> resulting discrete label 0 or 1 — as illustrated in the figure 3 <d-cite key="French1999"></d-cite> above, at the beginning the networks learn to predict the dataset distribution on task 1 in such a way that resulting the model $f(X;\theta_{0})$ with obtained parameters $\theta_{0}$.  Then whenever the model acquires the new knowledge from dataset distribution on task 2 without certain continual learning technique, it will suffer from catastrophic forgetting on distribution dataset on task 1 due to parameters drift as consequence of distribution drift which lead to accidentally changing the decision boundary. In contrast, the ideal case should be like the right image in figure 3 which the model performs well by generating a decision boundary that captures discriminative features on both distributions. This setting can be conveniently achieved on <a href="https://ruder.io/multi-task/">multi-task learning</a> settings while running the training on both dataset distributions but highly difficult for continual learning.</p> <h1 id="measuring-catastrophic-forgetting">Measuring Catastrophic Forgetting</h1> <p style="text-align: justify;">How to measure catastrophic forgetting could perhaps be separated into two perspectives thus quantifying to what extent the networks model is able to acquire new knowledge without forgetting and the other examine how fast the networks models adapt to past knowledge while relearning the past task after training on present task, both measurements called <strong>retention</strong> and <strong>relearning</strong> respectively <d-cite key="Ashley2021"></d-cite>.</p> <h2 id="retention">Retention</h2> <p style="text-align: justify;">Retention is most commonly used as a measuring technique for continual learning including incremental class learning or task incremental learning in the machine learning community nowadays. Simply training the networks until mastering on task 1, then moving forward to task 2 and let the networks mastering on task 2 and followed by measuring the accuracy metrics on task 1 and 2 independently is categorized as one of the retention measurements <d-cite key="Ashley2021"></d-cite>. Additionally, <d-cite key="Rebuffi2017"></d-cite> proposed widely adopted measuring technique called <strong><em>average incremental accuracy</em></strong> as formalized by following equation</p> \[accuracy = \frac{1}{T}\sum_{t = 1}^{T}A_{t},\] <p style="text-align: justify;">where <em>T</em> is the number of tasks has been encountered so far and $A_{t}$ means accuracy on tast $t$.</p> <p style="text-align: justify;">However, more complicated one has been proposed by <d-cite key="Kemker2018"></d-cite> which introducing</p> \[\Omega_{\text{base}} = \frac{1}{T - 1}\sum_{i = 2}^{T}\frac{\alpha_{base,i}}{\alpha_{\text{ideal}}},\] \[\Omega_{\text{new}} = \frac{1}{T - 1}\sum_{i = 2}^{T}\alpha_{new,i},\] \[\Omega_{\text{all}} = \frac{1}{T - 1}\sum_{i = 2}^{T}\frac{\alpha_{all,i}}{\alpha_{\text{ideal}}},\] <p style="text-align: justify;">$T$ is the total tasks/sessions have been trained so far, $\alpha_{new,i}$ denotes accuracy on test set for session <em>i</em> direcly after learning,$\ \alpha_{base,i}$ is the measurement of accuracy on base class/first session after learning on sesion <em>i</em>, while $\alpha_{all,i}$ is accuracy metric on all session given model trained on session <em>i</em>, and $\alpha_{\text{ideal}}$ indicates the offline model accuracy on the base set, which assumes the ideal performance or sometimes many experiments in continual learning anchor multi-task learning setting as the upper-bound. While, the function of alpha ideal as divisor here for normalization for ease to compare between datasets.</p> <p style="text-align: justify;">$\Omega_{\text{base}}$ indicates the model’s retention relative to the first session given trained model in later sessions. $\Omega_{\text{new}}$ measures the accuracy on training session <em>i</em> while the model is trained on session <em>i</em> as well, it is used for a model’s ability to immediately recall new tasks. While, $\Omega_{\text{all}}$ denotes the measurement for how well the model retain all session after trained on session <em>i</em>.</p> <h2 id="relearning">Relearning</h2> <p style="text-align: justify;">Frequently overlooked by existing recent experiments, relearning is another essential measure in catastrophic forgetting which was initially proposed in physiological study by Hermann Ebbinghaus known as ‘savings’ but implemented as metrics in catastrophic forgetting by Hetherington <d-cite key="Hetherington1989"></d-cite>. ‘Saving’ metrics measure the saved knowledge and how fast the networks relearn the past knowledge. This metric is built on top of the assumption that possibly networks are not totally unlearned the past knowledge but that their connections may save encoded important information of the past.</p> <p style="text-align: justify;">Practically it is measured via training the network on task 1 and task 2 sequentially, then retrain the networks on task 1 dataset and compare the time required for the network to learn task 1 on the first time against second time. Reducing time required to relearn the task 1 indicates that the networks still saved the past information.</p> <h2 id="activation-overlap">Activation Overlap</h2> <p style="text-align: justify;">Activation overlap initially proposed by French <d-cite key="French1993"></d-cite> who argue that due to distributed representation causing connectionist networks, forgetting can be measured by quantifying the overlapping in activation output. Recently, this formalized and modified by <d-cite key="Ashley2021"></d-cite> by suggesting dot product of two different samples from whether intra-class or inter-class given same hidden parameters as following,</p> \[s\left( a,b \right) = \frac{1}{n}\sum_{i = 0}^{n}{g_{\text{hi}}\left( a \right)\text{.}g_{\text{hi}}\left( b \right)}\] <p style="text-align: justify;">where $g_{\text{hi}}$ indicates hidden layer <em>i</em> parameters of the networks and $g_{\text{hi}}\left( x \right)$ indicating activation output of input $x$ given parameters $g_{\text{hi}}$.</p> <h2 id="pairwise-interference">Pairwise Interference</h2> <p>Initially proposed by <d-cite key="Liu2019a"></d-cite> and then implemented by</p> <d-cite key="Ghiassian2020"></d-cite> <p style="text-align: justify;">given sample <em>a</em> and sample <em>b</em> pairwise interference measure how large the interference of sample <em>b</em>  for trained model on sample <em>a</em> which can be defined as follow</p> \[\text{PI}\left( \theta_{t};a,b \right) = J\left( \theta_{t + 1};a \right) - \ J\left( \theta_{t};a \right).\] <p style="text-align: justify;">Where, $\theta_{t + 1}$ is a model obtained after training on sample <em>b</em>, and $J(.)$ indicates objective function.</p> <h1 id="overcoming-forgetting-in-neural-networks">Overcoming Forgetting in Neural Networks</h1> <p style="text-align: justify;">Contemporarily mitigating catastrophic forgetting highly involved in subfield of machine learning so-called continual learning. Recent advancement approaches in dealing with the issue encompassing exemplar/prototypical/experience rehearsal/replay buffer, parameters regularization, and architectural modification or otherwise named modular approach. In spite of those, in the recent past one year some scientists extend the study of moderating catastrophic forgetting a.k.a. continual learning to the search of connectivity with multi-task learning <d-cite key="Mirzadeh2020a"></d-cite>, loss landscape approximation <d-cite key="Mirzadeh2020a"></d-cite>, <d-cite key="Yin2020a"></d-cite>, relatedness with transfer learning <d-cite key="Ke2020"></d-cite>, more challenging task settings <d-cite key="SonglinDong2020"></d-cite>, <d-cite key="Zhao2020"></d-cite>, <d-cite key="Bertugli2020"></d-cite>, <d-cite key="Caccia2020"></d-cite>, <d-cite key="Ren2019"></d-cite>, <d-cite key="Dhamija2021"></d-cite>, <d-cite key="Rao2019"></d-cite> and even expanding beyond image classification task <d-cite key="Joseph2020a"></d-cite>, <d-cite key="Perez-Rua2020"></d-cite>, <d-cite key="Zheng2021"></d-cite>, <d-cite key="Chen2020d"></d-cite>.</p> <h2 id="rehearsal">Rehearsal</h2> <p style="text-align: justify;">Rehearsal/replay approach is dealing with catastrophic forgetting modestly by replaying the bunch of knowledge memory of past knowledge so-called “episodic memory”, e.g., samples of images, into the existing training steps while learning the novel knowledge e.g., new classes. Therefore, the catastrophic interference can be diminished as consequence of the updating parameters in respect of considering batch of combining existing datasets with small buffers of replayed episodic memory. Among others this technique was mostly explored and proposed in past five years in continual learning seeing its simplicity and effectiveness as baseline for continual learning experiments.</p> <div class="fake-img l-body"> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/catastrophic_forgetting/forgetting_hippo.svg" sizes="95vw"/> <img src="/assets/img/catastrophic_forgetting/forgetting_hippo.svg" class="img-fluid rounded z-depth-1 center" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Knowledge replays in the brain while sleeping involving the Neocortex and Hippocampus. Source: <a href="https://www.semanticscholar.org/paper/Continual-Lifelong-Learning-with-Neural-Networks%3A-A-Parisi-Kemker/9ea50b3408f993853f1c5e374690e5fbe73c2a3c">Parisi, G. I. et al.</a> </div> <p style="text-align: justify;">The similar mechanism also occurs in our brain when sleeping since our brain will reactivate and rehearse the past freshly acquired knowledges memorized periodically in hippocampus into peripheral permanent memory in the neocortex. As suggested in theory of Complementary Learning System (CLS) <d-cite key="McClelland1995"></d-cite> shown in Figure above, the Hippocampus encodes recent events or experiences via fast learning and these will be unconsciously reactivated while sleeping for gradual consolidation mechanism into neocortical memory systems.</p> <p style="text-align: justify;">However, the most challenging in rehearsal approach is both how to sampling the most significant examples and what kind of representations from the dataset that necessarily be rehearsed into future learning phase while minimizing catastrophic interference. Many of the latest research concerned with this issue along with proposing novel sampling techniques or including random sampling, uniform sampling, reservoir sampling <d-cite key="Vitter1985"></d-cite>, <d-cite key="Kim2020a"></d-cite>, distance-based sampling <d-cite key="Pomponi2020a"></d-cite>, maximally interfered sampling <d-cite key="Aljundi2019a"></d-cite>, among others. On the other hand, replaying expressive representations involve naïve image replay, embedding replay, anchor replay, and topological/relational replay.</p> <h2 id="regularization">Regularization</h2> <p style="text-align: justify;">Measuring the any past information, including parameters, importance relevant to both past task loss value and accuracy metrics and restricting the extreme updates to this information while learning is the other strategy named regularization approach. This is conceivably conjectured as the mechanism to control plasticity-stability dilemma of the neural networks on the subject of continual updates. As consequent, the restraint adopted to the information of interest, such as parameters, guarantee the minimization of interfered information essential for the prior task.</p> <p style="text-align: justify;">Up till now, according to <d-cite key="Delange2021"></d-cite>, some of experiments can be clustered into prior-focus/parameters-based and data-focused/logits-based regularization. Parameters-based control the model parameters distribution and plasticity-stability. While, data-focused distil the logits (model outputs before activation function) of given inputs inferenced on the present model as manoeuvre to recall past knowledge.</p> <div class="fake-img l-body"> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/catastrophic_forgetting/ewc.svg" sizes="95vw"/> <img src="/assets/img/catastrophic_forgetting/ewc.svg" class="img-fluid rounded z-depth-1 center" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Training with EWC as shown on red trajectories will finding out low loss elevation in space on both task A (old) and task B (new) such that the obtained parameters are capable to perform accurately both on task A and B. Source: <a href="https://www.pnas.org/content/114/13/3521">Kirkpatrick et al.</a> </div> <p style="text-align: justify;">The earliest method proposed this idea was Elastic Weight Consolidation (EWC) <d-cite key="Kirkpatrick2017a"></d-cite>. The basic idea is to measure weight importance for the previous task while controlling these previous weights $\theta_{A}^{*}$ and avoid significant updates to these weights via fisher information matrix $F$ as measure of the importance. While EWC minimize the loss of</p> \[\mathcal{L}\left ( \theta \right ) = \mathcal{L}_{B}\left ( \theta \right ) + \sum_{i}^{} \frac{\lambda}{2}F_{i}\left ( \theta_{i} - \theta_{A,i}^{*} \right )^{2},\] <p style="text-align: justify;">where $\mathcal{L}_{B}$ is the task B loss, $\lambda$ denotes the relation of old task to new, $i$ is each parameter index, and $\theta$ is the current parameters. As exhibited on the loss equation above, the new parameters will be enforced to close to old parameters to alleviate forgetting which the precision will be controlled by fisher information matrix $F$.</p> <h2 id="architectural">Architectural</h2> <p style="text-align: justify;">While architectural-based approach mainly concerned with constructing progressive neural networks while learning novel tasks or knowledges either by growing task-specific architecture <d-cite key="Rusu2016a"></d-cite>, producing single-independent head on classifier per class/task <d-cite key="Li2019LearnTG"></d-cite>, or rewiring the connections in neural networks layers while incrementally learning novel tasks <d-cite key="Wortsman2020a"></d-cite>.</p> <div class="fake-img l-body"> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/catastrophic_forgetting/progessive_networks.svg" sizes="95vw"/> <img src="/assets/img/catastrophic_forgetting/progessive_networks.svg" class="img-fluid rounded z-depth-1 center" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Progressive networks exhibit three columns networks which each column is associated to task-specific networks e.g., networks on column 1 and 2 for performing task 1 and 2, respectively. Whilst column 3 networks solve task 3 that this networks is enabled getting access to previous leaned features. Source: <a href="https://www.semanticscholar.org/paper/Progressive-Neural-Networks-Rusu-Rabinowitz/53c9443e4e667170acc60ca1b31a0ec7151fe753">Rusu, A. A. et al.</a> </div> <p style="text-align: justify;">Among others is Progressive Neural Networks proposed in 2016 as depicted in the figure 6 above. The progressive networks framework proposed addressing catastrophic forgetting through evolving task-specific networks instanting on a column for working on a task being solved. Then, as the task encountered is incremental growth, the novel column networks will be introduced which the previously learned features feasibly transferred to the new networks via lateral connections. Therefore, the last task with its associated networks are allowed to exploit all the features learned so far.</p> <blockquote style="text-align: justify;"> <p>[Notes]<br/> <span style="color:#8B0000">If you have any disapproval, correction, and critique to this article feel free to <a href="mailto:mrifkikurniawan17@gmail.com">email me</a>, I will happily adjusting and modifying this published contents respecting the corrections.</span></p> </blockquote>]]></content><author><name>Muhammad Rifki Kurniawan</name></author><category term="article"/><category term="continual_learning"/><category term="deep_learning"/><category term="catastrophic_forgetting"/><summary type="html"><![CDATA[Brief overview why forgetting happens and strategies to combat it]]></summary></entry></feed>