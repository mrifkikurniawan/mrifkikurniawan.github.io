<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta property="og:title" content="Evolving Parameterized Prompt Memory for Continual Learning. AAAI2024"> <meta property="og:image" content="https://mrifkikurniawan.github.io/assets/img/evoprompt/evoprompt_arch.svg"> <meta property="og:description" content="Non-expandable Prompt-based Continual Learning Via Continuous Prompting and Incremental Evolution. AAAI2024"> <meta property="og:url" content="https://mrifkikurniawan.github.io/EvoPrompt/"> <meta property="og:image:width" content="1200"> <meta property="og:image:height" content="663"> <meta property="og:type" content="website"> <script async="" src="https://www.googletagmanager.com/gtag/js?id=G-9VZKE74FPW"></script> <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-9VZKE74FPW');
</script> <meta charset="utf-8"> <meta name="description" content="Evolving Parameterized Prompt Memory for Continual Learning"> <meta name="keywords" content="Continual Learning, Incremental Learning, Prompt, Transformer, Pre-trained, Transfer Learning"> <meta name="viewport" content="width=device-width, initial-scale=1"> <title>Evolving Parameterized Prompt Memory for Continual Learning</title> <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet"> <link rel="stylesheet" href="/assets/static/css/bulma.min.css"> <link rel="stylesheet" href="/assets/static/css/bulma-carousel.min.css"> <link rel="stylesheet" href="/assets/static/css/bulma-slider.min.css"> <link rel="stylesheet" href="/assets/static/css/tab_gallery.css"> <link rel="stylesheet" href="/assets/static/css/fontawesome.all.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"> <link rel="stylesheet" href="/assets/static/css/index.css"> <link rel="icon" href="/assets/static/images/favicon.svg"> <link rel="stylesheet" href="/assets/juxtapose/css/juxtapose.css"> <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script> <script defer src="/assets/static/js/fontawesome.all.min.js"></script> <script src="/assets/static/js/bulma-carousel.min.js"></script> <script src="/assets/static/js/bulma-slider.min.js"></script> <script src="/assets/static/js/index.js"></script> <script src="/assets/static/js/magnifier.js"></script> <link href="https://fonts.cdnfonts.com/css/menlo" rel="stylesheet"> <link rel="stylesheet" href="/assets/static/css/image_card_fader.css"> <link rel="stylesheet" href="/assets/static/css/image_card_slider.css"> <style>@import url('https://fonts.cdnfonts.com/css/menlo');</style> </head> <body> <section class="hero"> <div class="hero-body"> <div class="container is-max-desktop"> <div class="columns is-centered"> <div class="column has-text-centered"> <h1 class="title is-2 publication-title">Evolving Parameterized Prompt Memory for Continual Learning</h1> <div class="is-size-5 publication-authors"> <span class="author-block"> <a href="https://mrifkikurniawan.github.io/">Muhammad Rifki Kurniawan</a><sup>1</sup>,</span> <span class="author-block"> <a href="https://scholar.google.com/citations?user=DnNdGckAAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Xiang Song</a><sup>1</sup>,</span> <span class="author-block"> <a href="https://scholar.google.com/citations?user=y6ijVukAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Zhiheng Ma</a><sup>2</sup>, </span> <span class="author-block"> <a href="https://gehenhe.github.io/" rel="external nofollow noopener" target="_blank">Yuhang He</a><sup>1</sup>, </span> <span class="author-block"> <a href="https://gr.xjtu.edu.cn/web/ygong" rel="external nofollow noopener" target="_blank">Yihong Gong</a><sup>1</sup>, </span> <span class="author-block"> <a href="https://gr.xjtu.edu.cn/web/yangqi" rel="external nofollow noopener" target="_blank">Yang Qi</a><sup>1</sup>, </span> <span class="author-block"> <a href="https://gr.xjtu.edu.cn/web/weixing" rel="external nofollow noopener" target="_blank">Xing Wei</a><sup>1</sup> </span> </div> <div class="is-size-5 publication-authors"> <span class="author-block"><sup>1</sup>Xi'an Jiaotong University,</span> <span class="author-block"><sup>2</sup>Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences</span> </div> <div class="is-size-5 publication-venue"> in AAAI 2024 (Oral, Top 2.3%) </div> <div class="column has-text-centered"> <div class="publication-links"> <span class="link-block"> <a href="https://ojs.aaai.org/index.php/AAAI/article/view/29231" class="external-link button is-normal is-rounded is-dark" rel="external nofollow noopener" target="_blank"> <span class="icon"> <i class="fas fa-file-pdf"></i> </span> <span>Paper</span> </a> </span> <span class="link-block"> <a href="https://github.com/MIV-XJTU/EvoPrompt" class="external-link button is-normal is-rounded is-dark" rel="external nofollow noopener" target="_blank"> <span class="icon"> <i class="fab fa-github"></i> </span> <span>Code</span> </a> </span> <span class="link-block"> <a href="https://github.com/MIV-XJTU/EvoPrompt/assets/slides.pdf" class="external-link button is-normal is-rounded is-dark" rel="external nofollow noopener" target="_blank"> <svg style="width:16px;height:16px;margin-left:-0px;margin-right:6px" width="16px" height="16px" viewbox="0 0 44 44"><path fill="currentColor" d="M10,26h8a2,2,0,0,0,2-2V14a2,2,0,0,0-2-2H10a2,2,0,0,0-2,2V24A2,2,0,0,0,10,26Zm0-12h8V24H10Zm15,4H35a1,1,0,0,0,0-2H25a1,1,0,0,0,0,2Zm0-4h6a1,1,0,0,0,0-2H25a1,1,0,0,0,0,2Zm0,8h4a1,1,0,0,0,0-2H25a1,1,0,0,0,0,2ZM42,2H24a2,2,0,0,0-4,0H2A2,2,0,0,0,0,4V6A2,2,0,0,0,2,8V32a2,2,0,0,0,2,2H21v2.59l-5.71,5.71a1,1,0,1,0,1.41,1.41L22,38.41l5.29,5.29a1,1,0,1,0,1.41-1.41L23,36.59V34H40a2,2,0,0,0,2-2V8a2,2,0,0,0,2-2V4A2,2,0,0,0,42,2ZM40,32H4V8H40ZM42,6H2V4H42ZM25,26H35a1,1,0,0,0,0-2H25a1,1,0,0,0,0,2Z"></path> </svg> <span>Slides</span> </a> </span> <span class="link-block"> <a href="https://github.com/MIV-XJTU/EvoPrompt/assets/poster.pdf" class="external-link button is-normal is-rounded is-dark" rel="external nofollow noopener" target="_blank"> <span class="icon"> <i class="far fa-image"></i> </span> <span>Poster</span> </a> </span> <span class="link-block"> <a href="#bibtex" class="external-link button is-normal is-rounded is-dark"> <span class="icon"> <i class="ai ai-obp"></i> </span> <span>BibTex</span> </a> </span> </div> </div> </div> </div> </div> </div> </section> <section class="hero is-light is-small"> <div class="hero-body"> <div class="container is-max-desktop has-text-centered"> <h2 class="title is-3">Evolving Parameterized Prompt Memory for Continual Learning</h2> <div class="content has-text-justified"> <p> <b>Delving into prompt-based continual learning, we are interested in scenarios with non-expandable prompt pools and end-to-end training devoid of discrete selection</b>. Our solution, <b>EvoPrompt</b> (<b>Evo</b>lving Parameterized <b>Prompt</b>), leverages a multi-layer perceptron (MLP) bottleneck for formulating prompting function. These prompts are stored in the weight space of the network, <b>gradually evolving</b> as new tasks are learned, all without expansion. Additionally, we present a novel method for synthesizing future classifiers from previously acquired knowledge. Remarkably, our approach employs minimal parameters, being <b>5X</b> and <b>13X</b> smaller than CODA-P, while exhibiting superior performance. <br> </p> </div> </div> </div> </section> <section class="section"> <div class="container is-max-desktop"> <div class="columns is-centered has-text-centered"> <div class="column is-four-fifths"> <h2 class="title is-3">Abstract</h2> <div class="content has-text-justified"> <p> Recent studies have demonstrated the potency of leveraging prompts in Transformers for continual learning (CL). Nevertheless, employing a discrete key-prompt bottleneck can lead to selection mismatches and inappropriate prompt associations during testing. Furthermore, this approach hampers adaptive prompting due to the lack of shareability among nearly identical instances at a more granular level. To address these challenges, we introduce the Evolving Parameterized Prompt Memory (EvoPrompt), a novel method involving adaptive and continuous prompting attached to pre-trained Vision Transformer (ViT), conditioned on specific instance. We formulate a continuous prompt function as a neural bottleneck and encode the collection of prompts on network weights. We establish a paired prompt memory system consisting of a stable reference and a flexible working prompt memory. Inspired by linear mode connectivity, we progressively fuse the working prompt memory and reference prompt memory during inter-task periods, resulting in continually evolved prompt memory. This fusion involves aligning functionally equivalent prompts using optimal transport and aggregating them in parameter space with an adjustable bias based on prompt node attribution. Additionally, to enhance backward compatibility, we propose compositional classifier initialization, which leverages prior prototypes from pre-trained models to guide the initialization of new classifiers in a subspace-aware manner. Comprehensive experiments validate that our approach achieves state-of-the-art performance in both class and domain incremental learning scenarios. </p> </div> </div> </div> </div> </section> <section class="section"> <div class="container is-max-desktop"> <div class="columns is-centered"> <div class="column is-full-width"> <h2 class="title is-3 has-text-centered">Evolving Parameterized Prompt Memory</h2> <h3 class="title is-4">Proposed Components</h3> <div class="content has-text-justified"> <p> </p> <ol> <li> <b>Reformulating Incremental Prompt Tuning: </b> We use a Feedforward Neural Networks (FFNs) to shift from discrete to continuous prompting, employing a Multilayer Perceptron (MLP) bottleneck for prompt encoding in the neural weight space, called <b>prompt memory</b>.</li> <li> <b>Prompt Memory Evolution via Incremental Fusion: </b> We adopt a dual memory approach, combining plastic <b>working prompt memory</b> (WPM) and stable <b>reference prompt memory</b> (RPM). These memories are integrated with alignment and attribution-dependent momentum, instead of appended.</li> <li> <b>Compositional Classifier Initialization: </b>Leveraging insights from the <i>anchoring-and-adjustment heuristic</i> in psychology, we predict future classifiers by referencing current classifiers and the prototype relationships between classes.</li> </ol> </div> <h3 class="title is-4">Prompt Memory Architecture and Its Evolution</h3> <div class="content has-text-centered"> <img src="/assets/img/evoprompt/evoprompt_arch.svg"> </div> <div class="content has-text-justified"> <p> The parameterization of memory prompts through <b>Feedforward Neural Networks (FFN)</b> and a training routine that involves step-by-step merging with <b>alignment</b> and <b>attribution-aware</b> momentum. When given input, the linear key memory identifies patterns to calculate a positive memory coefficient. This coefficient is then employed to allocate weights to the value memory, resulting in the ultimate prompt. We introduce a dual-functional prompt memory consisting of <b>Reference Prompt Memory</b> (RPM) and <b>Working Prompt Memory</b> (WPM). The RPM encompasses all prompts encountered so far, while the WPM is task-specific and adjusts swiftly to emerging tasks. </p> <p> To address <i>catastrophic forgetting</i>, we adopt ideas from <i>linear mode connectivity</i>, featuring a singular basin with a low error landscape amid different task solutions. Concretely, we introduce <b>incremental fusion</b> during inter-task periods to align the functionality of WPM with RPM, and subsequently fuse them in parameter space. We formulate the alignment as an <b>Optimal Transport</b> (OT) problem and the fusion as a linearly weighted aggregation adjusted by <b>neuron attribution</b>. </p> </div> <h3 class="title is-4">Compositional Classifier Initialization</h3> <div class="content has-text-centered"> <img src="/assets/img/evoprompt/compositional_initialization.svg" width="50%"> </div> <div class="content has-text-justified"> <p> The introduction of Compositional Classifier Initialization (CCI) is based on the <b>bias adjustment heuristic</b>. It entails estimating the unknown, such as a <b>future classifiers</b>, by leveraging <b>relevant existing information</b>. We compute class mean embeddings, or prototypes, from pre-trained models. Through attention mechanisms, we establish inter-class relationships among these prototypes, forming a <b>foundational relation</b> between past and target tasks. The resulting probability simplex from multihead attention is then used to linearly combine previous classifiers, facilitating the initialization of future classifiers and <b>introducing implicit bias</b>. </p> </div> </div> </div> <div class="container is-max-desktop"> <div class="columns is-centered"> <div class="column is-full-width"> <h2 class="title is-3 has-text-centered">Empirical Benchmark Results</h2> <h3 class="title is-4">Class Incremental Learning</h3> <div class="content has-text-justified"> <p> Methods evaluated on <b>Split CIFAR-100</b>. </p> </div> <center> <style>table{border-collapse:collapse}tr{border-top:1px solid black;border-bottom:1px solid black}td{border:0}</style> <table border="0" style="width: 100%"> <tr> <th>Method</th> <th colspan="2">5 Steps</th> <th colspan="2">10 Steps</th> <th colspan="2">20 Steps</th> <th colspan="2">Avg</th> </tr> <tr> <td></td> <td>Acc(↑)</td> <td>Forget(↓)</td> <td>Acc(↑)</td> <td>Forget(↓)</td> <td>Acc(↑)</td> <td>Forget(↓)</td> <td>Acc(↑)</td> <td>Forget(↓)</td> </tr> <tr> <td>FT-seq</td> <td>73.17</td> <td>2.95</td> <td>62.77</td> <td>20.73</td> <td>55.97</td> <td>32.74</td> <td>63.97 <span style="color: red;">(+0.00)</span> </td> <td>18.81 <span style="color: red;">(-0.00)</span> </td> </tr> <tr> <td>L2P</td> <td>86.53</td> <td>7.67</td> <td>84.97</td> <td>8.21</td> <td>83.39</td> <td>10.18</td> <td>84.96 <span style="color:teal;">(+20.99)</span> </td> <td>8.69 <span style="color:teal;">(-10.12)</span> </td> </tr> <tr> <td>DualPrompt</td> <td>88.26</td> <td><u>5.72</u></td> <td>86.83</td> <td>6.21</td> <td>84.11</td> <td>8.75</td> <td>86.40 <span style="color:teal;">(+22.43)</span> </td> <td>6.89 <span style="color:teal;">(-11.92)</span> </td> </tr> <tr> <td>ESN</td> <td>88.09</td> <td><b>5.18</b></td> <td>85.96</td> <td>4.54</td> <td>82.71</td> <td>6.44</td> <td>85.59 <span style="color:teal;">(+21.62)</span> </td> <td>5.39 <span style="color:teal;">(-13.42)</span> </td> </tr> <tr> <td>CODA-P-S</td> <td>88.90</td> <td>6.29</td> <td>86.33</td> <td>6.29</td> <td>81.71</td> <td>9.41</td> <td>85.65 <span style="color:teal;">(+21.68)</span> </td> <td>7.33 <span style="color:teal;">(-11.48)</span> </td> </tr> <tr> <td>CODA-P</td> <td><b>89.16</b></td> <td>6.08</td> <td>87.31</td> <td>5.95</td> <td>81.69</td> <td>9.85</td> <td>86.05 <span style="color:teal;">(+22.08)</span> </td> <td>7.29 <span style="color:teal;">(-11.52)</span> </td> </tr> <tr> <td><b>EvoPrompt-S</b></td> <td>88.69</td> <td>9.93</td> <td><u>87.95</u></td> <td><u>2.38</u></td> <td><b>84.98</b></td> <td><b>3.42</b></td> <td><b>87.20 <span style="color:teal;">(+23.23)</span></b></td> <td><b>5.24 <span style="color:teal;">(-13.57)</span></b></td> </tr> <tr> <td><b>EvoPrompt</b></td> <td><u>88.97</u></td> <td>10.12</td> <td><b>87.97</b></td> <td><b>2.60</b></td> <td><u>84.64</u></td> <td><u>3.98</u></td> <td><u>87.19 <span style="color:teal;">(+23.22)</span></u></td> <td><u>5.57 <span style="color:teal;">(-13.24)</span></u></td> </tr> </table> </center> <br> <div class="content has-text-justified"> <p> Methods evaluated on <b>Split ImageNet-R</b>. </p> </div> <center> <table border="0" style="width: 100%"> <tr> <th>Method</th> <th colspan="2">5 Steps</th> <th colspan="2">10 Steps</th> <th colspan="2">20 Steps</th> <th colspan="2">Avg</th> </tr> <tr> <td></td> <td>Acc(↑)</td> <td>Forget(↓)</td> <td>Acc(↑)</td> <td>Forget(↓)</td> <td>Acc(↑)</td> <td>Forget(↓)</td> <td>Acc(↑)</td> <td>Forget(↓)</td> </tr> <tr> <td>FT-seq</td> <td>61.41</td> <td>5.76</td> <td>50.28</td> <td>24.28</td> <td>39.25</td> <td>40.38</td> <td>50.31 <span style="color:red;">(+0.00)</span> </td> <td>23.48 <span style="color:red;">(-0.00)</span> </td> </tr> <tr> <td>L2P</td> <td>66.63</td> <td>6.65</td> <td>64.05</td> <td>10.05</td> <td>60.34</td> <td>14.44</td> <td>63.67 <span style="color:teal;">(+13.36)</span> </td> <td>10.38 <span style="color:teal;">(-13.10)</span> </td> </tr> <tr> <td>DualPrompt</td> <td>71.06</td> <td><u>4.19</u></td> <td>69.71</td> <td>5.44</td> <td>66.26</td> <td>8.74</td> <td>69.01 <span style="color:teal;">(+18.70)</span> </td> <td>6.12 <span style="color:teal;">(-17.36)</span> </td> </tr> <tr> <td>ESN</td> <td>73.42</td> <td><b>3.79</b></td> <td>71.07</td> <td>4.99</td> <td>64.77</td> <td>6.65</td> <td>69.75 <span style="color:teal;">(+19.44)</span> </td> <td>5.14 <span style="color:teal;">(-18.34)</span> </td> </tr> <tr> <td>CODA-P-S</td> <td>73.80</td> <td>5.56</td> <td>71.95</td> <td>5.92</td> <td>69.67</td> <td>6.23</td> <td>71.81 <span style="color:teal;">(+21.50)</span> </td> <td>5.90 <span style="color:teal;">(-17.58)</span> </td> </tr> <tr> <td>CODA-P</td> <td>73.77</td> <td>6.60</td> <td>72.42</td> <td>6.26</td> <td>70.18</td> <td>5.53</td> <td>72.12 <span style="color:teal;">(+21.81)</span> </td> <td>6.13 <span style="color:teal;">(-17.35)</span> </td> </tr> <tr> <td><b>EvoPrompt-S</b></td> <td><u>76.79</u></td> <td>9.84</td> <td><u>76.22</u></td> <td><b>2.33</b></td> <td><b>74.68</b></td> <td><u>2.70</u></td> <td><u>75.90 <span style="color:teal;">(+25.59)</span></u></td> <td><b>4.96 <span style="color:teal;">(-18.52)</span></b></td> </tr> <tr> <td><b>EvoPrompt</b></td> <td><b>77.16</b></td> <td>9.89</td> <td><b>76.83</b></td> <td><u>2.78</u></td> <td><u>74.41</u></td> <td><b>2.56</b></td> <td><b>76.13 <span style="color:teal;">(+25.82)</span></b></td> <td><u>5.08 <span style="color:teal;">(-18.40)</span></u></td> </tr> </table> </center> <br> <h3 class="title is-4">Domain Incremental Learning</h3> <div class="content has-text-justified"> <p> Benchmark results evaluated on <b>CORe50</b> dataset. </p> </div> <center> <table border="0" style="width: 50%"> <tr> <th>Method</th> <th>Test Acc. (%)</th> <th>Δ Acc. (%)</th> </tr> <tr> <td>NME-seq</td> <td>78.20</td> <td style="color:red;">+00.00</td> </tr> <tr> <td>L2P</td> <td>78.33</td> <td style="color:teal;">+0.13</td> </tr> <tr> <td>S-iPrompts</td> <td>83.13</td> <td style="color:teal;">+4.93</td> </tr> <tr> <td>S-liPrompts</td> <td>89.06</td> <td style="color:teal;">+10.86</td> </tr> <tr> <td>ESN</td> <td>91.80</td> <td style="color:teal;">+13.60</td> </tr> <tr> <td><b>EvoPrompt-S</b></td> <td><u>94.77</u></td> <td style="color:teal;">+16.57</td> </tr> <tr> <td><b>EvoPrompt</b></td> <td><b>95.27</b></td> <td style="color:teal;">+17.07</td> </tr> </table> </center> <br> <h3 class="title is-4">Online Learning</h3> <div class="content has-text-justified"> <p> Benchmark results evaluated on online setting on both <b>Split CIFAR-100</b> and <b>Split ImageNet-R</b>. </p> </div> <center> <table border="0" style="width: 60%"> <tr> <th>Method</th> <th colspan="2">Split CIFAR-100</th> <th colspan="2">Split ImageNet-R</th> </tr> <tr> <td></td> <td>Acc.(↑)</td> <td>Forget.(↓)</td> <td>Acc.(↑)</td> <td>Forget.(↓)</td> </tr> <tr> <td>L2P</td> <td>80.49</td> <td>8.74</td> <td>57.52</td> <td>6.54</td> </tr> <tr> <td>DualPrompt</td> <td>82.17</td> <td>7.52</td> <td>61.09</td> <td>4.40</td> </tr> <tr> <td>ESN</td> <td>74.17</td> <td>10.59</td> <td>-</td> <td>-</td> </tr> <tr> <td>CODA-P-S</td> <td>79.46</td> <td>11.92</td> <td>64.60</td> <td>6.09</td> </tr> <tr> <td>CODA-P</td> <td>81.07</td> <td>10.10</td> <td>66.47</td> <td>5.42</td> </tr> <tr> <td><b>EvoPrompt-S</b></td> <td style="text-decoration: underline;">84.23</td> <td style="text-decoration: underline;">1.64</td> <td style="text-decoration: underline;">73.56</td> <td style="text-decoration: underline;">3.82</td> </tr> <tr> <td><b>EvoPrompt</b></td> <td style="font-weight: bold;">84.72</td> <td style="font-weight: bold;">0.89</td> <td style="font-weight: bold;">74.05</td> <td style="font-weight: bold;">3.66</td> </tr> </table> </center> <div class="content has-text-justified"> </div> </div> </div> <div class="columns is-centered"> <div class="column is-full-width"> <h2 class="title is-3 has-text-centered">Further Analysis</h2> <h3 class="title is-4">Stability Gap</h3> <div class="content has-text-centered"> <img src="/assets/img/evoprompt/stability_gap.svg" width="75%"> </div> <div class="content has-text-justified"> <p> There is <b>no observable</b> stability gap in both random and compositional classifier initialization. Despite this, our compositional initialization displays <b>stability</b> in its performance, <b>smooth transitions</b> between tasks, and <b>rapid acquisition</b> of current knowledge. </p> </div> <h3 class="title is-4">Separability and Backward-compatibility</h3> <div class="content has-text-centered"> <img src="/assets/img/evoprompt/separability.svg" width="75%"> </div> <div class="content has-text-justified"> <p> Through our initialization method, we <b>minimize the distances</b> among points within the same class, illustrating <b>increased compactness</b> within classes. Simultaneously, we maintain <b>balanced margins</b> between different classes, resulting in smaller inter-class distances compared to random initialization, thus improving backward compatibility. </p> </div> <div class="content has-text-justified"> </div> </div> </div> <div class="columns is-centered"> <div class="column is-full-width"> <h2 class="title is-3 has-text-centered">Conclusion</h2> <div class="content has-text-justified"> <p>This paper presents EvoPrompt, a prompt-based approach that employs continually evolved parameterized memory prompt with continuous bottleneck using FFN and attribution-aware incremental prompt fusion, which facilitates the sharing and adaptability during prompting. Maximizing learned knowledge is achieved through the introduction of compositional classifier initialization, enhancing both learning stability and backward compatibility. Our framework scales to multiple steps scenarios and datasets with high intra-diversity, such as Split ImageNet-R and CORe50, proving the generalization capability introduced by our proposed method. Comprehensive experiments exhibit superior performance compared to the state-of-the-art. </p> </div> </div> </div> </div> <section class="section" id="BibTeX"> <div class="container is-max-desktop content"> <h2 class="title"><a id="bibtex">BibTeX</a></h2> <pre><code>@article{kurniawan2024evoprompt,
      title = {Evolving Parameterized Prompt Memory for Continual Learning},
      author = {Kurniawan, Muhammad Rifki and Song, Xiang and Ma, Zhiheng and He, Yuhang and Gong, Yihong and Yang, Qi and Wei, Xing},
      year = {2024},
      booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
}</code></pre> </div> </section> <footer class="footer"> <div class="columns is-centered"> <div class="column is-8"> <div class="content"> <p> This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>. </p> <p> Website adapted from the following <a href="https://github.com/nerfies/nerfies.github.io" rel="external nofollow noopener" target="_blank">source code</a>. </p> </div> </div> </div> </footer> <script src="/assets/juxtapose/js/juxtapose.js"></script> <script>
var slider;
let origImages = [
  {"src": "/assets/static/images/iguana_input.jpg", "label": "Input Photos or Artworks (128px)",},
  {"src": "/assets/static/images/iguana_output.jpg", "label": "Upsampled by GigaGAN (4K)",}
];
let origOptions = {
    "makeResponsive": true,
    "showLabels": true,
    "mode": "horizontal",
    "showCredits": true,
    "animate": true,
    "startingPosition": "50"
};

const juxtaposeSelector = "#juxtapose-embed";
const transientSelector = "#juxtapose-hidden";


function tab_gallery_click(name) {
  // Get the expanded image
  let inputImage = {
    label: "Input Photos or Artworks (128px)",
  };
  let outputImage = {
    label: "Upsampled by GigaGAN (4K)",
  };

  inputImage.src = "/assets/static/images/".concat(name, "_input.jpg")
  outputImage.src = "/assets/static/images/".concat(name, "_output.jpg")

  let images = [inputImage, outputImage];
  let options = slider.options;
  options.callback = function(obj) {
      var newNode = document.getElementById(obj.selector.substring(1));
      var oldNode = document.getElementById(juxtaposeSelector.substring(1));
      console.log(obj.selector.substring(1));
      console.log(newNode.children[0]);
      oldNode.replaceChild(newNode.children[0], oldNode.children[0]);
      //newNode.removeChild(newNode.children[0]);
      
  };
  
  slider = new juxtapose.JXSlider(transientSelector, images, options);
};



(function() {
    slider = new juxtapose.JXSlider(
        juxtaposeSelector, origImages, origOptions);
    //document.getElementById("left-button").onclick = replaceLeft;
    //document.getElementById("right-button").onclick = replaceRight;
})();
  // Get the image text
  var imgText = document.getElementById("imgtext");
  // Use the same src in the expanded image as the image being clicked on from the grid
  // expandImg.src = imgs.src;
  // Use the value of the alt attribute of the clickable image as text inside the expanded image
  imgText.innerHTML = name;
  // Show the container element (hidden with CSS)
  // expandImg.parentElement.style.display = "block";

$(".flip-card").click(function() {
            console.log("fading in")
            div_back = $(this).children().children()[1]
            div_front = $(this).children().children()[0]
            // console.log($(this).children("div.flip-card-back"))
            console.log(div_back)
            $(div_front).addClass("out");
            $(div_front).removeClass("in");

            $(div_back).addClass("in");
            $(div_back).removeClass("out");

});

$(".flip-card").mouseleave(function() {
            console.log("fading in")
            div_back = $(this).children().children()[1]
            div_front = $(this).children().children()[0]
            // console.log($(this).children("div.flip-card-back"))
            console.log(div_back)
            $(div_front).addClass("in");
            $(div_front).removeClass("out");

            $(div_back).addClass("out");
            $(div_back).removeClass("in");

});

</script> <script src="https://cdn.jsdelivr.net/npm/popper.js@1.12.9/dist/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/js/bootstrap.min.js"></script> </div></section> </body> </html>