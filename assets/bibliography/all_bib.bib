Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Arani2022,
abstract = {Humans excel at continually learning from an ever-changing environment whereas it remains a challenge for deep neural networks which exhibit catastrophic forgetting. The complementary learning system (CLS) theory suggests that the interplay between rapid instance-based learning and slow structured learning in the brain is crucial for accumulating and retaining knowledge. Here, we propose CLS-ER, a novel dual memory experience replay (ER) method which maintains short-term and long-term semantic memories that interact with the episodic memory. Our method employs an effective replay mechanism whereby new knowledge is acquired while aligning the decision boundaries with the semantic memories. CLS-ER does not utilize the task boundaries or make any assumption about the distribution of the data which makes it versatile and suited for "general continual learning". Our approach achieves state-of-the-art performance on standard benchmarks as well as more realistic general continual learning settings.},
archivePrefix = {arXiv},
arxivId = {2201.12604},
author = {Arani, Elahe and Sarfraz, Fahad and Zonooz, Bahram},
eprint = {2201.12604},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arani, Sarfraz, Zonooz - 2022 - Learning Fast, Learning Slow A General Continual Learning Method based on Complementary Learning System.pdf:pdf},
keywords = {continual learning},
mendeley-tags = {continual learning},
number = {2021},
title = {{Learning Fast, Learning Slow: A General Continual Learning Method based on Complementary Learning System}},
url = {http://arxiv.org/abs/2201.12604},
year = {2022}
}
@article{Zhao2016,
abstract = {Accurate wind speed forecasting, which strongly influences the safe usage of wind resources, is still a critical issue and a huge challenge. At present, the single-valued deterministic NWP forecast is primarily adopted by wind farms; however, recent techniques cannot meet the actual needs of grid dispatch in many cases. This paper contributes to a new multi-step forecasting method for operational wind forecast, 96-steps of the next day, termed the CS-FS-WRF-E model, which is based on a Weather Research and Forecasting (WRF) ensemble forecast, a novel Fuzzy System, and a Cuckoo Search (CS) algorithm. First, the WRF ensemble, which considers three horizontal resolutions and four initial fields, using a 0.5° horizontal grid-spacing Global Forecast System (GFS) model output, is constructed as the basic forecasting results. Then, a novel fuzzy system, which can extract the features of these ensembles, is built under the concept of membership degrees. With the help of CS optimization, the final model is constructed using this evolutionary algorithm to adjust and correct the results obtained based on physical laws, yielding the best forecasting performance and outperforming individual ensemble members and all of the other models for comparison.},
author = {Zhao, Jing and Guo, Zhen Hai and Su, Zhong Yue and Zhao, Zhi Yuan and Xiao, Xia and Liu, Feng},
doi = {10.1016/j.apenergy.2015.10.145},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao et al. - 2016 - An improved multi-step forecasting model based on WRF ensembles and creative fuzzy systems for wind speed.pdf:pdf},
issn = {03062619},
journal = {Applied Energy},
keywords = {Evolutionary algorithm,Fuzzy system,NWP ensemble,Operational wind forecast,WRF correction,Wind speed},
pages = {808--826},
publisher = {Elsevier Ltd},
title = {{An improved multi-step forecasting model based on WRF ensembles and creative fuzzy systems for wind speed}},
url = {http://dx.doi.org/10.1016/j.apenergy.2015.10.145},
volume = {162},
year = {2016}
}
@inproceedings{Tang2020,
abstract = {Despite significant advances, continual learning models still suffer from catastrophic forgetting when exposed to incrementally available data from non-stationary distributions. Rehearsal approaches alleviate the problem by maintaining and replaying a small episodic memory of previous samples, often implemented as an array of independent memory slots. In this work, we propose to augment such an array with a learnable random graph that captures pairwise similarities between its samples, and use it not only to learn new tasks but also to guard against forgetting. Empirical results on several benchmark datasets show that our model consistently outperforms recently proposed baselines for task-free continual learning.},
archivePrefix = {arXiv},
arxivId = {2007.04813},
author = {Tang, Binh and Matteson, David S.},
booktitle = {International Conference on Learning Representations},
eprint = {2007.04813},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tang, Matteson - 2020 - Graph-based continual learning.pdf:pdf},
issn = {23318422},
keywords = {continual learning,graph},
mendeley-tags = {continual learning,graph},
title = {{Graph-based continual learning}},
year = {2021}
}
@inproceedings{Norton2017,
abstract = {Recent studies have shown that attackers can force deep learning models to misclassify so-called 'adversarial examples:' maliciously generated images formed by making imperceptible modifications to pixel values. With growing interest in deep learning for security applications, it is important for security experts and users of machine learning to recognize how learning systems may be attacked. Due to the complex nature of deep learning, it is challenging to understand how deep models can be fooled by adversarial examples. Thus, we present a web-based visualization tool, Adversarial-Playground, to demonstrate the efficacy of common adversarial methods against a convolutional neural network (CNN) system. Adversarial-Playground is educational, modular and interactive. (1) It enables non-experts to compare examples visually and to understand why an adversarial example can fool a CNN-based image classifier. (2) It can help security experts explore more vulnerability of deep learning as a software module. (3) Building an interactive visualization is challenging in this domain due to the large feature space of image classification (generating adversarial examples is slow in general and visualizing images are costly). Through multiple novel design choices, our tool can provide fast and accurate responses to user requests. Empirically, we find that our client-server division strategy reduced the response time by an average of 1.5 seconds per sample. Our other innovation, a faster variant of JSMA evasion algorithm, empirically performed twice as fast as JSMA and yet maintains a comparable evasion rate1.},
archivePrefix = {arXiv},
arxivId = {1708.00807},
author = {Norton, Andrew P. and Qi, Yanjun},
booktitle = {2017 IEEE Symposium on Visualization for Cyber Security, VizSec 2017},
doi = {10.1109/VIZSEC.2017.8062202},
eprint = {1708.00807},
isbn = {9781538626931},
keywords = {I.2.6 [Artificial Intelligence]: Learning-Connecti,K.6.5 [Management of Computing and Information Sys},
title = {{Adversarial-Playground: A visualization suite showing how adversarial examples fool deep learning}},
year = {2017}
}
@article{Tesan2012,
abstract = {The word any may appear in some sentences, but not in others. For example, any is permitted in sentences that contain the word nobody, as in Nobody ate any fruit. However, in a minimally different context any seems strikingly anomalous: Everybody ate any fruit. The aim of the present study was to investigate how the brain responds to the word any in such minimally different contexts - where it is permitted (licensed) and where it is not permitted (unlicensed). Brain responses were measured from adult readers using magnetoencephalography (MEG). The results showed significantly larger responses to permissible contexts in the left posterior temporal areas between 400-500ms and 590-660ms. These results clarify the anatomy and timing of brain processes that contribute to our judgment that a word such as any is or is not permitted in a given context. {\textcopyright} 2011.},
author = {Tesan, Graciela and Johnson, Blake W. and Crain, Stephen},
doi = {10.1016/j.bandl.2011.08.006},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tesan, Johnson, Crain - 2012 - How the brain responds to any An MEG study.pdf:pdf},
issn = {0093934X},
journal = {Brain and Language},
keywords = {Brain imaging in language,Magnetoencephalography,Morphosyntactic processing,Negative polarity items (NPI),Posterior temporal gyrus,Semantic processing},
number = {1},
pages = {66--72},
pmid = {21944227},
publisher = {Elsevier Inc.},
title = {{How the brain responds to any: An MEG study}},
url = {http://dx.doi.org/10.1016/j.bandl.2011.08.006},
volume = {120},
year = {2012}
}
@inproceedings{Heoretic2022,
author = {Heoretic, I Nformation and Emory, O Nline M},
booktitle = {International Conference on Learning Representations},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Heoretic, Emory - 2022 - Information-Theoretic Online Memory Selection For Continual Learning.pdf:pdf},
keywords = {continual learning},
mendeley-tags = {continual learning},
title = {{Information-Theoretic Online Memory Selection For Continual Learning}},
year = {2022}
}
@article{McCloskey1989,
abstract = {Connectionist networks in which information is stored in weights on connections among simple processing units have attracted considerable interest in cognitive science. Much of the interest centers around two characteristics of these networks. First, the weights on connections between units need not be prewired by the model builder but rather may be established through training in which items to be learned are presented repeatedly to the network and the connection weights are adjusted in small increments according to a learning algorithm. Second, the networks may represent information in a distributed fashion. This chapter discusses the catastrophic interference in connectionist networks. Distributed representations established through the application of learning algorithms have several properties that are claimed to be desirable from the standpoint of modeling human cognition. These properties include content-addressable memory and so-called automatic generalization in which a network trained on a set of items responds correctly to other untrained items within the same domain. New learning may interfere catastrophically with old learning when networks are trained sequentially. The analysis of the causes of interference implies that at least some interference will occur whenever new learning may alter weights involved in representing old learning, and the simulation results demonstrate only that interference is catastrophic in some specific networks. {\textcopyright} 1989 Academic Press Inc.},
author = {McCloskey, Michael and Cohen, Neal J.},
doi = {10.1016/S0079-7421(08)60536-8},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/McCloskey, Cohen - 1989 - Catastrophic Interference in Connectionist Networks The Sequential Learning Problem.pdf:pdf},
issn = {00797421},
journal = {Psychology of Learning and Motivation - Advances in Research and Theory},
number = {C},
pages = {109--165},
title = {{Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem}},
volume = {24},
year = {1989}
}
@article{Sarkar2016,
abstract = {In this paper, all the models of PV cell, namely ideal single-diode model, single-diode                                                                           $$R_{\rm s}$$                                                                                    R                        s                                                                             model, single-diode                                                                           $$R_{\rm p}$$                                                                                    R                        p                                                                             model, the two-diode model, and the three-diode model, have been discussed. SPICE simulation is done to evaluate the impact of model parameters on the operation of PV cell. The effects of the parameters are discussed. The photocurrent,                                                                           $$I_{\rm L},$$                                                                                                              I                          L                                                ,                                                                             is proportional to irradiance, and the series resistance,                                                                           $$R_{\rm s},$$                                                                                                              R                          s                                                ,                                                                             reduces the short-circuit current and fill factor. The parallel resistance,                                                                           $$R_{\rm p},$$                                                                                                              R                          p                                                ,                                                                             reduces the open-circuit voltage, and both the diffusion diode and recombination diode reduce the open-circuit voltage value and fill factor. Finally, it is shown that an increase in cell operating temperature reduces the open-circuit voltage and fill factor and thus degrades the performance significantly.},
author = {Sarkar, Md. Nazmul Islam},
doi = {10.1186/s40807-016-0035-3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sarkar - 2016 - Effect of various model parameters on solar photovoltaic cell simulation a SPICE analysis.pdf:pdf},
issn = {2198-994X},
journal = {Renewables: Wind, Water, and Solar},
keywords = {Photovoltaic modeling,SPICE simulation of PV cell,Single-diode model,Solar cell modeling,Two-diode model,cell,photovoltaic modeling,single-diode model,solar cell,spice simulation of pv,two-diode model},
number = {1},
pages = {13},
publisher = {Springer Singapore},
title = {{Effect of various model parameters on solar photovoltaic cell simulation: a SPICE analysis}},
url = {http://jrenewables.springeropen.com/articles/10.1186/s40807-016-0035-3},
volume = {3},
year = {2016}
}
@article{Manuscript2013,
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Manuscript, Author and Nanobiomaterials, Biodegradable},
doi = {10.1021/nn300902w.Release},
eprint = {NIHMS150003},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Manuscript, Nanobiomaterials - 2013 - NIH Public Access.pdf:pdf},
isbn = {8585348585},
issn = {1053-8119},
keywords = {affect,amygdala,attention,decision making,emotion,value},
number = {8},
pages = {3416--3429},
pmid = {17977024},
title = {{NIH Public Access}},
volume = {6},
year = {2013}
}
@article{Salehinejad2018,
abstract = {Deep learning models have a large number of free parameters that must be estimated by efficient training of the models on a large number of training data samples to increase their generalization performance. In real-world applications, the data available to train these networks is often limited or imbalanced. We propose a sampling method based on the radial transform in a polar coordinate system for image augmentation to facilitate the training of deep learning models from limited source data. This pixel-wise transform provides representations of the original image in the polar coordinate system by generating a new image from each pixel. This technique can generate radial transformed images up to the number of pixels in the original image to increase the diversity of poorly represented image classes. Our experiments show improved generalization performance in training deep convolutional neural networks with radial transformed images.},
archivePrefix = {arXiv},
arxivId = {arXiv:1708.04347v4},
author = {Salehinejad, Hojjat and Valaee, Shahrokh and Dowdell, Tim and Barfett, Joseph},
doi = {10.1109/ICASSP.2018.8462241},
eprint = {arXiv:1708.04347v4},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Salehinejad et al. - 2018 - Image Augmentation Using Radial Transform for Training Deep Neural Networks.pdf:pdf},
isbn = {9781538646588},
issn = {15206149},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
keywords = {Augmentation,Deep learning,Imbalanced dataset,Polar coordinate system,Radial transform},
pages = {3016--3020},
title = {{Image Augmentation Using Radial Transform for Training Deep Neural Networks}},
volume = {2018-April},
year = {2018}
}
@article{Green2006,
abstract = {Objective: Patients with suspicion of acute coronary syndrome (ACS) are difficult to diagnose and they represent a very heterogeneous group. Some require immediate treatment while others, with only minor disorders, may be sent home. Detecting ACS patients using a machine learning approach would be advantageous in many situations. Methods and materials: Artificial neural network (ANN) ensembles and logistic regression models were trained on data from 634 patients presenting an emergency department with chest pain. Only data immediately available at patient presentation were used, including electrocardiogram (ECG) data. The models were analyzed using receiver operating characteristics (ROC) curve analysis, calibration assessments, inter- and intra-method variations. Effective odds ratios for the ANN ensembles were compared with the odds ratios obtained from the logistic model. Results: The ANN ensemble approach together with ECG data preprocessed using principal component analysis resulted in an area under the ROC curve of 80%. At the sensitivity of 95% the specificity was 41%, corresponding to a negative predictive value of 97%, given the ACS prevalence of 21%. Adding clinical data available at presentation did not improve the ANN ensemble performance. Using the area under the ROC curve and model calibration as measures of performance we found an advantage using the ANN ensemble models compared to the logistic regression models. Conclusion: Clinically, a prediction model of the present type, combined with the judgment of trained emergency department personnel, could be useful for the early discharge of chest pain patients in populations with a low prevalence of ACS. {\textcopyright} 2006 Elsevier B.V. All rights reserved.},
author = {Green, Michael and Bj{\"{o}}rk, Jonas and Forberg, Jakob and Ekelund, Ulf and Edenbrandt, Lars and Ohlsson, Mattias},
doi = {10.1016/j.artmed.2006.07.006},
isbn = {0933-3657 (Print)\r0933-3657 (Linking)},
issn = {09333657},
journal = {Artificial Intelligence in Medicine},
keywords = {Acute coronary syndrome,Acute myocardial infarction,Artificial neural networks,Clinical decision support,Ensemble methods,Logistic regression},
number = {3},
pages = {305--318},
pmid = {16962295},
title = {{Comparison between neural networks and multiple logistic regression to predict acute coronary syndrome in the emergency room}},
volume = {38},
year = {2006}
}
@inproceedings{Mirzadeh2020,
abstract = {Catastrophic forgetting affects the training of neural networks, limiting their ability to learn multiple tasks sequentially. From the perspective of the well established plasticity-stability dilemma, neural networks tend to be overly plastic, lacking the stability necessary to prevent the forgetting of previous knowledge, which means that as learning progresses, networks tend to forget previously seen tasks. This phenomenon coined in the continual learning literature, has attracted much attention lately, and several families of approaches have been proposed with different degrees of success. However, there has been limited prior work extensively analyzing the impact that different training regimes -- learning rate, batch size, regularization method-- can have on forgetting. In this work, we depart from the typical approach of altering the learning algorithm to improve stability. Instead, we hypothesize that the geometrical properties of the local minima found for each task play an important role in the overall degree of forgetting. In particular, we study the effect of dropout, learning rate decay, and batch size, on forming training regimes that widen the tasks' local minima and consequently, on helping it not to forget catastrophically. Our study provides practical insights to improve stability via simple yet effective techniques that outperform alternative baselines.},
archivePrefix = {arXiv},
arxivId = {2006.06958},
author = {Mirzadeh, Seyed Iman and Farajtabar, Mehrdad and Pascanu, Razvan and Ghasemzadeh, Hassan},
booktitle = {Neural Information Processing Systems (NeurIPS)},
eprint = {2006.06958},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mirzadeh et al. - 2020 - Understanding the Role of Training Regimes in Continual Learning.pdf:pdf},
month = {jun},
title = {{Understanding the Role of Training Regimes in Continual Learning}},
url = {http://arxiv.org/abs/2006.06958},
year = {2020}
}
@article{Netto2016,
abstract = {—Several works in the literature so far have been focused on deterministic point forecasts, which, usually, indicates the conditional mean of future observations. An increasing need for generating the entire conditional distribution of future observations has been required for the new generation of soft sensors. This study aims the probabilistic forecasts, reporting the use of a hybrid fuzzy forecasting model applied in two different forecasting problems. Our adapted model is applied to predict the rain of the city of Vitoria, in the state of Esp´ ırito Santo, Brazil. Real data from a wind farm, provided by the Irish EirGrid institute, was used for analyzing the proposal over a real time series with high fluctuations. Due to the stochasticity of the the hybrid model, which is calibrated through the use of an evolutionary metaheuristic, we adapted it in order to generate future using quantile regression. Computational experiments indicated the ability of the model in finding useful probabilistic quantiles, which were flexible enough in order to limit the lower and upper bounds of the historical datasets. While the probabilistic quantiles suggested the probability of rain and its magnitude, they were also able to predict expected ranges of the amount of energy generated from the wind farm.},
author = {Netto, Guilherme G. and Barbosa, Alexandre C. and Coelho, Mateus N. and Miranda, Arthur R. L. and Coelho, Vitor N. and Souza, Marcone J. F. and Guimaraes, Frederico G. and Reis, Agnaldo J. R.},
doi = {10.1109/EAIS.2016.7502494},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Netto et al. - 2016 - A hybrid evolutionary probabilistic forecasting model applied for rainfall and wind power forecast.pdf:pdf},
isbn = {978-1-5090-2583-1},
journal = {2016 IEEE Conference on Evolving and Adaptive Intelligent Systems (EAIS)},
keywords = {Hybrid forecasting model and metaheuristics,Probabilistic forecast,Rainfall forecast,Soft sensors,Wind power forecast},
pages = {73--78},
title = {{A hybrid evolutionary probabilistic forecasting model applied for rainfall and wind power forecast}},
url = {http://ieeexplore.ieee.org/document/7502494/},
year = {2016}
}
@article{You2020a,
abstract = {Neural networks are often represented as graphs of connections between neurons. However, despite their wide use, there is currently little understanding of the relationship between the graph structure of the neural network and its predictive performance. Here we systematically investigate how does the graph structure of neural networks affect their predictive performance. To this end, we develop a novel graph-based representation of neural networks called relational graph, where layers of neural network computation correspond to rounds of message exchange along the graph structure. Using this representation we show that: (1) a "sweet spot" of relational graphs leads to neural networks with significantly improved predictive performance; (2) neural network's performance is approximately a smooth function of the clustering coefficient and average path length of its relational graph; (3) our findings are consistent across many different tasks and datasets; (4) the sweet spot can be identified efficiently; (5) top-performing neural networks have graph structure surprisingly similar to those of real biological neural networks. Our work opens new directions for the design of neural architectures and the understanding on neural networks in general.},
archivePrefix = {arXiv},
arxivId = {2007.06559},
author = {You, Jiaxuan and Leskovec, Jure and He, Kaiming and Xie, Saining},
eprint = {2007.06559},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/You et al. - 2020 - Graph Structure of Neural Networks.pdf:pdf;:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/You et al. - 2020 - Graph Structure of Neural Networks(2).pdf:pdf},
journal = {arXiv},
month = {jul},
pages = {3--6},
title = {{Graph Structure of Neural Networks}},
url = {http://arxiv.org/abs/2007.06559},
year = {2020}
}
@article{Ayranci2016a,
abstract = {There is a movement in engineering to shift from conventional materials to those that can adapt and morph to their environment as a result of external stimuli. This category of materials is called shape memory materials. Among these, shape memory polymers have great potential due to their light weight and ease of shaping. They can significantly alter the way engineers think of their design approach; however, a number of them have stiffness and strength disadvantages compared to conventional engineering materials. Through composite material-based approaches, shape memory polymers have improved to meet some engineering challenges. Herein, fundamental aspects of shape memory polymers and composites are discussed; furthermore, recent adaptations of shape memory composites to shape memory braided composites are explored.},
author = {Ayranci, C. and Ivey, M. and Carey, Jason P.},
doi = {10.1016/B978-0-08-100369-5.00011-8},
isbn = {9780081003770},
journal = {Handbook of Advances in Braided Composite Materials: Theory, Production, Testing and Applications},
keywords = {Activation,Braids,Fundamental concepts,Manufacturing,Review,Shape memory polymer composites,Shape recovery properties},
pages = {397--408},
title = {{Shape memory composites and braids}},
volume = {1},
year = {2016}
}
@article{Itaba2017,
abstract = {This paper proposes a fuzzy-preconditioned ANN (Artificial Neural Network) model for electricity price forecasting. The deregulated electric power systems have been widely spread to trade electric power through electric power markets. The market players are interested in gaining the inside track to maximize the profits and minimize risks in advance. One of the most important tasks is how to forecast a complicated time series of electricity price that affects transmission network congestion. In practice, it is hard to forecast electricity price with the spikes due to the high nonlinearity. In this paper, GRBFN (General Radial Basis Function Network) of ANN is proposed for electricity price forecasting. It is an extension of RBFN of ANN in a way that the optimal parameters of the Gaussian functions are determined by the learning process in RBFN. To improve the model accuracy of GRBFN, FCE (fuzzy c-Elliptotypes) is introduced into GRBFN as a fuzzy precondition technique. FCE is an extension of FCM (fuzzy c-means) and plays a key role to classify input data into fuzzy clusters. The use of FCE contributes to the improvement of model accuracy for spikes of electricity price that bring about much higher price. This paper makes use of DA clustering to evaluate a better initial solution of the parameters of the Gaussian functions. Also, EPSO of evolutionary computation is used to evaluate better weights between neurons. The proposed method is successfully applied to real data of electricity price.},
author = {Itaba, Satoshi and Mori, Hiroyuki},
doi = {10.1016/j.procs.2017.09.010},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Itaba, Mori - 2017 - A Fuzzy-Preconditioned GRBFN Model for Electricity Price Forecasting.pdf:pdf},
isbn = {1877-0509},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {DA clustering,EPSO,GRBFN,RBFN,artificial neural network,electricity price,evolutionary computation,fuzzy c-Elliptotypes,fuzzy clustering,global clustering,power markets,spikes,time-series forecasting},
pages = {441--448},
publisher = {Elsevier B.V.},
title = {{A Fuzzy-Preconditioned GRBFN Model for Electricity Price Forecasting}},
url = {https://doi.org/10.1016/j.procs.2017.09.010},
volume = {114},
year = {2017}
}
@article{Rohrbach2017,
abstract = {Audio Description (AD) provides linguistic descriptions of movies and allows visually impaired people to follow a movie along with their peers. Such descriptions are by design mainly visual and thus naturally form an interesting data source for computer vision and computational linguistics. In this work we propose a novel dataset which contains transcribed ADs, which are temporally aligned to full length movies. In addition we also collected and aligned movie scripts used in prior work and compare the two sources of descriptions. In total the Large Scale Movie Description Challenge (LSMDC) contains a parallel corpus of 118,114 sentences and video clips from 202 movies. First we characterize the dataset by benchmarking different approaches for generating video descriptions. Comparing ADs to scripts, we find that ADs are indeed more visual and describe precisely what is shown rather than what should happen according to the scripts created prior to movie production. Furthermore, we present and compare the results of several teams who participated in a challenge organized in the context of the workshop "Describing and Understanding Video & The Large Scale Movie Description Challenge (LSMDC)", at ICCV 2015.},
archivePrefix = {arXiv},
arxivId = {1605.03705},
author = {Rohrbach, Anna and Torabi, Atousa and Rohrbach, Marcus and Tandon, Niket and Pal, Christopher and Larochelle, Hugo and Courville, Aaron and Schiele, Bernt},
doi = {10.1007/s11263-016-0987-1},
eprint = {1605.03705},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rohrbach et al. - 2017 - Movie Description.pdf:pdf},
issn = {15731405},
journal = {International Journal of Computer Vision},
keywords = {Audio description,LSMDC,Long short-term memory network,Movie description,Movie description challenge,Movie description dataset,Video captioning,Video description,Video understanding},
number = {1},
pages = {94--120},
publisher = {Springer US},
title = {{Movie Description}},
volume = {123},
year = {2017}
}
@article{Long2015,
abstract = {Recent studies reveal that a deep neural network can learn transferable features which generalize well to novel tasks for domain adaptation. However, as deep features eventually transition from general to specific along the network, the feature transferability drops significantly in higher layers with increasing domain discrepancy. Hence, it is important to formally reduce the dataset bias and enhance the transferability in task-specific layers. In this paper, we propose a new Deep Adaptation Network (DAN) architecture, which generalizes deep convolutional neural network to the domain adaptation scenario. In DAN, hidden representations of all task-specific layers are embedded in a reproducing kernel Hilbert space where the mean embeddings of different domain distributions can be explicitly matched. The domain discrepancy is further reduced using an optimal multi-kernel selection method for mean embedding matching. DAN can learn transferable features with statistical guarantees, and can scale linearly by unbiased estimate of kernel embedding. Extensive empirical evidence shows that the proposed architecture yields state-of-the-art image classification error rates on standard domain adaptation benchmarks.},
archivePrefix = {arXiv},
arxivId = {1502.02791},
author = {Long, Mingsheng and Cao, Yue and Wang, Jianmin and Jordan, Michael I.},
eprint = {1502.02791},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Long et al. - 2015 - Learning transferable features with deep adaptation networks.pdf:pdf},
isbn = {9781510810587},
journal = {32nd International Conference on Machine Learning, ICML 2015},
keywords = {Deep learning,domain adaptation,transfer learning,two-sample test},
mendeley-tags = {transfer learning},
pages = {97--105},
title = {{Learning transferable features with deep adaptation networks}},
volume = {1},
year = {2015}
}
@article{Prof2014,
author = {Prof, Directeur},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Prof - 2014 - Analysis and Improvement of the Spectral Properties in Mid-Infrared Semiconductor Quantum Cascade Lasers.pdf:pdf},
title = {{Analysis and Improvement of the Spectral Properties in Mid-Infrared Semiconductor Quantum Cascade Lasers}},
year = {2014}
}
@article{Evans2002,
abstract = {Interferometric gravitational-wave detectors, such as the Laser Interferometer Gravitational Wave Observatory (LIGO) detectors currently under construction, are based on kilometer-scale Michelson interferometers, with sensitivity that is enhanced by addition of multiple coupled optical resonators. Reducing the relative optic motions to bring the system to the resonant operating point is a significant challenge. We present a new approach to lock acquisition, used to lock a LIGO interferometer, whereby the sensor transformation matrix is dynamically calculated to sequentially bring the cavities into resonance.},
author = {Evans, M and Mavalvala, N and Fritschel, P and Bork, R and Bhawal, B and Gustafson, R and Kells, W and Landry, M and Sigg, D and Weiss, R and Whitcomb, S and Yamamoto, H},
doi = {10.1364/OL.27.000598},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Evans et al. - 2002 - Lock acquisition of a gravitational-wave interferometer.pdf:pdf},
issn = {0146-9592},
journal = {Opt. Lett.},
keywords = {Fabry-Perot; Interferometry; Optical resonators},
number = {8},
pages = {598--600},
pmid = {18007874},
title = {{Lock acquisition of a gravitational-wave interferometer}},
url = {http://ol.osa.org/abstract.cfm?URI=ol-27-8-598},
volume = {27},
year = {2002}
}
@article{Braglia1988,
abstract = {Fabrication of planar integrated optical waveguides on fluorozirconate glasses for medium infrared applications is described for the first time. ZBLAN glass (zirconium barium lanthanium aluminium sodium fluoride) was processed at relatively high temperature in a chlorine atmosphere, and waveguiding has been observed in He-Ne light.},
author = {Braglia, M. and {De Bernardi}, C. and Morasca, S. and Scarano, D.},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Braglia et al. - 1988 - Integrated optical waveguides fabricated on fluorozirconate glass for medium infrared applications.pdf:pdf},
issn = {05379989},
journal = {IEE Conference Publication},
number = {292 pt 1},
pages = {41--44},
title = {{Integrated optical waveguides fabricated on fluorozirconate glass for medium infrared applications}},
year = {1988}
}
@article{Fleetwood1999,
abstract = {Differential Evolution (DE) was introduced in 1996 by Price and Storn. It is a stochastic, population-based optimisation method that belongs to the class of Evolutionary Algorithms. It can be used to minimise real, integer, discrete and mixed parameter functions and it has recently been applied to problems in engineering, chemistry and agriculture. On classic optimisations test problems it has been shown to be more efficient than annealing methods and genetic algorithms. This talk provides a thorough introduction to the basic Differential Evolution algorithm including an example of its performance.},
archivePrefix = {arXiv},
arxivId = {hep-th/9310116},
author = {Fleetwood, Kelly},
doi = {10.1038/155531c0},
eprint = {9310116},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fleetwood - 1999 - An Introduction to Differential Evolution.pdf:pdf},
isbn = {0-07-709506-5},
issn = {0-07-709506-5},
journal = {New ideas in optimization},
pages = {79--108},
primaryClass = {hep-th},
title = {{An Introduction to Differential Evolution}},
url = {http://www.biodiversitylibrary.org/bibliography/4540},
year = {1999}
}
@article{Erickson2020,
abstract = {We introduce AutoGluon-Tabular, an open-source AutoML framework that requires only a single line of Python to train highly accurate machine learning models on an unprocessed tabular dataset such as a CSV file. Unlike existing AutoML frameworks that primarily focus on model/hyperparameter selection, AutoGluon-Tabular succeeds by ensembling multiple models and stacking them in multiple layers. Experiments reveal that our multi-layer combination of many models offers better use of allocated training time than seeking out the best. A second contribution is an extensive evaluation of public and commercial AutoML platforms including TPOT, H2O, AutoWEKA, auto-sklearn, AutoGluon, and Google AutoML Tables. Tests on a suite of 50 classification and regression tasks from Kaggle and the OpenML AutoML Benchmark reveal that AutoGluon is faster, more robust, and much more accurate. We find that AutoGluon often even outperforms the best-in-hindsight combination of all of its competitors. In two popular Kaggle competitions, AutoGluon beat 99% of the participating data scientists after merely 4h of training on the raw data.},
archivePrefix = {arXiv},
arxivId = {2003.06505},
author = {Erickson, Nick and Mueller, Jonas and Shirkov, Alexander and Zhang, Hang and Larroy, Pedro and Li, Mu and Smola, Alexander},
eprint = {2003.06505},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Erickson et al. - 2020 - AutoGluon-Tabular Robust and Accurate AutoML for Structured Data.pdf:pdf},
keywords = {auto ml,tabular data},
mendeley-tags = {auto ml,tabular data},
month = {mar},
title = {{AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data}},
url = {http://arxiv.org/abs/2003.06505 https://github.com/awslabs/autogluon},
year = {2020}
}
@article{May2019,
abstract = {Image augmentation is a widely used technique to improve the performance of convolutional neural networks (CNNs). In common image shifting, cropping, flipping, shearing and rotating are used for augmentation. But there are more advanced techniques like Cutout and SamplePairing. In this work we present two improvements of the state-of-the-art Cutout and SamplePairing techniques. Our new method called Copyout takes a square patch of another random training image and copies it onto a random location of each image used for training. The second technique we discovered is called CopyPairing. It combines Copyout and SamplePairing for further augmentation and even better performance. We apply different experiments with these augmentation techniques on the CIFAR-10 dataset to evaluate and compare them under different configurations. In our experiments we show that Copyout reduces the test error rate by 8.18% compared with Cutout and 4.27% compared with SamplePairing. CopyPairing reduces the test error rate by 11.97% compared with Cutout and 8.21% compared with SamplePairing. Copyout and CopyPairing implementations are available at https://github.com/t-systems-on-site-services-gmbh/coocop.},
archivePrefix = {arXiv},
arxivId = {1909.00390},
author = {May, Philip},
eprint = {1909.00390},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/May - 2019 - Improved Image Augmentation for Convolutional Neural Networks by Copyout and CopyPairing.pdf:pdf},
pages = {1--8},
title = {{Improved Image Augmentation for Convolutional Neural Networks by Copyout and CopyPairing}},
url = {http://arxiv.org/abs/1909.00390},
year = {2019}
}
@article{Davis2013,
abstract = {The purpose of this study is to explore African American women's attitudes toward cosmetics, how women use cosmetics, and how use of the products is related to African American women's self-identity and self-perception of appearance. The sample was 18 African American women who were residents of Pine Bluff, Arkansas, or Ames, Iowa. Recruitment was done by placing announcements about the study on the university Minority Students Office and Southeast Arkansas African American professional listserve. In-depth interviews were conducted with each woman. The women began wearing cosmetics at different periods in their lives during childhood, or adolescence. Shopping for cosmetics could be a hassle for some participants. Some reported difficulties in finding the right foundation to match their skin complexion. Many participants believed that finding cosmetics was a hit-or-miss experience when it came to shopping for cheaper cosmetics in local stores. Working with a consultant at a department store counter improved the experience. Stores in the predominantly White Iowa location carried few cosmetics appropriate for African American women's skin colors, causing much frustration on the part of the respondents in that location. Many of the women spent more money on quality cosmetics products that they felt made them look better and caused fewer skin problems. Many of the participants preferred the same brand of higher-end cosmetics. The women actively searched for YouTube tutorials to learn new tricks and techniques on how to apply their cosmetics. For many of the women, wearing cosmetics is a form of 'magic' that enhanced their beauty and self-confidence. Many of the women explained that applying cosmetics was needed to enhance their features; for a few, makeup was seen as unnecessary, but a nice addition. All used cosmetics to present an idealized appearance and enjoyed wearing them. The women in Arkansas made greater use of cosmetics on a daily basis, perhaps because of their work versus student roles and location in a larger African American community. Social comparison, self-objectification, and symbolic self-completion theories were useful in interpreting the findings. Black feminist perspectives considering personal power and issues of inclusion and exclusion in media and retail settings were also incorporated in the analysis. Copies of dissertations may be obtained by addressing your request to ProQuest, 789 E. Eisenhower Parkway, P.O. Box 1346, Ann Arbor, MI 48106-1346. Telephone 1-800-521-3042; e-mail: disspub@umi.com},
author = {Davis, LaPorchia C},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Davis - 2013 - African American women's use of cosmetics products in relation to their attitudes and self-identity.pdf:pdf},
isbn = {9781303166945},
journal = {Apparel, Merchandising, and Design},
title = {{African American women's use of cosmetics products in relation to their attitudes and self-identity}},
volume = {Master of },
year = {2013}
}
@article{Zhang2017c,
abstract = {Despite their massive size, successful deep artificial neural networks can exhibit a remarkably small difference between training and test performance. Conventional wisdom attributes small generalization error either to properties of the model family, or to the regularization techniques used during training. Through extensive systematic experiments, we show how these traditional approaches fail to explain why large neural networks generalize well in practice. Specifically, our experiments establish that state-of-the-art convolutional networks for image classification trained with stochastic gradient methods easily fit a random labeling of the training data. This phenomenon is qualitatively unaffected by explicit regularization, and occurs even if we replace the true images by completely unstructured random noise. We corroborate these experimental findings with a theoretical construction showing that simple depth two neural networks already have perfect finite sample expressivity as soon as the number of parameters exceeds the number of data points as it usually does in practice. We interpret our experimental findings by comparison with traditional models.},
archivePrefix = {arXiv},
arxivId = {1611.03530},
author = {Zhang, Chiyuan and Recht, Benjamin and Bengio, Samy and Hardt, Moritz and Vinyals, Oriol},
eprint = {1611.03530},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2017 - Understanding deep learning requires rethinking generalization.pdf:pdf},
journal = {5th International Conference on Learning Representations, ICLR 2017 - Conference Track Proceedings},
keywords = {deep learning,generalization},
mendeley-tags = {deep learning,generalization},
pages = {107--115},
title = {{Understanding deep learning requires rethinking generalization}},
year = {2017}
}
@article{Ren2019,
abstract = {Machine learning classifiers are often trained to recognize a set of pre-defined classes. However, in many applications, it is often desirable to have the flexibility of learning additional concepts, with limited data and without re-training on the full training set. This paper addresses this problem, incremental few-shot learning, where a regular classification network has already been trained to recognize a set of base classes, and several extra novel classes are being considered, each with only a few labeled examples. After learning the novel classes, the model is then evaluated on the overall classification performance on both base and novel classes. To this end, we propose a meta-learning model, the Attention Attractor Network, which regularizes the learning of novel classes. In each episode, we train a set of new weights to recognize novel classes until they converge, and we show that the technique of recurrent back-propagation can back-propagate through the optimization process and facilitate the learning of these parameters. We demonstrate that the learned attractor network can help recognize novel classes while remembering old classes without the need to review the original training set, outperforming various baselines.},
archivePrefix = {arXiv},
arxivId = {arXiv:1810.07218v3},
author = {Ren, Mengye and Liao, Renjie and Fetaya, Ethan and Zemel, Richard S.},
eprint = {arXiv:1810.07218v3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ren et al. - 2019 - Incremental few-shot learning with attention attractor networks.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
keywords = {continual learning,few-shot learning,meta-learning},
mendeley-tags = {continual learning,few-shot learning,meta-learning},
number = {NeurIPS},
pages = {1--15},
title = {{Incremental few-shot learning with attention attractor networks}},
url = {https://github.com/renmengye/inc-few-shot-attractor-public},
volume = {32},
year = {2019}
}
@article{Christodoulos2010,
abstract = {Forecasting diffusion of new technologies is usually performed by the means of aggregate diffusion models, which tend to monopolize this area of research and practice, making the alternative approaches, like the Box-Jenkins, less favourable choices due to their lack of providing accurate long-term predictions. This paper presents a new methodology focusing on the improvement of the short-term prediction that combines the advantages of both approaches and that can be applied in the early stages of a diffusion process. An application of the methodology is also illustrated, providing short-term forecasts for the world broadband and mobile telecommunications' penetration. The results reveal that the methodology is capable of producing improved one-year-ahead predictions, after a certain level of penetration, as compared to the results of both methods individually. This methodology can find applications to all cases of the high-technology market, where a diffusion model is usually used for obtaining future forecasts. The paper concludes with the limitations of the methodology, the discussion on the application's results and the proposals for further research. {\textcopyright} 2010 Elsevier Inc.},
author = {Christodoulos, Charisios and Michalakelis, Christos and Varoutas, Dimitris},
doi = {10.1016/j.techfore.2010.01.009},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Christodoulos, Michalakelis, Varoutas - 2010 - Forecasting with limited data Combining ARIMA and diffusion models.pdf:pdf},
isbn = {00401625 (ISSN)},
issn = {00401625},
journal = {Technological Forecasting and Social Change},
keywords = {ARIMA models,Linear Logistic model,Mobile and broadband penetration,Technology diffusion,Time-series forecasting},
number = {4},
pages = {558--565},
publisher = {Elsevier Inc.},
title = {{Forecasting with limited data: Combining ARIMA and diffusion models}},
url = {http://dx.doi.org/10.1016/j.techfore.2010.01.009},
volume = {77},
year = {2010}
}
@article{Jimoh2013,
author = {Jimoh, R. G. and Olagunju, M. and Folorunso, I.O. and Asiribo, M.A.},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jimoh et al. - 2013 - Modeling Rainfall Prediction using Fuzzy Logic.pdf:pdf},
journal = {International Journal of Innovative Research in Computer and Communication Engineering},
keywords = {2005,background to the study,continue to be processes,despite the fact that,forecast,fuzzy logic,i,improve,jim,meteorological processes continue to,physical processes not yet,planning,rainfall,rigorous numerical modeling of,solutions,that elude explicit analytical,there will likely,understood or},
number = {4},
pages = {929--936},
title = {{Modeling Rainfall Prediction using Fuzzy Logic}},
volume = {1},
year = {2013}
}
@article{Rezatofighi2019,
abstract = {Intersection over Union (IoU) is the most popular evaluation metric used in the object detection benchmarks. However, there is a gap between optimizing the commonly used distance losses for regressing the parameters of a bounding box and maximizing this metric value. The optimal objective for a metric is the metric itself. In the case of axis-aligned 2D bounding boxes, it can be shown that IoU can be directly used as a regression loss. However, IoU has a plateau making it infeasible to optimize in the case of non-overlapping bounding boxes. In this paper, we address the this weakness by introducing a generalized version of IoU as both a new loss and a new metric. By incorporating this generalized IoU ( GIoU) as a loss into the state-of-the art object detection frameworks, we show a consistent improvement on their performance using both the standard, IoU based, and new, GIoU based, performance measures on popular object detection benchmarks such as PASCAL VOC and MS COCO.},
archivePrefix = {arXiv},
arxivId = {1902.09630},
author = {Rezatofighi, Hamid and Tsoi, Nathan and Gwak, Junyoung and Sadeghian, Amir and Reid, Ian and Savarese, Silvio},
doi = {10.1109/CVPR.2019.00075},
eprint = {1902.09630},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rezatofighi et al. - 2019 - Generalized intersection over union A metric and a loss for bounding box regression.pdf:pdf},
isbn = {9781728132938},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
keywords = {Categorization,Deep Learning,Recognition: Detection,Retrieval,iou,loss function},
mendeley-tags = {iou,loss function},
pages = {658--666},
title = {{Generalized intersection over union: A metric and a loss for bounding box regression}},
volume = {2019-June},
year = {2019}
}
@article{Yuming1995,
author = {Yuming, Chen and Jing, Ding and Fanlun, Xiong},
doi = {10.1016/S1474-6670(17)45555-8},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yuming, Jing, Fanlun - 1995 - Genetic Algorithms for Irrigation Optimization.pdf:pdf},
issn = {14746670},
journal = {IFAC Proceedings Volumes},
keywords = {Genetic algorithms,Irrigation Optimization,genetic algorithms,irrigation optimization},
number = {4},
pages = {145--150},
publisher = {Elsevier},
title = {{Genetic Algorithms for Irrigation Optimization}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1474667017455558},
volume = {28},
year = {1995}
}
@article{Hoefler2021,
abstract = {The growing energy and performance costs of deep learning have driven the community to reduce the size of neural networks by selectively pruning components. Similarly to their biological counterparts, sparse networks generalize just as well, if not better than, the original dense networks. Sparsity can reduce the memory footprint of regular networks to fit mobile devices, as well as shorten training time for ever growing networks. In this paper, we survey prior work on sparsity in deep learning and provide an extensive tutorial of sparsification for both inference and training. We describe approaches to remove and add elements of neural networks, different training strategies to achieve model sparsity, and mechanisms to exploit sparsity in practice. Our work distills ideas from more than 300 research papers and provides guidance to practitioners who wish to utilize sparsity today, as well as to researchers whose goal is to push the frontier forward. We include the necessary background on mathematical methods in sparsification, describe phenomena such as early structure adaptation, the intricate relations between sparsity and the training process, and show techniques for achieving acceleration on real hardware. We also define a metric of pruned parameter efficiency that could serve as a baseline for comparison of different sparse networks. We close by speculating on how sparsity can improve future workloads and outline major open problems in the field.},
archivePrefix = {arXiv},
arxivId = {2102.00554},
author = {Hoefler, Torsten and Alistarh, Dan and Ben-Nun, Tal and Dryden, Nikoli and Peste, Alexandra},
eprint = {2102.00554},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hoefler et al. - 2021 - Sparsity in Deep Learning Pruning and growth for efficient inference and training in neural networks.pdf:pdf},
keywords = {efficient,efficient models,review,sparse network,sparsity,survey},
mendeley-tags = {efficient,efficient models,review,sparse network,sparsity,survey},
title = {{Sparsity in Deep Learning: Pruning and growth for efficient inference and training in neural networks}},
url = {http://arxiv.org/abs/2102.00554},
year = {2021}
}
@inproceedings{Wang2018a,
abstract = {We consider the problem of zero-shot recognition: Learning a visual classifier for a category with zero training examples, just using the word embedding of the category and its relationship to other categories, which visual data are provided. The key to dealing with the unfamiliar or novel category is to transfer knowledge obtained from familiar classes to describe the unfamiliar class. In this paper, we build upon the recently introduced Graph Convolutional Network (GCN) and propose an approach that uses both semantic embeddings and the categorical relationships to predict the classifiers. Given a learned knowledge graph (KG), our approach takes as input semantic embeddings for each node (representing visual category). After a series of graph convolutions, we predict the visual classifier for each category. During training, the visual classifiers for a few categories are given to learn the GCN parameters. At test time, these filters are used to predict the visual classifiers of unseen categories. We show that our approach is robust to noise in the KG. More importantly, our approach provides significant improvement in performance compared to the current state-of-the-art results (from 2 $\sim$ 3% on some metrics to whopping 20% on a few).},
archivePrefix = {arXiv},
arxivId = {1803.08035},
author = {Wang, Xiaolong and Ye, Yufei and Gupta, Abhinav},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2018.00717},
eprint = {1803.08035},
isbn = {9781538664209},
issn = {10636919},
title = {{Zero-Shot Recognition via Semantic Embeddings and Knowledge Graphs}},
year = {2018}
}
@article{Cook1995,
abstract = {Correlation analyses of recent back-propagation neural networks show that network results are due to imbalances in stimulus input. Conclusions concerning the effects of receptive field size, hemispheric specialization, and other issues of relevance to psychology cannot therefore be drawn until the dominating effects of low-level correlations are removed. Statistical techniques for evaluating the stimulus materials for neural networks are introduced. {\textcopyright} 1995.},
author = {Cook, Norman D.},
doi = {10.1016/0364-0213(95)90010-1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cook - 1995 - Correlations between input and output units in neural networks.pdf:pdf},
issn = {03640213},
journal = {Cognitive Science},
number = {4},
pages = {563--574},
title = {{Correlations between input and output units in neural networks}},
volume = {19},
year = {1995}
}
@article{Bebis,
author = {Bebis, George and Egbert, Dwight and Shah, Mubarak},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bebis, Egbert, Shah - Unknown - Review of Computer Vision Education.pdf.pdf:pdf},
keywords = {computer vision,image processing,research},
title = {{Review of Computer Vision Education.pdf}}
}
@article{Vondrick2018,
abstract = {We use large amounts of unlabeled video to learn models for visual tracking without manual human supervision. We leverage the natural temporal coherency of color to create a model that learns to colorize gray-scale videos by copying colors from a reference frame. Quantitative and qualitative experiments suggest that this task causes the model to automatically learn to track visual regions. Although the model is trained without any ground-truth labels, our method learns to track well enough to outperform the latest methods based on optical flow. Moreover, our results suggest that failures to track are correlated with failures to colorize, indicating that advancing video colorization may further improve self-supervised visual tracking.},
archivePrefix = {arXiv},
arxivId = {1806.09594},
author = {Vondrick, Carl and Shrivastava, Abhinav and Fathi, Alireza and Guadarrama, Sergio and Murphy, Kevin},
doi = {10.1007/978-3-030-01261-8_24},
eprint = {1806.09594},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vondrick et al. - 2018 - Tracking emerges by colorizing videos.pdf:pdf},
isbn = {9783030012601},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Colorization,Self-supervised learning,Tracking,Video},
pages = {402--419},
title = {{Tracking emerges by colorizing videos}},
volume = {11217 LNCS},
year = {2018}
}
@article{Li2017,
abstract = {We present a generative model which can automatically summarize the stroke composition of free-hand sketches of a given category. When our model is fit to a collection of sketches with similar poses, it discovers and learns the structure and appearance of a set of coherent parts, with each part represented by a group of strokes. It represents both consistent (topology) as well as diverse aspects (structure and appearance variations) of each sketch category. Key to the success of our model are important insights learned from a comprehensive study performed on human stroke data. By fitting this model to images, we are able to synthesize visually similar and pleasant free-hand sketches.},
archivePrefix = {arXiv},
arxivId = {1510.02644},
author = {Li, Yi and Song, Yi Zhe and Hospedales, Timothy M. and Gong, Shaogang},
doi = {10.1007/s11263-016-0963-9},
eprint = {1510.02644},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2017 - Free-Hand Sketch Synthesis with Deformable Stroke Models.pdf:pdf},
issn = {15731405},
journal = {International Journal of Computer Vision},
keywords = {Deformable stroke model,Perceptual grouping,Sketch synthesis,Stroke analysis},
number = {1},
pages = {169--190},
title = {{Free-Hand Sketch Synthesis with Deformable Stroke Models}},
volume = {122},
year = {2017}
}
@book{Cardon2018,
abstract = {Since 2010, machine learning based predictive techniques, and more specifically deep learning neural networks, have achieved spectacular performances in the fields of image recognition or automatic translation, under the umbrella term of “Artificial Intelligence”. But their filiation to this field of research is not straightforward. In the tumultuous history of AI, learning techniques using so-called "connectionist" neural networks have long been mocked and ostracized by the "symbolic" movement. This article retraces the history of artificial intelligence through the lens of the tension between symbolic and connectionist approaches. From a social history of science and technology perspective, it seeks to highlight how researchers, relying on the availability of massive data and the multiplication of computing power have undertaken to reformulate the symbolic AI project by reviving the spirit of adaptive and inductive machines dating back from the era of cybernetics. Keywords},
author = {Cardon, Dominique and Cointet, Jean Philippe and Mazi{\`{e}}res, Antoine},
booktitle = {Reseaux},
doi = {10.3917/res.211.0173},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cardon, Cointet, Mazi{\`{e}}res - 2018 - Neurons Spike Back.pdf:pdf},
isbn = {9782348040689},
issn = {07517971},
keywords = {artificial intelligence,history},
mendeley-tags = {artificial intelligence,history},
number = {5},
pages = {173--220},
title = {{Neurons Spike Back}},
volume = {211},
year = {2018}
}
@article{Kisi2004,
abstract = {Abstract Abstract The prediction and estimation of suspended sediment concentration are investigated by using multi-layer perceptrons (MLP). The fastest MLP training algorithm, that is the Levenberg-Marquardt algorithm, is used for optimization of the network weights for data from two stations on the Tongue River in Montana, USA. The first part of the study deals with prediction and estimation of upstream and down-stream station sediment data, separately, and the second part focuses on the estimation of downstream suspended sediment data by using data from both stations. In each case, the MLP test results are compared to those of generalized regression neural networks (GRNN), radial basis function (RBF) and multi-linear regression (MLR) for the best-input combinations. Based on the comparisons, it was found that the MLP generally gives better suspended sediment concentration estimates than the other neural network techniques and the conventional statistical method (MLR). However, for the estimation of max...},
author = {Kişi, {\"{O}}zg{\"{u}}r},
doi = {10.1623/hysj.49.6.1025.55720},
isbn = {0262-6667},
issn = {02626667},
journal = {Hydrological Sciences Journal},
keywords = {Estimation,Generalized regression neural networks,Multi-layer perceptrons,Multi-linear regression,Prediction,Radial basis function,Suspended sediment concentration},
number = {6},
pages = {1025--1040},
title = {{Multi-layer perceptrons with Levenberg-Marquardt training algorithm for suspended sediment concentration prediction and estimation}},
volume = {49},
year = {2004}
}
@article{Taskin2015a,
author = {Taskin, Ahmet and Kumbasar, Tufan},
doi = {10.1109/SSCI.2015.220},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Taskin, Kumbasar - 2015 - An Open Source Matlab Simulink Toolbox for Interval Type-2 Fuzzy Logic Systems.pdf:pdf},
isbn = {9781479975600},
pages = {1561--1568},
title = {{An Open Source Matlab / Simulink Toolbox for Interval Type-2 Fuzzy Logic Systems}},
year = {2015}
}
@article{Teknik,
author = {Teknik, Material},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Teknik - Unknown - 14. Pengenalan Komposit.pdf:pdf},
title = {{14. Pengenalan Komposit}}
}
@article{Knuppel2018,
abstract = {Past forecast errors are employed frequently in the estimation of the unconditional forecast uncertainty, and several institutions have increased their forecast horizons in recent times. This work addresses the question of how forecast-error-based estimation can be performed if there are very few errors available for the new forecast horizons. It extends the results of Kn{\"{u}}ppel (2014) in order to relax the condition on the data structure that is required for the SUR estimator to be independent of unknown quantities. It turns out that the SUR estimator of the forecast uncertainty, which estimates the forecast uncertainty for all horizons jointly, tends to deliver large efficiency gains relative to the OLS estimator (i.e., the sample mean of the squared forecast errors for each individual horizon) in the case of increased forecast horizons. The SUR estimator is applied to the forecast errors of the Bank of England, the US Survey of Professional Forecasters, and the FOMC.},
author = {Kn{\"{u}}ppel, Malte},
doi = {10.1016/j.ijforecast.2017.08.006},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kn{\"{u}}ppel - 2018 - Forecast-error-based estimation of forecast uncertainty when the horizon is increased.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Forecast error variance,Multi-step-ahead forecasts,SUR},
number = {1},
pages = {105--116},
publisher = {Elsevier B.V.},
title = {{Forecast-error-based estimation of forecast uncertainty when the horizon is increased}},
url = {http://dx.doi.org/10.1016/j.ijforecast.2017.08.006},
volume = {34},
year = {2018}
}
@inproceedings{Rebuffi2017,
abstract = {A major open problem on the road to artificial intelligence is the development of incrementally learning systems that learn about more and more concepts over time from a stream of data. In this work, we introduce a new training strategy, iCaRL, that allows learning in such a class-incremental way: only the training data for a small number of classes has to be present at the same time and new classes can be added progressively. iCaRL learns strong classifiers and a data representation simultaneously. This distinguishes it from earlier works that were fundamentally limited to fixed data representations and therefore incompatible with deep learning architectures. We show by experiments on CIFAR-100 and ImageNet ILSVRC 2012 data that iCaRL can learn many classes incrementally over a long period of time where other strategies quickly fail.},
archivePrefix = {arXiv},
arxivId = {1611.07725},
author = {Rebuffi, Sylvestre-Alvise and Kolesnikov, Alexander and Sperl, Georg and Lampert, Christoph H.},
booktitle = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/CVPR.2017.587},
eprint = {1611.07725},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rebuffi et al. - 2017 - iCaRL Incremental Classifier and Representation Learning.pdf:pdf},
isbn = {978-1-5386-0457-1},
month = {jul},
pages = {5533--5542},
publisher = {IEEE},
title = {{iCaRL: Incremental Classifier and Representation Learning}},
url = {http://arxiv.org/abs/1611.07725 http://ieeexplore.ieee.org/document/8100070/},
volume = {2017-Janua},
year = {2017}
}
@article{Kim2003,
abstract = {The use of conformal antennas for vehicle applications is growing rapidly due to new considerations such as styling and security. In automobile antenna design, there exist geometrical constraints and several requirements for antenna specifications, for example, directional gain patterns and polarization. In this paper, new FM frequency band conformal antennas for the automobile applications are designed using a Genetic Algorithm (GA). Azimuthal gain patterns and input impedance of the new designed conformal antennas are presented.},
author = {Kim, Y. and Walton, E.K.},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim, Walton - 2003 - Automobile conformal antenna design and optimization using genetic algorithm.pdf:pdf},
isbn = {0780378466},
issn = {02724693},
journal = {IEEE Antennas and Propagation Society, AP-S International Symposium (Digest)},
pages = {717--720},
title = {{Automobile conformal antenna design and optimization using genetic algorithm}},
volume = {3},
year = {2003}
}
@article{Rebekic2015,
abstract = {{\textcopyright} 2015, Faculty of Agriculture in Osijek. All rights Reserved. Most commonly used correlation coefficients are Pearson's product moment correlation coefficient and Spearman's rank correlation coefficient. The aim of this paper is to compare a Pearson's and Spearman's coefficient of correlation on the same data set. The winter wheat grain cadmium (Cd) concentration was correlated to grain zinc (Zn) concentration, plant height, plant weight, number of spikelets per spike and 1000 kernel weight. Data were collected from the experiment carried out in semi controlled conditions, where genotypic specificity of winter wheat varieties was tested on the grain Cd and Zn accumulation on uncontaminated and Cd contaminated soil. Results showed that selection of most convenient correlation coefficient mostly depends on the type of variables, presence of outliers normality and linearity of relationship.},
author = {Rebeki{\'{c}}, A. and Lon{\v{c}}ari{\'{c}}, Z. and Petrovi{\'{c}}, S. and Mari{\'{c}}, S.},
doi = {http://dx.doi.org/10.18047/poljo.21.2.8},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rebeki{\'{c}} et al. - 2015 - Pearson's or spearman's correlation coefficient – which one to use.pdf:pdf},
issn = {13307142},
journal = {Poljoprivreda},
number = {2},
pages = {47--54},
title = {{Pearson's or spearman's correlation coefficient – which one to use ?}},
volume = {21},
year = {2015}
}
@article{Ponulak2011,
abstract = {The concept that neural information is encoded in the firing rate of neurons has been the dominant paradigm in neurobiology for many years. This paradigm has also been adopted by the theory of artificial neural networks. Recent physiological experiments demonstrate, however, that in many parts of the nervous system, neural code is founded on the timing of individual action potentials. This finding has given rise to the emergence of a new class of neural models, called spiking neural networks. In this paper we summarize basic properties of spiking neurons and spiking networks. Our focus is, specifically, on models of spike-based information coding, synaptic plasticity and learning. We also survey real-life applications of spiking models. The paper is meant to be an introduction to spiking neural networks for scientists from various disciplines interested in spike-based neural processing.},
author = {Ponulak, Filip and Kasinski, Andrzej},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ponulak, Kasinski - 2011 - Introduction to spiking neural networks Information processing, learning and applications.pdf:pdf},
issn = {1689-0035},
journal = {Acta neurobiologiae experimentalis},
keywords = {learning,neural code,neural information processing,reinforcement learning,spiking neural networks,supervised,synaptic plasticity,unsupervised learning},
number = {4},
pages = {409--33},
pmid = {22237491},
title = {{Introduction to spiking neural networks: Information processing, learning and applications.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22237491},
volume = {71},
year = {2011}
}
@article{Brown2020,
abstract = {Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art finetuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.},
archivePrefix = {arXiv},
arxivId = {2005.14165},
author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
eprint = {2005.14165},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brown et al. - 2020 - Language models are few-shot learners.pdf:pdf},
journal = {arXiv},
title = {{Language models are few-shot learners}},
url = {https://arxiv.org/pdf/2005.14165.pdf https://github.com/openai/gpt-3},
year = {2020}
}
@inproceedings{Cui2021a,
abstract = {An important challenge for neural networks is to learn incre- mentally, i.e., learn new classes without catastrophic forget- ting. To overcome this problem, generative replay technique has been suggested, which can generate samples belonging to learned classes while learning new ones. However, such generative models usually suffer from increased distribution mismatch between the generated and original samples along the learning process. In this work, we propose DeepCollabo- ration (D-Collab), a collaborative framework of deep gener- ative and discriminative models to solve this problem effec- tively. We develop a discriminative learning model to incre- mentally update the latent feature space for continual classi- fication. At the same time, a generative model is introduced to achieve conditional generation using the latent feature dis- tribution produced by the discriminative model. Important- ly, the generative and discriminative models are connected through bidirectional training to enforce cycle-consistency of mappings between feature and image domains. Furthermore, a domain alignment module is used to eliminate the diver- gence between the feature distributions of generated images and real ones. This module together with the discriminative model can perform effective sample mining to achieve effi- cient incremental learning. Extensive experiments on several visual recognition datasets show that our system can achieve state-of-the-art performance. 1},
author = {Cui, Bo and Hu, Guyue and Yu, Shan},
booktitle = {35th AAAI Conference on Artificial Intelligence, AAAI 2021},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cui, Hu, Yu - 2021 - DeepCollaboration Collaborative Generative and Discriminative Models for Class Incremental Learning.pdf:pdf},
keywords = {continual learning,incremental learning},
mendeley-tags = {continual learning,incremental learning},
title = {{DeepCollaboration : Collaborative Generative and Discriminative Models for Class Incremental Learning}},
year = {2021}
}
@article{Karpathy2017,
abstract = {We present a model that generates natural language descriptions of images and their regions. Our approach leverages datasets of images and their sentence descriptions to learn about the inter-modal correspondences between language and visual data. Our alignment model is based on a novel combination of Convolutional Neural Networks over image regions, bidirectional Recurrent Neural Networks (RNN) over sentences, and a structured objective that aligns the two modalities through a multimodal embedding. We then describe a Multimodal Recurrent Neural Network architecture that uses the inferred alignments to learn to generate novel descriptions of image regions. We demonstrate that our alignment model produces state of the art results in retrieval experiments on Flickr8K, Flickr30K and MSCOCO datasets. We then show that the generated descriptions outperform retrieval baselines on both full images and on a new dataset of region-level annotations. Finally, we conduct large-scale analysis of our RNN language model on the Visual Genome dataset of 4.1 million captions and highlight the differences between image and region-level caption statistics.},
archivePrefix = {arXiv},
arxivId = {1412.2306},
author = {Karpathy, Andrej and Fei-Fei, Li},
doi = {10.1109/TPAMI.2016.2598339},
eprint = {1412.2306},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Karpathy, Fei-Fei - 2017 - Deep Visual-Semantic Alignments for Generating Image Descriptions(2).pdf:pdf},
isbn = {9781467369640},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Image captioning,deep neural networks,language model,recurrent neural network,visual-semantic embeddings},
number = {4},
pages = {664--676},
title = {{Deep Visual-Semantic Alignments for Generating Image Descriptions}},
volume = {39},
year = {2017}
}
@article{Ragesh2014,
abstract = {<p>Self-cleaning and multifunctional materials are used in applications such as windows, solar panels, cements, paints, and textiles. This state-of-the-art review summarizes the materials involved in self-cleaning and multifunctional coatings.</p>},
author = {Ragesh, Prathapan and {Anand Ganesh}, V. and Nair, Shantikumar V. and Nair, A. Sreekumaran},
doi = {10.1039/C4TA02542C},
isbn = {2050-7488},
issn = {2050-7488},
journal = {J. Mater. Chem. A},
number = {36},
pages = {14773--14797},
title = {{A review on ‘self-cleaning and multifunctional materials'}},
url = {http://xlink.rsc.org/?DOI=C4TA02542C},
volume = {2},
year = {2014}
}
@article{Khosravi2016,
author = {Khosravi, Shokoh},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khosravi - 2016 - Forecasting Temperature using Fuzzy Neural Networks and Genetic Algorithms ( Case Study Lorestan Province , Khorramaba.pdf:pdf},
keywords = {fuzzy neural,genetic algorithms,maximum,minimum,networks,predicting temperature},
number = {5},
pages = {993--1006},
title = {{Forecasting Temperature using Fuzzy Neural Networks and Genetic Algorithms ( Case Study Lorestan Province , Khorramabad City )}},
volume = {11},
year = {2016}
}
@article{Krizhevsky2012,
author = {Krizhevsky, By Alex and Sutskever, Ilya and Hinton, Geoffrey E},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krizhevsky, Sutskever, Hinton - 2012 - Cnn实际训练的.pdf:pdf},
journal = {Communications of the ACM},
number = {6},
pages = {84--90},
title = {{Cnn实际训练的}},
volume = {60},
year = {2012}
}
@article{Hinton2006,
abstract = {We show how to use “complementary priors” to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind.},
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee-Whye},
doi = {10.1162/neco.2006.18.7.1527},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hinton, Osindero, Teh - 2006 - A Fast Learning Algorithm for Deep Belief Nets.pdf:pdf},
issn = {0899-7667},
journal = {Neural Computation},
month = {jul},
number = {7},
pages = {1527--1554},
title = {{A Fast Learning Algorithm for Deep Belief Nets}},
url = {https://www.mitpressjournals.org/doi/abs/10.1162/neco.2006.18.7.1527},
volume = {18},
year = {2006}
}
@article{Ebtke,
author = {Ebtke, Energi and Energi, Kementrian and Sumber, D A N and Mineral, Daya},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ebtke et al. - Unknown - Audit Energi Di Pt . Suyuti Sido Maju Program Kerjasama Direktorat Jenderal Energi Baru , Terbarukan Dan Konser.pdf:pdf},
title = {{Audit Energi Di Pt . Suyuti Sido Maju Program Kerjasama Direktorat Jenderal Energi Baru , Terbarukan Dan Konservasi Dengan Pt . Rekadaya Sentra Mandiri}}
}
@article{Noroozi2016,
abstract = {We propose a novel unsupervised learning approach to build features suitable for object detection and classification. The features are pre-trained on a large dataset without human annotation and later transferred via fine-tuning on a different, smaller and labeled dataset. The pre-training consists of solving jigsaw puzzles of natural images. To facilitate the transfer of features to other tasks, we introduce the context-free network (CFN), a siamese-ennead convolutional neural network. The features correspond to the columns of the CFN and they process image tiles independently (i.e., free of context). The later layers of the CFN then use the features to identify their geometric arrangement. Our experimental evaluations show that the learned features capture semantically relevant content. We pre-train the CFN on the training set of the ILSVRC2012 dataset and transfer the features on the combined training and validation set of Pascal VOC 2007 for object detection (via fast RCNN) and classification. These features outperform all current unsupervised features with 51.8% for detection and 68.6% for classification, and reduce the gap with supervised learning (56.5% and 78.2% respectively).},
archivePrefix = {arXiv},
arxivId = {1603.09246},
author = {Noroozi, Mehdi and Favaro, Paolo},
doi = {10.1007/978-3-319-46466-4_5},
eprint = {1603.09246},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Noroozi, Favaro - 2016 - Unsupervised learning of visual representations by solving jigsaw puzzles.pdf:pdf},
isbn = {9783319464657},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Feature transfer,Image representation learning,Self-supervised learning,Unsupervised learning},
pages = {69--84},
title = {{Unsupervised learning of visual representations by solving jigsaw puzzles}},
volume = {9910 LNCS},
year = {2016}
}
@article{Sharma2017a,
abstract = {Due to advancement of auto regulated powered wireless sensors systems; piezoelectric pulsation energy harvesters (PVEHs) have received a significant attention. Though, a popular of these devices has very low input frequencies. This paper seeks to analyze the current method to harness energy from vibration using piezoelectric setup in the low range of frequency zone and demonstrate an experiment model to validate the results from the setup. Many reviewers have given different modelling approach to optimize the performance parameter such as mass ratio, damping constant, frequency, load resistance, electromechanical coupling constant and capacitance etc. Finally, it has been found from experimentally and simulation that the maximum power harvested from the piezoelectric vibration setup depends upon the maximum deflection of the beam subjected to many dynamic constraint parameters such as inertia of the beam, maximum lift force due to wind, and lift drag characteristics curve etc.},
author = {Sharma, Pramod Kumar and Baredar, Prashant V.},
doi = {10.1016/j.jksus.2017.11.002},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sharma, Baredar - 2017 - Analysis on piezoelectric energy harvesting small scale device - a review.pdf:pdf},
issn = {10183647},
journal = {Journal of King Saud University - Science},
keywords = {Aeroleastic vibration,IDTE,MEMS,PZT,Reduced velocity},
publisher = {King Saud University},
title = {{Analysis on piezoelectric energy harvesting small scale device - a review}},
url = {https://doi.org/10.1016/j.jksus.2017.11.002},
year = {2017}
}
@article{Jaderberg2015a,
abstract = {Convolutional Neural Networks define an exceptionally powerful class of models, but are still limited by the lack of ability to be spatially invariant to the input data in a computationally and parameter efficient manner. In this work we introduce a new learnable module, the Spatial Transformer, which explicitly allows the spatial manipulation of data within the network. This differentiable module can be inserted into existing convolutional architectures, giving neural networks the ability to actively spatially transform feature maps, conditional on the feature map itself, without any extra training supervision or modification to the optimisation process. We show that the use of spatial transformers results in models which learn invariance to translation, scale, rotation and more generic warping, resulting in state-of-the-art performance on several benchmarks, and for a number of classes of transformations.},
archivePrefix = {arXiv},
arxivId = {1506.02025},
author = {Jaderberg, Max and Simonyan, Karen and Zisserman, Andrew and Kavukcuoglu, Koray},
doi = {10.1145/2948076.2948084},
eprint = {1506.02025},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jaderberg et al. - 2015 - Spatial Transformer Networks.pdf:pdf},
isbn = {9781450341363},
journal = {ACM International Conference Proceeding Series},
keywords = {Academic-personal competence,Authentic and focused presence,Body-related awareness,Contact quality in communicative interactions,Emotional reality,Participation,Sensations},
month = {jun},
pages = {45--48},
title = {{Spatial Transformer Networks}},
url = {http://arxiv.org/abs/1506.02025},
volume = {2},
year = {2015}
}
@article{Liu2016,
abstract = {Passive millimeter wave imaging often suffers from issues such as low resolution, noise, and blurring. In this study, a blind image restoration method for the passive millimeter-wave images (PMMW) is proposed. The purpose of the proposed method is to simultaneously solve the point spread function (PSF) and restoration image. In this method, the data fidelity item is constructed based on Gaussian noise assuming, and the regularization item is constructed as the hyper-Laplace function ||x||0.6, which is fitted according to the high-resolution PMMW images. Moreover, a data-selected matrix is proposed to select the regions that are helpful for estimating the accurate PSF. The proposed method has been applied to simulated and real PMMW image experiments. Comparative results demonstrate that the proposed method significantly outperforms the state-of-the-art deblurring methods on both qualitative and quantitative assessments. The proposed method improves the resolution of the PMMW image and makes it more preferable for object recognition.},
author = {Liu, Tingting and Chen, Zengzhao and Liu, Sanyan and Zhang, Zhaoli and Shu, Jiangbo},
doi = {10.1016/j.jvcir.2016.06.007},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2016 - Blind image restoration with sparse priori regularization for passive millimeter-wave images.pdf:pdf},
issn = {10959076},
journal = {Journal of Visual Communication and Image Representation},
keywords = {Blind image restoration,Image processing,Millimeter wave imaging,Regularization,Sparse priori},
pages = {58--66},
title = {{Blind image restoration with sparse priori regularization for passive millimeter-wave images}},
url = {http://dx.doi.org/10.1016/j.jvcir.2016.06.007},
volume = {40},
year = {2016}
}
@article{Kocak2017a,
abstract = {Within classic time series approaches, a time series model can be studied under 3 groups, namely AR (autoregressive model), MA (moving averages model) and ARMA (autoregressive moving averages model). On the other hand, solutions are based mostly on fuzzy AR time series models in the fuzzy time series literature. However, just a few fuzzy ARMA time series models have proposed until now. Fuzzy AR time series models have been divided into two groups named first order and high order models in the literature, highlighting the impact of model degree on forecast performance. However, model structure has been disregarded in these fuzzy AR models. Therefore, it is necessary to eliminate the model specification error arising from not utilizing of MA variables in the fuzzy time series approaches. For this reason, a new high order fuzzy ARMA(p,q) time series solution algorithm based on fuzzy logic group relations including fuzzy MA variables along with fuzzy AR variables has been proposed in this study. The main purpose of this article is to show that the forecast performance can be significantly improved when the deficiency of not utilizing MA variables. The other aim is also to show that the proposed method is better than the other fuzzy ARMA time series models in the literature from the point of forecast performance. Therefore, the new proposed method has been compared regarding forecast performance against some methods commonly used in literature by applying them on gold prices in Turkey, Istanbul Stock Exchange (IMKB) and the Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX).},
author = {Kocak, Cem},
doi = {10.1016/j.asoc.2017.04.021},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kocak - 2017 - ARMA(p,q) type high order fuzzy time series forecast method based on fuzzy logic relations.pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {Fuzzy ARMA models,Fuzzy autoregressive – moving avarage model,Fuzzy time series,Group relation table,High order fuzzy time series},
pages = {92--103},
publisher = {Elsevier B.V.},
title = {{ARMA(p,q) type high order fuzzy time series forecast method based on fuzzy logic relations}},
url = {http://dx.doi.org/10.1016/j.asoc.2017.04.021},
volume = {58},
year = {2017}
}
@article{Bertugli2020,
abstract = {In real-world applications, data do not reflect the ones commonly used for neural networks training, since they are usually few, unbalanced, unlabeled and can be available as a stream. Hence many existing deep learning solutions suffer from a limited range of applications, in particular in the case of online streaming data that evolve over time. To narrow this gap, in this work we introduce a novel and complex setting involving unsupervised meta-continual learning with unbalanced tasks. These tasks are built through a clustering procedure applied to a fitted embedding space. We exploit a meta-learning scheme that simultaneously alleviates catastrophic forgetting and favors the generalization to new tasks, even Out-of-Distribution ones. Moreover, to encourage feature reuse during the meta-optimization, we exploit a single inner loop taking advantage of an aggregated representation achieved through the use of a self-attention mechanism. Experimental results on few-shot learning benchmarks show competitive performance even compared to the supervised case. Additionally, we empirically observe that in an unsupervised scenario, the small tasks and the variability in the clusters pooling play a crucial role in the generalization capability of the network. Further, on complex datasets, the exploitation of more clusters than the true number of classes leads to higher results, even compared to the ones obtained with full supervision, suggesting that a predefined partitioning into classes can miss relevant structural information.},
archivePrefix = {arXiv},
arxivId = {2009.08107},
author = {Bertugli, Alessia and Vincenzi, Stefano and Calderara, Simone and Passerini, Andrea},
eprint = {2009.08107},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bertugli et al. - 2020 - Few-shot unsupervised continual learning through meta-examples.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {continual learning,few-shot learning,meta-examples,unsupervised learning},
mendeley-tags = {continual learning,few-shot learning,meta-examples,unsupervised learning},
number = {NeurIPS},
title = {{Few-shot unsupervised continual learning through meta-examples}},
year = {2020}
}
@article{Takase2014,
abstract = {This study seeks to investigate zirconia modified with KOH as heterogeneous solid base catalyst for transesterification of new non-edible, Silybum marianum (oil content 46%, FFA 0.68% and linoleic acid 65.68%) oil using methanol to biodiesel. Having screened the catalytic performance of ZrO2loaded with different K-compounds, 32% KOH loaded on ZrO2was chosen. The catalyst was prepared using incipient wetness impregnation method. Following drying (after impregnation) and calcination at 530 C for 5 h, the catalyst was characterized by means of Hammett indicators, XRD, FTIR, SEM, TGA and N2adsorption desorption measurements. It was found that the yield of the fatty acid methyl esters (FAME) was related to the catalyst base strength. The catalyst had granular and porous structures with high basicity and superior catalytic performance for the transesterification reaction. Maximum yield (90.8%) was obtained at 15:1 methanol to oil molar ratio, 6% catalyst amount, 60 C reaction temperature in 2 h. The catalyst maintained sustained activity after five times of usage. The oxidative stability and iodine value were the only unsuitable properties of the biodiesel (out of range) but can easily be improved. The cetane number, flash point and the cold flow properties among others were however, comparable to international standards. The study indicated that KOH(32%)/ZrO2-5 is an economically, suitable catalyst for producing biodiesel from S. marianum oil which is a potential new non-edible feedstock that can contribute positively to biodiesel industry as its biodiesel can be rated as promising alternate fuel. {\textcopyright} 2014 Elsevier Ltd. All rights reserved {\textcopyright} 2014 Elsevier B.V.},
author = {Takase, Mohammed and Zhang, Min and Feng, Weiwei and Chen, Yao and Zhao, Ting and Cobbina, Samuel J. and Yang, Liuqing and Wu, Xiangyang},
doi = {10.1016/j.enconman.2014.01.034},
isbn = {0196-8904},
issn = {01968904},
journal = {Energy Conversion and Management},
keywords = {Biodiesel,Heterogeneous catalyst,Non-edible oil,Transesterification,Zirconia},
pages = {117--125},
publisher = {Elsevier Ltd},
title = {{Application of zirconia modified with KOH as heterogeneous solid base catalyst to new non-edible oil for biodiesel}},
url = {http://dx.doi.org/10.1016/j.enconman.2014.01.034},
volume = {80},
year = {2014}
}
@article{Zadeh1975,
abstract = {By a linguistic variable we mean a variable whose values are words or sentences in a natural or artificial language. For example, Age is a linguistic variable if its values are linguistic rather than numerical, i.e.,young, not young, very young, quite young, old, not very old and not very young, etc., rather than 20, 21,22, 23, In more specific terms, a linguistic variable is characterized by a quintuple (L>, T(L), U,G,M) in which L is the name of the variable; T(L) is the term-set of L, that is, the collection of its linguistic values; U is a universe of discourse; G is a syntactic rule which generates the terms in T(L); and M is a semantic rule which associates with each linguistic value X its meaning, M(X), where M(X) denotes a fuzzy subset of U. The meaning of a linguistic value X is characterized by a compatibility function, c: U 0,1, which associates with each u in U its compatibility with X. Thus, the compatibility of age 27 with young might be 0.7, while that of 35 might be 0.2. The function of the semantic rule is to relate the compatibilities of the so-called primary terms in a composite linguistic value-e.g., young and old in not very young and not very old-to the compatibility of the composite value. To this end, the hedges such as very, quite, extremely, etc., as well as the connectives and and or are treated as nonlinear operators which modify the meaning of their operands in a specified fashion. The concept of a linguistic variable provides a means of approximate characterization of phenomena which are too complex or too ill-defined to be amenable to description in conventional quantitative terms. In particular, treating Truth as a linguistic variable with values such as true, very true, completely true, not very true, untrue, etc., leads to what is called fuzzy logic. By providing a basis for approximate reasoning, that is, a mode of reasoning which is not exact nor very inexact, such logic may offer a more realistic framework for human reasoning than the traditional two-valued logic. It is shown that probabilities, too, can be treated as linguistic variables with values such as likely, very likely, unlikely, etc. Computation with linguistic probabilities requires the solution of nonlinear programs and leads to results which are imprecise to the same degree as the underlying probabilities. The main applications of the linguistic approach lie in the realm of humanistic systems-especially in the fields of artificial intelligence, linguistics, human decision processes, pattern recognition, psychology, law, medical diagnosis, information retrieval, economics and related areas.},
author = {Zadeh, L.A.},
doi = {10.1007/978-1-4684-2106-4_1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zadeh - 1975 - The concept of a linguistic variable and its applications to approximate reasoning I.pdf:pdf},
isbn = {0020-0255},
issn = {00200255},
journal = {Information Sciences},
number = {4},
pages = {199--249},
title = {{The concept of a linguistic variable and its applications to approximate reasoning I}},
url = {http://www.eecs.berkeley.edu/$\sim$zadeh/papers/The Concept of a Linguistic Variable and its Applications to Approximate Reasoning I-1975.pdf},
volume = {8},
year = {1975}
}
@article{Lee2016,
abstract = {Speed optimization of liner vessels has significant economic and environmental impact for reducing fuel cost and Green House Gas (GHG) emission as the shipping over maritime logistics takes more than 70% of world transportation. While slow steaming is widely used as best practices for liner shipping companies, they are also under the pressure to maintain service level agreement (SLA) with their cargo clients. Thus, deciding optimal speed that minimizes fuel consumption while maintaining SLA is managerial decision problem. Studies in the literature use theoretical fuel consumption functions in their speed optimization models but these functions have limitations due to weather conditions in voyages. This paper uses weather archive data to estimate the real fuel consumption function for speed optimization problems. In particular, Copernicus data set is used as the source of big data and data mining technique is applied to identify the impact of weather conditions based on a given voyage route. Particle swarm optimization, a metaheuristic optimization method, is applied to find Pareto optimal solutions that minimize fuel consumption and maximize SLA. The usefulness of the proposed approach is verified through the real data obtained from a liner company and real world implications are discussed.},
author = {Lee, Habin and Aydin, Nursen and Choi, Youngseok and Lekhavat, Saowanit and Irani, Zahir},
doi = {10.1016/j.cor.2017.06.005},
issn = {03050548},
journal = {Computers and Operations Research},
keywords = {Liner shipping,Particle swarm optimization,Speed optimization,Sustainable maritime logistics,Weather archive data},
pages = {1--13},
publisher = {Elsevier Ltd},
title = {{A decision support system for vessel speed decision in maritime logistics using weather archive big data}},
url = {http://dx.doi.org/10.1016/j.cor.2017.06.005},
volume = {0},
year = {2016}
}
@article{Chen2019,
abstract = {Large-scale and multidimensional spatiotemporal data sets are becoming ubiquitous in many real-world applications such as monitoring urban traffic and air quality. Making predictions on these time series has become a critical challenge due to not only the large-scale and high-dimensional nature but also the considerable amount of missing data. In this paper, we propose a Bayesian temporal factorization (BTF) framework for modeling multidimensional time series—in particular spatiotemporal data—in the presence of missing values. By integrating low-rank matrix/tensor factorization and vector autoregressive (VAR) process into a single probabilistic graphical model, this framework can characterize both global and local consistencies in large-scale time series data. The graphical model allows us to effectively perform probabilistic predictions and produce uncertainty estimates without imputing those missing values. We develop efficient Gibbs sampling algorithms for model inference and test the proposed BTF framework on several real-world spatiotemporal data sets for both missing data imputation and short-term/long-term rolling prediction tasks. The numerical experiments demonstrate the superiority of the proposed BTF approaches over many state-of-the-art techniques.},
archivePrefix = {arXiv},
arxivId = {1910.06366},
author = {Chen, Xinyu and Sun, Lijun},
eprint = {1910.06366},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Sun - 2019 - Bayesian Temporal Factorization for Multidimensional Time Series Prediction.pdf:pdf},
journal = {arXiv},
keywords = {Bayesian inference,Markov chain Monte Carlo (MCMC),Matrix/tensor factorization,Missing data,Time series analysis,Vector autoregression (VAR),time series},
mendeley-tags = {time series},
pages = {1--13},
title = {{Bayesian Temporal Factorization for Multidimensional Time Series Prediction}},
url = {https://arxiv.org/pdf/1910.06366v1.pdf https://github.com/xinychen/transdim},
year = {2019}
}
@article{Dambrosio2017,
abstract = {The control problem of a wind system considered as an isolate source of power has been taken into account. The considered wind system is composed by a horizontal-axis wind-turbine connected to an induction generator. The proposed control algorithm relies on the fuzzy logic framework exploiting the knowledge of few steady state working conditions (control input controlled output value pairs). The fuzzy logic scheme, not only properly combines the knowledge within the working point data set, but it is also able to consider the controlled variable deviation (control tracking error) and its first time derivative.},
author = {Dambrosio, Lorenzo},
doi = {10.1016/j.egypro.2017.08.299},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dambrosio - 2017 - Data-based Fuzzy Logic Control Tenchnique Appied to a Wind System.pdf:pdf},
issn = {18766102},
journal = {Energy Procedia},
keywords = {control,fuzzy logic,wind system},
pages = {690--697},
publisher = {Elsevier B.V.},
title = {{Data-based Fuzzy Logic Control Tenchnique Appied to a Wind System}},
url = {https://doi.org/10.1016/j.egypro.2017.08.299},
volume = {126},
year = {2017}
}
@article{Huang2020b,
abstract = {Recent works seek to endow recognition systems with the ability to handle the open world. Few shot learning aims for fast learning of new classes from limited examples, while open-set recognition considers unknown negative class from the open world. In this paper, we study the problem of few-shot open-set recognition (FSOR), which learns a recognition system robust to queries from new sources with few examples and from unknown open sources. To achieve that, we mimic human capability of envisioning new concepts from prior knowledge, and propose a novel task-adaptive negative class envision method (TANE) to model the open world. Essentially we use an external memory to estimate a negative class representation. Moreover, we introduce a novel conjugate episode training strategy that strengthens the learning process. Extensive experiments on four public benchmarks show that our approach significantly improves the state-of-the-art performance on few-shot open-set recognition. Besides, we extend our method to generalized few-shot open-set recognition (GFSOR), where we also achieve performance gains on MiniImageNet.},
archivePrefix = {arXiv},
arxivId = {2012.13073},
author = {Huang, Shiyuan and Ma, Jiawei and Han, Guangxing and Chang, Shih-Fu},
eprint = {2012.13073},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang et al. - 2020 - Task-Adaptive Negative Class Envision for Few-Shot Open-Set Recognition.pdf:pdf},
keywords = {classification,few-shot learning,open-set recognition},
mendeley-tags = {classification,few-shot learning,open-set recognition},
title = {{Task-Adaptive Negative Class Envision for Few-Shot Open-Set Recognition}},
url = {http://arxiv.org/abs/2012.13073},
year = {2020}
}
@article{Liu2022,
author = {Liu, Yu and Hong, Xiaopeng and Tao, Xiaoyu and Dong, Songlin and Shi, Jingang and Gong, Yihong},
doi = {10.1109/TNNLS.2022.3144183},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2022 - Model Behavior Preserving for Class-Incremental Learning.pdf:pdf},
issn = {2162-237X},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {catastrophic forgetting,continual learning,continuous learning,incremental learning},
mendeley-tags = {continual learning},
pages = {1--12},
publisher = {IEEE},
title = {{Model Behavior Preserving for Class-Incremental Learning}},
url = {https://ieeexplore.ieee.org/document/9705128/},
year = {2022}
}
@article{Chellappa2011,
abstract = {Light exposure can cascade numerous effects on the human circadian process via the non-imaging forming system, whose spectral relevance is highest in the short-wavelength range. Here we investigated if commercially available compact fluorescent lamps with different colour temperatures can impact on alertness and cognitive performance.},
author = {Chellappa, Sarah Laxhmi and Steiner, Roland and Blattner, Peter and Oelhafen, Peter and G{\"{o}}tz, Thomas and Cajochen, Christian},
doi = {10.1371/journal.pone.0016429},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chellappa et al. - 2011 - Non-visual effects of light on melatonin, alertness and cognitive performance Can blue-enriched light keep us.pdf:pdf},
isbn = {1932-6203 (Electronic)\r1932-6203 (Linking)},
issn = {19326203},
journal = {PLoS ONE},
number = {1},
pmid = {21298068},
title = {{Non-visual effects of light on melatonin, alertness and cognitive performance: Can blue-enriched light keep us alert?}},
volume = {6},
year = {2011}
}
@article{Wiewel2021,
abstract = {Deep Neural Networks (DNNs) suffer from a rapid decrease in performance when trained on a sequence of tasks where only data of the most recent task is available. This phenomenon, known as catastrophic forgetting, prevents DNNs from accumulating knowledge over time. Overcoming catastrophic forgetting and enabling continual learning is of great interest since it would enable the application of DNNs in settings where unrestricted access to all the training data at any time is not always possible, e.g. due to storage limitations or legal issues. While many recently proposed methods for continual learning use some training examples for rehearsal, their performance strongly depends on the number of stored examples. In order to improve performance of rehearsal for continual learning, especially for a small number of stored examples, we propose a novel way of learning a small set of synthetic examples which capture the essence of a complete dataset. Instead of directly learning these synthetic examples, we learn a weighted combination of shared components for each example that enables a significant increase in memory efficiency. We demonstrate the performance of our method on commonly used datasets and compare it to recently proposed related methods and baselines.},
archivePrefix = {arXiv},
arxivId = {2102.09890},
author = {Wiewel, Felix and Yang, Bin},
eprint = {2102.09890},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wiewel, Yang - 2021 - Condensed Composite Memory Continual Learning.pdf:pdf},
keywords = {continual learning,generative replay,rehearsal,replay},
mendeley-tags = {continual learning,generative replay,rehearsal,replay},
title = {{Condensed Composite Memory Continual Learning}},
url = {http://arxiv.org/abs/2102.09890},
year = {2021}
}
@article{Robertson1982,
abstract = {Some new passive and active methods for reducing the effects of seismic disturbances on suspended masses are described, with special reference to gravitational radiation detectors in which differential horizontal motions of two or more suspended test masses are monitored. In these methods it is important to be able to determine horizontal seismic accelerations independent of tilts of the ground. Measurement of changes in inclination of the suspension wire of a test mass, relative to a direction defined by a reference arm of long period of oscillation, makes it possible to carry this out over the frequency range of interest for earth-based gravitational radiation detectors. The signal obtained can then be used to compensate for the effects of seismic disturbances on the test mass if necessary. Alternatively the signal corresponding to horizontal acceleration can be used to move the point from which the test mass is suspended in such a way as to reduce the effect of the seismic disturbance and also damp pendulum motions of the suspended test mass. Experimental work with an active anti-seismic system of this type is described.},
author = {Robertson, N a and Drever, R W P and Kerr, I and Hough, J},
doi = {10.1088/0022-3735/15/10/032},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Robertson et al. - 1982 - Demonstration of light recycling in a Michelson interferometer with Fabry-Perot cavities.pdf:pdf},
issn = {0022-3735},
journal = {Journal of Physics E: Scientific Instruments},
keywords = {coupled cavities,detection,fabry-perot,inteiferometry,light recycling,michelson,techniques for gravitational radiation},
number = {10},
pages = {1101--1105},
pmid = {20720772},
title = {{Demonstration of light recycling in a Michelson interferometer with Fabry-Perot cavities.}},
url = {http://stacks.iop.org/0022-3735/15/i=10/a=032},
volume = {15},
year = {1982}
}
@article{Richemond2020,
abstract = {Bootstrap Your Own Latent (BYOL) is a self-supervised learning approach for image representation. From an augmented view of an image, BYOL trains an online network to predict a target network representation of a different augmented view of the same image. Unlike contrastive methods, BYOL does not explicitly use a repulsion term built from negative pairs in its training objective. Yet, it avoids collapse to a trivial, constant representation. Thus, it has recently been hypothesized that batch normalization (BN) is critical to prevent collapse in BYOL. Indeed, BN flows gradients across batch elements, and could leak information about negative views in the batch, which could act as an implicit negative (contrastive) term. However, we experimentally show that replacing BN with a batch-independent normalization scheme (namely, a combination of group normalization and weight standardization) achieves performance comparable to vanilla BYOL ($73.9\%$ vs. $74.3\%$ top-1 accuracy under the linear evaluation protocol on ImageNet with ResNet-$50$). Our finding disproves the hypothesis that the use of batch statistics is a crucial ingredient for BYOL to learn useful representations.},
archivePrefix = {arXiv},
arxivId = {2010.10241},
author = {Richemond, Pierre H. and Grill, Jean-Bastien and Altch{\'{e}}, Florent and Tallec, Corentin and Strub, Florian and Brock, Andrew and Smith, Samuel and De, Soham and Pascanu, Razvan and Piot, Bilal and Valko, Michal},
eprint = {2010.10241},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Richemond et al. - 2020 - BYOL works even without batch statistics.pdf:pdf},
keywords = {boostraping,byol,self-supervised learning},
mendeley-tags = {boostraping,byol,self-supervised learning},
pages = {1--6},
title = {{BYOL works even without batch statistics}},
url = {http://arxiv.org/abs/2010.10241 https://github.com/lucidrains/byol-pytorch},
year = {2020}
}
@book{Uto2016,
abstract = {Shape-memory systems represent an exciting class of "smart" materials that possess the unique capability to change from a temporary distorted structure back to a memorized permanent shape upon application of an external stimulus. Though metallic shape-memory alloys have gained traction as solid-state alternatives to conventional actuators in the automotive and robotics industry, shape-memory polymers (SMPs) are a cheap and efficient alternative with a diverse number of applications in the biomedical sector. Building on a variety of polymeric SMPs that offer one-way control over material geometry, exciting new research in reversible shape-memory systems has dramatically expanded the complexity over which researchers can dictate dynamic material properties. Such spatiotemporal control over material geometry will prove invaluable in the promising fields of drug delivery, tissue engineering, and regenerative medicine. In this chapter, we examine a variety of soft SMP and supramolecular biomaterial systems from the viewpoint of materials nanoarchitectonics.},
author = {Uto, Koichiro and DeForest, Cole A. and Kim, Deok Ho},
booktitle = {Biomaterials Nanoarchitectonics},
doi = {10.1016/B978-0-323-37127-8.00014-5},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Uto, DeForest, Kim - 2016 - Soft Shape-Memory Materials.pdf:pdf},
isbn = {9780323371278},
keywords = {Actively moving biomaterials,Biodegradable polymers,Glass transition temperature,Melting temperature,Shape-memory alloys,Shape-memory composites,Shape-memory effect,Shape-memory polymers,Surface shape memory,Temperature-memory polymers,Tissue engineering},
pages = {237--251},
publisher = {Elsevier Inc.},
title = {{Soft Shape-Memory Materials}},
url = {http://dx.doi.org/10.1016/B978-0-323-37127-8/00014-5},
year = {2016}
}
@article{Yu2010,
abstract = {This paper reports the first development of the Levenberg-Marquardt algorithm for neural networks. It describes the theory and application of the algorithm, which trains neural networks at a rate 10 to 100 times faster than the usual gradient descent backpropagation method.},
author = {Yu, Hao and Bogdan, M},
doi = {10.1201/b10604-15},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu, Bogdan - 2010 - Levenberg–Marquardt Training.pdf:pdf},
isbn = {978-1-4398-0283-0},
pages = {1--16},
title = {{Levenberg–Marquardt Training}},
year = {2010}
}
@techreport{Tao,
abstract = {Given an input feature vector f ∈ F ⊆ R n , the neu-ral gas (NG) net matches it to the node j whose centroid m j ∈ R n has the minimum distance d(f , m j) to f. In our implementation, we simply use the Euclidean distance as the distance measure, which is written in the following L 2 norm form: d(f , m j) = f − m j 2. To train a NG net of N nodes on the base class data, we first extract the feature set F (1) from D (1). We initialize NG net by randomly selecting N feature vectors from F (1) as the initial centroid vectors of N nodes. The number of nodes is determined according to diversity of F (1). We ensure the number of NG nodes is larger than the number of classes, so that each class has at least one node for correspondence. Heuristically, we set N = 400 for all datasets. Each node is adapted to f using Eq. (3) in the main paper. For node r i whose rank is i, the contribution by the input vector f is measured using the decay function e −i/$\alpha$. That is, if node r i has a large rank i $\alpha$, its distance with the input d(f , m ri) is very large, and we neglect the adaptation to speed up the training. For this purpose, we can set $\alpha$ to a smaller value (e.g. $\alpha$ = 10 in our experiments.) This can reduce the time complexity of "sorting" from O(N log 2 N) to O(log 2 N). The topology-preserving mechanism is achieved by the competitive Hebbian learning, where a topological connection between node i and j is established and maintained, if the two nodes are always simultaneously response to the input (i.e., the nearest and second nearest to the input). The "age" of the connection a ij is used to record how long the two nodes have not been activated simultaneously. If a ij > T , the connection is removed. We set T = 200 for training on the base class data according to [8]. Noting that * Corresponding author if the number of training iterations is smaller, the value of T should be decreased to a smaller value, correspondingly.},
author = {Tao, Xiaoyu and Xiaopeng, Hong and Chang, Xinyuan and Dong, Songlin and Wei, Xing and Gong, Yihong},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tao et al. - Unknown - Supplementary Material for Few-Shot Class-Incremental Learning 1. Experimental Details 1.1. Setups and Explanatio.pdf:pdf},
title = {{Supplementary Material for Few-Shot Class-Incremental Learning 1. Experimental Details 1.1. Setups and Explanations of Neural Gas}}
}
@article{Zhou2019a,
abstract = {Object Detection has been a significant topic in computer vision. As the continuous development of Deep Learning, many advanced academic and industrial outcomes are established on localising and classifying the target objects, such as instance segmentation, video tracking and robotic vision. As the core concept of Deep Learning, Deep Neural Networks (DNNs) and associated training are highly integrated with task-driven modelling, having great effects on accurate detection. The main focus of improving detection performance is proposing DNNs with extra layers and novel topological connections to extract the desired features from input data. However, training these models can be computationally expensive and laborious progress as the complicated model architecture and enormous parameters. Besides, the dataset is another reason causing this issue and low detection accuracy, because of insufficient data samples or difficult instances. To address these training difficulties, this thesis presents two different approaches to improve the detection performance in the relatively light-weight way. As the intrinsic feature of data-driven in deep learning, the first approach is "slot-based image augmentation" to enrich the dataset with extra foreground and background combinations. Instead of the commonly used image flipping method, the proposed system achieved similar mAP improvement with less extra images which decrease training time. This proposed augmentation system has extra flexibility adapting to various scenarios and the performance-driven analysis provides an alternative aspect of conducting image augmentation},
archivePrefix = {arXiv},
arxivId = {1907.12900},
author = {Zhou, Yingwei},
eprint = {1907.12900},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou - 2019 - Slot Based Image Augmentation System for Object Detection.pdf:pdf},
title = {{Slot Based Image Augmentation System for Object Detection}},
url = {http://arxiv.org/abs/1907.12900},
year = {2019}
}
@article{Rotich2012,
abstract = {In this master's thesis, wind speeds and directions were modeled with the aim of developing suitable models for hourly, daily, weekly and monthly forecasting. Artificial Neural Networks implemented in MATLAB software were used to perform the forecasts. Three main types of artificial neural network were built, namely: Feed forward neural networks, Jordan Elman neural networks and Cascade forward neural networks. Four sub models of each of these neural networks were also built, corresponding to the four forecast horizons, for both wind speeds and directions. A single neural network topology was used for each of the forecast horizons, regardless of the model type. All the models were then trained with real data of wind speeds and directions collected over a period of two years in the municipal region of Puumala in Finland. Only 70% of the data was used for training, validation and testing of the models, while the second last 15% of the data was presented to the trained models for verification. The model outputs were then compared to the last 15% of the original data, by measuring the mean square errors and sum square errors between them. Based on the results, the feed forward networks returned the lowest generalization errors for hourly, weekly and monthly forecasts of wind speeds; Jordan Elman networks returned the lowest errors when used for forecasting of daily wind speeds. Cascade forward networks gave the lowest errors when used for forecasting daily, weekly and monthly wind directions; Jordan Elman networks returned the lowest errors when used for hourly forecasting. The errors were relatively low during training of the models, but shot up upon simulation with new inputs. In addition, a combination of hyperbolic tangent transfer functions for both hidden and output layers returned better results compared to other combinations of transfer functions. In general, wind speeds were more predictable as compared to wind directions, opening up opportunities for further research into building better models for wind direction forecasting.},
author = {Rotich, Nicolus},
pages = {1--59},
title = {{Forecasting of wind speeds and directions with artificial neural networks}},
url = {http://www.doria.fi/handle/10024/98414},
year = {2012}
}
@article{MARQUES2016,
abstract = {With the demand in the production at large-scale food, confinement of animals has become a necessity of the productive process because of the increase in production capacity and optimization of the spaces reserved for creations. In this context, the aim of this study was the development and validation of models using fuzzy logic for predicting climate indices and productive performance of European quails kept in a climatic chamber. The model developed was analyzed from two points of view; the first one took into account the prediction of climate indexes where the input variables were the temperature (°C) and relative humidity (%) of the air. In the second, related to the prediction of productive performance, the input variables were air temperature (°C) and age of the birds (weeks) while the output variables were the food intake (FI, g), water consumption (WC, g), weight gain (WG, g) and food conversion (FC g g-1) of the birds. The Mamdani method was used for the preparation of the rules, and in the defuzzification was applied the center of gravity method. Based on the results generated by the models and compared with the experimental data it was obtained coefficients of determination (R1) of: 0.9771; 0.9897; 0.9955; 0.9995; 0.9993 and 0.9788, for BGTHI, RTL, WC, FI, WG and FC, respectively.},
author = {MARQUES, JORD{\^{A}}NIO I. and {LOPES NETO}, JOS{\'{E}} P. and LOPES, FERNANDA F. DE M. and FURTADO, DERMEVAL A. and ARA{\'{U}}JO, TIAGO G. P.},
doi = {10.1590/1809-4430-Eng.Agric.v36n4p604-612/2016},
issn = {0100-6916},
journal = {Engenharia Agr{\'{i}}cola},
keywords = {coturniculture,environmental quality,fuzzy logic,productivity},
number = {4},
pages = {604--612},
title = {{Fuzzy modeling in the prediction of climate indices and productive performance of quails kept in climate chamber}},
url = {http://www.scielo.br/scielo.php?script=sci_arttext&pid=S0100-69162016000400604&lng=en&tlng=en},
volume = {36},
year = {2016}
}
@article{Schrittwieser2019,
abstract = {Constructing agents with planning capabilities has long been one of the main challenges in the pursuit of artificial intelligence. Tree-based planning methods have enjoyed huge success in challenging domains, such as chess and Go, where a perfect simulator is available. However, in real-world problems the dynamics governing the environment are often complex and unknown. In this work we present the MuZero algorithm which, by combining a tree-based search with a learned model, achieves superhuman performance in a range of challenging and visually complex domains, without any knowledge of their underlying dynamics. MuZero learns a model that, when applied iteratively, predicts the quantities most directly relevant to planning: the reward, the action-selection policy, and the value function. When evaluated on 57 different Atari games - the canonical video game environment for testing AI techniques, in which model-based planning approaches have historically struggled - our new algorithm achieved a new state of the art. When evaluated on Go, chess and shogi, without any knowledge of the game rules, MuZero matched the superhuman performance of the AlphaZero algorithm that was supplied with the game rules.},
archivePrefix = {arXiv},
arxivId = {1911.08265},
author = {Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and Lillicrap, Timothy and Silver, David},
eprint = {1911.08265},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schrittwieser et al. - 2019 - Mastering atari, go, chess and shogi by planning with a learned model.pdf:pdf},
journal = {arXiv},
keywords = {games,reinforcement learning},
mendeley-tags = {games,reinforcement learning},
pages = {1--21},
title = {{Mastering atari, go, chess and shogi by planning with a learned model}},
url = {https://arxiv.org/pdf/1911.08265.pdf https://github.com/werner-duvaud/muzero-general?fbclid=IwAR0pIEAxKlAKw00nJ9GafCQV4_Cr-yWpZoxOE3TOwVScl148koh2Yqrp0v4},
year = {2019}
}
@article{Khosravi2018a,
abstract = {In this study, three models of machine learning algorithms are implemented to predict wind speed, wind direction and output power of a wind turbine. The first model is multilayer feed-forward neural network (MLFFNN) that is trained with different data training algorithms. The second model is support vector regression with a radial basis function (SVR-RBF). The third model is adaptive neuro-fuzzy inference system (ANFIS) that is optimized with a partial swarm optimization algorithm (ANFIS-PSO). Temperature, pressure, relative humidity and local time are considered as input variables of the models. A large set of wind speed and wind direction data measured at 5-min, 10-min, 30-min and 1-h intervals are utilized to accurately predict wind speed and its direction for Bushehr. Energy and exergy analysis of wind energy for a wind turbine (E-44, 900 kW) is done. Also, the developed models are used to predict the output power of the wind turbine. Comparison of the statistical indices for the predicted and actual data indicate that the SVR-RBF model outperforms the MLFFNN and ANFIS-PSO models. Also, the current energy and exergy analysis presents an average of 32% energy efficiency and approximately 25% exergy efficiency of the wind turbine in the study region.},
author = {Khosravi, A. and Koury, R. N.N. and Machado, L. and Pabon, J. J.G.},
doi = {10.1016/j.seta.2018.01.001},
issn = {22131388},
journal = {Sustainable Energy Technologies and Assessments},
keywords = {ANFIS,Partial swarm optimization,Support vector regression,Wind direction,Wind energy},
number = {December 2017},
pages = {146--160},
publisher = {Elsevier},
title = {{Prediction of wind speed and wind direction using artificial neural network, support vector regression and adaptive neuro-fuzzy inference system}},
url = {https://doi.org/10.1016/j.seta.2018.01.001},
volume = {25},
year = {2018}
}
@article{Ebrahimi2020b,
abstract = {Active learning aims to develop label-efficient algorithms by querying the most representative samples to be labeled by a human annotator. Current active learning techniques either rely on model uncertainty to select the most uncertain samples or use clustering or reconstruction to choose the most diverse set of unlabeled examples. While uncertainty-based strategies are susceptible to outliers, solely relying on sample diversity does not capture the information available on the main task. In this work, we develop a semi-supervised minimax entropy-based active learning algorithm that leverages both uncertainty and diversity in an adversarial manner. Our model consists of an entropy minimizing feature encoding network followed by an entropy maximizing classification layer. This minimax formulation reduces the distribution gap between the labeled/unlabeled data, while a discriminator is simultaneously trained to distinguish the labeled/unlabeled data. The highest entropy samples from the classifier that the discriminator predicts as unlabeled are selected for labeling. We extensively evaluate our method on various image classification and semantic segmentation benchmark datasets and show superior performance over the state-of-the-art methods.},
archivePrefix = {arXiv},
arxivId = {2012.10467},
author = {Ebrahimi, Sayna and Gan, William and Salahi, Kamyar and Darrell, Trevor},
eprint = {2012.10467},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ebrahimi et al. - 2020 - Minimax Active Learning.pdf:pdf},
keywords = {active learning,optimization},
mendeley-tags = {active learning,optimization},
title = {{Minimax Active Learning}},
url = {http://arxiv.org/abs/2012.10467 https://people.eecs.berkeley.edu/%0A˜sayna/mal.html},
year = {2020}
}
@article{Wang2020d,
abstract = {Graph neural networks (GNNs) have achieved strong performance in various applications. In the real world, network data is usually formed in a streaming fashion. The distributions of patterns that refer to neighborhood information of nodes may shift over time. The GNN model needs to learn the new patterns that cannot yet be captured. But learning incrementally leads to the catastrophic forgetting problem that historical knowledge is overwritten by newly learned knowledge. Therefore, it is important to train GNN model to learn new patterns and maintain existing patterns simultaneously, which few works focus on. In this paper, we propose a streaming GNN model based on continual learning so that the model is trained incrementally and up-to-date node representations can be obtained at each time step. Firstly, we design an approximation algorithm to detect new coming patterns efficiently based on information propagation. Secondly, we combine two perspectives of data replaying and model regularization for existing pattern consolidation. Specially, a hierarchy-importance sampling strategy for nodes is designed and a weighted regularization term for GNN parameters is derived, achieving greater stability and generalization of knowledge consolidation. Our model is evaluated on real and synthetic data sets and compared with multiple baselines. The results of node classification prove that our model can efficiently update model parameters and achieve comparable performance to model retraining. In addition, we also conduct a case study on the synthetic data, and carry out some specific analysis for each part of our model, illustrating its ability to learn new knowledge and maintain existing knowledge from different perspectives.},
archivePrefix = {arXiv},
arxivId = {2009.10951},
author = {Wang, Junshan and Song, Guojie and Wu, Yi and Wang, Liang},
doi = {10.1145/3340531.3411963},
eprint = {2009.10951},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2020 - Streaming Graph Neural Networks via Continual Learning.pdf:pdf},
isbn = {9781450368599},
keywords = {2020,acm reference format,and liang wang,continual learning,graph neural networks,guojie song,junshan wang,streaming graph,streaming networks,yi wu},
pages = {1515--1524},
title = {{Streaming Graph Neural Networks via Continual Learning}},
url = {http://arxiv.org/abs/2009.10951%0Ahttp://dx.doi.org/10.1145/3340531.3411963},
year = {2020}
}
@article{Guo2017b,
abstract = {To harness renewable energy in the transportation sector,research on the application of thermoelectric and piezoelectric effects in energy harvesting pavements has progressed significantly over the last few years. This study provides a comprehensive literature review of recent advances in the application of thermoelectric and piezoelectric technologies in pavements to generate electricity. Most studies on the piezoelectric effect application with piezoelectric transducers (PZTs) showed its limitation in the amount of instantaneous electricity output, while a limited number of studies indicated that a pipe system cooperating with a thermoelectric generator (TEG) may produce more electric power, and so has more application potential in energy harvesting pavements. Studies have also indicated that supercapacitors and rechargeable batteries will be needed to appropriately store the electricity generated from pavements. As a case study, the potentials of thermoelectric and piezoelectric technologies were assessed and compared based on the Florida roadway network. Using results from previous studies as well as Florida weather and traffic data, it was estimated that if the entire Florida roadway network was covered by a proposed pipe system (PP-TEG system), it would collect 55 GWh electrical energy per day, while the one covered by a series of PZTs (PZT system) would only generate 4.04 MWh electrical energy per day. Based on the cost effectiveness analysis of the two systems, unless the PZT system is only paved on the roadway section with very high traffic volume, the PP-TEG system is more cost-effective than the PZT system.},
author = {Guo, Lukai and Lu, Qing},
doi = {10.1016/j.rser.2017.01.090},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guo, Lu - 2017 - Potentials of piezoelectric and thermoelectric technologies for harvesting energy from pavements.pdf:pdf},
isbn = {8133908140},
issn = {18790690},
journal = {Renewable and Sustainable Energy Reviews},
keywords = {Energy harvesting pavement,GIS,Piezoelectric,Thermoelectric},
number = {November 2016},
pages = {761--773},
publisher = {Elsevier},
title = {{Potentials of piezoelectric and thermoelectric technologies for harvesting energy from pavements}},
url = {http://dx.doi.org/10.1016/j.rser.2017.01.090},
volume = {72},
year = {2017}
}
@article{Cb2010,
abstract = {R.E. Kalman: Lectures on controllability and observability.- E. Kulikowski:\nControllability and optimum contro.- A. Straszak: Supervisory controllabilityl.-\nL. Weiss: Lectures on controllability and observability.},
author = {Cb, Epda},
doi = {10.1115/1.3153679},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cb - 2010 - Controllability and Observability.pdf:pdf},
isbn = {0-13-134116-2},
issn = {1520-5215},
journal = {Analysis and Design of Descriptor Linear Systems},
number = {0},
pages = {1--27},
pmid = {18307326},
title = {{Controllability and Observability}},
year = {2010}
}
@article{Nasional2016,
author = {Nasional, Seminar and Informasi, Teknologi and Bangun, Rancang and Informasi, Sistem and Fitur, Dengan and Relationship, Customer and Pada, Management and Bhakti, Koperasi and Maria, Husada and Rumba, Florentina and Wisnubhadra, Irya and Rahayu, Sapty and Teknik, Magister and Universitas, Informatika and Jaya, Atma and Jl, Yogyakarta and Ph, Indonesia and Koperasi, Abstraks and Negeri, Pegawai and Husada, Bhakti and Sikka, Kabupaten and Usaha, Koperasi Serba and Menengah, Usaha Kecil and Sikka, Kabupaten and Husada, K P N Bhakti and Kunci, Kata and Informasi, Sistem and Management, Customer Relationship},
doi = {10.7537/marsnsj141016.18.Keywords},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nasional et al. - 2016 - 3 1,2,3.pdf:pdf},
keywords = {cooperative,customer relationship management,information system},
number = {Sentika},
pages = {18--19},
title = {3 1,2,3},
volume = {2016},
year = {2016}
}
@book{Uchino2017c,
author = {Uchino, K.},
booktitle = {Advanced Piezoelectric Materials},
doi = {10.1016/B978-0-08-102135-4.00001-1},
edition = {2},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Uchino - 2017 - The Development of Piezoelectric Materials and the New Perspective.pdf:pdf},
isbn = {978-0-08-102135-4},
keywords = {Barium titanate,Electromechanical coupling factor.,Lead zirconate titanate,Pb-free piezoelectrics,Piezoelectric material,Quartz,Relaxor ferroelectrics,Rochelle salt,barium titanate,electromechanical,lead,pb-free piezoelectrics,piezoelectric material,quartz,relaxor ferroelectrics,rochelle salt,zirconate titanate},
pages = {1--92},
publisher = {Elsevier Ltd.},
title = {{The Development of Piezoelectric Materials and the New Perspective}},
url = {http://linkinghub.elsevier.com/retrieve/pii/B9780081021354000011},
year = {2017}
}
@book{Abraham2017,
abstract = {Rheological analysis of materials provides an overview of their microstructure and their potential property enhancement. In this chapter, we present a comprehensive analysis of rheological characteristics of various systems such as nanofluids, aggregates or agglomerates of nanoparticles, gels, nanofiber suspensions, nanoparticle-polymer suspensions, and various polymer nanocomposites. So the present chapter is then dedicated to the state of the art on the rheology of polymer nanocomposites.},
author = {Abraham, J. and Sharika, T. and Mishra, Raghvendra Kumar and Thomas, Sabu},
booktitle = {Micro and Nano Fibrillar Composites (MFCs and NFCs) from Polymer Blends},
doi = {10.1016/B978-0-08-101991-7.00014-5},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abraham et al. - 2017 - Rheological characteristics of nanomaterials and nanocomposites.pdf:pdf},
isbn = {9780081019924},
keywords = {Nanocomposites,Nanofluids,Nanoparticles,Rheology,Shear thinning,Viscoelastic},
pages = {327--350},
publisher = {Elsevier Ltd.},
title = {{Rheological characteristics of nanomaterials and nanocomposites}},
url = {http://dx.doi.org/10.1016/B978-0-08-101991-7.00014-5},
year = {2017}
}
@article{Angalaeswari2017,
abstract = {The exponential increase in electrical energy demand in the current scenario makes the world to turn towards the use of renewable energy sources naturally. The best way to utilize the renewable energy sources is in the form of microgrid. Microgrids are having multiple distributed energy sources and energy storage elements located nearer to the consumer. This paper implements a Fuzzy Logic Controller that efficiently manages the loads in a grid operated Microgrid. In this paper, maximum power point tracking (MPPT) with fuzzy logic controller is used for a grid operated microgrid constituted by solar system and battery. The system consists of Photo Voltaic (PV) system with MPPT controller, Battery with Buck boost converter, Inverter, critical and non-critical loads and utility grid. The simulation results prove that the efficiency of the fuzzy logic controller for different irradiation level with different load conditions has been improved.},
author = {Angalaeswari, S. and Swathika, O. V.Gnana and Ananthakrishnan, V. and Daya, J. L.Febin and Jamuna, K.},
doi = {10.1016/j.egypro.2017.05.131},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Angalaeswari et al. - 2017 - Efficient Power Management of Grid operated MicroGrid Using Fuzzy Logic Controller (FLC).pdf:pdf},
issn = {18766102},
journal = {Energy Procedia},
keywords = {Battery,Fuzzy logic controller (FLC),Microgrid,PV system},
pages = {268--274},
publisher = {Elsevier B.V.},
title = {{Efficient Power Management of Grid operated MicroGrid Using Fuzzy Logic Controller (FLC)}},
url = {http://dx.doi.org/10.1016/j.egypro.2017.05.131},
volume = {117},
year = {2017}
}
@article{Yosinski2014,
abstract = {Many deep neural networks trained on natural images exhibit a curious phenomenon in common: on the first layer they learn features similar to Gabor filters and color blobs. Such first-layer features appear not to be specific to a particular dataset or task, but general in that they are applicable to many datasets and tasks. Features must eventually transition from general to specific by the last layer of the network, but this transition has not been studied extensively. In this paper we experimentally quantify the generality versus specificity of neurons in each layer of a deep convolutional neural network and report a few surprising results. Trans-ferability is negatively affected by two distinct issues: (1) the specialization of higher layer neurons to their original task at the expense of performance on the target task, which was expected, and (2) optimization difficulties related to splitting networks between co-adapted neurons, which was not expected. In an example network trained on ImageNet, we demonstrate that either of these two issues may dominate, depending on whether features are transferred from the bottom, middle, or top of the network. We also document that the transferability of features decreases as the distance between the base task and target task increases, but that transferring features even from distant tasks can be better than using random features. A final surprising result is that initializing a network with transferred features from almost any number of layers can produce a boost to generalization that lingers even after fine-tuning to the target dataset.},
archivePrefix = {arXiv},
arxivId = {1411.1792},
author = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
eprint = {1411.1792},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yosinski et al. - 2014 - How transferable are features in deep neural networks.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
keywords = {transfer learning},
mendeley-tags = {transfer learning},
number = {January},
pages = {3320--3328},
title = {{How transferable are features in deep neural networks?}},
volume = {4},
year = {2014}
}
@article{Crompton2018,
abstract = {Mobile device ownership has exploded with the majority of adults owning more than one mobile device. The largest demographic of mobile device users are 18–29 years old which is also the typical age of college attendees. This systematic review provides the scholarly community with a current synthesis of mobile learning research across 2010–2016 in higher education settings regarding the purposes, outcomes, methodologies, subject matter domains, educational level, educational context, device types and geographical distribution of studies. Major findings include that the majority of the studies focused on the impact of mobile learning on student achievement. Language instruction was the most often researched subject matter domain. The findings reveal that 74% involved undergraduate students and 54% took place in a formal educational context. Higher education faculty are encouraged to consider the opportunity to expand their learning possibilities beyond the classroom with mobile learning.},
author = {Crompton, Helen and Burke, Diane},
doi = {10.1016/j.compedu.2018.04.007},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Crompton, Burke - 2018 - The use of mobile learning in higher education A systematic review.pdf:pdf},
isbn = {9781522507840},
issn = {03601315},
journal = {Computers and Education},
keywords = {Cell phones,Higher education,Mlearning,Mobile learning,Tertiary},
pages = {53--64},
publisher = {Elsevier Ltd},
title = {{The use of mobile learning in higher education: A systematic review}},
url = {https://doi.org/10.1016/j.compedu.2018.04.007},
volume = {123},
year = {2018}
}
@article{Haque2017,
abstract = {Cancer is a group of diseases responsible for the major causes of mortality and morbidity among people of all ages. Even though medical sciences have made enormous growth, complete treatment of this deadly disease is still a challenging task. Last few decades witnessed an impressive growth in the design and development of near infrared (NIR) fluorophores with and without recognition moieties for molecular recognitions, imaging and image guided surgeries. The present article reviews recently reported NIR emitting organic/inorganic fluorophores that targets and accumulates in organelle/organs specifically for molecular imaging of cancerous cells. Near infrared (NIR probe) with or without a tumor-targeting warhead have been considered and discussed for their applications in the field of cancer imaging. In addition, challenges persist in this area are also delineated in this review.},
author = {Haque, Ashanul and Faizi, Md Serajul Haque and Rather, Jahangir Ahmad and Khan, Muhammad S.},
doi = {10.1016/j.bmc.2017.02.061},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Haque et al. - 2017 - Next generation NIR fluorophores for tumor imaging and fluorescence-guided surgery A review.pdf:pdf},
isbn = {0968-0896},
issn = {14643391},
journal = {Bioorganic and Medicinal Chemistry},
keywords = {Cancer,Near infrared-I/II,Targeted imaging},
number = {7},
pages = {2017--2034},
pmid = {28284863},
title = {{Next generation NIR fluorophores for tumor imaging and fluorescence-guided surgery: A review}},
url = {http://dx.doi.org/10.1016/j.bmc.2017.02.061},
volume = {25},
year = {2017}
}
@article{Lee2017,
abstract = {We present an unsupervised representation learning approach using videos without semantic labels. We leverage the temporal coherence as a supervisory signal by formulating representation learning as a sequence sorting task. We take temporally shuffled frames (i.e., in non-chronological order) as inputs and train a convolutional neural network to sort the shuffled sequences. Similar to comparison-based sorting algorithms, we propose to extract features from all frame pairs and aggregate them to predict the correct order. As sorting shuffled image sequence requires an understanding of the statistical temporal structure of images, training with such a proxy task allows us to learn rich and generalizable visual representation. We validate the effectiveness of the learned representation using our method as pre-training on high-level recognition problems. The experimental results show that our method compares favorably against state-of-the-art methods on action recognition, image classification, and object detection tasks.},
archivePrefix = {arXiv},
arxivId = {1708.01246},
author = {Lee, Hsin Ying and Huang, Jia Bin and Singh, Maneesh and Yang, Ming Hsuan},
doi = {10.1109/ICCV.2017.79},
eprint = {1708.01246},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee et al. - 2017 - Unsupervised Representation Learning by Sorting Sequences.pdf:pdf},
isbn = {9781538610329},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {667--676},
title = {{Unsupervised Representation Learning by Sorting Sequences}},
volume = {2017-Octob},
year = {2017}
}
@article{Iba1993,
abstract = {This paper presents a new approach to optimal reactive power\nplanning based on a genetic algorithm. Many outstanding methods to this\nproblem have been proposed in the past. However, most of these\napproaches have the common defect of being caught to a local minimum\nsolution. The integer problem which yields integer value solutions for\ndiscrete controllers/banks still remain as a difficult one. The genetic\nalgorithm is a kind of search algorithm based on the use of natural\nselection and genetics. This can search for a global solution using a\nmultiple path and treat the integer problem naturally. The proposed\nmethod was applied to practical 51-bus and 224-bus systems to show its\nfeasibility and capabilities. Although this method is not as fast as\nsophisticated traditional methods, the concept is quite promising and\nuseful},
author = {Iba, K.},
doi = {10.1109/PICA.1993.291017},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Iba - 1993 - Reactive power optimization by genetic algorithm.pdf:pdf},
isbn = {0-7803-1301-1},
journal = {Conference Proceedings Power Industry Computer Application Conference},
pages = {1--6},
title = {{Reactive power optimization by genetic algorithm}},
year = {1993}
}
@article{WolfgangLehmacher2017,
author = {{Wolfgang Lehmacher} and Betti, Francisco and {Beecher Paul} and Grotemeier, Christian and Lorenzen, Maike},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wolfgang Lehmacher et al. - 2017 - Impact of the Fourth Industrial Revolution on Supply Chains.pdf:pdf},
number = {October},
pages = {22},
title = {{Impact of the Fourth Industrial Revolution on Supply Chains}},
year = {2017}
}
@inproceedings{awasthi2019a,
abstract = {Continual learning broadly refers to the algorithms which aim to learn continuously over time across varying domains, tasks or data distributions. This is in contrast to algorithms restricted to learning a fixed number of tasks in a given domain, assuming a static data distribution. In this survey we aim to discuss a wide breadth of challenges faced in a continual learning setup and review existing work in the area. We discuss parameter regularization techniques to avoid catastrophic forgetting in neural networks followed by memory based approaches and the role of generative models in assisting continual learning algorithms. We discuss how dynamic neural networks assist continual learning by endowing neural networks with a new capacity to learn further. We conclude by discussing possible future directions.},
author = {Awasthi, Abhijeet and Sarawagi, Sunita},
booktitle = {Proceedings of the ACM India Joint International Conference on Data Science and Management of Data},
doi = {10.1145},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Awasthi, Sarawagi - 2019 - Continual Learning with Neural Networks A Review.pdf:pdf},
keywords = {continual learning,incremental learning,neural networks,review,survey},
mendeley-tags = {continual learning,incremental learning,neural networks,review,survey},
pages = {362--365},
title = {{Continual Learning with Neural Networks: A Review}},
url = {https://dl.acm.org/doi/pdf/10.1145/3297001.3297062},
year = {2019}
}
@article{Iandola2016,
abstract = {Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet). The SqueezeNet architecture is available for download here: https://github.com/DeepScale/SqueezeNet},
archivePrefix = {arXiv},
arxivId = {1602.07360},
author = {Iandola, Forrest N. and Han, Song and Moskewicz, Matthew W. and Ashraf, Khalid and Dally, William J. and Keutzer, Kurt},
eprint = {1602.07360},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Iandola et al. - 2016 - SqueezeNet AlexNet-level accuracy with 50x fewer parameters and 0.5MB model size.pdf:pdf},
pages = {1--13},
title = {{SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size}},
url = {http://arxiv.org/abs/1602.07360},
year = {2016}
}
@article{Cohen1988,
abstract = {A research paper includes several sections, each section having a particular purpose and containing a particular kind of information. This paper is a guide to reading a research paper. It describes the prototypical research paper and explains the purpose for each section. Issues for the astute reader to note are indicated and illustrated with examples from a research paper published in this issue of the journal.},
author = {Cohen, H.},
doi = {10.5014/ajot.42.9.596},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cohen - 1988 - How to read a research paper.pdf:pdf},
issn = {02729490},
journal = {The American journal of occupational therapy. : official publication of the American Occupational Therapy Association},
number = {9},
pages = {596--600},
pmid = {3189491},
title = {{How to read a research paper.}},
volume = {42},
year = {1988}
}
@article{He2021a,
abstract = {Both brain science and the deep learning communities have the problem of interpreting neural activity. For deep learning, even though we can access all neurons' activity data, interpretation of how the deep network solves the task is still challenging. Although a large amount of effort has been devoted to interpreting a deep network, there is still no consensus of what interpretation is. This paper tries to push the discussion in this direction and proposes an information-theoretic progressive framework to synthesize interpretation. Firstly, we discuss intuitions of interpretation: interpretation is meta-information; interpretation should be at the right level; inducing independence is helpful to interpretation; interpretation is naturally progressive; interpretation doesn't have to involve a human. Then, we build the framework with an information map splitting idea and implement it with the variational information bottleneck technique. After that, we test the framework with the CLEVR dataset. The framework is shown to be able to split information maps and synthesize interpretation in the form of meta-information.},
archivePrefix = {arXiv},
arxivId = {2101.02879},
author = {He, Zhengqi and Toyoizumi, Taro},
eprint = {2101.02879},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/He, Toyoizumi - 2021 - An Information-theoretic Progressive Framework for Interpretation.pdf:pdf},
keywords = {interpretable AI},
mendeley-tags = {interpretable AI},
title = {{An Information-theoretic Progressive Framework for Interpretation}},
url = {http://arxiv.org/abs/2101.02879},
year = {2021}
}
@article{Fairburn2017,
abstract = {The psychological treatment of mental health problems is beginning to undergo a sea-change driven by the widespread availability of digital technology. In this paper we provide an overview of the developments to date and those in the pipeline. We describe the various uses of digital interventions and consider their likely impact on clinical practice, clinical services and the global dissemination of psychological treatments. We note the importance of online clinics, blended treatment, digital assessment and digital training.},
author = {Fairburn, Christopher G. and Patel, Vikram},
doi = {10.1016/j.brat.2016.08.012},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fairburn, Patel - 2017 - The impact of digital technology on psychological treatments and their dissemination.pdf:pdf},
isbn = {0005-7967},
issn = {1873622X},
journal = {Behaviour Research and Therapy},
keywords = {Blended treatment,Digital health,Digital technology,Dissemination,Internet,Psychological treatment,Training},
pages = {19--25},
pmid = {28110672},
publisher = {Elsevier Ltd},
title = {{The impact of digital technology on psychological treatments and their dissemination}},
url = {http://dx.doi.org/10.1016/j.brat.2016.08.012},
volume = {88},
year = {2017}
}
@inproceedings{Cha_2021_ICCV,
author = {{Cha, Hyuntak and Lee, Jaeho and Shin}, Jinwoo},
booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
file = {:home/user/Cha_Co2L_Contrastive_Continual_Learning_ICCV_2021_paper.pdf:pdf},
keywords = {continual learning,contrastive learning,metric learning},
mendeley-tags = {continual learning,contrastive learning,metric learning},
pages = {9516--9525},
title = {{Co2L: Contrastive Continual Learning}},
year = {2021}
}
@article{Vaswani2017,
abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
archivePrefix = {arXiv},
arxivId = {1706.03762},
author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
eprint = {1706.03762},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vaswani et al. - 2017 - Attention Is All You Need.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
month = {jun},
title = {{Attention Is All You Need}},
url = {http://arxiv.org/abs/1706.03762 https://github.com/tensorflow/tensor2tensor},
volume = {2017-Decem},
year = {2017}
}
@article{Hassan2017,
abstract = {{\textcopyright} 2017 IEEE. Learning of fuzzy parameters for system modeling using evolutionary algorithms is an interesting topic. In this paper, two optimal design and tuning of Interval type-2 fuzzy logic system are proposed using hybrid learning algorithms. The consequent parameters of the interval type-2 fuzzy logic system in both the hybrid algorithms are tuned using Kalman filter. Whereas the antecedent parameters of the system in the first hybrid algorithm is optimized using the multi-objective particle swarm optimization (MOPSO) and using the multi-objective evolutionary algorithm Based on Decomposition (MOEA/D) in the second hybrid algorithm. Root mean square error and maximum absolute error as the two accuracy objective are utilized to find the Pareto-optimal solution with the MOPSO and MOEA/D respectively. The proposed hybrid multi-objective designs of the interval type-2 fuzzy logic system are utilized to the prediction of solar photovoltaic output. It is observed that MOEA/D outperforms MOPSO in this case in terms of quality of results and its diversity. Finally, one point is selected from the obtained Pareto front and its performance is illustrated.},
author = {Hassan, S. and Khanesar, M.A. and Hajizadeh, A. and Khosravi, A.},
doi = {10.1109/FUZZ-IEEE.2017.8015733},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hassan et al. - 2017 - Hybrid multi-objective forecasting of solar photovoltaic output using Kalman filter based interval type-2 fuzzy l.pdf:pdf},
isbn = {9781509060344},
issn = {10987584},
journal = {IEEE International Conference on Fuzzy Systems},
keywords = {Interval type-2 fuzzy logic system,Kalman filter,MOEA/D,MOPSO,Multi-objective optimization},
title = {{Hybrid multi-objective forecasting of solar photovoltaic output using Kalman filter based interval type-2 fuzzy logic system}},
year = {2017}
}
@article{Zarnani2013,
abstract = {Clustering methods are proposed and evaluated as post-processing techniques that can model the uncertainty of forecasts provided by Numerical Weather Prediction (NWP) systems. These techniques try to discover relevant information about forecast uncertainty that is inherent in the performance records of the system. We investigate the application of Fuzzy C-means clustering as a powerful unsupervised learning method to discover fuzzy sets of weather forecast situations which represent different forecast uncertainty patterns. These patterns are then utilized by different distribution fitting methods to obtain statistical prediction intervals which can express the expected accuracy of the NWP system output. Three years of weather forecast records in two weather stations are used in a set of experiments to empirically study the application of the proposed approach. Skills of the probabilistic forecasts obtained by these post-processing methods are investigated by considering cross fold validation and sampling variations. Results demonstrate that the Prediction intervals generated by the proposed procedure have a higher skill compared to baseline methods.},
author = {Zarnani, A. and Musilek, P.},
doi = {10.1109/IFSA-NAFIPS.2013.6608480},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zarnani, Musilek - 2013 - Non-parametric interval forecast models from fuzzy clustering of Numerical Weather Predictions.pdf:pdf},
isbn = {9781479903474},
journal = {Proceedings of the 2013 Joint IFSA World Congress and NAFIPS Annual Meeting, IFSA/NAFIPS 2013},
pages = {667--672},
title = {{Non-parametric interval forecast models from fuzzy clustering of Numerical Weather Predictions}},
year = {2013}
}
@article{Kerg2020,
abstract = {Attention and self-attention mechanisms, inspired by cognitive processes, are now central to state-of-the-art deep learning on sequential tasks. However, most recent progress hinges on heuristic approaches with limited understanding of attention's role in model optimization and computation, and rely on considerable memory and computational resources that scale poorly. In this work, we present a formal analysis of how self-attention affects gradient propagation in recurrent networks, and prove that it mitigates the problem of vanishing gradients when trying to capture long-term dependencies. Building on these results, we propose a relevancy screening mechanism, inspired by the cognitive process of memory consolidation, that allows for a scalable use of sparse self-attention with recurrence. While providing guarantees to avoid vanishing gradients, we use simple numerical experiments to demonstrate the tradeoffs in performance and computational resources by efficiently balancing attention and recurrence. Based on our results, we propose a concrete direction of research to improve scalability of attentive networks.},
archivePrefix = {arXiv},
arxivId = {2006.09471},
author = {Kerg, Giancarlo and Kanuparthi, Bhargav and Goyal, Anirudh and Goyette, Kyle and Bengio, Yoshua and Lajoie, Guillaume},
eprint = {2006.09471},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kerg et al. - 2020 - Untangling tradeoffs between recurrence and self-attention in neural networks.pdf:pdf},
journal = {arXiv},
pages = {1--43},
title = {{Untangling tradeoffs between recurrence and self-attention in neural networks}},
year = {2020}
}
@article{Zamir2019,
abstract = {Do visual tasks have relationships, or are they unrelated? For instance, could having surface normals simplify estimating the depth of an image? Intuition answers these questions positively, implying existence of a certain structure among visual tasks. Understanding this structure has notable values: it provides a principled way for identifying relationships across tasks, for instance, in order to reuse supervision among redundant tasks or solve many tasks in one system without piling up the complexity. We propose a fully computational approach for identifying the transfer learning structure of the space of visual tasks. This is done via computing the transfer learning dependencies across tasks in a dictionary of twenty-six 2D, 2.5D, 3D, and semantic tasks. The product is a computational taxonomic map among tasks for transfer learning, and we exploit it to reduce the demand for labeled data. For example, we show that the total number of labeled datapoints needed for solving a set of 10 tasks can be reduced by roughly 32 (compared to training independently) while keeping the performance nearly the same. We provide a set of tools for computing and visualizing this taxonomical structure at http://taskonomy.vision.},
archivePrefix = {arXiv},
arxivId = {1804.08328},
author = {Zamir, Amir and Sax, Alexander and Shen, William and Guibas, Leonidas and Malik, Jitendra and Savarese, Silvio},
doi = {10.24963/ijcai.2019/871},
eprint = {1804.08328},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zamir et al. - 2019 - Taskonomy Disentangling task transfer learning.pdf:pdf},
isbn = {9780999241141},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
keywords = {transfer learning},
mendeley-tags = {transfer learning},
pages = {6241--6245},
title = {{Taskonomy: Disentangling task transfer learning}},
volume = {2019-Augus},
year = {2019}
}
@article{Zhou2020,
abstract = {Learning disentangled representations is regarded as a fundamental task for improving the generalization, robustness, and interpretability of generative models. However, measuring disentanglement has been challenging and inconsistent, often dependent on an ad-hoc external model or specific to a certain dataset. To address this, we present a method for quantifying disentanglement that only uses the generative model, by measuring the topological similarity of conditional submanifolds in the learned representation. This method showcases both unsupervised and supervised variants. To illustrate the effectiveness and applicability of our method, we empirically evaluate several state-of-the-art models across multiple datasets. We find that our method ranks models similarly to existing methods. We make ourcode publicly available at https://github.com/stanfordmlgroup/disentanglement.},
archivePrefix = {arXiv},
arxivId = {2006.03680},
author = {Zhou, Sharon and Zelikman, Eric and Lu, Fred and Ng, Andrew Y and Carlsson, Gunnar and Ermon, Stefano},
eprint = {2006.03680},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou et al. - 2020 - Evaluating the Disentanglement of Deep Generative Models through Manifold Topology.pdf:pdf},
keywords = {disentangled representation,evaluation,representation learning},
mendeley-tags = {disentangled representation,evaluation,representation learning},
month = {jun},
pages = {1--12},
title = {{Evaluating the Disentanglement of Deep Generative Models through Manifold Topology}},
url = {http://arxiv.org/abs/2006.03680},
year = {2020}
}
@article{Zhang2019c,
abstract = {Deep neural networks (DNNs) often suffer from "catastrophic forgetting" during incremental learning (IL) --- an abrupt degradation of performance on the original set of classes when the training objective is adapted to a newly added set of classes. Existing IL approaches tend to produce a model that is biased towards either the old classes or new classes, unless with the help of exemplars of the old data. To address this issue, we propose a class-incremental learning paradigm called Deep Model Consolidation (DMC), which works well even when the original training data is not available. The idea is to first train a separate model only for the new classes, and then combine the two individual models trained on data of two distinct set of classes (old classes and new classes) via a novel double distillation training objective. The two existing models are consolidated by exploiting publicly available unlabeled auxiliary data. This overcomes the potential difficulties due to the unavailability of original training data. Compared to the state-of-the-art techniques, DMC demonstrates significantly better performance in image classification (CIFAR-100 and CUB-200) and object detection (PASCAL VOC 2007) in the single-headed IL setting.},
archivePrefix = {arXiv},
arxivId = {1903.07864},
author = {Zhang, Junting and Zhang, Jie and Ghosh, Shalini and Li, Dawei and Tasci, Serafettin and Heck, Larry and Zhang, Heming and Kuo, C. -C. Jay},
eprint = {1903.07864},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2019 - Class-incremental Learning via Deep Model Consolidation.pdf:pdf},
keywords = {architectural,continual learning,incremental learning},
mendeley-tags = {architectural,continual learning,incremental learning},
month = {mar},
title = {{Class-incremental Learning via Deep Model Consolidation}},
url = {https://github.com/juntingzh/incremental-learning-baselines http://arxiv.org/abs/1903.07864},
year = {2019}
}
@inproceedings{Lee2020,
abstract = {Contrastive representation learning has shown to be an effective way of learning representations from unlabeled data. However, much progress has been made in vision domains relying on data augmentations carefully designed using domain knowledge. In this work, we propose i-Mix, a simple yet effective regularization strategy for improving contrastive representation learning in both vision and non-vision domains. We cast contrastive learning as training a non-parametric classifier by assigning a unique virtual class to each data in a batch. Then, data instances are mixed in both the input and virtual label spaces, providing more augmented data during training. In experiments, we demonstrate that i-Mix consistently improves the quality of self-supervised representations across domains, resulting in significant performance gains on downstream tasks. Furthermore, we confirm its regularization effect via extensive ablation studies across model and dataset sizes.},
archivePrefix = {arXiv},
arxivId = {2010.08887},
author = {Lee, Kibok and Zhu, Yian and Sohn, Kihyuk and Li, Chun-Liang and Shin, Jinwoo and Lee, Honglak},
booktitle = {Iclr 2021},
eprint = {2010.08887},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee et al. - 2020 - i-Mix A Strategy for Regularizing Contrastive Representation Learning.pdf:pdf},
keywords = {contrastive learning,regularization,representation learning,self-supervised learning},
mendeley-tags = {contrastive learning,regularization,representation learning,self-supervised learning},
pages = {1--20},
title = {{i-Mix: A Strategy for Regularizing Contrastive Representation Learning}},
url = {http://arxiv.org/abs/2010.08887},
year = {2020}
}
@article{Marcus2020,
abstract = {Recent research in artificial intelligence and machine learning has largely emphasized general-purpose learning and ever-larger training sets and more and more compute. In contrast, I propose a hybrid, knowledge-driven, reasoning-based approach, centered around cognitive models, that could provide the substrate for a richer, more robust AI than is currently possible.},
archivePrefix = {arXiv},
arxivId = {2002.06177},
author = {Marcus, Gary},
eprint = {2002.06177},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Marcus - 2020 - The Next Decade in AI Four Steps Towards Robust Artificial Intelligence.pdf:pdf},
journal = {arXiv},
month = {feb},
title = {{The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence}},
url = {http://arxiv.org/abs/2002.06177},
year = {2020}
}
@article{Pomponi2020a,
abstract = {Continual learning of deep neural networks is a key requirement for scaling them up to more complex applicative scenarios and for achieving real lifelong learning of these architectures. Previous approaches to the problem have considered either the progressive increase in the size of the networks, or have tried to regularize the network behavior to equalize it with respect to previously observed tasks. In the latter case, it is essential to understand what type of information best represents this past behavior. Common techniques include regularizing the past outputs, gradients, or individual weights. In this work, we propose a new, relatively simple and efficient method to perform continual learning by regularizing instead the network internal embeddings. To make the approach scalable, we also propose a dynamic sampling strategy to reduce the memory footprint of the required external storage. We show that our method performs favorably with respect to state-of-the-art approaches in the literature, while requiring significantly less space in memory and computational time. In addition, inspired by to recent works, we evaluate the impact of selecting a more flexible model for the activation functions inside the network, evaluating the impact of catastrophic forgetting on the activation functions themselves.},
archivePrefix = {arXiv},
arxivId = {1909.03742},
author = {Pomponi, Jary and Scardapane, Simone and Lomonaco, Vincenzo and Uncini, Aurelio},
doi = {10.1016/j.neucom.2020.01.093},
eprint = {1909.03742},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pomponi et al. - 2020 - Efficient continual learning in neural networks with embedding regularization(2).pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Catastrophic forgetting,Continual learning,Embedding,Regularization,Trainable activation functions},
pages = {139--148},
publisher = {Elsevier B.V.},
title = {{Efficient continual learning in neural networks with embedding regularization}},
url = {https://doi.org/10.1016/j.neucom.2020.01.093},
volume = {397},
year = {2020}
}
@inproceedings{Xu2020a,
abstract = {With the development of computational power and techniques for data collection, deep learning demonstrates a superior performance over most existing algorithms on visual benchmark data sets. Many efforts have been devoted to studying the mechanism of deep learning. One important observation is that deep learning can learn the discriminative patterns from raw materials directly in a task-dependent manner. Therefore, the representations obtained by deep learning outperform hand-crafted features significantly. However, for some real-world applications, it is too expensive to collect the task-specific labels, such as visual search in online shopping. Compared to the limited availability of these task-specific labels, their coarse-class labels are much more affordable, but representations learned from them can be suboptimal for the target task. To mitigate this challenge, we propose an algorithm to learn the fine-grained patterns for the target task, when only its coarse-class labels are available. More importantly, we provide a theoretical guarantee for this. Extensive experiments on real-world data sets demonstrate that the proposed method can significantly improve the performance of learned representations on the target task, when only coarse-class information is available for training. Code is available at \url{https://github.com/idstcv/CoIns}.},
archivePrefix = {arXiv},
arxivId = {2005.09681},
author = {Xu, Yuanhong and Qian, Qi and Li, Hao and Jin, Rong and Hu, Juhua},
booktitle = {International Conference on Computer Vision},
eprint = {2005.09681},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu et al. - 2021 - Weakly Supervised Representation Learning with Coarse Labels.pdf:pdf},
keywords = {coarse labels,weakly supervised learning},
mendeley-tags = {coarse labels,weakly supervised learning},
pages = {10593--10601},
title = {{Weakly Supervised Representation Learning with Coarse Labels}},
url = {http://arxiv.org/abs/2005.09681},
year = {2021}
}
@article{Campo2020,
abstract = {This paper proposes a method for performing continual learning of predictive models that facilitate the inference of future frames in video sequences. For a first given experience, an initial Variational Autoencoder, together with a set of fully connected neural networks are utilized to respectively learn the appearance of video frames and their dynamics at the latent space level. By employing an adapted Markov Jump Particle Filter, the proposed method recognizes new situations and integrates them as predictive models avoiding catastrophic forgetting of previously learned tasks. For evaluating the proposed method, this article uses video sequences from a vehicle that performs different tasks in a controlled environment.},
archivePrefix = {arXiv},
arxivId = {2006.01945},
author = {Campo, Damian and Slavic, Giulia and Baydoun, Mohamad and Marcenaro, Lucio and Regazzoni, Carlo},
doi = {10.1109/ICIP40778.2020.9190980},
eprint = {2006.01945},
file = {:home/user/Downloads/campo2020.pdf:pdf},
isbn = {9781728163956},
issn = {15224880},
journal = {Proceedings - International Conference on Image Processing, ICIP},
keywords = {Continual learning,continual learning,incremental learning,kalman filter,lifelong learning,particle filter,variational autoencoder,video prediction,video understanding},
mendeley-tags = {continual learning,incremental learning,video prediction,video understanding},
pages = {753--757},
title = {{Continual Learning of Predictive Models in Video Sequences Via Variational Autoencoders}},
volume = {2020-Octob},
year = {2020}
}
@article{Bahng2019a,
abstract = {Many machine learning algorithms are trained and evaluated by splitting data from a single source into training and test sets. While such focus on in-distribution learning scenarios has led interesting advances, it has not been able to tell if models are relying on dataset biases as shortcuts for successful prediction (e.g., using snow cues for recognising snowmobiles). Such biased models fail to generalise when the bias shifts to a different class. The cross-bias generalisation problem has been addressed by de-biasing training data through augmentation or re-sampling, which are often prohibitive due to the data collection cost (e.g., collecting images of a snowmobile on a desert) and the difficulty of quantifying or expressing biases in the first place. In this work, we propose a novel framework to train a de-biased representation by encouraging it to be different from a set of representations that are biased by design. This tactic is feasible in many scenarios where it is much easier to define a set of biased representations than to define and quantify bias. Our experiments and analyses show that our method discourages models from taking bias shortcuts, resulting in improved performances on de-biased test data.},
archivePrefix = {arXiv},
arxivId = {1910.02806},
author = {Bahng, Hyojin and Chun, Sanghyuk and Yun, Sangdoo and Choo, Jaegul and Oh, Seong Joon},
eprint = {1910.02806},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bahng et al. - 2019 - Learning de-biased representations with biased representations.pdf:pdf;:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bahng et al. - 2019 - Learning de-biased representations with biased representations(2).pdf:pdf},
journal = {arXiv},
pages = {1--6},
title = {{Learning de-biased representations with biased representations}},
url = {https://github.com/clovaai/rebias},
volume = {2},
year = {2019}
}
@article{Iscen2020,
abstract = {In this work we introduce an approach for incremental learning, which preserves feature descriptors instead of images unlike most existing work. Keeping such low-dimensional embeddings instead of images reduces the memory footprint significantly. We assume that the model is updated incrementally for new classes as new data becomes available sequentially. This requires adapting the previously stored feature vectors to the updated feature space without having access to the corresponding images. Feature adaptation is learned with a multi-layer perceptron, which is trained on feature pairs of an image corresponding to the outputs of the original and updated network. We validate experimentally that such a transformation generalizes well to the features of the previous set of classes, and maps features to a discriminative subspace in the feature space. As a result, the classifier is optimized jointly over new and old classes without requiring old class images. Experimental results show that our method achieves state-of-the-art classification accuracy in incremental learning benchmarks, while having at least an order of magnitude lower memory footprint compared to image preserving strategies.},
author = {Iscen, Ahmet and Zhang, Jeffrey and Lazebnik, Svetlana and Schmid, Cordelia},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Iscen et al. - 2020 - Memory-efficient incremental learning through feature adaptation.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {feature adaptation,incremental learning,regularization},
mendeley-tags = {feature adaptation,incremental learning,regularization},
title = {{Memory-efficient incremental learning through feature adaptation}},
year = {2020}
}
@article{Lee2015,
abstract = {The calcium oxide catalysts derived from waste obtuse horn shells were utilized in the transesterification of palm oil into biodiesel. This environment-friendly catalyst is thermally activated at 800 °C for 3 h. The resulting CaO catalyst was characterized using thermogravimetric analysis (TGA), X-ray diffraction (XRD), temperature-programmed desorption of CO2(TPD-CO2), Brunauer-Emmett-Teller (BET) surface area analysis, and scanning electron microscopy (SEM). XRD patterns of calcined catalyst showed intense peaks of calcium oxide, consistent with XRF results that revealed calcium is the major element present in the obtuse horn shells. High calcination temperature (800 °C) tended to promote agglomeration of fine crystals, resulted in a smaller surface area (0.07 m2/g) as examined by BET. Catalytic activities in the transesterification process had been investigated using one-variable-at-a-time technique. The optimum palm oil conversion was 86.75% under reaction conditions of 6 h, 5 wt.% of catalyst amount and methanol to oil ratio of 12:1. Reusability of this waste shell derived catalyst was examined and results showed that the prepared catalysts are able to be reused up to 3 times with conversion of more than 70% after the third cycles. Although the reusability may not be excellent at the moment, it is still in the exploratory study. More efforts were done to improve its properties and stability.},
author = {Lee, Seik Lih and Wong, Yong Chen and Tan, Yen Ping and Yew, Sook Yan},
doi = {10.1016/j.enconman.2014.12.067},
issn = {01968904},
journal = {Energy Conversion and Management},
keywords = {Biodiesel,Calcium oxide,Obtuse horn shell,Palm oil,Transesterification},
pages = {282--288},
publisher = {Elsevier Ltd},
title = {{Transesterification of palm oil to biodiesel by using waste obtuse horn shell-derived CaO catalyst}},
url = {http://dx.doi.org/10.1016/j.enconman.2014.12.067},
volume = {93},
year = {2015}
}
@article{Arino2017,
abstract = {Predictive control of TS fuzzy systems has been addressed in prior literature with some simplifying assumptions or heuristic approaches. This paper presents a rigorous formulation of the model predictive control of TS systems, so that results are valid for any membership value (shape-independent) with a suitable account of causality (control can depend on current and past memberships and state). As in most fuzzy control results, a family of progressively better controllers can be obtained by increasing Polya-related complexity parameters, generalising over prior proposals.},
author = {Ari{\~{n}}o, Carlos and Querol, Andr{\'{e}}s and Sala, Antonio},
doi = {10.1016/j.engappai.2017.07.011},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ari{\~{n}}o, Querol, Sala - 2017 - Shape-independent model predictive control for Takagi–Sugeno fuzzy systems.pdf:pdf},
issn = {09521976},
journal = {Engineering Applications of Artificial Intelligence},
keywords = {Fuzzy control,Polya relaxations,Predictive control},
number = {August},
pages = {493--505},
publisher = {Elsevier Ltd},
title = {{Shape-independent model predictive control for Takagi–Sugeno fuzzy systems}},
url = {http://dx.doi.org/10.1016/j.engappai.2017.07.011},
volume = {65},
year = {2017}
}
@article{Chen2014,
abstract = {In this study, waste ostrich eggshell-derived calcium oxide (denoted as CaO(OE)) particles were synthesized and explored as cost-effective catalysts for the ultrasonic-assisted transesterification of palm oil. The physicochemical properties of the resultant catalysts were characterized by XRD, N2adsorption, XRF and Hammett indicator, while the catalytic activity was evaluated through transesterification of palm oil with methanol under ultrasonic conditions. More specifically, the CaO(OE) showed comparable catalytic activity to the one derived from commercial calcium carbonate (denoted as CaO(Lab)). Moreover, under ultrasonic conditions, the catalytic activity of CaO(OE) could be enhanced significantly. The maximum yield of fatty acid methyl esters could reach 92.7% under the optimal condition of reaction time of 60min with ultrasonic power of 60% (120W), methanol-to-oil ratio of 9:1, and catalyst loading of 8wt.%. The results indicated that the CaO(OE) catalysts showed good catalytic performance and reusability, and may potentially reduce the cost of biodiesel production.},
author = {Chen, Guanyi and Shan, Rui and Shi, Jiafu and Yan, Beibei},
doi = {10.1016/j.biortech.2014.08.102},
isbn = {0960-8524},
issn = {18732976},
journal = {Bioresource Technology},
keywords = {Biodiesel,Ostrich eggshell,Palm oil,Transesterification,Ultrasonic},
pages = {428--432},
pmid = {25226059},
publisher = {Elsevier Ltd},
title = {{Ultrasonic-assisted production of biodiesel from transesterification of palm oil over ostrich eggshell-derived CaO catalysts}},
url = {http://dx.doi.org/10.1016/j.biortech.2014.08.102},
volume = {171},
year = {2014}
}
@article{Li2016,
abstract = {This paper presents an optimisation method for reducing the number of
input channels and the complexity of the feed-forward NARX neural
network (NN) without compromising the accuracy of the NN model. By
utilising the correlation analysis method, the most significant
regressors are selected to form the input layer of the NN structure.
Applications of vehicle handling and ride model identification are
presented in this paper to demonstrate the optimisation technique, and
the optimal input layer structure and the optimal number of neurons for
the NN models are investigated. The results show that the developed NN
model requires significantly fewer coefficients and less training time
while maintaining high simulation accuracy compared with that of the
unoptimised model.},
author = {Li, Zongyan and Best, Matt},
doi = {10.1504/IJMIC.2016.075814},
issn = {1746-6172},
journal = {International Journal of Modelling, Identification and Control},
keywords = {by work on developing,correlation analysis,dynamics using system,f-ratio,his paper is motivated,levenberg-marquardt,mse,narx,neural network,optimisation,order models for vehicle,reduced},
number = {3},
pages = {217},
title = {{Structure optimisation of input layer for feed-forward NARX neural network}},
url = {http://www.inderscience.com/link.php?id=75814},
volume = {25},
year = {2016}
}
@article{Darrell2013,
author = {Darrell, T and Doherty, P and Cello, L Fari{\~{n}}as D E L and Lang, J},
doi = {10.1016/S0004-3702(13)00111-2},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Darrell et al. - 2013 - Editorial Board.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
pages = {IFC},
title = {{Editorial Board}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0004370213001112},
volume = {205},
year = {2013}
}
@article{Toms2017,
abstract = {We demonstrate that social movements can use accounting for progressive purposes, and that such outcomes can be promoted where they are aligned with the material interests of key fractions of capital. Such fractionalization is a function of technology and labour process, underpinned by adopted ideology. Alignment with social movement objectives overcomes the class belongingness of accounting that limits its progressive role in normal circumstances. We illustrate the role of accounting in achieving limitations to working hours and child labour, drawing on accounting evidence used to resist and support factory reform during the industrial revolution. We compare the evidence on costs and profits presented by both sides in parliamentary hearings and also with data revealed from the business accounts of the main protagonists. These comparisons show that assumptions about cost behaviour were used to exaggerate or mitigate the apparent effects of reduced working time on profits. Regressive fractions of capital were unable to resist change because they failed to consistently monopolize accounting information to impose a dominant narrative about the consequences of regulation.},
author = {Toms, Steven and Shepherd, Alice},
doi = {10.1016/j.cpa.2017.03.002},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Toms, Shepherd - 2017 - Accounting and social conflict Profit and regulated working time in the British Industrial Revolution.pdf:pdf},
isbn = {1045-2354},
issn = {10959955},
journal = {Critical Perspectives on Accounting},
keywords = {Accounting information,British Industrial Revolution,Factory reform,Labour process,Production costs,Social movements},
number = {June 2014},
pages = {57--75},
title = {{Accounting and social conflict: Profit and regulated working time in the British Industrial Revolution}},
volume = {49},
year = {2017}
}
@article{Gupta2020,
abstract = {The backpropagation algorithm is often debated for its biological plausibility. However, various learning methods for neural architecture have been proposed in search of more biologically plausible learning. Most of them have tried to solve the "weight transport problem" and try to propagate errors backward in the architecture via some alternative methods. In this work, we investigated a slightly different approach that uses only the local information which captures spike timing information with no propagation of errors. The proposed learning rule is derived from the concepts of spike timing dependant plasticity and neuronal association. A preliminary evaluation done on the binary classification of MNIST and IRIS datasets with two hidden layers shows comparable performance with backpropagation. The model learned using this method also shows a possibility of better adversarial robustness against the FGSM attack compared to the model learned through backpropagation of cross-entropy loss. The local nature of learning gives a possibility of large scale distributed and parallel learning in the network. And finally, the proposed method is a more biologically sound method that can probably help in understanding how biological neurons learn different abstractions.},
archivePrefix = {arXiv},
arxivId = {2011.12012},
author = {Gupta, Shashi Kant},
eprint = {2011.12012},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gupta - 2020 - A More Biologically Plausible Local Learning Rule for ANNs.pdf:pdf},
title = {{A More Biologically Plausible Local Learning Rule for ANNs}},
url = {http://arxiv.org/abs/2011.12012},
year = {2020}
}
@article{Mahmoud2012,
abstract = {For solving the world energy problem and the bad effect of conventional sources of energy on environment, great attention allover the world is paid towards the use of renewable energy sources. Special interest is paid towards wind energy because of its competitively. Savonius rotor is a vertical axis wind turbine which is characterized as cheaper, simpler in construction and low speed turbine. This makes it suitable for generating mechanical energy in many countries especially in Egypt. In this work different geometries of Savonius wind turbine are experimentally studied in order to determine the most effective operation parameters. It was found that, the two blades rotor is more efficient than three and four ones. The rotor with end plates gives higher efficiency than those of without end plates. Double stage rotors have higher performance compared to single stage rotors. The rotors without overlap ratio ($\beta$) are better in operation than those with overlap. The results show also that the power coefficient increases with rising the aspect ratio ($\alpha$). The conclusions from the measurements of the static torque for each rotor at different wind speeds verify the above summarized results of this work. {\textcopyright} 2012 Faculty of Engineering, Alexandria University. Production and hosting by Elsevier B.V. All rights reserved.},
author = {Mahmoud, N. H. and El-Haroun, A. A. and Wahba, E. and Nasef, M. H.},
doi = {10.1016/j.aej.2012.07.003},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mahmoud et al. - 2012 - An experimental study on improvement of Savonius rotor performance.pdf:pdf},
isbn = {0894-1777},
issn = {11100168},
journal = {Alexandria Engineering Journal},
keywords = {Renewable energy,Savonius rotor,Vertical axis wind turbine,Wind energy},
number = {1},
pages = {19--25},
publisher = {Faculty of Engineering, Alexandria University},
title = {{An experimental study on improvement of Savonius rotor performance}},
url = {http://dx.doi.org/10.1016/j.aej.2012.07.003},
volume = {51},
year = {2012}
}
@article{French1993,
author = {French, Robert and French, M},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/French, French - 1993 - Using Semi-Distributed Representations to Overcome Catastrophic Forgetting in Connectionlst Networks.pdf:pdf},
journal = {Proceedings of the AAAI Spring Symposium},
number = {JANUARY 1992},
pages = {70--77},
title = {{Using Semi-Distributed Representations to Overcome Catastrophic Forgetting in Connectionlst Networks}},
year = {1993}
}
@article{Jin2020,
author = {Jin, Leilei and Liang, Hong and Yang, Changsheng},
doi = {10.1109/access.2020.3025558},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jin, Liang, Yang - 2020 - Class-Incremental Learning of Convolutional Neural Networks Based on Double Consolidation Mechanism.pdf:pdf},
journal = {IEEE Access},
pages = {172553--172562},
title = {{Class-Incremental Learning of Convolutional Neural Networks Based on Double Consolidation Mechanism}},
volume = {8},
year = {2020}
}
@article{Hewitt2017,
abstract = {As the importance of the ocean in the weather and climate system is increasingly recognised, operational systems are now moving towards coupled prediction not only for seasonal to climate timescales but also for short-range forecasts. A three-way tension exists between the allocation of computing resources to refine model resolution, the expansion of model complexity/capability, and the increase of ensemble size. Here we review evidence for the benefits of increased ocean resolution in global coupled models, where the ocean component explicitly represents transient mesoscale eddies and narrow boundary currents. We consider lessons learned from forced ocean/sea-ice simulations; from studies concerning the SST resolution required to impact atmospheric simulations; and from coupled predictions. Impacts of the mesoscale ocean in western boundary current regions on the large-scale atmospheric state have been identified. Understanding of air-sea feedback in western boundary currents is modifying our view of the dynamics in these key regions. It remains unclear whether variability associated with open ocean mesoscale eddies is equally important to the large-scale atmospheric state. We include a discussion of what processes can presently be parameterised in coupled models with coarse resolution non-eddying ocean models, and where parameterizations may fall short. We discuss the benefits of resolution and identify gaps in the current literature that leave important questions unanswered.},
author = {Hewitt, Helene T. and Bell, Michael J. and Chassignet, Eric P. and Czaja, Arnaud and Ferreira, David and Griffies, Stephen M. and Hyder, Pat and McClean, Julie L. and New, Adrian L. and Roberts, Malcolm J.},
doi = {10.1016/j.ocemod.2017.11.002},
issn = {14635003},
journal = {Ocean Modelling},
keywords = {Atmosphere,Coupled,Ocean,Parameterisation,Resolution},
pages = {120--136},
publisher = {Elsevier Ltd},
title = {{Will high-resolution global ocean models benefit coupled predictions on short-range to climate timescales?}},
url = {https://doi.org/10.1016/j.ocemod.2017.11.002},
volume = {120},
year = {2017}
}
@article{Zhuang2021,
abstract = {Transfer learning aims at improving the performance of target learners on target domains by transferring the knowledge contained in different but related source domains. In this way, the dependence on a large number of target-domain data can be reduced for constructing target learners. Due to the wide application prospects, transfer learning has become a popular and promising area in machine learning. Although there are already some valuable and impressive surveys on transfer learning, these surveys introduce approaches in a relatively isolated way and lack the recent advances in transfer learning. Due to the rapid expansion of the transfer learning area, it is both necessary and challenging to comprehensively review the relevant studies. This survey attempts to connect and systematize the existing transfer learning research studies, as well as to summarize and interpret the mechanisms and the strategies of transfer learning in a comprehensive way, which may help readers have a better understanding of the current research status and ideas. Unlike previous surveys, this survey article reviews more than 40 representative transfer learning approaches, especially homogeneous transfer learning approaches, from the perspectives of data and model. The applications of transfer learning are also briefly introduced. In order to show the performance of different transfer learning models, over 20 representative transfer learning models are used for experiments. The models are performed on three different data sets, that is, Amazon Reviews, Reuters-21578, and Office-31, and the experimental results demonstrate the importance of selecting appropriate transfer learning models for different applications in practice.},
archivePrefix = {arXiv},
arxivId = {1911.02685},
author = {Zhuang, Fuzhen and Qi, Zhiyuan and Duan, Keyu and Xi, Dongbo and Zhu, Yongchun and Zhu, Hengshu and Xiong, Hui and He, Qing},
doi = {10.1109/JPROC.2020.3004555},
eprint = {1911.02685},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhuang et al. - 2021 - A Comprehensive Survey on Transfer Learning.pdf:pdf},
issn = {15582256},
journal = {Proceedings of the IEEE},
keywords = {Domain adaptation,interpretation,machine learning,review,survey,transfer learning},
mendeley-tags = {review,survey,transfer learning},
number = {1},
pages = {43--76},
title = {{A Comprehensive Survey on Transfer Learning}},
volume = {109},
year = {2021}
}
@article{McClelland1995,
abstract = {Damage to the hippocampal system disrupts recent memory but leaves remote memory intact. The account presented here suggests that memories are first stored via synaptic changes in the hippo-campal system, that these changes support reinstatement of recent memories in the neocortex, that neocortical synapses change a little on each reinstatement, and that remote memory is based on accumulated neocortical changes. Models that learn via changes to connections help explain this organization. These models discover the structure in ensembles of items if learning of each item is gradual and interleaved with learning about other items. This suggests that the neocortex learns slowly to discover the structure in ensembles of experiences. The hippocampal system permits rapid learning of new items without disrupting this structure, and reinstatement of new memories in-terleaves them with others to integrate them into structured neocortical memory systems.},
author = {McClelland, James L and McNaughton, Bruce L and O'Reilly, Randall C},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/McClelland, McNaughton, O'Reilly - 1995 - Why There Are Complementary Learning Systems in the Hippocampus and Neocortex Insights From th.pdf:pdf},
isbn = {0033-295X (Print)\r0033-295X (Linking)},
issn = {0033-295X},
journal = {Psychological Review},
keywords = {continual learning,neuroscience},
mendeley-tags = {continual learning,neuroscience},
number = {3},
pages = {419--457},
pmid = {7624455},
title = {{Why There Are Complementary Learning Systems in the Hippocampus and Neocortex: Insights From the Successes and Failures of Connectionist Models of Learning and Memory}},
volume = {102},
year = {1995}
}
@article{Bilgic2000,
abstract = {: This chapter presents a review of various interpretations of the fuzzy membershipfunction together with ways of obtaining a membership function. We emphasizethat different interpretations of the membership function call for different elicitation methods.We try to make this distinction clear using techniques from measurement theory.3.1 INTRODUCTION AND PREVIEWSince Zadeh (1965) introduced the notion of fuzzy sets one of the main difficulties hasbeen with the meaning and measurementof membership functions. Particularly, lack ofa consensus on the meaning of membership functions has created some confusion. Thisconfusion is neither bizarre nor unsound. After all fuzzy sets are totally characterizedby their membership functions and in order to diffuse this cloud of confusion and fora sound theory of fuzzy sets a rigorous semantics together with practical elicitationmethods for membership functions are necessary.There are various interpretations as to where fuzziness might...},
author = {Bilgi{\c{c}}, T and T{\"{u}}rkşen, Ib},
doi = {10.1007/978-1-4615-4429-6_4},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bilgi{\c{c}}, T{\"{u}}rkşen - 2000 - Measurement of membership functions theoretical and empirical work.pdf:pdf},
isbn = {978-0-7923-7732-0},
issn = {15684946},
journal = {Fundamentals of fuzzy sets, Springer US},
pages = {195--227},
title = {{Measurement of membership functions: theoretical and empirical work}},
url = {http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:MEASUREMENT+OF+MEMBERSHIP+FUNCTIONS+:#4%5Cnhttp://link.springer.com/chapter/10.1007/978-1-4615-4429-6_4},
year = {2000}
}
@article{Choksi2020,
author = {Choksi, Bhavin and Mozafari, Milad and {Biggs O'May}, Callum and Ador, Benjamin and Alamia, Andrea and VanRullen, Rufin},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Choksi et al. - 2020 - Brain-inspired predictive coding dynamics improve the robustness of deep neural networks.pdf:pdf},
keywords = {brain-inspired,predictive coding,robustness},
mendeley-tags = {brain-inspired,predictive coding,robustness},
title = {{Brain-inspired predictive coding dynamics improve the robustness of deep neural networks}},
url = {https://openreview.net/forum?id=q1o2mWaOssG},
year = {2020}
}
@article{Lei2020,
abstract = {In this paper, we address the problem of distillation-based class-incremental learning with a single head. A central theme of this task is to learn new classes that arrive in sequential phases over time while keeping the model's capability of recognizing seen classes with only limited memory for preserving seen data samples. Many regularization strategies have been proposed to mitigate the phenomenon of catastrophic forgetting. To understand better the essence of these regularizations, we introduce a feature-graph preservation perspective. Insights into their merits and faults motivate our weighted-Euclidean regularization for old knowledge preservation. We further propose rectified cosine normalization and show how it can work with binary cross-entropy to increase class separation for effective learning of new classes. Experimental results on both CIFAR-100 and ImageNet datasets demonstrate that our method outperforms the state-of-the-art approaches in reducing classification error, easing catastrophic forgetting, and encouraging evenly balanced accuracy over different classes. Our project page is at : https://github.com/yhchen12101/FGP-ICL.},
archivePrefix = {arXiv},
arxivId = {2012.08129},
author = {Lei, Cheng-Hsun and Yi-Hsin and Peng, Wen-Hsiao and Chiu, Wei-Chen},
eprint = {2012.08129},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lei et al. - 2020 - Class-incremental Learning with Rectified Feature-Graph Preservation.pdf:pdf},
keywords = {graph,incremental learning,regularization},
mendeley-tags = {graph,incremental learning,regularization},
title = {{Class-incremental Learning with Rectified Feature-Graph Preservation}},
url = {http://arxiv.org/abs/2012.08129 https://github.com/yhchen12101/FGP-ICL},
year = {2020}
}
@article{Tosun2017,
abstract = {Ultrasonic level sensors are commonly used to measure the motion of the free surface in fluid sloshing. They are used to measure the elevation of the free surface at a single point. The sloshing forces are generally measured with load sensors, which require two sets of measurements, with and without the fluid in the tank. This paper develops a method, which tracks the free surface motion during sloshing with a camera and uses the captured images to estimate the forces due to sloshing in a rectangular tank. One of the major assumptions is that the displacement input which causes sloshing is one dimensional and the resulting sloshing motion is two dimensional. For the method to correctly estimate the sloshing forces along the displacement input direction, sloshing should be around the resonant sloshing frequency. This new method can track the motion of the complete free surface rather than a single point. It estimates the sloshing forces using image processing and potential flow theory, without the need for a load cell measurement. Free surface shapes and sloshing force estimates obtained by image processing are compared with those measured by the sensors. Good agreement is observed for low amplitude sloshing around fundamental resonance frequency.},
author = {Tosun, Ufuk and Aghazadeh, Reza and Sert, C{\"{u}}neyt and {\"{O}}zer, Mehmet B{\"{u}}lent},
doi = {10.1016/j.expthermflusci.2017.06.016},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tosun et al. - 2017 - Tracking free surface and estimating sloshing force using image processing.pdf:pdf},
issn = {08941777},
journal = {Experimental Thermal and Fluid Science},
keywords = {Image processing,Modal expansion,Sloshing},
pages = {423--433},
publisher = {Elsevier Inc.},
title = {{Tracking free surface and estimating sloshing force using image processing}},
url = {http://dx.doi.org/10.1016/j.expthermflusci.2017.06.016},
volume = {88},
year = {2017}
}
@article{Rotich2012a,
abstract = {In this master's thesis, wind speeds and directions were modeled with the aim of developing suitable models for hourly, daily, weekly and monthly forecasting. Artificial Neural Networks implemented in MATLAB software were used to perform the forecasts. Three main types of artificial neural network were built, namely: Feed forward neural networks, Jordan Elman neural networks and Cascade forward neural networks. Four sub models of each of these neural networks were also built, corresponding to the four forecast horizons, for both wind speeds and directions. A single neural network topology was used for each of the forecast horizons, regardless of the model type. All the models were then trained with real data of wind speeds and directions collected over a period of two years in the municipal region of Puumala in Finland. Only 70% of the data was used for training, validation and testing of the models, while the second last 15% of the data was presented to the trained models for verification. The model outputs were then compared to the last 15% of the original data, by measuring the mean square errors and sum square errors between them. Based on the results, the feed forward networks returned the lowest generalization errors for hourly, weekly and monthly forecasts of wind speeds; Jordan Elman networks returned the lowest errors when used for forecasting of daily wind speeds. Cascade forward networks gave the lowest errors when used for forecasting daily, weekly and monthly wind directions; Jordan Elman networks returned the lowest errors when used for hourly forecasting. The errors were relatively low during training of the models, but shot up upon simulation with new inputs. In addition, a combination of hyperbolic tangent transfer functions for both hidden and output layers returned better results compared to other combinations of transfer functions. In general, wind speeds were more predictable as compared to wind directions, opening up opportunities for further research into building better models for wind direction forecasting.},
author = {Rotich, Nicolus},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rotich - 2012 - Forecasting of wind speeds and directions with artificial neural networks.pdf:pdf},
pages = {1--59},
title = {{Forecasting of wind speeds and directions with artificial neural networks}},
url = {http://www.doria.fi/handle/10024/98414},
year = {2012}
}
@book{Gaxiola2016,
author = {Gaxiola, Fernando and Melin, Patricia and Valdez, Fevrier},
isbn = {9783319340869},
pages = {111},
publisher = {Springer},
title = {{New Backpropagation Algorithm with Type-2 Fuzzy Weights for Neural Networks}},
year = {2016}
}
@article{Nugrahani2012,
author = {Nugrahani, Elita Fidiya and K, Ir Sekartedjo and Hatta, A M and Si, M},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nugrahani et al. - 2012 - Perancangan Sistem Transmisi Cahaya Matahari Melalui Serat Optik untuk Pencahayaan Ruangan.pdf:pdf},
number = {1},
pages = {1--6},
title = {{Perancangan Sistem Transmisi Cahaya Matahari Melalui Serat Optik untuk Pencahayaan Ruangan}},
volume = {1},
year = {2012}
}
@article{Lopes2017,
abstract = {Recent advances in model compression have provided procedures for compressing large neural networks to a fraction of their original size while retaining most if not all of their accuracy. However, all of these approaches rely on access to the original training set, which might not always be possible if the network to be compressed was trained on a very large dataset, or on a dataset whose release poses privacy or safety concerns as may be the case for biometrics tasks. We present a method for data-free knowledge distillation, which is able to compress deep neural networks trained on large-scale datasets to a fraction of their size leveraging only some extra metadata to be provided with a pretrained model release. We also explore different kinds of metadata that can be used with our method, and discuss tradeoffs involved in using each of them.},
archivePrefix = {arXiv},
arxivId = {1710.07535},
author = {Lopes, Raphael Gontijo and Fenu, Stefano and Starner, Thad},
eprint = {1710.07535},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lopes, Fenu, Starner - 2017 - Data-Free Knowledge Distillation for Deep Neural Networks.pdf:pdf},
title = {{Data-Free Knowledge Distillation for Deep Neural Networks}},
url = {http://arxiv.org/abs/1710.07535},
year = {2017}
}
@article{Pezeshki2020a,
abstract = {We identify and formalize a fundamental gradient descent phenomenon resulting in a learning proclivity in over-parameterized neural networks. Gradient Starvation arises when cross-entropy loss is minimized by capturing only a subset of features relevant for the task, despite the presence of other predictive features that fail to be discovered. This work provides a theoretical explanation for the emergence of such feature imbalance in neural networks. Using tools from Dynamical Systems theory, we identify simple properties of learning dynamics during gradient descent that lead to this imbalance, and prove that such a situation can be expected given certain statistical structure in training data. Based on our proposed formalism, we develop guarantees for a novel regularization method aimed at decoupling feature learning dynamics, improving accuracy and robustness in cases hindered by gradient starvation. We illustrate our findings with simple and real-world out-of-distribution (OOD) generalization experiments.},
archivePrefix = {arXiv},
arxivId = {2011.09468},
author = {Pezeshki, Mohammad and Kaba, S{\'{e}}kou-Oumar and Bengio, Yoshua and Courville, Aaron and Precup, Doina and Lajoie, Guillaume},
eprint = {2011.09468},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pezeshki et al. - 2020 - Gradient Starvation A Learning Proclivity in Neural Networks(5).pdf:pdf},
keywords = {generalization,learning dynamics,optimization,regularization,theory},
mendeley-tags = {generalization,learning dynamics,optimization,regularization,theory},
title = {{Gradient Starvation: A Learning Proclivity in Neural Networks}},
year = {2020}
}
@article{Ye2020,
author = {Ye, Fei and Bors, Adrian G},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ye, Bors - 2020 - Lifelong learning of interpretable image representations.pdf:pdf},
isbn = {9781728187501},
title = {{Lifelong learning of interpretable image representations}},
year = {2020}
}
@article{Al-Kaff2018,
abstract = {This paper presents a complete review of computer vision algorithms and vision-based intelligent applications, that are developed in the field of the Unmanned Aerial Vehicles (UAVs) in the latest decade. During this time, the evolution of relevant technologies for UAVs; such as component miniaturization, the increase of computational capabilities, and the evolution of computer vision techniques have allowed an important advance in the development of UAVs technologies and applications. Particularly, computer vision technologies integrated in UAVs allow to develop cutting-edge technologies to cope with aerial perception difficulties; such as visual navigation algorithms, obstacle detection and avoidance and aerial decision-making. All these expert technologies have developed a wide spectrum of application for UAVs, beyond the classic military and defense purposes. Unmanned Aerial Vehicles and Computer Vision are common topics in expert systems, so thanks to the recent advances in perception technologies, modern intelligent applications are developed to enhance autonomous UAV positioning, or automatic algorithms to avoid aerial collisions, among others. Then, the presented survey is based on artificial perception applications that represent important advances in the latest years in the expert system field related to the Unmanned Aerial Vehicles. In this paper, the most significant advances in this field are presented, able to solve fundamental technical limitations; such as visual odometry, obstacle detection, mapping and localization, et cetera. Besides, they have been analyzed based on their capabilities and potential utility. Moreover, the applications and UAVs are divided and categorized according to different criteria.},
author = {Al-Kaff, Abdulla and Mart{\'{i}}n, David and Garc{\'{i}}a, Fernando and de la Escalera, Arturo and {Mar{\'{i}}a Armingol}, Jos{\'{e}}},
doi = {10.1016/j.eswa.2017.09.033},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Al-Kaff et al. - 2018 - Survey of computer vision algorithms and applications for unmanned aerial vehicles.pdf:pdf},
isbn = {0957417417306},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Computer vision,Navigation system,Obstacle avoidance,Pose estimation,UAV,Vision-Based applications,Visual servoing},
pages = {447--463},
title = {{Survey of computer vision algorithms and applications for unmanned aerial vehicles}},
volume = {92},
year = {2018}
}
@article{Silverio2009,
author = {Silverio, Lauren},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Silverio - 2009 - ODU Digital Commons Makeup' s Effects on Self-Perception.pdf:pdf},
journal = {OTS Master's Level Projects & Papers STEM},
title = {{ODU Digital Commons Makeup' s Effects on Self-Perception}},
url = {http://digitalcommons.odu.edu/ots_masters_projects},
year = {2009}
}
@article{Xie2019a,
abstract = {We present a simple self-training method that achieves 87.4% top-1 accuracy on ImageNet, which is 1.0% better than the state-of-the-art model that requires 3.5B weakly labeled Instagram images. On robustness test sets, it improves ImageNet-A top-1 accuracy from 16.6% to 74.2%, reduces ImageNet-C mean corruption error from 45.7 to 31.2, and reduces ImageNet-P mean flip rate from 27.8 to 16.1. To achieve this result, we first train an EfficientNet model on labeled ImageNet images and use it as a teacher to generate pseudo labels on 300M unlabeled images. We then train a larger EfficientNet as a student model on the combination of labeled and pseudo labeled images. We iterate this process by putting back the student as the teacher. During the generation of the pseudo labels, the teacher is not noised so that the pseudo labels are as good as possible. But during the learning of the student, we inject noise such as data augmentation, dropout, stochastic depth to the student so that the noised student is forced to learn harder from the pseudo labels.},
archivePrefix = {arXiv},
arxivId = {1911.04252},
author = {Xie, Qizhe and Hovy, Eduard and Luong, Minh-Thang and Le, Quoc V.},
eprint = {1911.04252},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xie et al. - 2019 - Self-training with Noisy Student improves ImageNet classification.pdf:pdf},
title = {{Self-training with Noisy Student improves ImageNet classification}},
url = {http://arxiv.org/abs/1911.04252},
year = {2019}
}
@article{Cocke2014,
abstract = {In this paper, a genetic algorithm is employed for shape optimization of hydrofoils for application in a sailing craft. The hydrofoil for a sailing craft should have high lift at lower speeds and low drag at higher speeds. Computations are performed for a hydrofoil in deep water as well as one close to the free surface. Commercially available software is employed for calculation of the flowfield. It is shown that the genetic algorithm based shape optimization technique is capable of accurately and efficiently finding globally optimal hydrofoils. {\textcopyright} 2012 by Travis Cocke, Zachary Moscicki, and Ramesh K. Agarwal. Published by the American Institute of Aeronautics and Astronautics, Inc.},
author = {Cocke, Travis and Moscicki, Zachary and Agarwal, Ramesh},
doi = {10.2514/1.C032001},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cocke, Moscicki, Agarwal - 2014 - Optimization of Hydrofoils Using a Genetic Algorithm.pdf:pdf},
isbn = {9781624101854},
issn = {0021-8669},
journal = {Journal of Aircraft},
number = {1},
pages = {78--89},
title = {{Optimization of Hydrofoils Using a Genetic Algorithm}},
url = {http://arc.aiaa.org/doi/10.2514/1.C032001},
volume = {51},
year = {2014}
}
@article{Sun2020,
author = {Sun, Ke and Wang, Lei and Xu, Bo and Zhao, Wenhong and Teng, Shyh Wei and Xia, Feng},
doi = {10.1109/ACCESS.2020.3037118},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sun et al. - 2020 - Network Representation Learning From Traditional Feature Learning to Deep Learning.pdf:pdf},
issn = {2169-3536},
journal = {IEEE Access},
pages = {205600--205617},
title = {{Network Representation Learning: From Traditional Feature Learning to Deep Learning}},
url = {https://ieeexplore.ieee.org/document/9253633/},
volume = {8},
year = {2020}
}
@article{Knoblauch2020,
abstract = {Continual Learning (CL) algorithms incrementally learn a predictor or representation across multiple sequentially observed tasks. Designing CL algorithms that perform reliably and avoid so-called catastrophic forgetting has proven a persistent challenge. The current paper develops a theoretical approach that explains why. In particular, we derive the computational properties which CL algorithms would have to possess in order to avoid catastrophic forgetting. Our main finding is that such optimal CL algorithms generally solve an NP-hard problem and will require perfect memory to do so. The findings are of theoretical interest, but also explain the excellent performance of CL algorithms using experience replay, episodic memory and core sets relative to regularization-based approaches.},
archivePrefix = {arXiv},
arxivId = {2006.05188},
author = {Knoblauch, Jeremias and Husain, Hisham and Diethe, Tom},
eprint = {2006.05188},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Knoblauch, Husain, Diethe - 2020 - Optimal Continual Learning has Perfect Memory and is NP-hard.pdf:pdf},
number = {Cl},
title = {{Optimal Continual Learning has Perfect Memory and is NP-hard}},
url = {http://arxiv.org/abs/2006.05188},
year = {2020}
}
@article{Arik2019,
abstract = {We propose a novel high-performance and interpretable canonical deep tabular data learning architecture, TabNet. TabNet uses sequential attention to choose which features to reason from at each decision step, enabling interpretability and more efficient learning as the learning capacity is used for the most salient features. We demonstrate that TabNet outperforms other neural network and decision tree variants on a wide range of non-performance-saturated tabular datasets and yields interpretable feature attributions plus insights into the global model behavior. Finally, for the first time to our knowledge, we demonstrate self-supervised learning for tabular data, significantly improving performance with unsupervised representation learning when unlabeled data is abundant.},
archivePrefix = {arXiv},
arxivId = {1908.07442},
author = {Arik, Sercan O. and Pfister, Tomas},
eprint = {1908.07442},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arik, Pfister - 2019 - TabNet Attentive Interpretable Tabular Learning.pdf:pdf},
keywords = {tabular data},
mendeley-tags = {tabular data},
month = {aug},
title = {{TabNet: Attentive Interpretable Tabular Learning}},
url = {http://arxiv.org/abs/1908.07442 https://github.com/google-research/google-research/tree/master/tabnet https://github.com/dreamquark-ai/tabnet},
year = {2019}
}
@article{Davis1987,
abstract = {The idea that empathy may best be considered a multidimensional construct, consisting of both cognitive and emotional facets, has recently been gaining in popularity. To date, however, little research explicitly based on such a view has been carried out. We conducted the present experiment to explore the different influences of cognitive and emotional empathy on two types of responses to dramatic stimuli: positive and negative emotional reactions. Consistent with a multidimensional view of empathy, the two types of empathy exhibited different effects; positive emotional reactions were affected primarily by cognitive empathy, and negative emotional reactions were most heavily influenced by emotional empathy. The results are discussed in terms of their relevance to a multidimensional approach to the study of empathic responding.},
author = {Davis, Mark H. and Hull, Jay G. and Young, Richard D. and Warren, Gregory G.},
doi = {10.1037/0022-3514.52.1.126},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Davis et al. - 1987 - Emotional reactions to dramatic film stimuli The influence of cognitive and emotional empathy.pdf:pdf},
isbn = {0022-3514 (Print)\r0022-3514 (Linking)},
issn = {1939-1315},
journal = {Journal of Personality and Social Psychology},
number = {1},
pages = {126--133},
pmid = {3820067},
title = {{Emotional reactions to dramatic film stimuli: The influence of cognitive and emotional empathy.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0022-3514.52.1.126},
volume = {52},
year = {1987}
}
@article{Kornblith2019,
abstract = {Transfer learning is a cornerstone of computer vision, yet little work has been done to evaluate the relationship between architecture and transfer. An implicit hypothesis in modern computer vision research is that models that perform better on ImageNet necessarily perform better on other vision tasks. However, this hypothesis has never been systematically tested. Here, we compare the performance of 16 classification networks on 12 image classification datasets. We find that, when networks are used as fixed feature extractors or fine-tuned, there is a strong correlation between ImageNet accuracy and transfer accuracy (r = 0.99 and 0.96, respectively). In the former setting, we find that this relationship is very sensitive to the way in which networks are trained on ImageNet; many common forms of regularization slightly improve ImageNet accuracy but yield features that are much worse for transfer learning. Additionally, we find that, on two small fine-grained image classification datasets, pretraining on ImageNet provides minimal benefits, indicating the learned features from ImageNet do not transfer well to fine-grained tasks. Together, our results show that ImageNet architectures generalize well across datasets, but ImageNet features are less general than previously suggested.},
archivePrefix = {arXiv},
arxivId = {1805.08974},
author = {Kornblith, Simon and Shlens, Jonathon and Le, Quoc V.},
doi = {10.1109/CVPR.2019.00277},
eprint = {1805.08974},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kornblith, Shlens, Le - 2019 - Do better imagenet models transfer better.pdf:pdf},
isbn = {9781728132938},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
keywords = {Deep Learning,Representation Learning,imagenet,transfer learning},
mendeley-tags = {imagenet,transfer learning},
pages = {2656--2666},
title = {{Do better imagenet models transfer better?}},
volume = {2019-June},
year = {2019}
}
@article{Rahman2014,
abstract = {This paper presents two new algorithms developed to make improvements in weather forecasting which can be applied to Bangladesh Meteorological Department (BMD) The algorithm Fuzzifier considers the overlapped wind speed of a cyclone to get a fuzzy output which is used in another algorithm Neuronet to determine the best range of wind speed. The best range produces a value which is converted to a percentage of the danger level. This would allow people living in coastal areas to get a better understanding of the forthcoming danger of a cyclone as compared to what is currently being practiced by the BMD which just warns by an alert number.},
author = {Rahman, Tamjid and Haque, Abul L.},
doi = {10.1016/j.procs.2014.09.061},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rahman, Haque - 2014 - A fuzzy-neuro based weather prediction system for Bangladesh.pdf:pdf},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {Algorithm,Bangladesh meteorological department,Cyclone,Forthcoming danger,Wind speed},
number = {C},
pages = {606--611},
publisher = {Elsevier Masson SAS},
title = {{A fuzzy-neuro based weather prediction system for Bangladesh}},
url = {http://dx.doi.org/10.1016/j.procs.2014.09.061},
volume = {36},
year = {2014}
}
@article{Luo2016,
abstract = {The recent advanced face recognition systems were built on large Deep Neural Networks (DNNs) or their ensembles, which have millions of parameters. However, the expensive computation of DNNs make their deployment difficult on mobile and embedded devices. This work addresses model compression for face recognition, where the learned knowledge of a large teacher network or its ensemble is utilized as supervision to train a compact student network. Unlike previous works that represent the knowledge by the soften label probabilities, which are difficult to fit, we represent the knowledge by using the neurons at the higher hidden layer, which preserve as much information as the label probabilities, but are more compact. By leveraging the essential characteristics (domain knowledge) of the learned face representation, a neuron selection method is proposed to choose neurons that are most relevant to face recognition. Using the selected neurons as supervision to mimic the single networks of DeepID2+ and DeepID3, which are the state-of-The-Art face recognition systems, a compact student with simple network structure achieves better verification accuracy on LFW than its teachers, respectively. When using an ensemble of DeepID2+ as teacher, a mimicked student is able to outperform it and achieves 51.6 × compression ratio and 90 × speed-up in inference, making this cumbersome model applicable on portable devices.},
author = {Luo, Ping and Zhu, Zhenyao and Liu, Ziwei and Wang, Xiaogang and Tang, Xiaoou},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Luo et al. - 2016 - Face model compression by distilling knowledge from neurons.pdf:pdf},
isbn = {9781577357605},
journal = {30th AAAI Conference on Artificial Intelligence, AAAI 2016},
keywords = {Technical Papers: Vision},
pages = {3560--3566},
title = {{Face model compression by distilling knowledge from neurons}},
year = {2016}
}
@article{Kondratenko2003a,
abstract = {This paper reports empirical evidence that a neural networks model is applicable to the statistically reliable prediction of foreign exchange rates. Time series data and technical indicators such as moving average, are fed to neural nets to capture the underlying "rules" of the movement in currency exchange rates. The trained recurrent neural networks forecast the exchange rates between American Dollar and four other major currencies, Japanese Yen, Swiss Frank, British Pound and EURO. Various statistical estimates of forecast quality have been carried out. Obtained results show, that neural networks are able to give forecast with coefficient of multiple determination not worse then 0.65. Linear and nonlinear statistical data preprocessing, such as Kolmogorov-Smirnov test and Hurst exponents for each currency were calculated and analyzed.},
archivePrefix = {arXiv},
arxivId = {cond-mat/0304469},
author = {Kondratenko, V V and Kuperin, Yu a},
doi = {10.2298/CSIS140728005B},
eprint = {0304469},
isbn = {9780956494443},
issn = {1820-0214},
journal = {Time},
keywords = {complex systems theory,foreign exchange rate,hurst exponent,neural networks,statistical tests},
pages = {23},
primaryClass = {cond-mat},
title = {{Using Recurrent Neural Networks To Forecasting of Forex}},
url = {http://arxiv.org/abs/cond-mat/0304469},
year = {2003}
}
@article{Srinivasan2016,
author = {Srinivasan, Rangan},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Srinivasan - 2016 - Analysis of Recurrent Neural Networks for Prediction of Wave Height Using Wind Data.pdf:pdf},
number = {October},
title = {{Analysis of Recurrent Neural Networks for Prediction of Wave Height Using Wind Data}},
url = {https://www.researchgate.net/profile/Rangan_Srinivasan/publication/309485844_Recurrent_Neural_Networks/links/5812d45408ae1f5510c2baec/Recurrent-Neural-Networks.pdf},
year = {2016}
}
@article{Sarwar2018a,
abstract = {Cardiovascular disease is the leading cause of mortality and morbidity globally. With widespread and growing use of smart phones and mobile devices, the use of mobile health (mHealth) in transmission of physiologic parameters and patient-referred symptoms to healthcare providers and researchers, as well as reminders and care plan applications from providers to patients, has potential to revolutionize both clinical care and the conduct of clinical trials with improved designs, data capture, and potentially lower costs. In randomized early phase proof-of-concept studies, focusing on lifestyle intervention, there is evidence that mHealth technology can improve outcomes. By contrast, results from small randomized controlled trials that tested mHealth interventions in heart failure patients were disappointing with inconsistent findings. These inconclusive results could be partially attributed to a lack of methodological rigor (insufficient sample size, quasi-experimental design, inadequate mHealth equipment). Therefore, there is an urgent need to develop systematic evidence-based guidelines and parameters for mHealth to be effectively utilized in cardiovascular clinical trials.},
author = {Sarwar, Chaudhry M.S. and Vaduganathan, Muthiah and Anker, Stefan D. and Coiro, Stefano and Papadimitriou, Lampros and Saltz, Joel and Schoenfeld, Elinor R. and Clark, Richard L. and Dinh, Wilfried and Kramer, Frank and Gheorghiade, Mihai and Fonarow, Gregg C. and Butler, Javed},
doi = {10.1016/j.ijcard.2018.06.039},
issn = {18741754},
journal = {International Journal of Cardiology},
keywords = {Clinical trials,Endpoints,Heart failure,Mobile health},
pages = {#pagerange#},
publisher = {Elsevier B.V},
title = {{Mobile health applications in cardiovascular research}},
url = {https://doi.org/10.1016/j.ijcard.2018.06.039},
year = {2018}
}
@article{Vassos2013,
abstract = {In a seminal paper, Lin and Reiter introduced a model-theoretic definition for the progression of a basic action theory in the situation calculus, and proved that it implies the intended properties. They also showed that this definition comes with a strong negative result, namely that for certain cases first-order logic is not expressive enough to correctly characterize the progressed theory and second-order axioms are necessary. However, they also considered an alternative simpler definition according to which the progressed theory is always first-order definable. They conjectured that this alternative definition is incorrect in the sense that the progressed theory is too weak and may sometimes lose information. This conjecture and the status of the definability of progression in first-order logic has remained open since. In this paper we present two significant results about this alternative definition of progression. First, we prove the Lin and Reiter conjecture by presenting a case where the progressed theory indeed does lose information, thus closing a question that has remained open for more than ten years. Second, we prove that the alternative definition is nonetheless correct for reasoning about a large class of sentences, including some that quantify over situations. {\textcopyright} 2012 Elsevier B.V. All rights reserved.},
author = {Vassos, Stavros and Levesque, Hector J.},
doi = {10.1016/j.artint.2012.10.005},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vassos, Levesque - 2013 - How to progress a database III.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {Knowledge representation,Reasoning about action,Situation calculus},
pages = {203--221},
publisher = {Elsevier B.V.},
title = {{How to progress a database III}},
url = {http://dx.doi.org/10.1016/j.artint.2012.10.005},
volume = {195},
year = {2013}
}
@article{By,
author = {By, Presented and Hariharasudan, Karthika N Maheshwari N},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/By, Hariharasudan - Unknown - Shape memory polymer.pdf:pdf},
title = {{Shape memory polymer}}
}
@inproceedings{Tao2020b,
abstract = {In this paper, we propose a novel single-task continual learning framework named Bi-Objective Continual Learning (BOCL). BOCL aims at both consolidating historical knowledge and learning from new data. On one hand, we propose to preserve the old knowledge using a small set of pillars, and develop the pillar consolidation (PLC) loss to preserve the old knowledge and to alleviate the catastrophic forgetting problem. On the other hand, we develop the contrastive pillar (CPL) loss term to improve the classification performance, and examine several data sampling strategies for efficient onsite learning from ‘new' with a reasonable amount of computational resources. Comprehensive experiments on CIFAR10/100, CORe50 and a subset of ImageNet validate the BOCL framework. We also reveal the performance accuracy of different sampling strategies when used to finetune a given CNN model. The code will be released.},
author = {Tao, Xiaoyu and Hong, Xiaopeng and Chang, Xinyuan and Gong, Yihong},
booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
doi = {10.1609/aaai.v34i04.6060},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tao et al. - 2020 - Bi-Objective Continual Learning Learning ‘New' While Consolidating ‘Known'.pdf:pdf},
issn = {2374-3468},
month = {apr},
number = {04},
pages = {5989--5996},
title = {{Bi-Objective Continual Learning: Learning ‘New' While Consolidating ‘Known'}},
url = {https://aaai.org/ojs/index.php/AAAI/article/view/6060 https://github.com/xyutao/bocl},
volume = {34},
year = {2020}
}
@inproceedings{Perez-Rua2020a,
author = {Perez-Rua, Juan-Manuel and Zhu, Xiatian and Hospedales, Timothy M. and Xiang, Tao},
booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/CVPR42600.2020.01386},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Perez-Rua et al. - 2020 - Incremental Few-Shot Object Detection(2).pdf:pdf},
isbn = {978-1-7281-7168-5},
keywords = {continual learning,few-shot learning,incremental learning,object detection},
mendeley-tags = {continual learning,few-shot learning,incremental learning,object detection},
month = {jun},
number = {2},
pages = {13843--13852},
publisher = {IEEE},
title = {{Incremental Few-Shot Object Detection}},
url = {https://ieeexplore.ieee.org/document/9157715/},
year = {2020}
}
@article{Berkowitz2016,
abstract = {Following a twerk-heavy performance by Miley Cyrus on the Video Music Awards program, CNN featured the story on the top of its website. The Onion—a fake-news organization—then ran a satirical column purporting to be by CNN's Web editor explaining this decision. Through textual analysis, this paper demonstrates how a Fifth Estate comprised of bloggers, columnists and fake-news organizations worked to relocate mainstream journalism back to within its professional boundaries.},
author = {Berkowitz, Dan and Schwartz, David Asa},
doi = {10.1080/17512786.2015.1006933},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Berkowitz, Schwartz - 2016 - Miley, CNN and the onion When fake news becomes realer than real.pdf:pdf},
issn = {17512794},
journal = {Journalism Practice},
keywords = {Bloggers,Boundary work,CNN,Fifth estate,Hyper-reality,Miley cyrus,The onion},
number = {1},
pages = {1--17},
title = {{Miley, CNN and the onion: When fake news becomes realer than real}},
volume = {10},
year = {2016}
}
@article{Li2021a,
author = {Li, Xiaobin and Shan, Lianlei and Li, Minglong and Wang, Weiqiang},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2021 - Energy Minimum Regularization in Continual Learning.pdf:pdf},
keywords = {continual learning,regularization},
mendeley-tags = {continual learning,regularization},
number = {January},
title = {{Energy Minimum Regularization in Continual Learning}},
year = {2021}
}
@article{Zavorotynska2016,
abstract = {Magnesium borohydride (Mg(BH4)2) shows interesting properties both from fundamental and applicative points of view. Mg(BH4)2has the most complex crystal structures and the largest number of phase polymorphs among other borohydrides. Some of these polymorphs possess a significant porosity, and on the other hand ultra-density with the second highest volumetric hydrogen content among all known hydrides. Additionally, Mg(BH4)2demonstrates the lowest theoretical stability, the lowest temperature of hydrogen release, and the mildest conditions for partial rehydrogenation among the alkali and alkaline-earth borohydrides. Mg(BH4)2could also be of interest in batteries applications, since Mg metal holds better volumetric capacity and is more abundant than Li. In this work we review recent results on synthesis, structure, hydrogen storage properties and battery-related applications of Mg(BH4)2.},
author = {Zavorotynska, Olena and El-Kharbachi, Abdelouahab and Deledda, Stefano and Hauback, Bj{\o}rn C.},
doi = {10.1016/j.ijhydene.2016.02.015},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zavorotynska et al. - 2016 - Recent progress in magnesium borohydride Mg(BH4)2 Fundamentals and applications for energy storage.pdf:pdf},
issn = {03603199},
journal = {International Journal of Hydrogen Energy},
keywords = {Batteries,Decomposition pathway,FTIR,Hydrogen storage,Magnesium borohydride},
number = {32},
pages = {14387--14403},
publisher = {Elsevier Ltd},
title = {{Recent progress in magnesium borohydride Mg(BH4)2: Fundamentals and applications for energy storage}},
url = {http://dx.doi.org/10.1016/j.ijhydene.2016.02.015},
volume = {41},
year = {2016}
}
@article{Galich2012,
abstract = {Background: The wider background to this article is the shift in the energy paradigm from fossil energy sources to renewable sources which should occur in the twenty-first century. This transformation requires the development of alternative energy technologies that enable the deployment of renewable energy sources in transportation, heating, and electricity. Among others, hydrogen and fuel cell technologies have the potential to fulfill this requirement and to contribute to a sustainable and emission-free transport and energy system. However, whether they will ever reach broad societal acceptance will not only depend on technical issues alone. The aim of our study is to reveal the importance of nontechnical issues. Therefore, the article at hand presents a case study of hydrogen and fuel cells in Germany and aims at highlighting the cultural context that affects their development. Methods: Our results were obtained from a rich pool of data generated in various research projects through more than 30 in-depth interviews, direct observations, and document analyses. Results: We found that individual and collective actors developed five specific supportive practices which they deploy in five diverse arenas of meaning in order to attach certain values to hydrogen and fuel cell technologies. Conclusions: Based on the results, we drew more general conclusions and deducted an overall model for the analysis of culture in technological innovations that is outlined at the end of the article. It constitutes our contribution to the interdisciplinary collaboration required for tackling the shift in this energy paradigm.},
author = {Galich, Ante and Marz, Lutz},
doi = {10.1186/2192-0567-2-2},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Galich, Marz - 2012 - Alternative energy technologies as a cultural endeavor a case study of hydrogen and fuel cell development in Germa.pdf:pdf},
keywords = {culture,hydrogen and fuel cells,shift in the energy paradigm},
pages = {1--10},
title = {{Alternative energy technologies as a cultural endeavor: a case study of hydrogen and fuel cell development in Germany}},
url = {https://energsustainsoc.springeropen.com/track/pdf/10.1186/2192-0567-2-2?site=energsustainsoc.springeropen.com},
year = {2012}
}
@article{RajeevS.1992,
abstract = {ABSTRACT: Optimizing most structural systems used in practice requires considering design variables as discrete quantities. The paper presents a simple genetic algorithm for optimizing structural systems with discrete design variables. As genetic algorithms (GAs) are best suited for unconstrained optimization problems, it is necessary to transform the constrained problem into an unconstrained one. A penalty-based transformation method is used in the present work. The penalty parameter depends on the degree of constraint violation, which is found to be wellsuited for a parallel search using genetic algorithms. The concept of optimization using the genetic algorithm is presented in detail using a three-bar truss problem. All the computations for three successive generations are presented in the form of tables for easy understanding of the algorithm. Two standard problems from literature are solved and results compared. The application of the genetic algorithm to design optimization of a larger problem is illustrated using a 160-bar transmission tower},
author = {{Rajeev S.} and Krishnamoorthy, C. S.},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rajeev S., Krishnamoorthy - 1992 - DISCRETE OPTIMIZATION OF STRUCTURES USING G E N E T I C ALGORITHMS By. S. Rajeev 1 and C. S. Krishnam.pdf:pdf},
number = {5},
pages = {1233--1250},
title = {{DISCRETE OPTIMIZATION OF STRUCTURES USING G E N E T I C ALGORITHMS By. S. Rajeev 1 and C. S. Krishnamoorthy 2}},
volume = {118},
year = {1992}
}
@article{Belouadah2021,
abstract = {The ability of artificial agents to increment their capabilities when confronted with new data is an open challenge in artificial intelligence. The main challenge faced in such cases is catastrophic forgetting, i.e., the tendency of neural networks to underfit past data when new ones are ingested. A first group of approaches tackles forgetting by increasing deep model capacity to accommodate new knowledge. A second type of approaches fix the deep model size and introduce a mechanism whose objective is to ensure a good compromise between stability and plasticity of the model. While the first type of algorithms were compared thoroughly, this is not the case for methods which exploit a fixed size model. Here, we focus on the latter, place them in a common conceptual and experimental framework and propose the following contributions: (1) define six desirable properties of incremental learning algorithms and analyze them according to these properties, (2) introduce a unified formalization of the class-incremental learning problem, (3) propose a common evaluation framework which is more thorough than existing ones in terms of number of datasets, size of datasets, size of bounded memory and number of incremental states, (4) investigate the usefulness of herding for past exemplars selection, (5) provide experimental evidence that it is possible to obtain competitive performance without the use of knowledge distillation to tackle catastrophic forgetting and (6) facilitate reproducibility by integrating all tested methods in a common open-source repository. The main experimental finding is that none of the existing algorithms achieves the best results in all evaluated settings. Important differences arise notably if a bounded memory of past classes is allowed or not.},
archivePrefix = {arXiv},
arxivId = {2011.01844},
author = {Belouadah, Eden and Popescu, Adrian and Kanellos, Ioannis},
doi = {10.1016/j.neunet.2020.12.003},
eprint = {2011.01844},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Belouadah, Popescu, Kanellos - 2021 - A comprehensive study of class incremental learning algorithms for visual tasks.pdf:pdf},
isbn = {0000000280},
issn = {18792782},
journal = {Neural Networks},
keywords = {Catastrophic forgetting,Convolutional neural networks,Image classification,Imbalanced learning,Incremental learning,Review,Survey,continual learning,review,survey},
mendeley-tags = {continual learning,review,survey},
pages = {38--54},
pmid = {33341513},
title = {{A comprehensive study of class incremental learning algorithms for visual tasks}},
url = {https://github.com/EdenBelouadah/class-incremental-learning},
volume = {135},
year = {2021}
}
@article{Wu2015,
abstract = {Two-dimensional (2D) nanomaterials, especially the transition metal sulfide semiconductors, have drawn great interests due to their potential applications in viable photonic and optoelectronic devices. In this work, 2D tungsten disulfide (WS2) based saturable absorber (SA) for ultrafast photonic applications was demonstrated. WS2 nanosheets were prepared using liquid-phase exfoliation method and embedded in polyvinyl alcohol (PVA) thin film for the practical usage. Saturable absorption was discovered in the WS2-PVA SA at the telecommunication wavelength near 1550 nm. By incorporating WS2-PVA SA into a fiber laser cavity, both stable mode locking operation and Q-switching operation were achieved. In the mode locking operation, the laser obtained femtosecond output pulse width and high spectral purity in the radio frequency spectrum. In the Q-switching operation, the laser had tunable repetition rate and output pulse energy of a few tens of nano joule. Our findings suggest that few-layer WS2 nanosheets embedded in PVA thin film are promising nonlinear optical materials for ultrafast photonic applications as a mode locker or Q-switcher. (C) 2015 Optical Society of America},
archivePrefix = {arXiv},
arxivId = {1411.5777},
author = {Wu, Kan and Zhang, Xiaoyan and Wang, Jun and Li, Xing and Chen, Jianping},
doi = {10.1364/OE.23.011453},
eprint = {1411.5777},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu et al. - 2015 - WS_2 as a saturable absorber for ultrafast photonic applications of mode-locked and Q-switched lasers.pdf:pdf},
isbn = {1094-4087},
issn = {1094-4087},
journal = {Optics Express},
number = {9},
pages = {11453},
title = {{WS_2 as a saturable absorber for ultrafast photonic applications of mode-locked and Q-switched lasers}},
url = {https://www.osapublishing.org/abstract.cfm?URI=oe-23-9-11453},
volume = {23},
year = {2015}
}
@article{Zhou2019,
abstract = {Detection identifies objects as axis-aligned boxes in an image. Most successful object detectors enumerate a nearly exhaustive list of potential object locations and classify each. This is wasteful, inefficient, and requires additional post-processing. In this paper, we take a different approach. We model an object as a single point --- the center point of its bounding box. Our detector uses keypoint estimation to find center points and regresses to all other object properties, such as size, 3D location, orientation, and even pose. Our center point based approach, CenterNet, is end-to-end differentiable, simpler, faster, and more accurate than corresponding bounding box based detectors. CenterNet achieves the best speed-accuracy trade-off on the MS COCO dataset, with 28.1% AP at 142 FPS, 37.4% AP at 52 FPS, and 45.1% AP with multi-scale testing at 1.4 FPS. We use the same approach to estimate 3D bounding box in the KITTI benchmark and human pose on the COCO keypoint dataset. Our method performs competitively with sophisticated multi-stage methods and runs in real-time.},
archivePrefix = {arXiv},
arxivId = {1904.07850},
author = {Zhou, Xingyi and Wang, Dequan and Kr{\"{a}}henb{\"{u}}hl, Philipp},
eprint = {1904.07850},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou, Wang, Kr{\"{a}}henb{\"{u}}hl - 2019 - Objects as Points.pdf:pdf},
title = {{Objects as Points}},
url = {http://arxiv.org/abs/1904.07850},
year = {2019}
}
@article{Javed2019,
abstract = {One of the key differences between the learning mechanism of humans and Artificial Neural Networks (ANNs) is the ability of humans to learn one task at a time. ANNs, on the other hand, can only learn multiple tasks simultaneously. Any attempts at learning new tasks incrementally cause them to completely forget about previous tasks. This lack of ability to learn incrementally, called Catastrophic Forgetting, is considered a major hurdle in building a true AI system. In this paper, our goal is to isolate the truly effective existing ideas for incremental learning from those that only work under certain conditions. To this end, we first thoroughly analyze the current state of the art (iCaRL) method for incremental learning and demonstrate that the good performance of the system is not because of the reasons presented in the existing literature. We conclude that the success of iCaRL is primarily due to knowledge distillation and recognize a key limitation of knowledge distillation, i.e., it often leads to bias in classifiers. Finally, we propose a dynamic threshold moving algorithm that is able to successfully remove this bias. We demonstrate the effectiveness of our algorithm on CIFAR100 and MNIST datasets showing near-optimal results. Our implementation is available at: https://github.com/Khurramjaved96/incremental-learning.},
archivePrefix = {arXiv},
arxivId = {1807.02802},
author = {Javed, Khurram and Shafait, Faisal},
doi = {10.1007/978-3-030-20876-9_1},
eprint = {1807.02802},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Javed, Shafait - 2019 - Revisiting Distillation and Incremental Classifier Learning.pdf:pdf},
isbn = {9783030208752},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Catastrophic Forgetting,Incremental classifier,Incremental learning,Knowledge distillation,continual learning,incremental learning,knowledge distillation},
mendeley-tags = {continual learning,incremental learning,knowledge distillation},
pages = {3--17},
title = {{Revisiting Distillation and Incremental Classifier Learning}},
url = {https://github.com/khurramjaved96/incremental-learning},
volume = {11366 LNCS},
year = {2019}
}
@article{Yang2016,
abstract = {Electricity demand forecasting, as a vital tool in the electricity market, plays a critical role in power utilities, which can not only reduce production costs but also save energy resources, thus making the forecasting techniques become an indispensable part of the energy system. A novel combined forecasting method based on Back Propagation (BP) neural network, Adaptive Network-based Fuzzy Inference System (ANFIS) and Difference Seasonal Autoregressive Integrated Moving Average (diff-SARIMA) are presented in this paper. Firstly, the combined method uses all the three methods (BP, ANFIS, diff-SARIMA) to forecast respectively, and the three forecasting results were obtained. By multiplying optimal weight coefficients of the three forecasting results respectively and then adding them up, in the end the final forecasting results can be obtained. Among the three individual methods, BP and ANFIS had the ability to deal with the nonlinearity data, and diff-SARIMA had the ability to deal with the linearity and seasonality data. So the combined method eliminates drawbacks and incorporates in the merits of the individual methods. It has the capability to deal with the linearity, nonlinearity and seasonality data. In order to optimize weight coefficients, Differential Evolution (DE) optimization algorithm is brought into the combined method. To prove the superiority and accuracy, the capability of the combined method is verified by comparing it with the three individual methods. The forecasting results of the combined method proved to be better than all the three individual methods and the combined method was able to reduce errors and improve the accuracy between the actual values and forecasted values effectively. Using the half-hour electricity power data of the State of New South Wales in Australia, relevant experimental case studies showed that the proposed combined method performed better than the other three individual methods and had a higher accuracy.},
author = {Yang, Yi and Chen, Yanhua and Wang, Yachen and Li, Caihong and Li, Lian},
doi = {10.1016/j.asoc.2016.07.053},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2016 - Modelling a combined method based on ANFIS and neural network improved by DE algorithm A case study for short-term.pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {ANFIS,BP,Combined forecasting method,DE,Electricity demand forecasting,diff-SARIMA},
pages = {663--675},
publisher = {Elsevier B.V.},
title = {{Modelling a combined method based on ANFIS and neural network improved by DE algorithm: A case study for short-term electricity demand forecasting}},
url = {http://dx.doi.org/10.1016/j.asoc.2016.07.053},
volume = {49},
year = {2016}
}
@inproceedings{Wei2020c,
abstract = {Self-training algorithms, which train a model to fit pseudolabels predicted by another previously-learned model, have been very successful for learning with unlabeled data using neural networks. However, the current theoretical understanding of self-training only applies to linear models. This work provides a unified theoretical analysis of self-training with deep networks for semi-supervised learning, unsupervised domain adaptation, and unsupervised learning. At the core of our analysis is a simple but realistic “expansion” assumption, which states that a low-probability subset of the data must expand to a neighborhood with large probability relative to the subset. We also assume that neighborhoods of examples in different classes have minimal overlap. We prove that under these assumptions, the minimizers of population objectives based on self-training and input-consistency regularization will achieve high accuracy with respect to ground-truth labels. By using off-the-shelf generalization bounds, we immediately convert this result to sample complexity guarantees for neural nets that are polynomial in the margin and Lipschitzness. Our results help explain the empirical successes of recently proposed self-training algorithms which use input consistency regularization.},
archivePrefix = {arXiv},
arxivId = {2010.03622},
author = {Wei, Colin and Shen, Kendrick and Chen, Yining and Ma, Tengyu},
booktitle = {Iclr 2021},
eprint = {2010.03622},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wei et al. - 2020 - Theoretical analysis of self-training with deep networks on unlabeled data.pdf:pdf},
issn = {23318422},
keywords = {empirical study,pseudolabels,theory,unlabeled data},
mendeley-tags = {empirical study,pseudolabels,theory,unlabeled data},
pages = {1--31},
title = {{Theoretical analysis of self-training with deep networks on unlabeled data}},
year = {2020}
}
@article{Cramer2003,
abstract = {Devwudfw Wklv sdshu ghvfulehv wkh ruljlqv ri wkh orjlvwlf ixqfwlrq/ lwv dgrs0 wlrq lq elr0dvvd|/ dqg lwv zlghu dffhswdqfh lq vwdwlvwlfv1 Lwv urrwv vsuhdg idu edfn wr wkh hduo| 4<wk fhqwxu|> wkh vxuylydo ri wkh whup orjlvwlf dqg wkh zlgh dssolfdwlrq ri wkh ghylfh kdyh ehhq ghwhuplqhg ghflvlyho| e| wkh shuvrqdo klvwrulhv dqg lqglylgxdo dfwlrqv ri d ihz vfkroduv1 Wklv lv d pxfk h{whqghg yhuvlrq ri Fkdswhu < ri Orjlw Prghov iurp Hfrqrplfv dqg Rwkhu Ilhogv/ iruwkfrplqj dw Fdpeulgjh Xqlyhuvlw| Suhvv AE Xqlyhuvlw| ri Dpvwhugdp dqg Wlqehujhq Lqvwlwxwh/ Dpvwhugdp> srvwdo dguhvv Eddpeuxjvh ]xzh 4<7/ 6978 DP Ylqnhyhhq/ wkh Qhwkhuodqgv> h0pdlo dgguhvv pduv1fudpCzruogrqolqh1qo1 L kdg wkh ehqhw ri frpphqwv ri M1 Vdqghh rq dq hduolhu yhuvlrq1 4}},
author = {Cramer, JS},
doi = {10.2139/ssrn.360300},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cramer - 2003 - The Origins of Logistic Regression.pdf:pdf},
issn = {1556-5068},
journal = {SSRN Electronic Journal},
title = {{The Origins of Logistic Regression}},
url = {http://www.ssrn.com/abstract=360300},
year = {2003}
}
@article{Sharot2004,
abstract = {Studies examining memories of arousing 'real-life' events show that emotion heightens the feeling of remembering, without necessarily enhancing the objective accuracy of the memories. We measured brain activity associated with the feeling of remembering emotional and neutral photos. Subjects indicated whether recognition was accompanied by a recollection of details about the study episode ('remember') or not ('know'). 'Remember' judgments were boosted for emotional photos, but accuracy did not differ. For neutral photos, 'remember' judgments were related to enhanced activity in the parahippocampal cortex, previously related to recognition of visual details, which one might expect to supply the retrieval clues for a 'remember' judgment. In contrast, 'remember' judgments for emotional photos were associated with enhanced activity in the amygdala, suggesting that subjects rely on arousal and perceptual fluency to evaluate these memories. For the first time, we identify the neural mechanisms underlying the enhanced feeling of remembering for emotional events.},
author = {Sharot, Tali and Delgado, Mauricio R. and Phelps, Elizabeth A.},
doi = {10.1038/nn1353},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sharot, Delgado, Phelps - 2004 - How emotion enhances the feeling of remembering.pdf:pdf},
isbn = {10976256 (ISSN)},
issn = {10976256},
journal = {Nature Neuroscience},
number = {12},
pages = {1376--1380},
pmid = {15558065},
title = {{How emotion enhances the feeling of remembering}},
volume = {7},
year = {2004}
}
@article{Hamamoto2018,
abstract = {Due to the sheer number of applications that uses computer networks, in which some are crucial to users and enterprises, network management is essential. Therefore, integrity and availability of computer networks become priorities, making it a fundamental resource to be managed. In this work, a scheme combining Genetic Algorithm and a Fuzzy Logic for network anomaly detection is discussed. The Genetic Algorithm is used to generate a Digital Signature of Network Segment using Flow Analysis, where information extracted from network flows data is used to predict the networks traffic behavior for a given time interval. Furthermore, a Fuzzy Logic scheme is applied to decide whether an instance represents an anomaly or not, differing from some approaches present in the literature. Indeed, it is proposed an expert system with the capability to monitor the network's traffic with IP flows while expected behaviors are generated in a regular time interval basis, issuing alarms when a possible problem is present. The proposed anomaly detection system exposes network problems autonomously. The results acquired from applying the proposed approach in a real network traffic flows achieve an accuracy of 96.53% and false positive rate of 0.56%. Moreover, our method succeeds in achieving higher performance compared to several other approaches.},
author = {Hamamoto, Anderson Hiroshi and Carvalho, Luiz Fernando and Sampaio, Lucas Dias Hiera and Abr{\~{a}}o, Taufik and Proen{\c{c}}a, Mario Lemes},
doi = {10.1016/j.eswa.2017.09.013},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hamamoto et al. - 2018 - Network Anomaly Detection System using Genetic Algorithm and Fuzzy Logic.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Fuzzy Logic,Genetic Algorithm,Network Anomaly Detection System,Network management},
pages = {390--402},
publisher = {Elsevier Ltd},
title = {{Network Anomaly Detection System using Genetic Algorithm and Fuzzy Logic}},
volume = {92},
year = {2018}
}
@article{Lamb2020,
abstract = {Feed-forward neural networks consist of a sequence of layers, in which each layer performs some processing on the information from the previous layer. A downside to this approach is that each layer (or module, as multiple modules can operate in parallel) is tasked with processing the entire hidden state, rather than a particular part of the state which is most relevant for that module. Methods which only operate on a small number of input variables are an essential part of most programming languages, and they allow for improved modularity and code re-usability. Our proposed method, Neural Function Modules (NFM), aims to introduce the same structural capability into deep learning. Most of the work in the context of feed-forward networks combining top-down and bottom-up feedback is limited to classification problems. The key contribution of our work is to combine attention, sparsity, top-down and bottom-up feedback, in a flexible algorithm which, as we show, improves the results in standard classification, out-of-domain generalization, generative modeling, and learning representations in the context of reinforcement learning.},
archivePrefix = {arXiv},
arxivId = {2010.08012},
author = {Lamb, Alex and Goyal, Anirudh and S{\l}owik, Agnieszka and Mozer, Michael and Beaudoin, Philippe and Bengio, Yoshua},
eprint = {2010.08012},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lamb et al. - 2020 - Neural Function Modules with Sparse Arguments A Dynamic Approach to Integrating Information across Layers.pdf:pdf},
title = {{Neural Function Modules with Sparse Arguments: A Dynamic Approach to Integrating Information across Layers}},
url = {http://arxiv.org/abs/2010.08012},
year = {2020}
}
@article{Murdoch2019,
abstract = {Machine-learning models have demonstrated great success in learning complex patterns that enable them to make predictions about unobserved data. In addition to using models for prediction, the ability to interpret what a model has learned is receiving an increasing amount of attention. However, this increased focus has led to considerable confusion about the notion of interpretability. In particular, it is unclear how the wide array of proposed interpretation methods are related and what common concepts can be used to evaluate them. We aim to address these concerns by defining interpretability in the context of machine learning and introducing the predictive, descriptive, relevant (PDR) framework for discussing interpretations. The PDR framework provides 3 overarching desiderata for evaluation: predictive accuracy, descriptive accuracy, and relevancy, with relevancy judged relative to a human audience. Moreover, to help manage the deluge of interpretation methods, we introduce a categorization of existing techniques into model-based and post hoc categories, with subgroups including sparsity, modularity, and simulatability. To demonstrate how practitioners can use the PDR framework to evaluate and understand interpretations, we provide numerous real-world examples. These examples highlight the often underappreciated role played by human audiences in discussions of interpretability. Finally, based on our framework, we discuss limitations of existing methods and directions for future work. We hope that this work will provide a common vocabulary that will make it easier for both practitioners and researchers to discuss and choose from the full range of interpretation methods.},
author = {Murdoch, W. James and Singh, Chandan and Kumbier, Karl and Abbasi-Asl, Reza and Yu, Bin},
doi = {10.1073/pnas.1900654116},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Murdoch et al. - 2019 - Definitions, methods, and applications in interpretable machine learning.pdf:pdf},
issn = {10916490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Explainability,Interpretability,Machine learning,Relevancy},
number = {44},
pages = {22071--22080},
pmid = {31619572},
title = {{Definitions, methods, and applications in interpretable machine learning}},
volume = {116},
year = {2019}
}
@article{Tifrea2020,
abstract = {Machine learning models are often used in practice if they achieve good generalization results on in-distribution (ID) holdout data. When employed in the wild, they should also be able to detect samples they cannot predict well. We show that current out-of-distribution (OOD) detection algorithms for neural networks produce unsatisfactory results in a variety of OOD detection scenarios, e.g. when OOD data consists of unseen classes or corrupted measurements. This paper studies how such "hard" OOD scenarios can benefit from adjusting the detection method after observing a batch of the test data. This transductive setting is relevant when the advantage of even a slightly delayed OOD detection outweighs the financial cost for additional tuning. We propose a novel method that uses an artificial labeling scheme for the test data and regularization to obtain ensembles of models that produce contradictory predictions only on the OOD samples in a test batch. We show via comprehensive experiments that our approach is indeed able to significantly outperform both inductive and transductive baselines on difficult OOD detection scenarios, such as unseen classes on CIFAR-10/CIFAR-100, severe corruptions(CIFAR-C), and strong covariate shift (ImageNet vs ObjectNet).},
archivePrefix = {arXiv},
arxivId = {2012.05825},
author = {Ţifrea, Alexandru and Stavarache, Eric and Yang, Fanny},
eprint = {2012.05825},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ţifrea, Stavarache, Yang - 2020 - Learn what you can't learn Regularized Ensembles for Transductive Out-of-distribution Detection.pdf:pdf},
keywords = {out-of-distribution},
mendeley-tags = {out-of-distribution},
title = {{Learn what you can't learn: Regularized Ensembles for Transductive Out-of-distribution Detection}},
url = {http://arxiv.org/abs/2012.05825},
year = {2020}
}
@article{Talukder2020,
abstract = {In this paper, we explore an alternate method for synthesizing neural network architectures, inspired by the brain's stochastic synaptic pruning. During a person's lifetime, numerous distinct neuronal architectures are responsible for performing the same tasks. This indicates that biological neural networks are, to some degree, architecture agnostic. However, artificial networks rely on their fine-tuned weights and hand-crafted architectures for their remarkable performance. This contrast begs the question: Can we build artificial architecture agnostic neural networks? To ground this study we utilize sparse, binary neural networks that parallel the brain's circuits. Within this sparse, binary paradigm we sample many binary architectures to create families of architecture agnostic neural networks not trained via backpropagation. These high-performing network families share the same sparsity, distribution of binary weights, and succeed in both static and dynamic tasks. In summation, we create an architecture manifold search procedure to discover families or architecture agnostic neural networks.},
archivePrefix = {arXiv},
arxivId = {2011.02712},
author = {Talukder, Sabera and Raghavan, Guruprasad and Yue, Yisong},
eprint = {2011.02712},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Talukder, Raghavan, Yue - 2020 - Architecture Agnostic Neural Networks.pdf:pdf},
pages = {1--12},
title = {{Architecture Agnostic Neural Networks}},
url = {http://arxiv.org/abs/2011.02712},
year = {2020}
}
@article{PatelG.C2017,
abstract = {Today, in competitive manufacturing environment reducing casting defects with improved mechanical properties is of industrial relevance. This led the present work to deal with developing the input-output relationship in squeeze casting process utilizing the neural network based forward and reverse mapping. Forward mapping is aimed to predict the casting quality (such as density, hardness and secondary dendrite arm spacing) for the known combination of casting variables (that is, squeeze pressure, pressure duration, die and pouring temperature). Conversely, attempt is also made to determine the appropriate set of casting variables for the required casting quality (that is, reverse mapping). Forward and reverse mapping tasks are carried out utilizing back propagation, recurrent and genetic algorithm tuned neural networks. Parameter study has been conducted to adjust and optimize the neural network parameters utilizing the batch mode of training. Since, batch mode of training requires huge data, the training data is generated artificially using response equations. Furthermore, neural network prediction performances are compared among themselves (reverse mapping) and with those of statistical regression models (forward mapping) with the help of test cases. The results shown all developed neural network models in both forward and reverse mappings are capable of making effective predictions. The results obtained will help the foundry personnel to automate and pr{\'{e}}cised control of squeeze casting process.},
author = {{Patel G.C}, Manjunath and Shettigar, Arun Kumar and Krishna, Prasad and Parappagoudar, Mahesh B.},
doi = {10.1016/j.asoc.2017.06.018},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Patel G.C et al. - 2017 - Back propagation genetic and recurrent neural network applications in modelling and analysis of squeeze castin.pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {Back-propagation neural network (BPNN),Genetic algorithm neural network (GA-NN),Recurrent neural network (RNN) and forward and rev,Squeeze casting process},
pages = {418--437},
publisher = {Elsevier B.V.},
title = {{Back propagation genetic and recurrent neural network applications in modelling and analysis of squeeze casting process}},
url = {http://dx.doi.org/10.1016/j.asoc.2017.06.018},
volume = {59},
year = {2017}
}
@article{Park2014,
abstract = {High power densities have been obtained from MFC reactors having a purple color characteristic of Rhodopseudomonas. We investigated the microbial community structure and population in developed purple MFC medium (DPMM) and MFC effluent (DPME) using 16S rRNA pyrosequencing. In DPMM, dominant bacteria were Comamonas (44.6%), Rhodopseudomonas (19.5%) and Pseudomonas (17.2%). The bacterial community of DPME mainly consisted of bacteria related to Rhodopseudomonas (72.2%). Hydrogen oxidizing bacteria were identified in both purple-colored samples: Hydrogenophaga and Sphaerochaeta in the DPMM, and Arcobacter, unclassified Ignavibacteriaceae, Acinetobacter, Desulfovibrio and Wolinella in the DPME. The methanogenic community of both purple-colored samples was dominated by hydrogenotrophic methanogens including Methanobacterium, Methanobrevibacter and Methanocorpusculum with significantly lower numbers of Methanosarcina. These results suggeste that hydrogen is actively produced by Rhodopseudomonas that leads to the dominance of hydrogen consuming microorganisms in both purple-colored samples. The syntrophic relationship between Rhodopseudomonas and hydrogenotrophic microbes might be important for producing high power density in the acetate-fed MFC under light conditions.},
author = {Park, Tae Jin and Ding, Weijun and Cheng, Shaoan and Brar, Manreetpal Singh and Ma, Angel Po Yee and Tun, Hein Min and Leung, Frederick C.},
doi = {10.1186/s13568-014-0022-2},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Park et al. - 2014 - Microbial community in microbial fuel cell (MFC) medium and effluent enriched with purple photosynthetic bacterium.pdf:pdf},
issn = {21910855},
journal = {AMB Express},
keywords = {Hydrogen oxidizing bacteria,Hydrogenotrophic methanogens,Microbial community,Purple color characteristic of rhodopseudomonas,Syntrophic relationship},
number = {1},
pages = {1--8},
pmid = {24949257},
title = {{Microbial community in microbial fuel cell (MFC) medium and effluent enriched with purple photosynthetic bacterium (rhodopseudomonas sp.)}},
volume = {4},
year = {2014}
}
@article{Bahng2019b,
abstract = {Many machine learning algorithms are trained and evaluated by splitting data from a single source into training and test sets. While such focus on in-distribution learning scenarios has led interesting advances, it has not been able to tell if models are relying on dataset biases as shortcuts for successful prediction (e.g., using snow cues for recognising snowmobiles). Such biased models fail to generalise when the bias shifts to a different class. The cross-bias generalisation problem has been addressed by de-biasing training data through augmentation or re-sampling, which are often prohibitive due to the data collection cost (e.g., collecting images of a snowmobile on a desert) and the difficulty of quantifying or expressing biases in the first place. In this work, we propose a novel framework to train a de-biased representation by encouraging it to be different from a set of representations that are biased by design. This tactic is feasible in many scenarios where it is much easier to define a set of biased representations than to define and quantify bias. Our experiments and analyses show that our method discourages models from taking bias shortcuts, resulting in improved performances on de-biased test data.},
archivePrefix = {arXiv},
arxivId = {1910.02806},
author = {Bahng, Hyojin and Chun, Sanghyuk and Yun, Sangdoo and Choo, Jaegul and Oh, Seong Joon},
eprint = {1910.02806},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bahng et al. - 2019 - Learning de-biased representations with biased representations(2).pdf:pdf},
journal = {arXiv},
pages = {1--6},
title = {{Learning de-biased representations with biased representations}},
volume = {2},
year = {2019}
}
@article{Liu2020h,
abstract = {This paper proposes a Hyperbolic Visual Embedding Learning Network for zero-shot recognition. The network learns image embeddings in hyperbolic space, which is capable of preserving the hierarchical structure of semantic classes in low dimensions. Comparing with existing zero-shot learning approaches, the network is more robust because the embedding feature in hyperbolic space better represents class hierarchy and thereby avoid misleading resulted from unrelated siblings. Our network outperforms exiting baselines under hierarchical evaluation with an extremely challenging setting, i.e., learning only from 1,000 categories to recognize 20,841 unseen categories. While under flat evaluation, it has competitive performance as state-of-the-art methods but with five times lower embedding dimensions. Our code is publicly available * .},
author = {Liu, Shaoteng and Chen, Jingjing and Pan, Liangming and Ngo, Chong-Wah and Chua, Tat-Seng and Jiang, Yu-Gang},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2020 - Hyperbolic Visual Embedding Learning for Zero-Shot Recognition.pdf:pdf},
pages = {9273--9281},
title = {{Hyperbolic Visual Embedding Learning for Zero-Shot Recognition}},
url = {https://github.com/ShaoTengLiu/Hyperbolic_ZSL},
year = {2020}
}
@article{Krogen2017,
abstract = {The generation of intense mid-infrared (mid-IR) optical pulses with customizable shape and spectra spanning a multiple-octave range of vibrational frequencies is an elusive technological capability. While some recent approaches to mid-IR supercontinuum generation—such as filamentation, multicolour four-wave-mixing and optical rectification1, 2, 3, 4, 5, 6, 7, 8—have successfully generated broad spectra, no process has been identified for achieving complex pulse shaping at the generation step. The adiabatic frequency converter9, 10 allows for a one-to-one transfer of spectral phase through nonlinear frequency conversion over a larger-than-octave-spanning range and with an overall linear phase transfer function. Here, we show that we can convert shaped near-infrared (near-IR) pulses to shaped, energetic, multi-octave-spanning mid-IR pulses lasting only 1.2 optical cycles, and extendable to the sub-cycle regime. We expect this capability to enable a new class of precisely controlled nonlinear interactions in the mid-IR spectral range, from nonlinear vibrational spectroscopy to strong light–matter interactions and single-shot remote sensing.},
author = {Krogen, Peter and Suchowski, Haim and Liang, Houkun and Flemens, Noah and Hong, Kyung Han and K{\"{a}}rtner, Franz X. and Moses, Jeffrey},
doi = {10.1038/nphoton.2017.34},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krogen et al. - 2017 - Generation and multi-octave shaping of mid-infrared intense single-cycle pulses.pdf:pdf},
issn = {17494893},
journal = {Nature Photonics},
number = {4},
pages = {222--226},
publisher = {Nature Publishing Group},
title = {{Generation and multi-octave shaping of mid-infrared intense single-cycle pulses}},
url = {http://dx.doi.org/10.1038/nphoton.2017.34},
volume = {11},
year = {2017}
}
@article{Wortsman2020,
abstract = {We present the Supermasks in Superposition (SupSup) model, capable of sequentially learning thousands of tasks without catastrophic forgetting. Our approach uses a randomly initialized, fixed base network and for each task finds a subnetwork (supermask) that achieves good performance. If task identity is given at test time, the correct subnetwork can be retrieved with minimal memory usage. If not provided, SupSup can infer the task using gradient-based optimization to find a linear superposition of learned supermasks which minimizes the output entropy. In practice we find that a single gradient step is often sufficient to identify the correct mask, even among 2500 tasks. We also showcase two promising extensions. First, SupSup models can be trained entirely without task identity information, as they may detect when they are uncertain about new data and allocate an additional supermask for the new training distribution. Finally the entire, growing set of supermasks can be stored in a constant-sized reservoir by implicitly storing them as attractors in a fixed-sized Hopfield network.},
archivePrefix = {arXiv},
arxivId = {2006.14769},
author = {Wortsman, Mitchell and Ramanujan, Vivek and Liu, Rosanne and Kembhavi, Aniruddha and Rastegari, Mohammad and Yosinski, Jason and Farhadi, Ali},
eprint = {2006.14769},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wortsman et al. - 2020 - Supermasks in Superposition.pdf:pdf;:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Recall et al. - Unknown - Algorithm pseudo-code Extended Details for HopSupSup.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {architectural,continual learning},
mendeley-tags = {architectural,continual learning},
number = {NeurIPS},
pages = {13--25},
title = {{Supermasks in Superposition}},
url = {https://proceedings.neurips.cc/paper/2020/hash/ad1f8bb9b51f023cdc80cf94bb615aa9-Abstract.html https://github.com/RAIVNLab/supsup},
year = {2020}
}
@article{Arandjelovic2017,
abstract = {We consider the question: what can be learnt by looking at and listening to a large number of unlabelled videos? There is a valuable, but so far untapped, source of information contained in the video itself - the correspondence between the visual and the audio streams, and we introduce a novel 'Audio-Visual Correspondence' learning task that makes use of this. Training visual and audio networks from scratch, without any additional supervision other than the raw unconstrained videos themselves, is shown to successfully solve this task, and, more interestingly, result in good visual and audio representations. These features set the new state-of-the-art on two sound classification benchmarks, and perform on par with the state-of-the-art selfsupervised approaches on ImageNet classification. We also demonstrate that the network is able to localize objects in both modalities, as well as perform fine-grained recognition tasks.},
archivePrefix = {arXiv},
arxivId = {1705.08168},
author = {Arandjelovic, Relja and Zisserman, Andrew},
doi = {10.1109/ICCV.2017.73},
eprint = {1705.08168},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arandjelovic, Zisserman - 2017 - Look, Listen and Learn.pdf:pdf},
isbn = {9781538610329},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {609--617},
title = {{Look, Listen and Learn}},
volume = {2017-Octob},
year = {2017}
}
@article{Alajmi2014,
abstract = {Effective optimization of unconstrained building optimization problem involves coupling a building energy simulation program with an optimization evolutionary algorithm such as the genetic algorithm (GA). The aim of this paper is to find the most appropriate GA set that obtains the optimum, or near optimum, solutions in a reasonable computational time (less numbers of simulations). Twelve control parameter sets of binary encoded GA are tested to solve unconstrained building optimization problems that are coupled with EnergyPlus simulation program. The results show that population size is the most significant control parameter and that the crossover probability and mutation rate have insignificant effects on the GA performance. In general, a binary encoded GA with small population sizes can be used to solve unconstrained building optimization problems by around 250 building simulation calls. In particular, the smaller population size of about 5 individuals helps reach the optimum solution faster than larger population sizes.},
author = {Alajmi, Ali and Wright, Jonathan},
doi = {10.1016/j.ijsbe.2014.07.003},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alajmi, Wright - 2014 - Selecting the most efficient genetic algorithm sets in solving unconstrained building optimization problem.pdf:pdf},
isbn = {2212-6090},
issn = {22126104},
journal = {International Journal of Sustainable Built Environment},
keywords = {Building Simulation program,EnergyPlus,GA control parameters,Genetic algorithms,Simulation-based building optimization problem},
number = {1},
pages = {18--26},
publisher = {The Gulf Organisation for Research and Development},
title = {{Selecting the most efficient genetic algorithm sets in solving unconstrained building optimization problem}},
url = {http://dx.doi.org/10.1016/j.ijsbe.2014.07.003},
volume = {3},
year = {2014}
}
@article{Huang2019,
abstract = {We address one-shot imitation learning, where the goal is to execute a previously unseen task based on a single demonstration. While there has been exciting progress in this direction, most of the approaches still require a few hundred tasks for meta-training, which limits the scalability of the approaches. Our main contribution is to formulate one-shot imitation learning as a symbolic planning problem along with the symbol grounding problem. This formulation disentangles the policy execution from the inter-task generalization and leads to better data efficiency. The key technical challenge is that the symbol grounding is prone to error with limited training data and leads to subsequent symbolic planning failures. We address this challenge by proposing a continuous relaxation of the discrete symbolic planner that directly plans on the probabilistic outputs of the symbol grounding model. Our continuous relaxation of the planner can still leverage the information contained in the probabilistic symbol grounding and significantly improve over the baseline planner for the one-shot imitation learning tasks without using large training data.},
archivePrefix = {arXiv},
arxivId = {1908.06769},
author = {Huang, De-An and Xu, Danfei and Zhu, Yuke and Garg, Animesh and Savarese, Silvio and Fei-Fei, Li and Niebles, Juan Carlos},
eprint = {1908.06769},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang et al. - 2019 - Continuous Relaxation of Symbolic Planner for One-Shot Imitation Learning.pdf:pdf},
title = {{Continuous Relaxation of Symbolic Planner for One-Shot Imitation Learning}},
url = {http://arxiv.org/abs/1908.06769},
year = {2019}
}
@article{Zhou2020a,
abstract = {Many real-world applications require the prediction of long sequence time-series, such as electricity consumption planning. Long sequence time-series forecasting (LSTF) demands a high prediction capacity of the model, which is the ability to capture precise long-range dependency coupling between output and input efficiently. Recent studies have shown the potential of Transformer to increase the prediction capacity. However, there are several severe issues with Transformer that prevent it from being directly applicable to LSTF, such as quadratic time complexity, high memory usage, and inherent limitation of the encoder-decoder architecture. To address these issues, we design an efficient transformer-based model for LSTF, named Informer, with three distinctive characteristics: (i) a $ProbSparse$ Self-attention mechanism, which achieves $O(L \log L)$ in time complexity and memory usage, and has comparable performance on sequences' dependency alignment. (ii) the self-attention distilling highlights dominating attention by halving cascading layer input, and efficiently handles extreme long input sequences. (iii) the generative style decoder, while conceptually simple, predicts the long time-series sequences at one forward operation rather than a step-by-step way, which drastically improves the inference speed of long-sequence predictions. Extensive experiments on four large-scale datasets demonstrate that Informer significantly outperforms existing methods and provides a new solution to the LSTF problem.},
archivePrefix = {arXiv},
arxivId = {2012.07436},
author = {Zhou, Haoyi and Zhang, Shanghang and Peng, Jieqi and Zhang, Shuai and Li, Jianxin and Xiong, Hui and Zhang, Wancai},
eprint = {2012.07436},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou et al. - 2020 - Informer Beyond Efficient Transformer for Long Sequence Time-Series Forecasting.pdf:pdf},
keywords = {time series},
mendeley-tags = {time series},
title = {{Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting}},
url = {http://arxiv.org/abs/2012.07436 https://github.com/zhouhaoyi/Informer2020},
year = {2020}
}
@article{LopezRodriguez2017a,
abstract = {Mobile Model Predictive control is a novel control technique for irrigation canals that optimizes the actions carried out by human operators. In this paper it is assessed preliminary by means of the numerical model of a reduced scale laboratory irrigation canal located in the facilities of the University of {\'{E}}vora (Portugal). Other control algorithms have also been tested by using a numerical model of the canal and compared with the novel control method: proportional integral control, linear quadratic regulator and centralized model predictive control. The results show that mobile model predictive control offers a performance comparable to that of fully automatic control despite being based exclusively on human operation.},
author = {{L{\'{o}}pez Rodr{\'{i}}guez}, F. and Horv{\'{a}}th, K. and {Garc{\'{i}}a Mart{\'{i}}n}, J. and Maestre, J. M.},
doi = {10.1016/j.ifacol.2017.08.614},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/L{\'{o}}pez Rodr{\'{i}}guez et al. - 2017 - Mobile Model Predictive Control for the {\'{E}}vora irrigation test canal.pdf:pdf},
issn = {24058963},
journal = {IFAC-PapersOnLine},
keywords = {Predictive control,automatic control,control applications},
number = {1},
pages = {6570--6575},
title = {{Mobile Model Predictive Control for the {\'{E}}vora irrigation test canal}},
volume = {50},
year = {2017}
}
@article{Boixader2018,
abstract = {This paper generalizes (fuzzifies) actions of a monoid or group on a set to deal with situations where imprecision and uncertainty are present. Fuzzy actions can handle the granularity of a set or even create it by defining a fuzzy equivalence relation on it.},
author = {Boixader, D. and Recasens, J.},
doi = {10.1016/j.fss.2017.10.006},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boixader, Recasens - 2018 - Fuzzy actions.pdf:pdf},
issn = {01650114},
journal = {Fuzzy Sets and Systems},
keywords = {Fuzzy action,Fuzzy mapping,Fuzzy subgroup,T-indistinguishability operator},
pages = {17--30},
publisher = {Elsevier B.V.},
title = {{Fuzzy actions}},
url = {https://doi.org/10.1016/j.fss.2017.10.006},
volume = {339},
year = {2018}
}
@article{Masana2020a,
abstract = {In this paper, we propose an approach without any forgetting to continual learning for the task-aware regime, where at inference the task-label is known. By using ternary masks we can upgrade a model to new tasks, reusing knowledge from previous tasks while not forgetting anything about them. Using masks prevents both catastrophic forgetting and backward transfer. We argue -- and show experimentally -- that avoiding the former largely compensates for the lack of the latter, which is rarely observed in practice. In contrast to earlier works, our masks are applied to the features (activations) of each layer instead of the weights. This considerably reduces the number of mask parameters to be added for each new task; with more than three orders of magnitude for most networks. The encoding of the ternary masks into two bits per feature creates very little overhead to the network, avoiding scalability issues. Our masks do not permit any changes to features which are used by previous tasks. As this may be too restrictive to allow learning of new tasks, we add task-specific feature normalization. This way, already learned features can adapt to the current task without changing the behavior of these features for previous tasks. Extensive experiments on several finegrained datasets and ImageNet show that our method outperforms current state-of-the-art while reducing memory overhead in comparison to weight-based approaches.},
archivePrefix = {arXiv},
arxivId = {2001.08714},
author = {Masana, Marc and Tuytelaars, Tinne and van de Weijer, Joost},
eprint = {2001.08714},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Masana, Tuytelaars, van de Weijer - 2020 - Ternary Feature Masks continual learning without any forgetting.pdf:pdf},
keywords = {architectural,catastrophic forgetting,continual learning},
mendeley-tags = {architectural,continual learning},
month = {jan},
number = {December},
title = {{Ternary Feature Masks: continual learning without any forgetting}},
url = {http://arxiv.org/abs/2001.08714 https://github.com/mmasana/TernaryFeatureMasks},
year = {2020}
}
@article{Crompton2018a,
abstract = {Mobile device ownership has exploded with the majority of adults owning more than one mobile device. The largest demographic of mobile device users are 18–29 years old which is also the typical age of college attendees. This systematic review provides the scholarly community with a current synthesis of mobile learning research across 2010–2016 in higher education settings regarding the purposes, outcomes, methodologies, subject matter domains, educational level, educational context, device types and geographical distribution of studies. Major findings include that the majority of the studies focused on the impact of mobile learning on student achievement. Language instruction was the most often researched subject matter domain. The findings reveal that 74% involved undergraduate students and 54% took place in a formal educational context. Higher education faculty are encouraged to consider the opportunity to expand their learning possibilities beyond the classroom with mobile learning.},
author = {Crompton, Helen and Burke, Diane},
doi = {10.1016/j.compedu.2018.04.007},
isbn = {9781522507840},
issn = {03601315},
journal = {Computers and Education},
keywords = {Cell phones,Higher education,Mlearning,Mobile learning,Tertiary},
pages = {53--64},
publisher = {Elsevier Ltd},
title = {{The use of mobile learning in higher education: A systematic review}},
url = {https://doi.org/10.1016/j.compedu.2018.04.007},
volume = {123},
year = {2018}
}
@article{Steinmetz2017,
abstract = {Physical temperature can fundamentally affect psychological processes. Among other things, physical warmth typically fosters the motivation to affiliate. We argue that physical warmth can increase affirmative and acquiescent response behavior in psychological surveys and experiments as a result of such an affiliative motive. In Study 1, we find that participants give more biased answers in a memory test in warmer, compared to colder, environments. In Studies 2–3b, physical warmth fosters a response bias toward the affirmation of unrelated items in questionnaires. In Study 4, the effect of physical warmth on the affirmation bias is amplified when the person reading a participant's answers is a friend (stronger affiliation prime) compared to a stranger. Taken together, temperature affects general response behavior by fostering affirmation. Thereby, physical temperature has deeper psychological as well as methodological consequences than previously thought.},
author = {Steinmetz, Janina and Posten, Ann Christin},
doi = {10.1016/j.jesp.2016.12.001},
issn = {10960465},
journal = {Journal of Experimental Social Psychology},
keywords = {Affiliation,Physical warmth,Response bias,Temperature},
pages = {294--300},
publisher = {Elsevier B.V.},
title = {{Physical temperature affects response behavior}},
url = {http://dx.doi.org/10.1016/j.jesp.2016.12.001},
volume = {70},
year = {2017}
}
@article{Workshop2007,
abstract = {NPS Lidar Workshop\r\nMay 24, 2007},
author = {Workshop, N P S Lidar and Liadsky, Joe},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Workshop, Liadsky - 2007 - Introduction to LIDAR Lidar topics Basic principle of operation Desirable attributes and features of a system.pdf:pdf},
title = {{Introduction to LIDAR Lidar topics Basic principle of operation Desirable attributes and features of a system}},
year = {2007}
}
@article{Lake2017,
abstract = {Recent progress in artificial intelligence has renewed interest in building systems that learn and think like people. Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving performance that equals or even beats that of humans in some respects. Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways. We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn and how they learn it. Specifically, we argue that these machines should (1) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (2) ground learning in intuitive theories of physics and psychology to support and enrich the knowledge that is learned; and (3) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations. We suggest concrete challenges and promising routes toward these goals that can combine the strengths of recent neural network advances with more structured cognitive models.},
archivePrefix = {arXiv},
arxivId = {1604.00289},
author = {Lake, Brenden M. and Ullman, Tomer D. and Tenenbaum, Joshua B. and Gershman, Samuel J.},
doi = {10.1017/S0140525X16001837},
eprint = {1604.00289},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lake et al. - 2017 - Building machines that learn and think like people.pdf:pdf},
issn = {14691825},
journal = {Behavioral and Brain Sciences},
pmid = {27881212},
publisher = {Cambridge University Press},
title = {{Building machines that learn and think like people}},
volume = {40},
year = {2017}
}
@article{Nwokocha2012,
abstract = {The current climate change threat by green house gas emissions from the combustion of fossil fuels has necessitated a search for alternative non-polluting, reliable, renewable and sustainable sources of energy such as solar energy and its derivatives. During anaerobic microbial metabolism of small carbohydrates, protons and electrons are generated together with carbon dioxide gas. After the electrons are donated to the anode by the microbes (or with the aid of chemical mediators), these electrons can be channelled through a circuit bearing a load to the cathode, where the atmospheric oxygen is reduced, first to its divalent ions and subsequently to water. Unlike other biomass-to-energy conversion techniques such as torrefaction and gasification, no emissions are produced and the process is carbon neutral. There is no need for expensive conversion techniques such as transesterification, thermal or catalytic cracking or catalytic liquefaction. It is also non-destructive; the energy is harvested in-situ and is guaranteed as long as feedstock is available, can be implemented using industrial waste water, can be used in desalination or remediation and has application potential in wetlands and erosion sites which are prevalent in Sub-Saharan Africa, reducing competition with food supply and other conventional sources of bio-energy.},
author = {Nwokocha, John V and Nwokocha, J and Nnanna, A},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nwokocha, Nwokocha, Nnanna - 2012 - The Microbial Fuel Cell The Solution to the Global Energy and Environmental Crises.pdf:pdf},
journal = {International Journal of Academic Research in Progressive Education and Development},
keywords = {Alternative energy,In-situ energy,Plant-Microbial Fuel Cell,electrigens,zero emissions},
number = {1},
pages = {2226--6348},
title = {{The Microbial Fuel Cell: The Solution to the Global Energy and Environmental Crises?}},
url = {www.hrmars.com},
volume = {1},
year = {2012}
}
@article{Rijk2010,
author = {Rijk, Gerard and Gulpers, Marco},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rijk, Gulpers - 2010 - The third industrial revolution.pdf:pdf},
keywords = {Duurzame merken,branding,consumentengedrag},
number = {31 20},
title = {{The third industrial revolution}},
year = {2010}
}
@article{Kamra2017,
abstract = {Despite advances in deep learning, neural networks can only learn multiple tasks when trained on them jointly. When tasks arrive sequentially, they lose performance on previously learnt tasks. This phenomenon called catastrophic forgetting is a fundamental challenge to overcome before neural networks can learn continually from incoming data. In this work, we derive inspiration from human memory to develop an architecture capable of learning continuously from sequentially incoming tasks, while averting catastrophic forgetting. Specifically, our contributions are: (i) a dual memory architecture emulating the complementary learning systems (hippocampus and the neocortex) in the human brain, (ii) memory consolidation via generative replay of past experiences, (iii) demonstrating advantages of generative replay and dual memories via experiments, and (iv) improved performance retention on challenging tasks even for low capacity models. Our architecture displays many characteristics of the mammalian memory and provides insights on the connection between sleep and learning.},
archivePrefix = {arXiv},
arxivId = {1710.10368},
author = {Kamra, Nitin and Gupta, Umang and Liu, Yan},
eprint = {1710.10368},
file = {:home/user/Downloads/1710.10368.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {continual learning,generative replay,incremental learning,rehearsal,replay},
mendeley-tags = {continual learning,generative replay,incremental learning,rehearsal,replay},
title = {{Deep generative dual memory network for continual learning}},
year = {2017}
}
@article{Constantino2017,
author = {Constantino, Sara},
doi = {10.1038/s41562-017-0159},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Constantino - 2017 - Psychology Moral contagion online.pdf:pdf},
issn = {23973374},
journal = {Nature Human Behaviour},
number = {8},
pages = {1},
publisher = {Macmillan Publishers Limited},
title = {{Psychology: Moral contagion online}},
url = {http://dx.doi.org/10.1038/s41562-017-0159},
volume = {1},
year = {2017}
}
@article{Ahmad2017,
abstract = {We are seeing an enormous increase in the availability of streaming, time-series data. Largely driven by the rise of connected real-time data sources, this data presents technical challenges and opportunities. One fundamental capability for streaming analytics is to model each stream in an unsupervised fashion and detect unusual, anomalous behaviors in real-time. Early anomaly detection is valuable, yet it can be difficult to execute reliably in practice. Application constraints require systems to process data in real-time, not batches. Streaming data inherently exhibits concept drift, favoring algorithms that learn continuously. Furthermore, the massive number of independent streams in practice requires that anomaly detectors be fully automated. In this paper we propose a novel anomaly detection algorithm that meets these constraints. The technique is based on an online sequence memory algorithm called Hierarchical Temporal Memory (HTM). We also present results using the Numenta Anomaly Benchmark (NAB), a benchmark containing real-world data streams with labeled anomalies. The benchmark, the first of its kind, provides a controlled open-source environment for testing anomaly detection algorithms on streaming data. We present results and analysis for a wide range of algorithms on this benchmark, and discuss future challenges for the emerging field of streaming analytics.},
author = {Ahmad, Subutai and Lavin, Alexander and Purdy, Scott and Agha, Zuha},
doi = {10.1016/j.neucom.2017.04.070},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ahmad et al. - 2017 - Unsupervised real-time anomaly detection for streaming data.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Anomaly detection,Benchmark dataset,Concept drift,Hierarchical Temporal Memory,Streaming data,Unsupervised learning,time series},
mendeley-tags = {time series},
number = {June},
pages = {134--147},
publisher = {Elsevier B.V.},
title = {{Unsupervised real-time anomaly detection for streaming data}},
url = {http://dx.doi.org/10.1016/j.neucom.2017.04.070 https://github.com/numenta/NAB},
volume = {262},
year = {2017}
}
@inproceedings{Abdelkarim2021,
abstract = {Several approaches have been proposed in recent literature to alleviate the long-tail problem, mainly in object classification tasks. In this paper, we make the first large-scale study concerning the task of Long-Tail Visual Relationship Recognition (LTVRR). LTVRR aims at improving the learning of structured visual relationships that come from the long-tail (e.g., "rabbit grazing on grass"). In this setup, the subject, relation, and object classes each follow a long-tail distribution. To begin our study and make a future benchmark for the community, we introduce two LTVRR-related benchmarks, dubbed VG8K-LT and GQA-LT, built upon the widely used Visual Genome and GQA datasets. We use these benchmarks to study the performance of several state-of-the-art long-tail models on the LTVRR setup. Lastly, we propose a visiolinguistic hubless (VilHub) loss and a Mixup augmentation technique adapted to LTVRR setup, dubbed as RelMix. Both VilHub and RelMix can be easily integrated on top of existing models and despite being simple, our results show that they can remarkably improve the performance, especially on tail classes. Benchmarks, code, and models have been made available at: https://github.com/Vision-CAIR/LTVRR.},
archivePrefix = {arXiv},
arxivId = {2004.00436},
author = {Abdelkarim, Sherif and Agarwal, Aniket and Achlioptas, Panos and Chen, Jun and Huang, Jiaji and Li, Boyang and Church, Kenneth and Elhoseiny, Mohamed},
booktitle = {International Conference on Computer Vision},
eprint = {2004.00436},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abdelkarim et al. - 2021 - Exploring Long Tail Visual Relationship Recognition with Large Vocabulary.pdf:pdf},
keywords = {long-tailed recognition},
mendeley-tags = {long-tailed recognition},
pages = {15921--15930},
title = {{Exploring Long Tail Visual Relationship Recognition with Large Vocabulary}},
url = {https://arxiv.org/abs/2004.00436v6},
year = {2021}
}
@article{Lee2018,
abstract = {Speed optimization of liner vessels has significant economic and environmental impact for reducing fuel cost and Green House Gas (GHG) emission as the shipping over maritime logistics takes more than 70% of world transportation. While slow steaming is widely used as best practices for liner shipping companies, they are also under the pressure to maintain service level agreement (SLA) with their cargo clients. Thus, deciding optimal speed that minimizes fuel consumption while maintaining SLA is managerial decision problem. Studies in the literature use theoretical fuel consumption functions in their speed optimization models but these functions have limitations due to weather conditions in voyages. This paper uses weather archive data to estimate the real fuel consumption function for speed optimization problems. In particular, Copernicus data set is used as the source of big data and data mining technique is applied to identify the impact of weather conditions based on a given voyage route. Particle swarm optimization, a metaheuristic optimization method, is applied to find Pareto optimal solutions that minimize fuel consumption and maximize SLA. The usefulness of the proposed approach is verified through the real data obtained from a liner company and real world implications are discussed.},
author = {Lee, Habin and Aydin, Nursen and Choi, Youngseok and Lekhavat, Saowanit and Irani, Zahir},
doi = {10.1016/j.cor.2017.06.005},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee et al. - 2018 - A decision support system for vessel speed decision in maritime logistics using weather archive big data.pdf:pdf},
issn = {03050548},
journal = {Computers and Operations Research},
keywords = {Liner shipping,Particle swarm optimization,Speed optimization,Sustainable maritime logistics,Weather archive data},
pages = {330--342},
publisher = {Elsevier Ltd},
title = {{A decision support system for vessel speed decision in maritime logistics using weather archive big data}},
url = {http://dx.doi.org/10.1016/j.cor.2017.06.005},
volume = {98},
year = {2018}
}
@article{JothiKumarR,
abstract = {Organizations are maintaining history of data for future analysis. These huge volume of database is analysed to Predict and improve the benefits and profits of the organization and also for the development. By analysing the history of data, strategic decisions can be made to improve the performance of the organizations by the top level peoples. So organizations are interested in analysing the data which will result in valuable insight. The data subjected to mining consists of inconsistent, blank or null and noisy values which have to be cleaned before mining. Usually the Techniques of Mean, Mode, and Median will be used to clean the data which are inefficient methods. Here I am representing the efficient data pre-processing which is to be carried out before actual mining process can be performed. The data from different databases, different locations and different formats are considered for pre-processing. This results in identification of reasonable patterns to improve the performance of organization. Even the Neural Networks has complex structure, consumes more learning time and difficult to understand the representation of results, it have more acceptance ability to clean impure data with more precise and accuracy in pre-processing which results in efficient data pre-processing for Data Mining. The data pre-processing includes four stages. They are cleaning the Data, Selecting the data, Data Enhancement and Data Transformation. Cleaning the data: is to fill the empty value of the data and to ignore the noisy data and to correct the inconsistencies data. Selecting the data: is choosing the appropriate data which suits for learning. Data Enhancement: is done to enhance the data quality which has been selected. Data Expression: is to transform the data after pre-processing into the form which can be accepted by the data mining algorithm based on neural network. The data mining based on neural network can only handle numerical data, so it is need to transform the sign data into numerical data. The simplest method is to establish a table with one-to-one correspondence between the sign data and the numerical data. The other more complex approach is to adopt the appropriate Hash function to generate a unique numerical data according to given string. Although there are many data types in relational database, but they all basically can be simply come down to sign data, discrete numerical data and serial numerical data. Then, the discrete numerical data can be quantified into continuous numerical data and can also be encoded into coding data which can be easily and efficiently handled by data mining algorithms. KEYWORDS—Data mining; neural networks, data mining process, Pre-processing.},
author = {JothiKumarR and SivabalanRV},
journal = {International Journal of Scientific Research and Management Studies},
number = {4},
pages = {2349--3771},
title = {{Efficient Data Pre-Processing for Data Mining Using Neural Networks}},
volume = {1}
}
@article{Pan2008,
abstract = {Transfer learning addresses the problem of how to utilize plenty of labeled data in a source domain to solve related but different problems in a target domain, even when the training and testing problems have different distributions or features. In this paper, we consider transfer learning via dimensionality reduction. To solve this problem, we learn a low-dimensional latent feature space where the distributions between the source domain data and the target domain data are the same or close to each other. Onto this latent feature space, we project the data in related domains where we can apply standard learning algorithms to train classification or regression models. Thus, the latent feature space can be treated as a bridge of transferring knowledge from the source domain to the target domain. The main contribution of our work is that we propose a new dimensionality reduction method to find a latent space, which minimizes the distance between distributions of the data in different domains in a latent space. The effectiveness of our approach to transfer learning is verified by experiments in two real world applications: indoor WiFi localization and binary text classification. Copyright {\textcopyright} 2008, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
author = {Pan, Sinno Jialin and Kwok, James T. and Yang, Qiang},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pan, Kwok, Yang - 2008 - Transfer learning via dimensionality reduction.pdf:pdf},
isbn = {9781577353683},
journal = {Proceedings of the National Conference on Artificial Intelligence},
keywords = {Machine Learning,dimensionality reduction,transfer learning},
mendeley-tags = {dimensionality reduction,transfer learning},
pages = {677--682},
title = {{Transfer learning via dimensionality reduction}},
volume = {2},
year = {2008}
}
@article{Guidelines2021,
author = {Guidelines, Bmvc Author},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guidelines - 2021 - FFNB Forgetting-Free Neural Blocks for Deep Continual Learning.pdf:pdf;:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guidelines - 2021 - FFNB Forgetting-Free Neural Blocks for Deep Continual Learning(2).pdf:pdf},
keywords = {architectural,continual learning},
mendeley-tags = {architectural,continual learning},
title = {{FFNB : Forgetting-Free Neural Blocks for Deep Continual Learning}},
year = {2021}
}
@article{Sciancalepore2014c,
author = {Sciancalepore, Corrado and Manfredini, Tiziano and Bondioli, Federica},
doi = {10.4028/www.scientific.net/AST.92.90},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sciancalepore, Manfredini, Bondioli - 2014 - Antibacterial and Self-Cleaning Coatings for Silicate Ceramics A Review(2).pdf:pdf},
isbn = {3038353043},
issn = {1662-0356},
journal = {Advances in Science and Technology},
number = {December 2015},
pages = {90--99},
title = {{Antibacterial and Self-Cleaning Coatings for Silicate Ceramics: A Review}},
url = {http://www.scientific.net/AST.92.90},
volume = {92},
year = {2014}
}
@article{Chen2020a,
abstract = {The computer vision world has been re-gaining enthusiasm in various pre-trained models, including both classical ImageNet supervised pre-training and recently emerged self-supervised pre-training such as simCLR and MoCo. Pre-trained weights often boost a wide range of downstream tasks including classification, detection, and segmentation. Latest studies suggest that the pre-training benefits from gigantic model capacity. We are hereby curious and ask: after pre-training, does a pre-trained model indeed have to stay large for its universal downstream transferability? In this paper, we examine the supervised and self-supervised pre-trained models through the lens of lottery ticket hypothesis (LTH). LTH identifies highly sparse matching subnetworks that can be trained in isolation from (nearly) scratch, to reach the full models' performance. We extend the scope of LTH to questioning whether matching subnetworks still exist in the pre-training models, that enjoy the same downstream transfer performance. Our extensive experiments convey an overall positive message: from all pre-trained weights obtained by ImageNet classification, simCLR and MoCo, we are consistently able to locate such matching subnetworks at 59.04% to 96.48% sparsity that transfer universally to multiple downstream tasks, whose performance see no degradation compared to using full pre-trained weights. Further analyses reveal that subnetworks found from different pre-training tend to yield diverse mask structures and perturbation sensitivities. We conclude that the core LTH observations remain generally relevant in the pre-training paradigm of computer vision, but more delicate discussions are needed in some cases. Codes and pre-trained models will be made available at: https://github.com/VITA-Group/CV_LTH_Pre-training.},
archivePrefix = {arXiv},
arxivId = {2012.06908},
author = {Chen, Tianlong and Frankle, Jonathan and Chang, Shiyu and Liu, Sijia and Zhang, Yang and Carbin, Michael and Wang, Zhangyang},
eprint = {2012.06908},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2020 - The Lottery Tickets Hypothesis for Supervised and Self-supervised Pre-training in Computer Vision Models.pdf:pdf},
title = {{The Lottery Tickets Hypothesis for Supervised and Self-supervised Pre-training in Computer Vision Models}},
url = {http://arxiv.org/abs/2012.06908},
year = {2020}
}
@article{Hull1995,
abstract = {Abstract People recreating outdoors (at an urban, park) and people recreating indoors (in their homes) assessed their moods at the start, middle, and end of their brief (less than 2?hr) leisure experiences. Moods changed slightly but significantly, and some of these changes were consistent with predictions that leisure reduces stress. Contrary to expectations, recreating near nature produced no more restoration than did recreating indoors, away from nature.\nAbstract People recreating outdoors (at an urban, park) and people recreating indoors (in their homes) assessed their moods at the start, middle, and end of their brief (less than 2?hr) leisure experiences. Moods changed slightly but significantly, and some of these changes were consistent with predictions that leisure reduces stress. Contrary to expectations, recreating near nature produced no more restoration than did recreating indoors, away from nature.},
author = {Hull, R. B. and Michael, Sean E.},
doi = {10.1080/01490409509513239},
isbn = {1521-0588, Electronic\r0149-0400, Print},
issn = {15210588},
journal = {Leisure Sciences},
keywords = {Arousal,Benefit,Emotion,Experience,Mood regulation,Recreation,Stress},
number = {1},
pages = {1--14},
title = {{Nature‐based Recreation, mood change, and stress restoration}},
volume = {17},
year = {1995}
}
@article{Le2020,
archivePrefix = {arXiv},
arxivId = {arXiv:1908.10223v2},
author = {Le, Canyu and Wei, Xihan and Wang, Biao and Zhang, Lei and Chen, Zhonggui},
eprint = {arXiv:1908.10223v2},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Le et al. - 2020 - Learning Continually from Low-shot Data Stream.pdf:pdf},
keywords = {continual learning,data stream,low-shot},
mendeley-tags = {continual learning,data stream,low-shot},
number = {i},
title = {{Learning Continually from Low-shot Data Stream}},
year = {2020}
}
@article{Kuciauskas1998,
author = {Kuciauskas, Arunas P. and Brody, L. Robin and Hadjimichael, Michael and Bankert, Richard L. and Tag, Paul M. and Peak, James E.},
doi = {10.1017/S1350482798001005},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuciauskas et al. - 1998 - A fuzzy expert system to assist in the prediction of hazardous wind conditions within the Mediterranean basin.pdf:pdf},
issn = {13504827},
journal = {Meteorological Applications},
number = {4},
pages = {307--320},
title = {{A fuzzy expert system to assist in the prediction of hazardous wind conditions within the Mediterranean basin}},
volume = {5},
year = {1998}
}
@article{Wang1999,
abstract = {The stability, controllability and observability of lightly damped linear mechanical systems are considered and gyroscopic effects (e.g., control moment gyros) are also included. The structure of the equations is further specified to include both 'rigid' and 'elastic' modes, possibly coupled by gyroscopic terms. Stability and asymptotic stability results are summarized in two theorems. The special structure of the system equations permits a statement of the necessary and sufficient conditions for controllability and observability in terms of simple rank tests. Of great practical significance, the minimum number of actuators and sensors are among the necessary conditions derived. Natural definitions for modal controllability and observability are also evolved which give a direct indication of beneficial locations for actuators and sensors.},
author = {Wang, Cj},
doi = {10.3724/SP.J.1004.2009.01249},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang - 1999 - Controllability and Observability of Linear Time-Varying Singular Systems.pdf:pdf},
isbn = {0-13-134116-2},
issn = {0254-4156},
journal = {Automatic Control, IEEE Transactions on},
number = {10},
pages = {1901--1905},
pmid = {18307326},
title = {{Controllability and Observability of Linear Time-Varying Singular Systems}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=793733},
volume = {44},
year = {1999}
}
@article{Aljundi2018,
abstract = {Humans can learn in a continuous manner. Old rarely utilized knowledge can be overwritten by new incoming information while important, frequently used knowledge is prevented from being erased. In artificial learning systems, lifelong learning so far has focused mainly on accumulating knowledge over tasks and overcoming catastrophic forgetting. In this paper, we argue that, given the limited model capacity and the unlimited new information to be learned, knowledge has to be preserved or erased selectively. Inspired by neuroplasticity, we propose a novel approach for lifelong learning, coined Memory Aware Synapses (MAS). It computes the importance of the parameters of a neural network in an unsupervised and online manner. Given a new sample which is fed to the network, MAS accumulates an importance measure for each parameter of the network, based on how sensitive the predicted output function is to a change in this parameter. When learning a new task, changes to important parameters can then be penalized, effectively preventing important knowledge related to previous tasks from being overwritten. Further, we show an interesting connection between a local version of our method and Hebb's rule, which is a model for the learning process in the brain. We test our method on a sequence of object recognition tasks and on the challenging problem of learning an embedding for predicting <subject, predicate, object> triplets. We show state-of-the-art performance and, for the first time, the ability to adapt the importance of the parameters based on unlabeled data towards what the network needs (not) to forget, which may vary depending on test conditions.},
archivePrefix = {arXiv},
arxivId = {1711.09601},
author = {Aljundi, Rahaf and Babiloni, Francesca and Elhoseiny, Mohamed and Rohrbach, Marcus and Tuytelaars, Tinne},
doi = {10.1007/978-3-030-01219-9_9},
eprint = {1711.09601},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aljundi et al. - 2018 - Memory Aware Synapses Learning What (not) to Forget.pdf:pdf},
isbn = {9783030012182},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {adaptation marcus,contin-,hebbian learning,i would remove keywords,incremental learning,lifelong learning,to have space for,ual learning},
pages = {144--161},
title = {{Memory Aware Synapses: Learning What (not) to Forget}},
volume = {11207 LNCS},
year = {2018}
}
@article{Santos2017,
abstract = {Nowadays, products customization by consumers tends to be one more variable in the manufacturing process, and smart factories will have to be able to customize what each customers have into consideration, adapting to the preferences. One of the main characteristics of Industry 4.0 is support the integration and virtualization of manufacturing design and production process using the information and internet to create smart products. This paper will present a state of the art review of Industry 4.0 based on recent developments in research and practice within PDP domain. A multi-criteria decision making approach using the Promethee will realize an analysis of the Product Development Process Phases and Industry 4.0 concepts, considering relationship, attributing values, and some other characteristics between them. Subsequently, an overview of different opportunities for product development process in Industry 4.0 will be presented.},
author = {Santos, K{\'{a}}ssio and Loures, Eduardo and Piechnicki, Fl{\'{a}}vio and Canciglieri, Os{\'{i}}ris},
doi = {10.1016/j.promfg.2017.07.265},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Santos et al. - 2017 - Opportunities Assessment of Product Development Process in Industry 4.0.pdf:pdf},
isbn = {2351-9789},
issn = {23519789},
journal = {Procedia Manufacturing},
keywords = {Industry 4.0,Product Development Process,Promethee},
number = {June},
pages = {1358--1365},
publisher = {The Author(s)},
title = {{Opportunities Assessment of Product Development Process in Industry 4.0}},
url = {http://dx.doi.org/10.1016/j.promfg.2017.07.265},
volume = {11},
year = {2017}
}
@article{Micic2018,
abstract = {Right invariant fuzzy quasi-orders for fuzzy automata are broadly studied in the recent literature, as they arise as solutions to particular systems of fuzzy relation equations and inequalities. Some of their applications include determinization and state reduction procedures, as well as simulations and bisimulations for fuzzy automata. In this paper we provide a procedure for computing the greatest right invariant fuzzy quasi-order for a given fuzzy automaton over a complete residuated lattice. The proposed procedure terminates in a finite number of steps whenever the underlying structure of the fuzzy automaton is locally finite. When the previous condition is not satisfied, we show that the greatest right invariant fuzzy quasi-order can be obtained by taking the limit value of the convergent array of fuzzy quasi-orders for fuzzy automata over BL-algebras on the real unit interval [0,1]. Analogous procedures for computing the greatest left invariant fuzzy quasi-order, as well as the greatest right and left invariant fuzzy equivalences for a fuzzy automaton are also presented. In addition, the faster algorithm for computing the greatest right invariant equivalence on a nondeterministic automaton is also presented.},
author = {Mici{\'{c}}, Ivana and Jan{\v{c}}i{\'{c}}, Zorana and Stanimirovi{\'{c}}, Stefan},
doi = {10.1016/j.fss.2017.09.004},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mici{\'{c}}, Jan{\v{c}}i{\'{c}}, Stanimirovi{\'{c}} - 2018 - Computation of the greatest right and left invariant fuzzy quasi-orders and fuzzy equivalences.pdf:pdf},
issn = {01650114},
journal = {Fuzzy Sets and Systems},
keywords = {Complete residuated lattice,Fuzzy automaton,Fuzzy equivalence,Fuzzy quasi-order},
pages = {99--118},
title = {{Computation of the greatest right and left invariant fuzzy quasi-orders and fuzzy equivalences}},
volume = {339},
year = {2018}
}
@article{Sellors2002,
abstract = {We're all familiar with the statistics — we know that we are far more likely to be killed in a car accident than in almost any other type of accident, yet we feel more comfortable and in control of cars than other forms of transport.},
author = {Sellors, Nick},
doi = {10.1016/S1353-4858(02)00211-8},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sellors - 2002 - Viral hoaxes.pdf:pdf},
issn = {13534858},
journal = {Network Security},
number = {2},
pages = {5},
title = {{Viral hoaxes}},
volume = {2002},
year = {2002}
}
@article{Lou2020,
abstract = {Recent advances in deep representation learning on Riemannian manifolds extend classical deep learning operations to better capture the geometry of the manifold. One possible extension is the Fr\'echet mean, the generalization of the Euclidean mean; however, it has been difficult to apply because it lacks a closed form with an easily computable derivative. In this paper, we show how to differentiate through the Fr\'echet mean for arbitrary Riemannian manifolds. Then, focusing on hyperbolic space, we derive explicit gradient expressions and a fast, accurate, and hyperparameter-free Fr\'echet mean solver. This fully integrates the Fr\'echet mean into the hyperbolic neural network pipeline. To demonstrate this integration, we present two case studies. First, we apply our Fr\'echet mean to the existing Hyperbolic Graph Convolutional Network, replacing its projected aggregation to obtain state-of-the-art results on datasets with high hyperbolicity. Second, to demonstrate the Fr\'echet mean's capacity to generalize Euclidean neural network operations, we develop a hyperbolic batch normalization method that gives an improvement parallel to the one observed in the Euclidean setting.},
archivePrefix = {arXiv},
arxivId = {2003.00335},
author = {Lou, Aaron and Katsman, Isay and Jiang, Qingxuan and Belongie, Serge and Lim, Ser-Nam and {De Sa}, Christopher},
eprint = {2003.00335},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lou et al. - 2020 - Differentiating through the Fr'echet Mean.pdf:pdf},
journal = {arXiv},
month = {feb},
title = {{Differentiating through the Fr\'echet Mean}},
url = {http://arxiv.org/abs/2003.00335},
year = {2020}
}
@article{Fu2016,
abstract = {This paper presents an experimental study of bubbly flows at relatively high void fractions using an advanced image processing method. Bubble overlapping is a common problem in such flows and the past studies often treat the overlapping bubbles as a whole, which introduces considerable measurement uncertainties. In this study, a hybrid method combining intersection point detection and watershed segmentation is used to separate the overlapping bubbles. In order to reconstruct bubbles from separated segments, a systematic procedure is developed which can preserve more features captured in the raw image compared to the simple ellipse fitting method. The distributions of void fraction, interfacial area concentration, number density and velocity are obtained from the extracted bubble information. High-speed images of air-water bubbly flows are acquired and processed for eight test runs conducted in a 30 mm × 10 mm rectangular channel. The developed image processing scheme can effectively separate overlapping bubbles and the results compare well with the measurements by the gas flow meter and double-sensor conductivity probe. The development of flows in transverse and mainstream directions are analyzed and compared with the prediction made by the one-dimensional interfacial area transport equation (IATE) and the bubble number density transport equation.},
author = {Fu, Yucheng and Liu, Yang},
doi = {10.1016/j.nucengdes.2016.10.044},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fu, Liu - 2016 - Experimental study of bubbly flow using image processing techniques.pdf:pdf},
issn = {00295493},
journal = {Nuclear Engineering and Design},
keywords = {Bubble number density,Bubbly flow,Image processing,Interfacial area transport},
pages = {570--579},
publisher = {Elsevier B.V.},
title = {{Experimental study of bubbly flow using image processing techniques}},
url = {http://dx.doi.org/10.1016/j.nucengdes.2016.10.044},
volume = {310},
year = {2016}
}
@article{Allen-Zhu2018a,
abstract = {How can local-search methods such as stochastic gradient descent (SGD) avoid bad local minima in training multi-layer neural networks? Why can they fit random labels even given non-convex and non-smooth architectures? Most existing theory only covers networks with one hidden layer, so can we go deeper? In this paper, we focus on recurrent neural networks (RNNs) which are multi-layer networks widely used in natural language processing. They are harder to analyze than feedforward neural networks, because the same recurrent unit is repeatedly applied across the entire time horizon of length L, which is analogous to feedforward networks of depth L. We show when the number of neurons is sufficiently large, meaning polynomial in the training data size and in L, then SGD is capable of minimizing the regression loss in the linear convergence rate. This gives theoretical evidence of how RNNs can memorize data. More importantly, in this paper we build general toolkits to analyze multi-layer networks with ReLU activations. For instance, we prove why ReLU activations can prevent exponential gradient explosion or vanishing, and build a perturbation theory to analyze first-order approximation of multi-layer networks.},
archivePrefix = {arXiv},
arxivId = {1810.12065},
author = {Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
eprint = {1810.12065},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Allen-Zhu, Li, Song - 2018 - On the convergence rate of training recurrent neural networks.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {convergence,optimization,recurrent neural networks,theory},
mendeley-tags = {convergence,optimization,recurrent neural networks,theory},
title = {{On the convergence rate of training recurrent neural networks}},
year = {2018}
}
@article{Shinta2012,
abstract = {Keywords: Abstrak. Kata kunci: This study purpose to determine whether there is differences in the provision of effective communications training to improve student self-efficacy. The subject of this study is students of the Faculty of Psychology, University of Airlangga force 2011. The number of subjects in this study were 15 people, nine people consisting of male subjects and 6 female subjects. Data collection tool used in the form of self-efficacy questionnaire soft skills consisted of 47 items. Analysis of the data used in this study is a statistical test Paired t-tests with SPSS version 17.0. From the analysis of data obtained showed that the level of significance of the results of calculations with the Paired T-test in this study at 0,002, this suggests that the hypothesis in this study significant, in other words there is a difference providing Communication Training to Improve Student Self-Efficacy. While the effect size in this study is 1,37, which means that the provision of effective communication training to great effect to enhance student self-efficacy Penelitian ini bertujuan untuk mengetahui apakah terdapat perbedaan pemberian pelatihan komunikasi efektif untuk meningkatkan efikasi diri mahasiswa. Subjek penelitian ini adalah mahasiswa Fakultas Psikologi Universitas Airlangga angkatan 2011. Jumlah subjek dalam penelitian ini adalah 15 orang, 9 orang terdiri dari subjek laki-laki dan 6 orang subjek perempuan. Alat pengumpulan data yang digunakan berupa kuesioner efikasi diri soft skill yang terdiri dari 47 butir. Analisis data yang digunakan dalam penelitian ini adalah uji statistik Paired T-test dengan bantuan program spss versi 17.0. Dari hasil analisis data yang diperoleh menunjukkan hasil bahwa taraf signifikansi penghitungan dengan Paired T-test dalam penelitian ini sebesar 0,002, hal ini menunjukkan bahwa hipotesa dalam penelitian ini signifikan, dengan kata lain ada perbedaan pemberian Pelatihan Komunikasi Efektif untuk Meningkatkan Efikasi Diri Mahasiswa. Sedangkan nilai efek size dalam penelitian ini adalah 1,37 yang artinya bahwa},
author = {Shinta, Deta and Wardani, Kusuma},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shinta, Wardani - 2012 - Pengaruh Pelatihan Komunikasi Efektif Untuk Meningkatkan Efikasi Diri Mahasiswa.pdf:pdf},
keywords = {self-efficacy,training of communication},
number = {02},
title = {{Pengaruh Pelatihan Komunikasi Efektif Untuk Meningkatkan Efikasi Diri Mahasiswa}},
volume = {1},
year = {2012}
}
@article{Bertini2011,
abstract = {Unpaired electrons can exert effects that allow interatomic contacts in molecules to be detected more easily using nuclear magnetic resonance. One such effect reveals unusual interactions between certain atoms in a protein.},
author = {Bertini, Ivano and Luchinat, Claudio},
doi = {10.1038/470469a},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bertini, Luchinat - 2011 - Spectroscopy Unexpected interactions.pdf:pdf},
isbn = {1476-4687 (Electronic)\r0028-0836 (Linking)},
issn = {00280836},
journal = {Nature},
number = {7335},
pages = {469--470},
pmid = {21350473},
title = {{Spectroscopy: Unexpected interactions}},
volume = {470},
year = {2011}
}
@article{OBrien2015,
abstract = {The objective of soft tissue quantitative ultrasound (QUS) is to improve diagnostic ultrasound imaging capabilities via quantitative outcomes. Over the past three or so decades, there have been an increasing number of QUS successes. A temporal view moves us back in history almost six decades when techniques and theoretical developments were in their earliest stages that impacted modern QUS successes. The earliest theoretical developments and techniques some six decades ago can be attributed to Lev Chernov, Philip Morse, Herman Feshbach, Uno Ingard, John Wild and Jack Reid. Later, Floyd Dunn developed important views as to how connective tissue affected the interaction between ultrasound and soft tissue. Then, as the theory of wave propagation in soft tissues with random inhomogeneities was extended and applied by Fred Lizzi, Jim Zagzebski and Mike Insana (and their colleagues), contemporary QUS successes started to emerge.},
author = {O'Brien, William D.},
doi = {10.1016/j.phpro.2015.08.241},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/O'Brien - 2015 - A temporal view of soft tissue quantitative ultrasound.pdf:pdf},
issn = {18753892},
journal = {Physics Procedia},
keywords = {Backscattered Coefficient,Quantitative Ultrasound,Ultrasound Imaging},
pages = {1127--1130},
publisher = {Elsevier B.V.},
title = {{A temporal view of soft tissue quantitative ultrasound}},
url = {http://dx.doi.org/10.1016/j.phpro.2015.08.241},
volume = {70},
year = {2015}
}
@article{SALEH2016,
abstract = {Journal of Modern Power Systems and Clean Energy, doi:10.1007/s40565-016-0196-5},
author = {SALEH, Ibrahim M. M. and ALI, Rashid and ZHANG, Hongwei},
doi = {10.1007/s40565-016-0196-5},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/SALEH, ALI, ZHANG - 2016 - Simplified mathematical model of proton exchange membrane fuel cell based on horizon fuel cell stack.pdf:pdf},
issn = {2196-5625},
journal = {Journal of Modern Power Systems and Clean Energy},
keywords = {Proton exchange membrane (PEM) fuel cell,Activatio,activation losses,anode model,cathode,concentration losses,fuel cell,membrane hydration model,ohmic losses,pem,proton exchange membrane},
number = {4},
pages = {668--679},
publisher = {Springer Berlin Heidelberg},
title = {{Simplified mathematical model of proton exchange membrane fuel cell based on horizon fuel cell stack}},
url = {http://link.springer.com/10.1007/s40565-016-0196-5},
volume = {4},
year = {2016}
}
@article{Xu2017,
abstract = {Ride-sourcing services have become increasingly important in meeting travel needs in metropolitan areas. However, the cruising of vacant ride-sourcing vehicles generates additional traffic demand that may worsen traffic conditions. This paper investigates the allocation of a certain portion of road space to on-street parking for vacant ride-sourcing vehicles. A macroscopic conceptual framework is developed to capture the trade-off between capacity loss and the reduction of cruising. Considering a hypothetical matching mechanism adopted by the platform, we further materialize the framework and then apply it to study the interactions between the ride-sourcing system and parking provision under various market structures.},
author = {Xu, Zhengtian and Yin, Yafeng and Zha, Liteng},
doi = {10.1016/j.trb.2017.10.003},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu, Yin, Zha - 2017 - Optimal parking provision for ride-sourcing services.pdf:pdf},
issn = {01912615},
journal = {Transportation Research Part B: Methodological},
keywords = {Cruising,Matching,Parking,Parking provision,Ride-sourcing services},
pages = {559--578},
publisher = {Elsevier Ltd},
title = {{Optimal parking provision for ride-sourcing services}},
volume = {105},
year = {2017}
}
@article{War1914,
author = {War, Civil},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/War - 1914 - The 2nd Industrial Revolution.pdf:pdf},
pages = {1879--1881},
title = {{The 2nd Industrial Revolution}},
year = {1914}
}
@article{Christodoulos2010a,
abstract = {Forecasting diffusion of new technologies is usually performed by the means of aggregate diffusion models, which tend to monopolize this area of research and practice, making the alternative approaches, like the Box-Jenkins, less favourable choices due to their lack of providing accurate long-term predictions. This paper presents a new methodology focusing on the improvement of the short-term prediction that combines the advantages of both approaches and that can be applied in the early stages of a diffusion process. An application of the methodology is also illustrated, providing short-term forecasts for the world broadband and mobile telecommunications' penetration. The results reveal that the methodology is capable of producing improved one-year-ahead predictions, after a certain level of penetration, as compared to the results of both methods individually. This methodology can find applications to all cases of the high-technology market, where a diffusion model is usually used for obtaining future forecasts. The paper concludes with the limitations of the methodology, the discussion on the application's results and the proposals for further research. {\textcopyright} 2010 Elsevier Inc.},
author = {Christodoulos, Charisios and Michalakelis, Christos and Varoutas, Dimitris},
doi = {10.1016/j.techfore.2010.01.009},
isbn = {00401625 (ISSN)},
issn = {00401625},
journal = {Technological Forecasting and Social Change},
keywords = {ARIMA models,Linear Logistic model,Mobile and broadband penetration,Technology diffusion,Time-series forecasting},
number = {4},
pages = {558--565},
publisher = {Elsevier Inc.},
title = {{Forecasting with limited data: Combining ARIMA and diffusion models}},
url = {http://dx.doi.org/10.1016/j.techfore.2010.01.009},
volume = {77},
year = {2010}
}
@article{MARQUES2016a,
abstract = {With the demand in the production at large-scale food, confinement of animals has become a necessity of the productive process because of the increase in production capacity and optimization of the spaces reserved for creations. In this context, the aim of this study was the development and validation of models using fuzzy logic for predicting climate indices and productive performance of European quails kept in a climatic chamber. The model developed was analyzed from two points of view; the first one took into account the prediction of climate indexes where the input variables were the temperature (°C) and relative humidity (%) of the air. In the second, related to the prediction of productive performance, the input variables were air temperature (°C) and age of the birds (weeks) while the output variables were the food intake (FI, g), water consumption (WC, g), weight gain (WG, g) and food conversion (FC g g-1) of the birds. The Mamdani method was used for the preparation of the rules, and in the defuzzification was applied the center of gravity method. Based on the results generated by the models and compared with the experimental data it was obtained coefficients of determination (R1) of: 0.9771; 0.9897; 0.9955; 0.9995; 0.9993 and 0.9788, for BGTHI, RTL, WC, FI, WG and FC, respectively.},
author = {MARQUES, JORD{\^{A}}NIO I. and {LOPES NETO}, JOS{\'{E}} P. and LOPES, FERNANDA F. DE M. and FURTADO, DERMEVAL A. and ARA{\'{U}}JO, TIAGO G. P.},
doi = {10.1590/1809-4430-Eng.Agric.v36n4p604-612/2016},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/MARQUES et al. - 2016 - Fuzzy modeling in the prediction of climate indices and productive performance of quails kept in climate chamber.pdf:pdf},
issn = {0100-6916},
journal = {Engenharia Agr{\'{i}}cola},
keywords = {coturniculture,environmental quality,fuzzy logic,productivity},
number = {4},
pages = {604--612},
title = {{Fuzzy modeling in the prediction of climate indices and productive performance of quails kept in climate chamber}},
url = {http://www.scielo.br/scielo.php?script=sci_arttext&pid=S0100-69162016000400604&lng=en&tlng=en},
volume = {36},
year = {2016}
}
@article{Weston2015,
abstract = {We describe a new class of learning models called memory networks. Memory networks reason with inference components combined with a long-term memory component; they learn how to use these jointly. The long-term memory can be read and written to, with the goal of using it for prediction. We investigate these models in the context of question answering (QA) where the long-term memory effectively acts as a (dynamic) knowledge base, and the output is a textual response. We evaluate them on a large-scale QA task, and a smaller, but more complex, toy task generated from a simulated world. In the latter, we show the reasoning power of such models by chaining multiple supporting sentences to answer questions that require understanding the intension of verbs.},
archivePrefix = {arXiv},
arxivId = {1410.3916},
author = {Weston, Jason and Chopra, Sumit and Bordes, Antoine},
eprint = {1410.3916},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Weston, Chopra, Bordes - 2015 - Memory networks.pdf:pdf},
journal = {3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings},
keywords = {architecture,memory,memory networks,neural networks},
mendeley-tags = {architecture,memory,memory networks,neural networks},
pages = {1--15},
title = {{Memory networks}},
url = {https://github.com/facebook/MemNN},
year = {2015}
}
@article{Makridakis2017,
abstract = {The impact of the industrial and digital (information) revolutions has, undoubtedly, been substantial on practically all aspects of our society, life, firms and employment. Will the forthcoming AI revolution produce similar, far-reaching effects? By examining analogous inventions of the industrial, digital and AI revolutions, this article claims that the latter is on target and that it would bring extensive changes that will also affect all aspects of our society and life. In addition, its impact on firms and employment will be considerable, resulting in richly interconnected organizations with decision making based on the analysis and exploitation of “big” data and intensified, global competition among firms. People will be capable of buying goods and obtaining services from anywhere in the world using the Internet, and exploiting the unlimited, additional benefits that will open through the widespread usage of AI inventions. The paper concludes that significant competitive advantages will continue to accrue to those utilizing the Internet widely and willing to take entrepreneurial risks in order to turn innovative products/services into worldwide commercial success stories. The greatest challenge facing societies and firms would be utilizing the benefits of availing AI technologies, providing vast opportunities for both new products/services and immense productivity improvements while avoiding the dangers and disadvantages in terms of increased unemployment and greater wealth inequalities.},
author = {Makridakis, Spyros},
doi = {10.1016/j.futures.2017.03.006},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Makridakis - 2017 - The forthcoming Artificial Intelligence (AI) revolution Its impact on society and firms.pdf:pdf},
isbn = {0016-3287},
issn = {00163287},
journal = {Futures},
keywords = {AI revolution,Artificial Intelligence (AI),Benefits and dangers of AI technologies,Digital revolution,Impact of AI revolution,Industrial revolution},
pages = {46--60},
publisher = {Elsevier Ltd},
title = {{The forthcoming Artificial Intelligence (AI) revolution: Its impact on society and firms}},
url = {http://dx.doi.org/10.1016/j.futures.2017.03.006},
volume = {90},
year = {2017}
}
@article{Ukm2010,
author = {Ukm, Pelaku and Lingkungan, D I and Pembuatan, Industri},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ukm, Lingkungan, Pembuatan - 2010 - Jurnal Keuangan &Bisnis Volume 2 No. 3, November 2010.pdf:pdf},
keywords = {corporate culture,performance},
number = {3},
title = {{Jurnal Keuangan &Bisnis Volume 2 No. 3, November 2010}},
volume = {2},
year = {2010}
}
@article{Hill2012,
abstract = {Although consumer spending typically declines in economic recessions, some observers have noted that recessions appear to increase women's spending on beauty products—the so-called lipstick effect. Using both historical spending data and rigorous experiments, the authors examine how and why economic recessions influence women's consumer behavior. Findings revealed that recessionary cues—whether naturally occurring or experimentally primed—decreased desire for most products (e.g., electronics, household items). However, these cues consistently increased women's desire for products that increase attractiveness to mates—the first experimental demonstration of the lipstick effect. Additional studies show that this effect is driven by women's desire to attract mates with resources and depends on the perceived mate attraction function served by these products. In addition to showing how and why economic recessions influence women's desire for beauty products, this research provides novel insights into women's mating psychology, consumer behavior, and the relationship between the two.},
author = {Hill, Sarah E. and Rodeheffer, Christopher D. and Griskevicius, Vladas and Durante, Kristina and White, Andrew Edward},
doi = {10.1037/a0028657},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hill et al. - 2012 - Boosting beauty in an economic decline Mating, spending, and the lipstick effect.pdf:pdf},
isbn = {9781462509133},
issn = {00223514},
journal = {Journal of Personality and Social Psychology},
keywords = {Attractiveness,Consumer behavior,Economic recessions,Evolutionary psychology,Mating},
number = {2},
pages = {275--291},
pmid = {22642483},
title = {{Boosting beauty in an economic decline: Mating, spending, and the lipstick effect}},
volume = {103},
year = {2012}
}
@article{Balmas2014,
abstract = {This research assesses possible associations between viewing fake news (i.e., political satire) and attitudes of inefficacy, alienation, and cynicism toward political candidates. Using survey data collected during the 2006 Israeli election campaign, the study provides evidence for an indirect positive effect of fake news viewing in fostering the feelings of inefficacy, alienation, and cynicism, through the mediator variable of perceived realism of fake news. Within this process, hard news viewing serves as a moderator of the association between viewing fake news and their perceived realism. It was also demonstrated that perceived realism of fake news is stronger among individuals with high exposure to fake news and low exposure to hard news than among those with high exposure to both fake and hard news. Overall, this study contributes to the scientific knowledge regarding the influence of the interaction between various types of media use on political effects.},
archivePrefix = {arXiv},
arxivId = {0809.1869v1},
author = {Balmas, Meital},
doi = {10.1177/0093650212453600},
eprint = {0809.1869v1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Balmas - 2014 - When Fake News Becomes Real Combined Exposure to Multiple News Sources and Political Attitudes of Inefficacy, Alienation.pdf:pdf},
isbn = {00936502},
issn = {00936502},
journal = {Communication Research},
keywords = {content analysis,fake news,political attitudes,political effects,political satire,survey},
number = {3},
pages = {430--454},
pmid = {70583450},
title = {{When Fake News Becomes Real: Combined Exposure to Multiple News Sources and Political Attitudes of Inefficacy, Alienation, and Cynicism}},
volume = {41},
year = {2014}
}
@article{Kabiri2011,
author = {Kabiri, Peyman and Pandi, Mohammad H and Kourki, Sirous and Ghaderi, Hamid and Red, N I R},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kabiri et al. - 2011 - NDVI Optimization Using Genetic Algorithm.pdf:pdf},
isbn = {9781457715358},
keywords = {-genetic algorithm,multispectral images,ndvi},
title = {{NDVI Optimization Using Genetic Algorithm}},
year = {2011}
}
@article{Kingma2015,
abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
archivePrefix = {arXiv},
arxivId = {1412.6980},
author = {Kingma, Diederik P. and Ba, Jimmy Lei},
eprint = {1412.6980},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kingma, Ba - 2015 - Adam A method for stochastic optimization.pdf:pdf},
journal = {3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings},
pages = {1--15},
title = {{Adam: A method for stochastic optimization}},
year = {2015}
}
@article{Sarwar2018,
abstract = {Cardiovascular disease is the leading cause of mortality and morbidity globally. With widespread and growing use of smart phones and mobile devices, the use of mobile health (mHealth) in transmission of physiologic parameters and patient-referred symptoms to healthcare providers and researchers, as well as reminders and care plan applications from providers to patients, has potential to revolutionize both clinical care and the conduct of clinical trials with improved designs, data capture, and potentially lower costs. In randomized early phase proof-of-concept studies, focusing on lifestyle intervention, there is evidence that mHealth technology can improve outcomes. By contrast, results from small randomized controlled trials that tested mHealth interventions in heart failure patients were disappointing with inconsistent findings. These inconclusive results could be partially attributed to a lack of methodological rigor (insufficient sample size, quasi-experimental design, inadequate mHealth equipment). Therefore, there is an urgent need to develop systematic evidence-based guidelines and parameters for mHealth to be effectively utilized in cardiovascular clinical trials.},
author = {Sarwar, Chaudhry M.S. and Vaduganathan, Muthiah and Anker, Stefan D. and Coiro, Stefano and Papadimitriou, Lampros and Saltz, Joel and Schoenfeld, Elinor R. and Clark, Richard L. and Dinh, Wilfried and Kramer, Frank and Gheorghiade, Mihai and Fonarow, Gregg C. and Butler, Javed},
doi = {10.1016/j.ijcard.2018.06.039},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sarwar et al. - 2018 - Mobile health applications in cardiovascular research.pdf:pdf},
issn = {18741754},
journal = {International Journal of Cardiology},
keywords = {Clinical trials,Endpoints,Heart failure,Mobile health},
pages = {#pagerange#},
publisher = {Elsevier B.V},
title = {{Mobile health applications in cardiovascular research}},
url = {https://doi.org/10.1016/j.ijcard.2018.06.039},
year = {2018}
}
@article{Liu2020k,
abstract = {Multi-task learns multiple tasks, while sharing knowledge and computation among them. However, it suffers from catastrophic forgetting of previous knowledge when learned incrementally without access to the old data. Most existing object detectors are domain-specific and static, while some are learned incrementally but only within a single domain. Training an object detector incrementally across various domains has rarely been explored. In this work, we propose three incremental learning scenarios across various domains and categories for object detection. To mitigate catastrophic forgetting, attentive feature distillation is proposed to leverages both bottom-up and top-down attentions to extract important information for distillation. We then systematically analyze the proposed distillation method in different scenarios. We find out that, contrary to common understanding, domain gaps have smaller negative impact on incremental detection, while category differences are problematic. For the difficult cases, where the domain gaps and especially category differences are large, we explore three different exemplar sampling methods and show the proposed adaptive sampling method is effective to select diverse and informative samples from entire datasets, to further prevent forgetting. Experimental results show that we achieve the significant improvement in three different scenarios across seven object detection benchmark datasets.},
archivePrefix = {arXiv},
arxivId = {2002.05347},
author = {Liu, Xialei and Yang, Hao and Ravichandran, Avinash and Bhotika, Rahul and Soatto, Stefano},
eprint = {2002.05347},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2020 - Multi-Task Incremental Learning for Object Detection(2).pdf:pdf},
keywords = {continual learning,incremental learning,object detection},
mendeley-tags = {continual learning,incremental learning,object detection},
title = {{Multi-Task Incremental Learning for Object Detection}},
url = {http://arxiv.org/abs/2002.05347},
year = {2020}
}
@article{Kang2020,
abstract = {Class incremental learning is an online learning paradigm wherein the classes to be recognized are gradually increased with limited memory, storing only a partial set of examples of past tasks. At a task transition, we observe an unintentional imbalance of confidence or likelihood between the classes of the past and the new task. We argue that the imbalance aggravates a catastrophic forgetting for class incremental learning. We propose a simple yet effective learning objective to balance the confidence of classes of old tasks and new task in the class incremental learning setup. In addition, we compare various sample memory configuring strategies and propose a novel sample memory management policy to alleviate the forgetting further. The proposed method outperforms the state of the arts in many evaluation metrics including accuracy and forgetting F by a large margin (up to 5.71% in A10 and 17.1% in F10) in extensive empirical validations on multiple visual recognition datasets such as CIFAR100, TinyImageNet and a subset of the ImageNet.},
author = {Kang, Dongmin and Jo, Yeonsik and Nam, Yeongwoo and Choi, Jonghyun},
doi = {10.1109/ACCESS.2020.3007234},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kang et al. - 2020 - Confidence Calibration for Incremental Learning.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Incremental learning,confidence calibration,continual learning},
pages = {126648--126660},
title = {{Confidence Calibration for Incremental Learning}},
volume = {8},
year = {2020}
}
@article{Algorithm2014,
abstract = {In the context of energy saving and carbon emission reduction, the electric vehicle (EV) has been identified as a promising alternative to traditional fossil fuel-driven vehicles. Due to a different refueling manner and driving characteristic, the introduction of EVs to the current logistics system can make a significant impact on the vehicle routing and the associated operation costs. Based on the traveling salesman problem, this paper proposes a new optimal EV route model considering the fast-charging and regular-charging under the time-of-use price in the electricity market. The proposed model aims to minimize the total distribution costs of the EV route while satisfying the constraints of battery capacity, charging time and delivery/pickup demands, and the impact of vehicle loading on the unit electricity consumption per mile. To solve the proposed model, this paper then develops a learnable partheno-genetic algorithm with integration of expert knowledge about EV charging station and customer selection. A comprehensive numerical test is conducted on the 36-node and 112-node systems, and the results verify the feasibility and effectiveness of the proposed model and solution algorithm.},
author = {Algorithm, Partheno-genetic and Yang, Hongming and Yang, Songping and Xu, Yan and Cao, Erbao and Lai, Mingyong and Dong, Zhaoyang and Algorithm, Partheno-genetic and Yang, Hongming and Yang, Songping and Xu, Yan and Cao, Erbao and Lai, Mingyong},
doi = {10.1109/TSG.2014.2382684},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Algorithm et al. - 2014 - Electric Vehicle Route Optimization Considering Time-of-Use Electricity Price by Learnable.pdf:pdf},
isbn = {1949-3053},
issn = {19493053},
journal = {IEEE Transactions on Smart Grid},
keywords = {Electric vehicle (EV),learnable partheno-genetic algorithm (LPGA),time-of-use (TOU) electricity price,vehicle route optimization},
number = {2},
pages = {1--10},
title = {{Electric Vehicle Route Optimization Considering Time-of-Use Electricity Price by Learnable}},
volume = {6},
year = {2014}
}
@article{Lammers2013,
abstract = {The current research explores whether momentary changes in power can shift professional interview outcomes. Two experiments manipulated power by asking applicants to recall a time they had or lacked power prior to writing a job application letter (Experiment 1) or being interviewed for admission to business schools (Experiment 2). Independent judges, who were unaware of the applicants' experimental condition or even the existence of the power manipulation, significantly preferred the written and face-to-face interview performance of powerful applicants to that of powerless (Experiments 1 and 2) or power-neutral applicants (Experiment 2). In addition, the judges' preference for power-primed applicants was mediated by perceptions of the applicant's persuasiveness. Overall, merely asking participants to remember a personal experience with power dramatically affected the impressions that interviewers had of them. Our findings illustrate power's far-reaching effects and have potentially important implications for understanding the psychology of job interviews. {\textcopyright} 2013 Elsevier Inc.},
author = {Lammers, Joris and Dubois, David and Rucker, Derek D. and Galinsky, Adam D.},
doi = {10.1016/j.jesp.2013.02.008},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lammers et al. - 2013 - Power gets the job Priming power improves interview outcomes.pdf:pdf},
isbn = {0022-1031},
issn = {00221031},
journal = {Journal of Experimental Social Psychology},
keywords = {Application,Job-interview,Power},
number = {4},
pages = {776--779},
publisher = {Elsevier Inc.},
title = {{Power gets the job: Priming power improves interview outcomes}},
url = {http://dx.doi.org/10.1016/j.jesp.2013.02.008},
volume = {49},
year = {2013}
}
@article{Amouzgar2012,
author = {Amouzgar, Kaveh},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Amouzgar - 2012 - Multi-Objective Optimization using Genetic Algorithms Kaveh Amouzgar THESIS WORK 2012 Multi-Objective Optimization usi.pdf:pdf},
journal = {Thesis},
number = {vx},
title = {{Multi-Objective Optimization using Genetic Algorithms Kaveh Amouzgar THESIS WORK 2012 Multi-Objective Optimization using Genetic Algorithms}},
volume = {00},
year = {2012}
}
@article{Fedorov2020,
abstract = {Sensory input from multiple sources is crucial for robust and coherent human perception. Different sources contribute complementary explanatory factors and get combined based on factors they share. This system motivated the design of powerful unsupervised representation-learning algorithms. In this paper, we unify recent work on multimodal self-supervised learning under a single framework. Observing that most self-supervised methods optimize similarity metrics between a set of model components, we propose a taxonomy of all reasonable ways to organize this process. We empirically show on two versions of multimodal MNIST and a multimodal brain imaging dataset that (1) multimodal contrastive learning has significant benefits over its unimodal counterpart, (2) the specific composition of multiple contrastive objectives is critical to performance on a downstream task, (3) maximization of the similarity between representations has a regularizing effect on a neural network, which sometimes can lead to reduced downstream performance but still can reveal multimodal relations. Consequently, we outperform previous unsupervised encoder-decoder methods based on CCA or variational mixtures MMVAE on various datasets on linear evaluation protocol.},
archivePrefix = {arXiv},
arxivId = {2012.13623},
author = {Fedorov, Alex and Sylvain, Tristan and Luck, Margaux and Wu, Lei and DeRamus, Thomas P. and Kirilin, Alex and Bleklov, Dmitry and Calhoun, Vince D. and Plis, Sergey M.},
eprint = {2012.13623},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fedorov et al. - 2020 - Taxonomy of multimodal self-supervised representation learning.pdf:pdf},
keywords = {multi-modal,representation learning,self-supervised learning},
mendeley-tags = {multi-modal,representation learning,self-supervised learning},
title = {{Taxonomy of multimodal self-supervised representation learning}},
url = {http://arxiv.org/abs/2012.13623},
year = {2020}
}
@article{Tan2019a,
abstract = {Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on scaling up MobileNets and ResNet. To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets. In particular, our EfficientNet-B7 achieves state-of-the-art 84.4% top-1 / 97.1% top-5 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet. Our EfficientNets also transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7%), Flowers (98.8%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters.},
archivePrefix = {arXiv},
arxivId = {1905.11946},
author = {Tan, Mingxing and Le, Quoc V.},
eprint = {1905.11946},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tan, Le - 2019 - EfficientNet Rethinking model scaling for convolutional neural networks.pdf:pdf},
isbn = {9781510886988},
journal = {36th International Conference on Machine Learning, ICML 2019},
pages = {10691--10700},
title = {{EfficientNet: Rethinking model scaling for convolutional neural networks}},
volume = {2019-June},
year = {2019}
}
@article{Chang2014,
abstract = {The complex temporal heterogeneity of rainfall coupled with mountainous physiographic context makes a great challenge in the development of accurate short-term rainfall forecasts. This study aims to explore the effectiveness of multiple rainfall sources (gauge measurement, and radar and satellite products) for assimilation-based multi-sensor precipitation estimates and make multi-step-ahead rainfall forecasts based on the assimilated precipitation. Bias correction procedures for both radar and satellite precipitation products were first built, and the radar and satellite precipitation products were generated through the Quantitative Precipitation Estimation and Segregation Using Multiple Sensors (QPESUMS) and the Precipitation Estimation from Remotely Sensed Information using Artificial Neural Networks-Cloud Classification System (PERSIANN-CCS), respectively. Next, the synthesized assimilated precipitation was obtained by merging three precipitation sources (gauges, radars and satellites) according to their individual weighting factors optimized by nonlinear search methods. Finally, the multi-step-ahead rainfall forecasting was carried out by using the adaptive network-based fuzzy inference system (ANFIS). The Shihmen Reservoir watershed in northern Taiwan was the study area, where 641 hourly data sets of thirteen historical typhoon events were collected. Results revealed that the bias adjustments in QPESUMS and PERSIANN-CCS products did improve the accuracy of these precipitation products (in particular, 30-60% improvement rates for the QPESUMS, in terms of RMSE), and the adjusted PERSIANN-CCS and QPESUMS individually provided about 10% and 24% contribution accordingly to the assimilated precipitation. As far as rainfall forecasting is concerned, the results demonstrated that the ANFIS fed with the assimilated precipitation provided reliable and stable forecasts with the correlation coefficients higher than 0.85 and 0.72 for one- and two-hour-ahead rainfall forecasting, respectively. The obtained forecasting results are very valuable information for the flood warning in the study watershed during typhoon periods. {\textcopyright} 2013 Elsevier B.V.},
author = {Chang, Fi John and Chiang, Yen Ming and Tsai, Meng Jung and Shieh, Ming Chang and Hsu, Kuo Lin and Sorooshian, Soroosh},
doi = {10.1016/j.jhydrol.2013.11.011},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chang et al. - 2014 - Watershed rainfall forecasting using neuro-fuzzy networks with the assimilation of multi-sensor information.pdf:pdf},
issn = {00221694},
journal = {Journal of Hydrology},
keywords = {Artificial Neural Network,Data assimilation,Data merging,Radar,Rainfall forecasting,Satellite},
pages = {374--384},
publisher = {Elsevier B.V.},
title = {{Watershed rainfall forecasting using neuro-fuzzy networks with the assimilation of multi-sensor information}},
url = {http://dx.doi.org/10.1016/j.jhydrol.2013.11.011},
volume = {508},
year = {2014}
}
@article{Jain2010a,
author = {Jain, Amit and Jain, M Babita and Srinivas, E},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jain, Jain, Srinivas - 2010 - A Novel Hybrid Method for Short Term Load Forecasting using Fuzzy Logic and Particle Swarm Optimization.pdf:pdf},
isbn = {9781424459391},
pages = {1--7},
title = {{A Novel Hybrid Method for Short Term Load Forecasting using Fuzzy Logic and Particle Swarm Optimization}},
year = {2010}
}
@article{Miao2022,
archivePrefix = {arXiv},
arxivId = {arXiv:2003.03196v3},
author = {Miao, Zichen and Wang, Ze and Chen, Wei and Qiu, Qiang},
eprint = {arXiv:2003.03196v3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Miao et al. - 2022 - Continual Learning With Filter Atom Swapping.pdf:pdf},
keywords = {continual learning},
mendeley-tags = {continual learning},
title = {{Continual Learning With Filter Atom Swapping}},
year = {2022}
}
@book{Uchino2017,
author = {Uchino, K.},
booktitle = {Advanced Piezoelectric Materials},
doi = {10.1016/B978-0-08-102135-4.00016-3},
edition = {2},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Uchino - 2017 - Manufacturing Technologies for Piezoelectric Transducers.pdf:pdf},
isbn = {9780081021354},
keywords = {Acoustic imaging,Bolt-clamped Langevin transducer,Cymbal,Piezoelectric transformer.,Pulse drive actuator,Soft and hard PZT,Transducer array,Underwater acoustics,acoustic imaging,bolt-clamped langevin,cymbal,piezoelectric transformer,pulse drive actuator,soft and hard pzt,transducer,transducer array,underwater acoustics},
pages = {615--644},
publisher = {Elsevier Ltd.},
title = {{Manufacturing Technologies for Piezoelectric Transducers}},
url = {http://linkinghub.elsevier.com/retrieve/pii/B9780081021354000163},
year = {2017}
}
@article{Holmstrom2016,
abstract = {Weather forecasting has traditionally been done by physical models of the atmosphere, which are unstable to perturbations, and thus are inaccurate for large periods of time. Since machine learning techniques are more robust to perturbations, in this paper we explore their application to weather forecasting to potentially generate more accurate weather forecasts for large periods of time. The scope of this paper was restricted to forecasting the maximum temperature and the minimum tem- perature for seven days, given weather data for the past two days. A linear regression model and a variation on a functional regression model were used, with the latter able to capture trends in the weather. Both of our models were outperformed by professional weather forecasting services, although the discrepancy between our models and the professional ones diminished rapidly for fore- casts of later days, and perhaps for even longer time scales our models could outperform professional ones. The linear regression model outperformed the functional regression model, suggesting that two days were too short for the latter to capture significant weather trends, and perhaps basing our forecasts on weather data for four or five days would allow the functional regression model to outperform the linear regression model.},
author = {Holmstrom, Mark and Liu, Dylan and Vo, Christopher},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Holmstrom, Liu, Vo - 2016 - Machine Learning Applied to Weather Forecasting.pdf:pdf},
journal = {Meteorological Applications},
keywords = {Accuracy,Australia,Melbourne,Verification,Weather forecasts},
title = {{Machine Learning Applied to Weather Forecasting}},
year = {2016}
}
@article{Djedovic2016,
abstract = {— Business process management is the process of modifying or adjusting an organization's business process in order to achieve higher productivity or lower costs. Each company or organization has a value creating process that usually involves people, machines and information. One of the main problems with such processes is that it is very difficult to predict how much of each resource is actually needed. In light of the above, the objective of this paper is to implement a methodology that is capable of optimizing the allocation of resources to tasks in a given business process. In this paper, the genetic algorithm was used for optimization. The idea is that once the units are properly presented, the optimal schedule of users should be determined using the genetic algorithm. The fitness function includes Key Performance Indicators of process: waiting time and cost of the resource. Since al the users are not qualified in performing all the tasks in the process, the algorithm has to consider minimal and the maximal available number of users for each activity. The usability of this approach is tested in the process of credit requirement. Finally, the results are compared to the current work process.},
author = {Djedovi{\'{c}}, Almir and {\v{Z}}uni{\'{c}}, Emir and Avdagi{\'{c}}, Zikrija and Karabegovi{\'{c}}, Almir},
doi = {10.1109/BIHTEL.2016.7775724},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Djedovi{\'{c}} et al. - 2016 - Optimization of business processes by automatic reallocation of resources using the genetic algorithm.pdf:pdf},
isbn = {9781509029013},
journal = {2016 11th International Symposium on Telecommunications, BIHTEL 2016},
keywords = {Business Process Modeling Genetic algorithm,Business process management,Process optimization,Resource allocation,Simulation},
title = {{Optimization of business processes by automatic reallocation of resources using the genetic algorithm}},
year = {2016}
}
@book{Lucklum2008,
abstract = {New understandings underlying the principles of Piezoelectric Transducers, new technological advances in its applications, and new areas of utility for these transducers made a second edition of this book inevitable. The second edition of Piezoelectric Transducers and Applications includes these new developments together with a deep revision and enlargement of the topics already included in the first edition. It provides a guide for graduate students and researchers to the current state of the art of this complex and multidisciplinary area. The book fills an urgent need for a unified source of information on piezoelectric devices and their astounding variety of existing and emerging applications. Some of the chapters focus more on the basic concepts of the different disciplines involved and are presented in a didactic manner. Others go deeper into the complex aspects of specific fields of research, thus reaching the technical level of a scientific paper. Among other topics resonant sensors, especially bulk acoustic wave thickness shear mode resonators, chemical and bio-sensors, as well as broadband ultrasonic systems are treated in-depth.},
author = {Lucklum, Ralf and Soares, David and Kanazawa, Kay},
booktitle = {Piezoelectric Transducers and Applications},
doi = {10.1007/978-3-540-77508-9_3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lucklum, Soares, Kanazawa - 2008 - Models for resonant sensors.pdf:pdf},
isbn = {9783540775072},
pages = {63--96},
title = {{Models for resonant sensors}},
year = {2008}
}
@article{Berman2018,
abstract = {The Jaccard index, also referred to as the intersection-over-union score, is commonly employed in the evaluation of image segmentation results given its perceptual qualities, scale invariance - which lends appropriate relevance to small objects, and appropriate counting of false negatives, in comparison to per-pixel losses. We present a method for direct optimization of the mean intersection-over-union loss in neural networks, in the context of semantic image segmentation, based on the convex Lov{\~{A}}¡sz extension of submodular losses. The loss is shown to perform better with respect to the Jaccard index measure than the traditionally used cross-entropy loss. We show quantitative and qualitative differences between optimizing the Jaccard index per image versus optimizing the Jaccard index taken over an entire dataset. We evaluate the impact of our method in a semantic segmentation pipeline and show substantially improved intersection-over-union segmentation scores on the Pascal VOC and Cityscapes datasets using state-of-the-art deep learning segmentation architectures.},
archivePrefix = {arXiv},
arxivId = {1705.08790},
author = {Berman, Maxim and Triki, Amal Rannen and Blaschko, Matthew B.},
doi = {10.1109/CVPR.2018.00464},
eprint = {1705.08790},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Berman, Triki, Blaschko - 2018 - The Lovasz-Softmax Loss A Tractable Surrogate for the Optimization of the Intersection-Over-Union Measu.pdf:pdf},
isbn = {9781538664209},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {4413--4421},
title = {{The Lovasz-Softmax Loss: A Tractable Surrogate for the Optimization of the Intersection-Over-Union Measure in Neural Networks}},
year = {2018}
}
@article{Nawi2013,
abstract = {Recently, the popularity of artificial neural networks (ANN) is increasing since its capacity to model very complex problems in the area of Machine Learning, Data Mining and Pattern Recognition. Improving training efficacy of ANN based algorithm is a dynamic area of research and several papers have been reviewed in the literature. The performance of Multi-layer Perceptrons (MLP) trained with Back Propagation Artificial Neural Network (BP-ANN) method is highly influenced by the size of the datasets and the data-preprocessing techniques used. This work analyses the benefits of using pre-processing datasets using different techniques in-order to improve the ANN convergence. Specifically Min-Max, Z-Score and Decimal Scaling Normalization preprocessing techniques were evaluated. The simulation results show that the computational efficiency of ANN training process is highly enhanced when coupled with different preprocessing techniques.},
author = {Nawi, Nazri Mohd and Atomi, Walid Hasen and Rehman, M.Z.},
doi = {10.1016/j.protcy.2013.12.159},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nawi, Atomi, Rehman - 2013 - The Effect of Data Pre-processing on Optimized Training of Artificial Neural Networks.pdf:pdf},
issn = {22120173},
journal = {Procedia Technology},
keywords = {artificial neural networks,back propagation,gain value,gradient descent,pre-processing data},
number = {Iceei},
pages = {32--39},
publisher = {Elsevier B.V.},
title = {{The Effect of Data Pre-processing on Optimized Training of Artificial Neural Networks}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2212017313003137},
volume = {11},
year = {2013}
}
@inproceedings{Guo2020a,
author = {Guo, Yunhui and Liu, Mingrui and Yang, Tianbao and Rosing, Tajana},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guo et al. - 2020 - Improved Schemes for Episodic Memory based Lifelong Learning Algorithm.pdf:pdf},
number = {NeurIPS},
pages = {1--16},
title = {{Improved Schemes for Episodic Memory based Lifelong Learning Algorithm}},
year = {2020}
}
@article{Carvalho2017,
abstract = {In this paper, we propose a fuzzy forecasting methodology of time series, which is tested on two series: the price of electricity in New South Wales, Australia; and on the futures market index of Taiwan. The method uses a triangular membership function in a fuzzification process, including an $\alpha$-cut, and applies the extended autocorrelation function. The identification algorithm enables optimization of the number of fuzzy sets to be used, to determine the optimal order for the fuzzy prediction model and estimate its parameters with greater accuracy. The fuzzy prediction models of time series found in the scientific literature are compared using mainly trivalent membership functions (0, 0.5 and 1 as membership values), and the proposed method shows more accurate results.},
author = {Carvalho, J. G. and Costa, C. T.},
doi = {10.1016/j.asoc.2016.11.003},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Carvalho, Costa - 2017 - Identification method for fuzzy forecasting models of time series(2).pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {Autoregressive seasonal fuzzy model,Electrical energy price,Futures market index,Fuzzy prediction,$\alpha$-cut},
pages = {166--182},
publisher = {Elsevier B.V.},
title = {{Identification method for fuzzy forecasting models of time series}},
url = {http://dx.doi.org/10.1016/j.asoc.2016.11.003},
volume = {50},
year = {2017}
}
@article{Sung2018,
abstract = {The objectives of this paper are (1) to have a detailed, practical discussion of Industry 4.0, and (2) to suggest policy implications to transition toward Industry 4.0 in Korea. Companies should consider Industry 4.0 very seriously as they develop their future initiatives since traditional manufacturing business models do not fit with the emerging technologies of Industry 4.0. Some issues should be addressed with care: IT security, reliability and stability needed for critical machine-to-machine communication; a need to maintain the integrity of production processes, avoid IT snags, and protect industrial knowhow; and the lack of adequate skill-sets, general reluctance to change by stakeholders, and loss of many jobs to automatic processes and IT-controlled processes. To successfully transform Korean industry toward Industry 4.0, it is necessary to (1) refine and elaborate the strategies enacted by the central government to build economic and social systems that can flexibly respond to changes, (2) establish some kind of operational system to maximize the effectiveness of initiatives and policies, (3) develop concrete and workable action plans to transition toward economic and social systems that can accommodate innovative changes, and (4) establish infrastructure to lead all initiatives.},
author = {Sung, Tae Kyung},
doi = {10.1016/j.techfore.2017.11.005},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sung - 2018 - Industry 4.0 A Korea perspective.pdf:pdf},
issn = {00401625},
journal = {Technological Forecasting and Social Change},
keywords = {Fourth industrial revolution,Industry 4.0,Policy implications},
number = {November},
pages = {40--45},
publisher = {Elsevier},
title = {{Industry 4.0: A Korea perspective}},
url = {http://dx.doi.org/10.1016/j.techfore.2017.11.005},
volume = {132},
year = {2018}
}
@article{Reddy2017,
abstract = {Distributed generator (DG) resources are small scale electric power generating plants that can provide power to homes, businesses or industrial facilities in distribution systems. Power loss reductions, voltage profile improvement and increasing reliability are some advantages of DG units. The above benefits can be achieved by optimal placement of DGs. Whale optimization algorithm (WOA), a novel metaheuristic algorithm, is used to determine the optimal DG size. WOA is modeled based on the unique hunting behavior of humpback whales. The WOA is evaluated on IEEE 15, 33, 69 and 85-bus test systems. WOA was compared with different types of DGs and other evolutionary algorithms. When compared with voltage sensitivity index method, WOA and index vector methods gives better results. From the analysis best results have been achieved from type III DG operating at 0.9 pf.},
author = {Reddy, P. Dinakara Prasad and Reddy, V. C. Veera and Manohar, T. Gowri},
doi = {10.1186/s40807-017-0040-1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Reddy, Reddy, Manohar - 2017 - Whale optimization algorithm for optimal sizing of renewable resources for loss reduction in distribution.pdf:pdf},
issn = {2198-994X},
journal = {Renewables: Wind, Water, and Solar},
keywords = {Whale optimization algorithm,Index vector method,D,distributed generation placement,distribution system,index vector method,loss reduction,radial,whale optimization algorithm},
number = {1},
pages = {3},
publisher = {Springer Singapore},
title = {{Whale optimization algorithm for optimal sizing of renewable resources for loss reduction in distribution systems}},
url = {http://jrenewables.springeropen.com/articles/10.1186/s40807-017-0040-1},
volume = {4},
year = {2017}
}
@article{Han2016,
abstract = {Neural networks are both computationally intensive and memory intensive, making them difficult to deploy on embedded systems with limited hardware resources. To address this limitation, we introduce “deep compression”, a three stage pipeline: pruning, trained quantization and Huffman coding, that work together to reduce the storage requirement of neural networks by 35× to 49× without affecting their accuracy. Our method first prunes the network by learning only the important connections. Next, we quantize the weights to enforce weight sharing, finally, we apply Huffman coding. After the first two steps we retrain the network to fine tune the remaining connections and the quantized centroids. Pruning, reduces the number of connections by 9× to 13×; Quantization then reduces the number of bits that represent each connection from 32 to 5. On the ImageNet dataset, our method reduced the storage required by AlexNet by 35×, from 240MB to 6.9MB, without loss of accuracy. Our method reduced the size of VGG-16 by 49× from 552MB to 11.3MB, again with no loss of accuracy. This allows fitting the model into on-chip SRAM cache rather than off-chip DRAM memory. Our compression method also facilitates the use of complex neural networks in mobile applications where application size and download bandwidth are constrained. Benchmarked on CPU, GPU and mobile GPU, compressed network has 3× to 4× layerwise speedup and 3× to 7× better energy efficiency.},
archivePrefix = {arXiv},
arxivId = {1510.00149},
author = {Han, Song and Mao, Huizi and Dally, William J.},
eprint = {1510.00149},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Han, Mao, Dally - 2016 - Deep compression Compressing deep neural networks with pruning, trained quantization and Huffman coding.pdf:pdf},
journal = {4th International Conference on Learning Representations, ICLR 2016 - Conference Track Proceedings},
pages = {1--14},
title = {{Deep compression: Compressing deep neural networks with pruning, trained quantization and Huffman coding}},
year = {2016}
}
@article{Stein2017,
abstract = {One approach to the recognition of complex human activities is to use feature descriptors that encode visual interactions by describing properties of local visual features with respect to trajectories of tracked objects. We explore an example of such an approach in which dense tracklets are described relative to multiple reference trajectories, providing a rich representation of complex interactions between objects of which only a subset can be tracked. Specifically, we report experiments in which reference trajectories are provided by tracking inertial sensors in a food preparation scenario. Additionally, we provide baseline results for HOG, HOF and MBH, and combine these features with others for multi-modal recognition. The proposed histograms of relative tracklets (RETLETS) showed better activity recognition performance than dense tracklets, HOG, HOF, MBH, or their combination. Our comparative evaluation of features from accelerometers and video highlighted a performance gap between visual and accelerometer-based motion features and showed a substantial performance gain when combining features from these sensor modalities. A considerable further performance gain was observed in combination with RETLETS and reference tracklet features.},
author = {Stein, Sebastian and McKenna, Stephen J.},
doi = {10.1016/j.cviu.2016.08.012},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stein, McKenna - 2017 - Recognising complex activities with histograms of relative tracklets.pdf:pdf},
issn = {1090235X},
journal = {Computer Vision and Image Understanding},
keywords = {Activity recognition,Food preparation,Relative tracklets,Sensor fusion},
pages = {82--93},
publisher = {Elsevier Inc.},
title = {{Recognising complex activities with histograms of relative tracklets}},
url = {http://dx.doi.org/10.1016/j.cviu.2016.08.012},
volume = {154},
year = {2017}
}
@article{Zhang2019a,
abstract = {Increasing the batch size is a popular way to speed up neural network training, but beyond some critical batch size, larger batch sizes yield diminishing returns. In this work, we study how the critical batch size changes based on properties of the optimization algorithm, including acceleration and preconditioning, through two different lenses: Large scale experiments, and analysis of a simple noisy quadratic model (NQM). We experimentally demonstrate that optimization algorithms that employ preconditioning, specifically Adam and K-FAC, result in much larger critical batch sizes than stochastic gradient descent with momentum. We also demonstrate that the NQM captures many of the essential features of real neural network training, despite being drastically simpler to work with. The NQM predicts our results with preconditioned optimizers, previous results with accelerated gradient descent, and other results around optimal learning rates and large batch training, making it a useful tool to generate testable predictions about neural network optimization.},
archivePrefix = {arXiv},
arxivId = {1907.04164},
author = {Zhang, Guodong and Li, Lala and Nado, Zachary and Martens, James and Sachdeva, Sushant and Dahl, George E. and Shallue, Christopher J. and Grosse, Roger},
eprint = {1907.04164},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2019 - Which algorithmic choices matter at which batch sizes insights from a noisy quadratic model.pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
pages = {1--12},
title = {{Which algorithmic choices matter at which batch sizes? insights from a noisy quadratic model}},
year = {2019}
}
@article{Gundes2009,
abstract = {Reliable stabilization and regulation of two-channel decentralized multi-input multi-output (MIMO) control systems is considered. The system has integral-action due to using proportional??+??integral??+??derivative (PID) controllers. Closed-loop stability and asymptotic tracking of step-input references are achieved at each output channel when all controllers are operational. Stability is maintained when one of the controllers fails completely and is set to zero. Controller synthesis procedures are proposed for stable MIMO plants and for several unstable MIMO plant classes that admit PID controllers. These synthesis procedures are applied to various examples of process systems to illustrate the design methodology. ?? 2008 Elsevier Ltd. All rights reserved.},
author = {G{\"{u}}ndeş, A. N. and Mete, A. N. and Palazoǧlu, A.},
doi = {10.1016/j.automatica.2008.08.014},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/G{\"{u}}ndeş, Mete, Palazoǧlu - 2009 - Reliable decentralized PID controller synthesis for two-channel MIMO processes.pdf:pdf},
issn = {00051098},
journal = {Automatica},
keywords = {Decentralized control,Multi-input multi-output systems,PID controller,Process control,Reliable stabilization},
number = {2},
pages = {353--363},
publisher = {Elsevier Ltd},
title = {{Reliable decentralized PID controller synthesis for two-channel MIMO processes}},
url = {http://dx.doi.org/10.1016/j.automatica.2008.08.014},
volume = {45},
year = {2009}
}
@article{Meana-Llorian2017,
abstract = {The Internet of Things is arriving to our homes or cities through fields already known like Smart Homes, Smart Cities, or Smart Towns. The monitoring of environmental conditions of cities can help to adapt the indoor locations of the cities in order to be more comfortable for people who stay there. A way to improve the indoor conditions is an efficient temperature control, however, it depends on many factors like the different combinations of outdoor temperature and humidity. Therefore, adjusting the indoor temperature is not setting a value according to other value. There are many more factors to take into consideration, hence the traditional logic based in binary states cannot be used. Many problems cannot be solved with a set of binary solutions and we need a new way of development. Fuzzy logic is able to interpret many states, more than two states, giving to computers the capacity to react in a similar way to people. In this paper we will propose a new approach to control the temperature using the Internet of Things together its platforms and fuzzy logic regarding not only the indoor temperature but also the outdoor temperature and humidity in order to save energy and to set a more comfortable environment for their users. Finally, we will conclude that the fuzzy approach allows us to achieve an energy saving around 40% and thus, save money.},
archivePrefix = {arXiv},
arxivId = {1701.02545},
author = {Meana-Llori{\'{a}}n, Daniel and {Gonz{\'{a}}lez Garc{\'{i}}a}, Cristian and {Pelayo G-Bustelo}, B. Cristina and {Cueva Lovelle}, Juan Manuel and Garcia-Fernandez, Nestor},
doi = {10.1016/j.future.2016.11.020},
eprint = {1701.02545},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Meana-Llori{\'{a}}n et al. - 2017 - IoFClime The fuzzy logic and the Internet of Things to control indoor temperature regarding the outdoor a.pdf:pdf},
issn = {0167739X},
journal = {Future Generation Computer Systems},
keywords = {Fuzzy logic,Internet of Things,Temperature control,Temperature sensors},
pages = {275--284},
publisher = {Elsevier B.V.},
title = {{IoFClime: The fuzzy logic and the Internet of Things to control indoor temperature regarding the outdoor ambient conditions}},
url = {http://dx.doi.org/10.1016/j.future.2016.11.020},
volume = {76},
year = {2017}
}
@article{Michieli2021a,
abstract = {Deep neural networks suffer from the major limitation of catastrophic forgetting old tasks when learning new ones. In this paper we focus on class incremental continual learning in semantic segmentation, where new categories are made available over time while previous training data is not retained. The proposed continual learning scheme shapes the latent space to reduce forgetting whilst improving the recognition of novel classes. Our framework is driven by three novel components which we also combine on top of existing techniques effortlessly. First, prototypes matching enforces latent space consistency on old classes, constraining the encoder to produce similar latent representation for previously seen classes in the subsequent steps. Second, features sparsification allows to make room in the latent space to accommodate novel classes. Finally, contrastive learning is employed to cluster features according to their semantics while tearing apart those of different classes. Extensive evaluation on the Pascal VOC2012 and ADE20K datasets demonstrates the effectiveness of our approach, significantly outperforming state-of-the-art methods.},
archivePrefix = {arXiv},
arxivId = {2103.06342},
author = {Michieli, Umberto and Zanuttigh, Pietro},
eprint = {2103.06342},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Michieli, Zanuttigh - 2021 - Continual Semantic Segmentation via Repulsion-Attraction of Sparse and Disentangled Latent Representations.pdf:pdf},
keywords = {continual learning,incremental learning,semantic segmentation},
mendeley-tags = {continual learning,incremental learning,semantic segmentation},
title = {{Continual Semantic Segmentation via Repulsion-Attraction of Sparse and Disentangled Latent Representations}},
url = {http://arxiv.org/abs/2103.06342},
year = {2021}
}
@article{VandeVen2020,
abstract = {Artificial neural networks suffer from catastrophic forgetting. Unlike humans, when these networks are trained on something new, they rapidly forget what was learned before. In the brain, a mechanism thought to be important for protecting memories is the reactivation of neuronal activity patterns representing those memories. In artificial neural networks, such memory replay can be implemented as ‘generative replay', which can successfully – and surprisingly efficiently – prevent catastrophic forgetting on toy examples even in a class-incremental learning scenario. However, scaling up generative replay to complicated problems with many tasks or complex inputs is challenging. We propose a new, brain-inspired variant of replay in which internal or hidden representations are replayed that are generated by the network's own, context-modulated feedback connections. Our method achieves state-of-the-art performance on challenging continual learning benchmarks (e.g., class-incremental learning on CIFAR-100) without storing data, and it provides a novel model for replay in the brain.},
author = {van de Ven, Gido M. and Siegelmann, Hava T. and Tolias, Andreas S.},
doi = {10.1038/s41467-020-17866-2},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/van de Ven, Siegelmann, Tolias - 2020 - Brain-inspired replay for continual learning with artificial neural networks.pdf:pdf},
issn = {20411723},
journal = {Nature Communications},
month = {dec},
number = {1},
pmid = {32792531},
publisher = {Nature Research},
title = {{Brain-inspired replay for continual learning with artificial neural networks}},
volume = {11},
year = {2020}
}
@article{Yu2020c,
abstract = {We study incremental learning for semantic segmentation where when learning new classes we have no access to the labeled data of previous tasks. When incrementally learning new classes, deep neural networks suffer from catastrophic forgetting of previous learned knowledge. To address this problem, we propose to apply a self-training approach that leverages unlabeled data, which is used for rehearsal of previous knowledge. Additionally, conflict reduction is proposed to resolve the conflicts of pseudo labels generated from both the old and new models. We show that maximizing self-entropy can further improve results by smoothing the overconfident predictions. The experiments demonstrate state-of-the-art results: obtaining a relative gain of up to 114% on Pascal-VOC 2012 and 8.5% on the more challenging ADE20K compared to previous state-of-the-art methods.},
archivePrefix = {arXiv},
arxivId = {2012.03362},
author = {Yu, Lu and Liu, Xialei and van de Weijer, Joost},
eprint = {2012.03362},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu, Liu, van de Weijer - 2020 - Self-Training for Class-Incremental Semantic Segmentation.pdf:pdf},
title = {{Self-Training for Class-Incremental Semantic Segmentation}},
url = {http://arxiv.org/abs/2012.03362},
year = {2020}
}
@article{Author2021,
abstract = {Learning multiple tasks sequentially without forgetting previous knowledge, called Continual Learning (CL), remains a long-standing challenge for neural networks. Most existing methods rely on additional network capacity or data replay. In contrast, we introduce a novel approach which we refer to as Recursive Gradient Optimization (RGO). RGO is composed of an iteratively updated optimizer that modifies the gradient to minimize forgetting without data replay and a virtual Feature Encoding Layer (FEL) that represents different network structures with only task descriptors. Experiments demonstrate that RGO has significantly better performance on popular continual classification benchmarks when compared to the baselines and achieves new state-of-the-art performance on 20-split-CIFAR100 (82.22%) and 20-split-miniImageNet (72.63%). With higher average accuracy than Single-Task Learning (STL), this method is flexible and reliable to provide continual learning capabilities for learning models that rely on gradient descent.},
archivePrefix = {arXiv},
arxivId = {arXiv:2201.12522v1},
author = {Liu, Hao and Liu, Huaping},
eprint = {arXiv:2201.12522v1},
file = {:home/user/Downloads/2201.12522.pdf:pdf},
keywords = {continual learning},
mendeley-tags = {continual learning},
number = {NeurIPS},
pages = {1--18},
title = {{Continual Learning with Recursive Gradient Optimization}},
year = {2021}
}
@article{Ghiasi2020,
abstract = {Building instance segmentation models that are data-efficient and can handle rare object categories is an important challenge in computer vision. Leveraging data augmentations is a promising direction towards addressing this challenge. Here, we perform a systematic study of the Copy-Paste augmentation ([13, 12]) for instance segmentation where we randomly paste objects onto an image. Prior studies on Copy-Paste relied on modeling the surrounding visual context for pasting the objects. However, we find that the simple mechanism of pasting objects randomly is good enough and can provide solid gains on top of strong baselines. Furthermore, we show Copy-Paste is additive with semi-supervised methods that leverage extra data through pseudo labeling (e.g. self-training). On COCO instance segmentation, we achieve 49.1 mask AP and 57.3 box AP, an improvement of +0.6 mask AP and +1.5 box AP over the previous state-of-the-art. We further demonstrate that Copy-Paste can lead to significant improvements on the LVIS benchmark. Our baseline model outperforms the LVIS 2020 Challenge winning entry by +3.6 mask AP on rare categories.},
archivePrefix = {arXiv},
arxivId = {2012.07177},
author = {Ghiasi, Golnaz and Cui, Yin and Srinivas, Aravind and Qian, Rui and Lin, Tsung-Yi and Cubuk, Ekin D. and Le, Quoc V. and Zoph, Barret},
eprint = {2012.07177},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghiasi et al. - 2020 - Simple Copy-Paste is a Strong Data Augmentation Method for Instance Segmentation.pdf:pdf},
keywords = {image augmentation,instance segmentation},
mendeley-tags = {image augmentation,instance segmentation},
title = {{Simple Copy-Paste is a Strong Data Augmentation Method for Instance Segmentation}},
url = {http://arxiv.org/abs/2012.07177},
year = {2020}
}
@article{Zhang2020a,
abstract = {We present a causal view on the robustness of neural networks against input manipulations, which applies not only to traditional classification tasks but also to general measurement data. Based on this view, we design a deep causal manipulation augmented model (deep CAMA) which explicitly models possible manipulations on certain causes leading to changes in the observed effect. We further develop data augmentation and test-time fine-tuning methods to improve deep CAMA's robustness. When compared with discriminative deep neural networks, our proposed model shows superior robustness against unseen manipulations. As a by-product, our model achieves disentangled representation which separates the representation of manipulations from those of other latent causes.},
archivePrefix = {arXiv},
arxivId = {2005.01095},
author = {Zhang, Cheng and Zhang, Kun and Li, Yingzhen},
eprint = {2005.01095},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Zhang, Li - 2020 - A Causal View on Robustness of Neural Networks.pdf:pdf},
journal = {arXiv},
keywords = {robustness},
mendeley-tags = {robustness},
number = {NeurIPS},
pages = {1--21},
title = {{A Causal View on Robustness of Neural Networks}},
year = {2020}
}
@article{Lecun2015,
abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
author = {Lecun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
doi = {10.1038/nature14539},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lecun, Bengio, Hinton - 2015 - Deep learning.pdf:pdf},
issn = {14764687},
journal = {Nature},
number = {7553},
pages = {436--444},
pmid = {26017442},
title = {{Deep learning}},
volume = {521},
year = {2015}
}
@article{Shihabudheen2018,
abstract = {This paper improves the performance of adaptive neuro-fuzzy inference system (ANFIS) using extreme learning machines (ELM) concept and particle swarm optimization (PSO). The proposed learning machine, particle swarm optimization (PSO) based regularized extreme learning adaptive neuro-fuzzy inference system (PSO-RELANFIS), has the advantages of reduced randomness, reduced computational complexity and better generalization. The fuzzy membership function parameters of the proposed system are randomly selected with in constraint ranges. A regularized loss function is developed using constrained optimization and the optimized regularization parameter is obtained using PSO technique. Performance analysis on regression and classification problems shows that proposed algorithm achieves similar or better generalization performance compared to well-known kernel based methods and ELM based neuro-fuzzy systems.},
author = {Shihabudheen, K. V. and Mahesh, M. and Pillai, G. N.},
doi = {10.1016/j.eswa.2017.09.037},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shihabudheen, Mahesh, Pillai - 2018 - Particle swarm optimization based extreme learning neuro-fuzzy system for regression and classific.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {ELM based neuro-fuzzy system,Regression and multi-class classification,Regularization,Takagi–Sugeno–Kang (TSK) fuzzy inference system},
pages = {474--484},
publisher = {Elsevier Ltd},
title = {{Particle swarm optimization based extreme learning neuro-fuzzy system for regression and classification}},
url = {https://doi.org/10.1016/j.eswa.2017.09.037},
volume = {92},
year = {2018}
}
@article{Sciancalepore2014,
author = {Sciancalepore, Corrado and Manfredini, Tiziano and Bondioli, Federica},
doi = {10.4028/www.scientific.net/AST.92.90},
isbn = {3038353043},
issn = {1662-0356},
journal = {Advances in Science and Technology},
keywords = {abstract,antibacterial tiles,durability,in many,innovation is strongly felt,into materials and components,like textiles or ceramics,materials is increasingly leading,nanostructured coating,over the last twenty,self-cleaning tiles,the development of advanced,the so-called,this drive in technological,tio 2,to integration of functions,traditional,traditional fields,years},
pages = {90--99},
title = {{Antibacterial and Self-Cleaning Coatings for Silicate Ceramics: A Review}},
url = {http://www.scientific.net/AST.92.90},
volume = {92},
year = {2014}
}
@article{Zhong2015,
abstract = {Advanced modulation formats combined with digital signal processing and direct detection is a promising way to realize high capacity, low cost and power efficient short reach optical transmission system. In this paper, we present a detailed investigation on the performance of three advanced modulation formats for 100 Gb/s short reach transmission system. They are PAM-4, CAP-16 and DMT. The detailed digital signal processing required for each modulation format is presented. Comprehensive simulations are carried out to evaluate the performance of each modulation format in terms of received optical power, transmitter bandwidth, relative intensity noise and thermal noise. The performance of each modulation format is also experimentally studied. To the best of our knowledge, we report the first demonstration of a 112 Gb/s transmission over 10km of SSMF employing single band CAP-16 with EML. Finally, a comparison of computational complexity of DSP for the three formats is presented.},
author = {Zhong, Kangping and Zhou, Xian and Gui, Tao and Tao, Li and Gao, Yuliang and Chen, Wei and Man, Jiangwei and Zeng, Li and Lau, Alan Pak Tao and Lu, Chao},
doi = {10.1364/OE.23.001176},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhong et al. - 2015 - Experimental study of PAM-4, CAP-16, and DMT for 100 Gbs Short Reach Optical Transmission Systems.pdf:pdf},
isbn = {doi:10.1364/OE.23.001176},
issn = {1094-4087},
journal = {Optics Express},
number = {2},
pages = {1176},
pmid = {25835877},
title = {{Experimental study of PAM-4, CAP-16, and DMT for 100 Gb/s Short Reach Optical Transmission Systems}},
url = {https://www.osapublishing.org/abstract.cfm?URI=oe-23-2-1176},
volume = {23},
year = {2015}
}
@article{Senior2020,
abstract = {Protein structure prediction can be used to determine the three-dimensional shape of a protein from its amino acid sequence1. This problem is of fundamental importance as the structure of a protein largely determines its function2; however, protein structures can be difficult to determine experimentally. Considerable progress has recently been made by leveraging genetic information. It is possible to infer which amino acid residues are in contact by analysing covariation in homologous sequences, which aids in the prediction of protein structures3. Here we show that we can train a neural network to make accurate predictions of the distances between pairs of residues, which convey more information about the structure than contact predictions. Using this information, we construct a potential of mean force4 that can accurately describe the shape of a protein. We find that the resulting potential can be optimized by a simple gradient descent algorithm to generate structures without complex sampling procedures. The resulting system, named AlphaFold, achieves high accuracy, even for sequences with fewer homologous sequences. In the recent Critical Assessment of Protein Structure Prediction5 (CASP13)—a blind assessment of the state of the field—AlphaFold created high-accuracy structures (with template modelling (TM) scores6 of 0.7 or higher) for 24 out of 43 free modelling domains, whereas the next best method, which used sampling and contact information, achieved such accuracy for only 14 out of 43 domains. AlphaFold represents a considerable advance in protein-structure prediction. We expect this increased accuracy to enable insights into the function and malfunction of proteins, especially in cases for which no structures for homologous proteins have been experimentally determined7.},
author = {Senior, Andrew W. and Evans, Richard and Jumper, John and Kirkpatrick, James and Sifre, Laurent and Green, Tim and Qin, Chongli and {\v{Z}}{\'{i}}dek, Augustin and Nelson, Alexander W.R. and Bridgland, Alex and Penedones, Hugo and Petersen, Stig and Simonyan, Karen and Crossan, Steve and Kohli, Pushmeet and Jones, David T. and Silver, David and Kavukcuoglu, Koray and Hassabis, Demis},
doi = {10.1038/s41586-019-1923-7},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Senior et al. - 2020 - Improved protein structure prediction using potentials from deep learning.pdf:pdf},
issn = {14764687},
journal = {Nature},
number = {7792},
pages = {706--710},
pmid = {31942072},
title = {{Improved protein structure prediction using potentials from deep learning}},
url = {https://github.com/deepmind/deepmind-research/tree/master/alphafold_casp13},
volume = {577},
year = {2020}
}
@article{Oyelade2010,
abstract = {The ability to monitor the progress of students academic performance is a critical issue to the academic community of higher learning. A system for analyzing students results based on cluster analysis and uses standard statistical algorithms to arrange their scores data according to the level of their performance is described. In this paper, we also implemented k mean clustering algorithm for analyzing students result data. The model was combined with the deterministic model to analyze the students results of a private Institution in Nigeria which is a good benchmark to monitor the progression of academic performance of students in higher Institution for the purpose of making an effective decision by the academic planners.},
archivePrefix = {arXiv},
arxivId = {1002.2425},
author = {Oyelade, O J and Oladipupo, O O and Obagbuwa, I C},
eprint = {1002.2425},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oyelade, Oladipupo, Obagbuwa - 2010 - Application of k Means Clustering algorithm for prediction of Students Academic Performance.pdf:pdf},
issn = {1947-5500},
journal = {International Journal of Computer Science and Information Security},
keywords = {academic performance,algorithm,clustering,k,mean},
number = {1},
pages = {292--295},
title = {{Application of k Means Clustering algorithm for prediction of Students Academic Performance}},
url = {http://arxiv.org/abs/1002.2425},
volume = {7},
year = {2010}
}
@article{Pajarinen2017,
abstract = {This paper investigates manipulation of multiple unknown objects in a crowded environment. Because of incomplete knowledge due to unknown objects and occlusions in visual observations, object observations are imperfect and action success is uncertain, making planning challenging. We model the problem as a partially observable Markov decision process (POMDP), which allows a general reward based optimization objective and takes uncertainty in temporal evolution and partial observations into account. In addition to occlusion dependent observation and action success probabilities, our POMDP model also automatically adapts object specific action success probabilities. To cope with the changing system dynamics and performance constraints, we present a new online POMDP method based on particle filtering that produces compact policies. The approach is validated both in simulation and in physical experiments in a scenario of moving dirty dishes into a dishwasher. The results indicate that: 1) a greedy heuristic manipulation approach is not sufficient, multi-object manipulation requires multi-step POMDP planning, and 2) on-line planning is beneficial since it allows the adaptation of the system dynamics model based on actual experience.},
archivePrefix = {arXiv},
arxivId = {1402.0649},
author = {Pajarinen, Joni and Kyrki, Ville},
doi = {10.1016/j.artint.2015.04.001},
eprint = {1402.0649},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pajarinen, Kyrki - 2017 - Robotic manipulation of multiple objects as a POMDP.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {Cluttered environment,Manipulation,Multiple objects,POMDP,Planning under uncertainty,Task planning,Unknown objects},
pages = {213--228},
publisher = {Elsevier B.V.},
title = {{Robotic manipulation of multiple objects as a POMDP}},
url = {http://dx.doi.org/10.1016/j.artint.2015.04.001},
volume = {247},
year = {2017}
}
@article{Mulesa2017,
author = {Mulesa, Oksana and Geche, Fedir and Voloshchuk, Veronika and Buchok, Viktor and Batyuk, Anatoliy},
doi = {10.1109/STC-CSIT.2017.8098747},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mulesa et al. - 2017 - Information technology for time series forecasting with considering fuzzy expert evaluations.pdf:pdf},
isbn = {9781538616383},
journal = {Proceedings of the 12th International Scientific and Technical Conference on Computer Sciences and Information Technologies, CSIT 2017},
keywords = {fuzzy expert evaluations,information technology,information-analytical system,system model,the task of numeric evaluation of the object,time series forecasting},
pages = {105--108},
title = {{Information technology for time series forecasting with considering fuzzy expert evaluations}},
volume = {1},
year = {2017}
}
@article{Ma2021,
author = {Ma, Jiawei and Tao, Xiaoyu and Ma, Jianxing and Hong, Xiaopeng and Gong, Yihong},
doi = {10.1109/icip42928.2021.9506788},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ma et al. - 2021 - Class Incremental Learning for Video Action Classification.pdf:pdf},
keywords = {continual learning,video classification},
mendeley-tags = {continual learning,video classification},
pages = {504--508},
title = {{Class Incremental Learning for Video Action Classification}},
year = {2021}
}
@article{Bates1969a,
abstract = {Aggregating information by combining forecasts from two or more forecasting methods is an alternative to using just a single method. In this paper we provide extensive empirical results showing that combined forecasts obtained through weighted averages can be quite accurate. Five procedures for estimating weights are investigated, and two appear to be superior to the others. These two procedures provide forecasts that are more accurate overall than forecasts from individual methods. Furthermore, they are superior to forecasts found from a simple unweighted average of the same methods. CR - Copyright &#169; 1983 Royal Statistical Society},
author = {Bates, J. M. and Granger, C. W. J.},
doi = {10.2307/3008764},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bates, Granger - 1969 - The Combination of Forecasts.pdf:pdf},
isbn = {9780511753961},
issn = {14732858},
journal = {Operational Research Society},
number = {4},
pages = {451--468},
title = {{The Combination of Forecasts}},
url = {http://www.jstor.org/stable/3008764?origin=crossref},
volume = {20},
year = {1969}
}
@article{Lubana2021,
abstract = {Quadratic regularizers are often used for mitigating catastrophic forgetting in deep neural networks (DNNs), but are unable to compete with recent continual learning methods. To understand this behavior, we analyze parameter updates under quadratic regularization and demonstrate such regularizers prevent forgetting of past tasks by implicitly performing a weighted average between current and previous values of model parameters. Our analysis shows the inferior performance of quadratic regularizers arises from (a) dependence of weighted averaging on training hyperparameters, which often results in unstable training and (b) assignment of lower importance to deeper layers, which are generally the cause for forgetting in DNNs. To address these limitations, we propose Explicit Movement Regularization (EMR), a continual learning algorithm that modifies quadratic regularization to remove the dependence of weighted averaging on training hyperparameters and uses a relative measure for importance to avoid problems caused by lower importance assignment to deeper layers. Compared to quadratic regularization, EMR achieves 6.2% higher average accuracy and 4.5% lower average forgetting.},
archivePrefix = {arXiv},
arxivId = {2102.02805},
author = {Lubana, Ekdeep Singh and Trivedi, Puja and Dick, Robert P.},
eprint = {2102.02805},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lubana, Trivedi, Dick - 2021 - Rethinking Quadratic Regularizers Explicit Movement Regularization for Continual Learning.pdf:pdf},
keywords = {continual learning,regularization},
mendeley-tags = {continual learning,regularization},
title = {{Rethinking Quadratic Regularizers: Explicit Movement Regularization for Continual Learning}},
url = {http://arxiv.org/abs/2102.02805},
year = {2021}
}
@inproceedings{Aljundi2019,
abstract = {Methods proposed in the literature towards continual deep learning typically operate in a task-based sequential learning setup. A sequence oftasks is learned, one at a time, with all data ofcurrent task available but not ofprevious or future tasks. Task boundaries and identities are known at all times. This setup, however, is rarely encountered in practi- cal applications. Therefore we investigate how to transform continual learning to an online setup. We develop a sys- tem that keeps on learning over time in a streaming fash- ion, with data distributions gradually changing and with- out the notion of separate tasks. To this end, we build on the work on Memory Aware Synapses, and show how this method can be made online by providing a protocol to de- cide i) when to update the importance weights, ii) which data to use to update them, and iii) how to accumulate the importance weights at each update step. Experimental re- sults show the validity ofthe approach in the context oftwo applications: (self-)supervised learning of a face recogni- tion model by watching soap series and learning a robot to avoid collisions.},
author = {Aljundi, Rahaf and Kelchtermans, Klaas and Tuytelaars, Tinne},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aljundi, Kelchtermans, Tuytelaars - 2019 - Task-Free Continual Learning.pdf:pdf},
keywords = {continual learning,online learning,task-free},
mendeley-tags = {continual learning,online learning,task-free},
month = {jun},
title = {{Task-Free Continual Learning}},
url = {https://openaccess.thecvf.com/content_CVPR_2019/papers/Aljundi_Task-Free_Continual_Learning_CVPR_2019_paper.pdf},
year = {2019}
}
@inproceedings{MuhammadAbdullahJamal2021,
author = {{Muhammad Abdullah Jamal} and Wang, Liqiang and Gong, Boqing},
booktitle = {International Conference on Computer Vision},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Muhammad Abdullah Jamal, Wang, Gong - 2021 - A Lazy Approach to Long-Horizon Gradient-Based Meta-Learning.pdf:pdf},
keywords = {gradient-based,meta-learning},
mendeley-tags = {gradient-based,meta-learning},
pages = {6577--6586},
title = {{A Lazy Approach to Long-Horizon Gradient-Based Meta-Learning}},
year = {2021}
}
@article{Martens2020,
abstract = {Natural gradient descent is an optimization method traditionally motivated from the perspective of information geometry, and works well for many applications as an alternative to stochastic gradient descent. In this paper we critically analyze this method and its properties, and show how it can be viewed as a type of 2nd-order optimization method, with the Fisher information matrix acting as a substitute for the Hessian. In many important cases, the Fisher information matrix is shown to be equivalent to the Generalized Gauss-Newton matrix, which both approximates the Hessian, but also has certain properties that favor its use over the Hessian. This perspective turns out to have significant implications for the design of a practical and robust natural gradient optimizer, as it motivates the use of techniques like trust regions and Tikhonov regularization. Additionally, we make a series of contributions to the understanding of natural gradient and 2nd-order methods, including: a thorough analysis of the convergence speed of stochastic natural gradient descent (and more general stochastic 2nd-order methods) as applied to convex quadratics, a critical examination of the oft-used \empirical"approximation of the Fisher matrix, and an analysis of the (approximate) parameterization invariance property possessed by natural gradient methods (which we show also holds for certain other curvature matrices, but notably not the Hessian).},
archivePrefix = {arXiv},
arxivId = {1412.1193},
author = {Martens, James},
eprint = {1412.1193},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Martens - 2020 - New insights and perspectives on the natural gradient method.pdf:pdf},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {2nd-order optimization,Convergence rate,Natural gradient methods,Neural networks,Parameterization invariance},
pages = {1--76},
title = {{New insights and perspectives on the natural gradient method}},
volume = {21},
year = {2020}
}
@article{Lin,
archivePrefix = {arXiv},
arxivId = {arXiv:1312.4400v3},
author = {Lin, Min and Chen, Qiang and Yan, Shuicheng},
eprint = {arXiv:1312.4400v3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin, Chen, Yan - Unknown - Network In Network.pdf:pdf},
pages = {1--10},
title = {{Network In Network}}
}
@article{Zhang2012,
abstract = {A PEM electrolyzer system for hydrogen production is established and the corresponding efficiency is derived. Based on semi-empirical equations, thermodynamic-electrochemical modeling of water splitting reaction is systematically carried out. It is confirmed that the Joule heat resulting from the irreversibilities inside the PEM electrolyzer is larger than that needed in the water splitting process in the whole region of the electric current density. Some alternative configurations are designed to improve the overall performance of the system and the corresponding expressions of the efficiency are also derived. The curves of the efficiency varying with the electric current density are presented and the efficiencies of the different configurations are compared. The optimally operating region of the electric current density is determined. The effects of some of the important parameters on the performance of the PEM electrolyzer system are analyzed in detail. Some significant results for the optimum design strategies of a practical PEM electrolyzer system for hydrogen production are obtained.},
author = {Zhang, Houcheng and Su, Shanhe and Lin, Guoxing and Chen, Jincan},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2012 - Efficiency calculation and configuration design of a PEM electrolyzer system for hydrogen production.pdf:pdf},
isbn = {1452-3981},
issn = {14523981},
journal = {International Journal of Electrochemical Science},
keywords = {Configuration design,Efficiency calculation,Hydrogen production,PEM electrolyzer system,Performance analysis},
number = {5},
pages = {4143--4157},
title = {{Efficiency calculation and configuration design of a PEM electrolyzer system for hydrogen production}},
volume = {7},
year = {2012}
}
@book{Klee1992,
author = {Klee, Mareike},
booktitle = {Advanced Materials},
doi = {10.1002/adma.19920041217},
isbn = {0080347207},
issn = {0935-9648},
number = {12},
pages = {826--827},
title = {{Concise encyclopedia of advanced ceramic materials. Edited byR. J. Brook, Pergamon, Oxford 1991, 588 pp., hardcover, {\pounds} 110, ISBN 0-08-034720-78}},
url = {http://doi.wiley.com/10.1002/adma.19920041217},
volume = {4},
year = {1992}
}
@article{Rosca2020a,
abstract = {How sensitive should machine learning models be to input changes? We tackle the question of model smoothness and show that it is a useful inductive bias which aids generalization, adversarial robustness, generative modeling and reinforcement learning. We explore current methods of imposing smoothness constraints and observe they lack the flexibility to adapt to new tasks, they don't account for data modalities, they interact with losses, architectures and optimization in ways not yet fully understood. We conclude that new advances in the field are hinging on finding ways to incorporate data, tasks and learning into our definitions of smoothness.},
archivePrefix = {arXiv},
arxivId = {2012.07969},
author = {Rosca, Mihaela and Weber, Theophane and Gretton, Arthur and Mohamed, Shakir},
eprint = {2012.07969},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rosca et al. - 2020 - A case for new neural network smoothness constraints(2).pdf:pdf},
issn = {23318422},
keywords = {generalization,robustness},
mendeley-tags = {generalization,robustness},
number = {1},
pages = {1--13},
title = {{A case for new neural network smoothness constraints}},
url = {http://arxiv.org/abs/2012.07969},
year = {2020}
}
@article{Zhang2015,
abstract = {Thermoelectric materials have drawn vast attentions for centuries, because thermoelectric effects enable direct conversion between thermal and electrical energy, thus providing an alternative for power generation and refrigeration. This review summaries the thermoelectric phenomena, applications and parameter relationships. The approaches used for thermoelectric performance enhancement are outlined, including: modifications of electronic band structures and band convergence to enhance Seebeck coefficients; nanostructuring and all-scale hierarchical architecturing to reduce the lattice thermal conductivity. Several promising thermoelectric materials with intrinsically low thermal conductivities are introduced. The low thermal conductivities may arise from large molecular weights, complex crystal structures, liquid like transports or high anharmonicity of chemical bonds. At the end, a discussion of future possible strategies is proposed, aiming at further thermoelectric performance enhancements.},
author = {Zhang, Xiao and Zhao, Li Dong},
doi = {10.1016/j.jmat.2015.01.001},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Zhao - 2015 - Thermoelectric materials Energy conversion between heat and electricity.pdf:pdf},
isbn = {23528478},
issn = {23528486},
journal = {Journal of Materiomics},
keywords = {Electrical conductivity,Seebeck coefficient,Thermal conductivity,Thermoelectric},
number = {2},
pages = {92--105},
publisher = {Elsevier Ltd},
title = {{Thermoelectric materials: Energy conversion between heat and electricity}},
url = {http://dx.doi.org/10.1016/j.jmat.2015.01.001},
volume = {1},
year = {2015}
}
@article{Kaushik2021,
abstract = {Catastrophic forgetting in neural networks is a significant problem for continual learning. A majority of the current methods replay previous data during training, which violates the constraints of an ideal continual learning system. Additionally, current approaches that deal with forgetting ignore the problem of catastrophic remembering, i.e. the worsening ability to discriminate between data from different tasks. In our work, we introduce Relevance Mapping Networks (RMNs) which are inspired by the Optimal Overlap Hypothesis. The mappings reflects the relevance of the weights for the task at hand by assigning large weights to essential parameters. We show that RMNs learn an optimized representational overlap that overcomes the twin problem of catastrophic forgetting and remembering. Our approach achieves state-of-the-art performance across all common continual learning datasets, even significantly outperforming data replay methods while not violating the constraints for an ideal continual learning system. Moreover, RMNs retain the ability to detect data from new tasks in an unsupervised manner, thus proving their resilience against catastrophic remembering.},
archivePrefix = {arXiv},
arxivId = {2102.11343},
author = {Kaushik, Prakhar and Gain, Alex and Kortylewski, Adam and Yuille, Alan},
eprint = {2102.11343},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kaushik et al. - 2021 - Understanding Catastrophic Forgetting and Remembering in Continual Learning with Optimal Relevance Mapping.pdf:pdf},
keywords = {Relevance Mapping Networks,continual learning},
mendeley-tags = {Relevance Mapping Networks,continual learning},
title = {{Understanding Catastrophic Forgetting and Remembering in Continual Learning with Optimal Relevance Mapping}},
url = {http://arxiv.org/abs/2102.11343},
year = {2021}
}
@article{Khalid2016,
author = {Khalid, Adia and Javaid, Nadeem and Mateen, Abdul and Khalid, Bilal and Khan, Zahoor Ali and Qasim, Umar},
doi = {10.1109/CISIS.2016.128},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khalid et al. - 2016 - Demand Side Management Using Hybrid Bacterial Foraging and Genetic Algorithm Optimization Techniques.pdf:pdf},
isbn = {978-1-5090-0987-9},
journal = {2016 10th International Conference on Complex, Intelligent, and Software Intensive Systems (CISIS)},
pages = {494--502},
title = {{Demand Side Management Using Hybrid Bacterial Foraging and Genetic Algorithm Optimization Techniques}},
url = {http://ieeexplore.ieee.org/document/7791933/},
volume = {2013},
year = {2016}
}
@article{Li2020b,
abstract = {We motivate Energy-Based Models (EBMs) as a promising model class for continual learning problems. Instead of tackling continual learning via the use of external memory, growing models, or regularization, EBMs have a natural way to support a dynamically-growing number of tasks or classes that causes less interference with previously learned information. We find that EBMs outperform the baseline methods by a large margin on several continual learning benchmarks. We also show that EBMs are adaptable to a more general continual learning setting where the data distribution changes without the notion of explicitly delineated tasks. These observations point towards EBMs as a class of models naturally inclined towards the continual learning regime.},
archivePrefix = {arXiv},
arxivId = {2011.12216},
author = {Li, Shuang and Du, Yilun and van de Ven, Gido M. and Torralba, Antonio and Mordatch, Igor},
eprint = {2011.12216},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2020 - Energy-Based Models for Continual Learning.pdf:pdf},
keywords = {continual learning,energy-based learning},
mendeley-tags = {continual learning,energy-based learning},
pages = {1--21},
title = {{Energy-Based Models for Continual Learning}},
url = {http://arxiv.org/abs/2011.12216 https://github.com/ShuangLI59/ebm-continual-learning},
year = {2020}
}
@article{Parker2009,
abstract = {Drawing on evidence from the United Kingdom and elsewhere in Europe, this paper explores how people have responded to flood warning information and how these responses impact upon the effectiveness of a flood warning through saving lives and injuries, and reducing economic damages. Methods of flood warning that the public rely upon are discussed alongside empirical evidence of how flood victims prepare for, and respond to, flood warnings in rapid to medium-onset floods. The paper investigates why some members of the public fail to act appropriately, or most effectively, to flood warning information, touching on ideas of a lack of understanding, mistrust in authority and a lack of ownership of flood reducing actions. The paper examines the styles of public learning about flood warning response which might be most appropriate and effective, and how recent positive steps to increase the public's understanding of effective response might be further enhanced in the United Kingdom.},
author = {Parker, D J and Priest, S J and Tapsell, S M},
doi = {10.1002/met},
isbn = {1469-8080},
issn = {13504827},
journal = {Meteorological Applications},
keywords = {accepted 26 november 2008,behavioural response,effective response,flood warning,public understanding,received 24 october 2008,revised 21 november 2008,styles of learning},
number = {January},
pages = {103--114},
title = {{Understanding and enhancing the public ' s behavioural response to flood warning information}},
volume = {114},
year = {2009}
}
@article{Techapanurak,
abstract = {This paper proposes a method for OOD detection. Questioning the premise of previous studies that ID and OOD samples are separated distinctly, we consider samples lying in the intermediate of the two and use them for training a network. We generate such samples using multiple image transformations that corrupt inputs in various ways and with different severity levels. We estimate where the generated samples by a single image transformation lie between ID and OOD using a network trained on clean ID samples. To be specific, we make the network classify the generated samples and calculate their mean classification accuracy, using which we create a soft target label for them. We train the same network from scratch using the original ID samples and the generated samples with the soft labels created for them. We detect OOD samples by thresholding the entropy of the predicted softmax probability. The experimental results show that our method outperforms the previous state-of-the-art in the standard benchmark tests. We also analyze the effect of the number and particular combinations of image corrupting transformations on the performance .},
archivePrefix = {arXiv},
arxivId = {2101.02500v1},
author = {Techapanurak, Engkarat and Dang, Anh-Chuong and Okatani, Takayuki},
eprint = {2101.02500v1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Techapanurak, Dang, Okatani - Unknown - Bridging In-and Out-of-distribution Samples for Their Better Discriminability.pdf:pdf},
keywords = {out-of-distribution,representation learning},
mendeley-tags = {out-of-distribution,representation learning},
title = {{Bridging In-and Out-of-distribution Samples for Their Better Discriminability}}
}
@article{Poudel2019,
abstract = {The encoder-decoder framework is state-of-the-art for offline semantic image segmentation. Since the rise in autonomous systems, real-time computation is increasingly desirable. In this paper, we introduce fast segmentation convolutional neural network (Fast-SCNN), an above real-time semantic segmentation model on high resolution image data (1024x2048px) suited to efficient computation on embedded devices with low memory. Building on existing two-branch methods for fast segmentation, we introduce our `learning to downsample' module which computes low-level features for multiple resolution branches simultaneously. Our network combines spatial detail at high resolution with deep features extracted at lower resolution, yielding an accuracy of 68.0% mean intersection over union at 123.5 frames per second on Cityscapes. We also show that large scale pre-training is unnecessary. We thoroughly validate our metric in experiments with ImageNet pre-training and the coarse labeled data of Cityscapes. Finally, we show even faster computation with competitive results on subsampled inputs, without any network modifications.},
archivePrefix = {arXiv},
arxivId = {1902.04502},
author = {Poudel, Rudra P K and Liwicki, Stephan and Cipolla, Roberto},
eprint = {1902.04502},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Poudel, Liwicki, Cipolla - 2019 - Fast-SCNN Fast Semantic Segmentation Network.pdf:pdf},
title = {{Fast-SCNN: Fast Semantic Segmentation Network}},
url = {http://arxiv.org/abs/1902.04502},
year = {2019}
}
@article{Sauer2021,
abstract = {Neural networks are prone to learning shortcuts -- they often model simple correlations, ignoring more complex ones that potentially generalize better. Prior works on image classification show that instead of learning a connection to object shape, deep classifiers tend to exploit spurious correlations with low-level texture or the background for solving the classification task. In this work, we take a step towards more robust and interpretable classifiers that explicitly expose the task's causal structure. Building on current advances in deep generative modeling, we propose to decompose the image generation process into independent causal mechanisms that we train without direct supervision. By exploiting appropriate inductive biases, these mechanisms disentangle object shape, object texture, and background; hence, they allow for generating counterfactual images. We demonstrate the ability of our model to generate such images on MNIST and ImageNet. Further, we show that the counterfactual images can improve out-of-distribution robustness with a marginal drop in performance on the original classification task, despite being synthetic. Lastly, our generative model can be trained efficiently on a single GPU, exploiting common pre-trained models as inductive biases.},
archivePrefix = {arXiv},
arxivId = {2101.06046},
author = {Sauer, Axel and Geiger, Andreas},
eprint = {2101.06046},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sauer, Geiger - 2021 - Counterfactual Generative Networks.pdf:pdf},
journal = {arXiv},
keywords = {inductive bias,neural networks},
mendeley-tags = {inductive bias,neural networks},
month = {jan},
title = {{Counterfactual Generative Networks}},
url = {http://arxiv.org/abs/2101.06046},
volume = {1},
year = {2021}
}
@article{Jung2016,
abstract = {A catastrophic forgetting problem makes deep neural networks forget the previously learned information, when learning data collected in new environments, such as by different sensors or in different light conditions. This paper presents a new method for alleviating the catastrophic forgetting problem. Unlike previous research, our method does not use any information from the source domain. Surprisingly, our method is very effective to forget less of the information in the source domain, and we show the effectiveness of our method using several experiments. Furthermore, we observed that the forgetting problem occurs between mini-batches when performing general training processes using stochastic gradient descent methods, and this problem is one of the factors that degrades generalization performance of the network. We also try to solve this problem using the proposed method. Finally, we show our less-forgetting learning method is also helpful to improve the performance of deep neural networks in terms of recognition rates.},
archivePrefix = {arXiv},
arxivId = {1607.00122},
author = {Jung, Heechul and Ju, Jeongwoo and Jung, Minju and Kim, Junmo},
eprint = {1607.00122},
file = {:home/user/Downloads/1607.00122.pdf:pdf},
keywords = {continual learning,incremental learning,regularization},
mendeley-tags = {continual learning,incremental learning,regularization},
number = {X},
pages = {1--5},
title = {{Less-forgetting Learning in Deep Neural Networks}},
url = {http://arxiv.org/abs/1607.00122},
volume = {XX},
year = {2016}
}
@article{Kim2018b,
abstract = {Capitalism needs momentum and market for growth. Even without subscribing to a specific academic school, capitalism has felt the need for theories or mechanisms to overcome crises in the past. This research tries to shed light on the recent momentum of industry 4.0 with an expanded scope that includes this wave in a series of meso revolutions brought about by the spread of capitalism. After reviewing a lineage of theories that could shape meso revolutions in economic history, this research used Bank of Korea's data, including total capital efficiency and machinery investment efficiency, to check the recent status of the private sector of Korea. An institutional review of the preliminary budget analysis adopted in Korea was then conducted to draw some implications for the country's preparedness toward the so-called industry 4.0 with potential implications for other countries.},
author = {Kim, Junmo},
doi = {10.1016/j.techfore.2017.11.006},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim - 2018 - Are countries ready for the new meso revolution Testing the waters for new industrial change in Korea.pdf:pdf},
issn = {00401625},
journal = {Technological Forecasting and Social Change},
keywords = {Industry 4.0,Investment efficiency,Meso revolution,Preparedness for change},
number = {November},
pages = {34--39},
publisher = {Elsevier},
title = {{Are countries ready for the new meso revolution? Testing the waters for new industrial change in Korea}},
url = {http://dx.doi.org/10.1016/j.techfore.2017.11.006},
volume = {132},
year = {2018}
}
@article{Shanahan2019,
abstract = {With a view to bridging the gap between deep learning and symbolic AI, we present a novel end-to-end neural network architecture that learns to form propositional representations with an explicitly relational structure from raw pixel data. In order to evaluate and analyse the architecture, we introduce a family of simple visual relational reasoning tasks of varying complexity. We show that the proposed architecture, when pre-trained on a curriculum of such tasks, learns to generate reusable representations that better facilitate subsequent learning on previously unseen tasks when compared to a number of baseline architectures. The workings of a successfully trained model are visualised to shed some light on how the architecture functions.},
archivePrefix = {arXiv},
arxivId = {1905.10307},
author = {Shanahan, Murray and Nikiforou, Kyriacos and Creswell, Antonia and Kaplanis, Christos and Barrett, David and Garnelo, Marta},
eprint = {1905.10307},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shanahan et al. - 2019 - An explicitly relational neural network architecture.pdf:pdf},
journal = {arXiv},
title = {{An explicitly relational neural network architecture}},
year = {2019}
}
@article{Russello2009,
abstract = {Abstract: The current study explored the effects of media exposure on men and women's body satisfaction, self-esteem, level of internalization of sociocultural ideals, and level of social comparison. Male and female undergraduates (N = 32) were exposed to television advertisements either with muscular men and thin women (sociocultural ideal group) or without those types of men and women (neutral advertisement group). Men were more satisfied with their bodies than women, and they internalized ideals less. Self-esteem and social comparison levels were similar for both men and women. In addition, exposure to physical-ideal advertisements did not appear to effect body satisfaction, self-esteem, or internalization. Also, the level of internalization increased as the level of social comparison increased. According},
author = {Russello, Salenna},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Russello - 2009 - The Impact of Media Exposure on Self-Esteem and Body Satisfaction in Men and Women.pdf:pdf},
journal = {Journal of Interdisciplinary Undergraduate Research},
number = {2009},
pages = {1--12},
title = {{The Impact of Media Exposure on Self-Esteem and Body Satisfaction in Men and Women}},
volume = {1},
year = {2009}
}
@article{Lesort2020c,
abstract = {Continual learning (CL) is a particular machine learning paradigm where the data distribution and learning objective change through time, or where all the training data and objective criteria are never available at once. The evolution of the learning process is modeled by a sequence of learning experiences where the goal is to be able to learn new skills all along the sequence without forgetting what has been previously learned. CL can be seen as an online learning where knowledge fusion needs to take place in order to learn from streams of data presented sequentially in time. Continual learning also aims at the same time at optimizing the memory, the computation power and the speed during the learning process. An important challenge for machine learning is not necessarily finding solutions that work in the real world but rather finding stable algorithms that can learn in real world. Hence, the ideal approach would be tackling the real world in a embodied platform: an autonomous agent. Continual learning would then be effective in an autonomous agent or robot, which would learn autonomously through time about the external world, and incrementally develop a set of complex skills and knowledge.Robotic agents have to learn to adapt and interact with their environment using a continuous stream of observations. Some recent approaches aim at tackling continual learning for robotics, but most recent papers on continual learning only experiment approaches in simulation or with static datasets. Unfortunately, the evaluation of those algorithms does not provide insights on whether their solutions may help continual learning in the context of robotics. This paper aims at reviewing the existing state of the art of continual learning, summarizing existing benchmarks and metrics, and proposing a framework for presenting and evaluating both robotics and non robotics approaches in a way that makes transfer between both fields easier. We put light on continual learning in the context of robotics to create connections between fields and normalize approaches.},
annote = {Overview of a CL framework for applications in robotic, together with discussion of existing CL strategies and techniques.},
author = {Lesort, Timoth{\'{e}}e and Lomonaco, Vincenzo and Stoian, Andrei and Maltoni, Davide and Filliat, David and D{\'{i}}az-Rodr{\'{i}}guez, Natalia},
doi = {10.1016/j.inffus.2019.12.004},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lesort et al. - 2020 - Continual learning for robotics Definition, framework, learning strategies, opportunities and challenges.pdf:pdf},
issn = {1566-2535},
journal = {Information Fusion},
keywords = {Catastrophic Forgetting,Continual Learning,Deep Learning,Lifelong Learning,Reinforcement Learning,Robotics,catastrophic forgetting,continual learning,deep learning,lifelong learning,reinforcement learning,robotics},
language = {en},
mendeley-tags = {catastrophic forgetting,continual learning,deep learning,lifelong learning,reinforcement learning,robotics},
month = {jun},
pages = {52--68},
shorttitle = {Continual learning for robotics},
title = {{Continual learning for robotics: Definition, framework, learning strategies, opportunities and challenges}},
url = {http://www.sciencedirect.com/science/article/pii/S1566253519307377},
volume = {58},
year = {2020}
}
@article{Zago2021,
abstract = {Convolutional neural networks (CNNs) are fragile to small perturbations in the input images. These networks are thus prone to malicious attacks that perturb the inputs to force a misclassification. Such slightly manipulated images aimed at deceiving the classifier are known as adversarial images. In this work, we investigate statistical differences between natural images and adversarial ones. More precisely, we show that employing a proper image transformation and for a class of adversarial attacks, the distribution of the leading digit of the pixels in adversarial images deviates from Benford's law. The stronger the attack, the more distant the resulting distribution is from Benford's law. Our analysis provides a detailed investigation of this new approach that can serve as a basis for alternative adversarial example detection methods that do not need to modify the original CNN classifier neither work on the raw high-dimensional pixels as features to defend against attacks.},
archivePrefix = {arXiv},
arxivId = {2102.04615},
author = {Zago, Jo{\~{a}}o G. and Baldissera, Fabio L. and Antonelo, Eric A. and Saad, Rodrigo T.},
eprint = {2102.04615},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zago et al. - 2021 - Benford's law what does it say on adversarial images.pdf:pdf},
keywords = {adversarial attacks,adversarial detection,adversarial learning,benford,benford law,convolutional neural networks,s law},
mendeley-tags = {adversarial learning,benford law},
pages = {1--12},
title = {{Benford's law: what does it say on adversarial images?}},
url = {http://arxiv.org/abs/2102.04615},
year = {2021}
}
@article{DeSousaMeneses2013,
abstract = {A new decomposition method of infrared spectra which takes into account the configurational and dynamical origins of the disorder allows retrieving structural information on short and medium range orders in potassium silicate glasses. The distribution of tetrahedral units, the occupation of cation sites, the ratio of SiO bond ionicities involving bridging and non bridging oxygen, and a measure of the impact of low frequency floppy modes on the high frequency dynamics are byproducts of the modeling process. The composition dependence of two vibrational modes clearly identified as spectral components signing medium range order, shows that the disruption of the silicate network follows selective schemes. The 3D silica like network completely disappears in glasses with K2O amounts greater than 11 mol% and above this threshold a progressive appearance of 2D silicate sheets is evidenced. {\textcopyright} 2012 Elsevier B.V.},
author = {{De Sousa Meneses}, Domingos and Eckes, Myriam and {Del Campo}, Leire and Santos, Cristiane N. and Vaills, Yann and Echegut, Patrick},
doi = {10.1016/j.vibspec.2012.11.015},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Sousa Meneses et al. - 2013 - Investigation of medium range order in silicate glasses by infrared spectroscopy.pdf:pdf},
issn = {09242031},
journal = {Vibrational Spectroscopy},
keywords = {Infrared spectroscopy,Medium range order,Potassium silicate glass},
pages = {50--57},
publisher = {Elsevier B.V.},
title = {{Investigation of medium range order in silicate glasses by infrared spectroscopy}},
url = {http://dx.doi.org/10.1016/j.vibspec.2012.11.015},
volume = {65},
year = {2013}
}
@article{Liu2015b,
abstract = {Image restoration is one of the most fundamental issues in imaging science. Total variation regularization is widely used in image restoration problems for its capability to preserve edges. In the literature, however, it is also well known for producing staircase artifacts. In this work we extend the total variation with overlapping group sparsity, which we previously developed for one dimension signal processing, to image restoration. A convex cost function is given and an efficient algorithm is proposed for solving the corresponding minimization problem. In the experiments, we compare our method with several state-of-the-art methods. The results illustrate the efficiency and effectiveness of the proposed method in terms of PSNR and computing time.},
author = {Liu, Jun and Huang, Ting Zhu and Selesnick, Ivan W. and Lv, Xiao Guang and Chen, Po Yu},
doi = {10.1016/j.ins.2014.10.041},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2015 - Image restoration using total variation with overlapping group sparsity.pdf:pdf},
issn = {00200255},
journal = {Information Sciences},
keywords = {ADMM,Convex optimization,Image restoration,MM,Overlapping group sparsity,Total variation},
pages = {232--246},
publisher = {Elsevier Inc.},
title = {{Image restoration using total variation with overlapping group sparsity}},
url = {http://dx.doi.org/10.1016/j.ins.2014.10.041},
volume = {295},
year = {2015}
}
@article{Larochelle2012,
abstract = {Recent developments have demonstrated the capacity of restricted Boltzmann machines (RBM) to be powerful generative models, able to extract useful features from input data or construct deep artificial neural networks. In such settings, the RBMonly yields a preprocessing or an initialization for some other model, instead of acting as a complete supervised model in its own right. In this paper, we argue that RBMs can provide a self-contained framework for developing competitive classifiers. We study the Classification RBM (ClassRBM), a variant on the RBM adapted to the classification setting. We study different strategies for training the ClassRBM and show that competitive classification performances can be reached when appropriately combining discriminative and generative training objectives. Since training according to the generative objective requires the computation of a generally intractable gradient, we also compare different approaches to estimating this gradient and address the issue of obtaining such a gradient for problems with very high dimensional inputs. Finally, we describe how to adapt the ClassRBM to two special cases of classification problems, namely semi-supervised and multitask learning. {\textcopyright} 2012 Hugo Larochelle, Michael Mandel, Razvan Pascanu and Yoshua Bengio.},
author = {Larochelle, Hugo and Mandel, Michael and Pascanu, Razvan and Bengio, Yoshua},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Larochelle et al. - 2012 - Learning algorithms for the classification restricted Boltzmann machine.pdf:pdf},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {Classification,Discriminative learning,Generative learning,Restricted Boltzmannmachine},
pages = {643--669},
title = {{Learning algorithms for the classification restricted Boltzmann machine}},
volume = {13},
year = {2012}
}
@article{Abdelsalam2020,
abstract = {We introduce the "Incremental Implicitly-Refined Classi-fication (IIRC)" setup, an extension to the class incremental learning setup where the incoming batches of classes have two granularity levels. i.e., each sample could have a high-level (coarse) label like "bear" and a low-level (fine) label like "polar bear". Only one label is provided at a time, and the model has to figure out the other label if it has already learnfed it. This setup is more aligned with real-life scenarios, where a learner usually interacts with the same family of entities multiple times, discovers more granularity about them, while still trying not to forget previous knowledge. Moreover, this setup enables evaluating models for some important lifelong learning challenges that cannot be easily addressed under the existing setups. These challenges can be motivated by the example "if a model was trained on the class bear in one task and on polar bear in another task, will it forget the concept of bear, will it rightfully infer that a polar bear is still a bear? and will it wrongfully associate the label of polar bear to other breeds of bear?". We develop a standardized benchmark that enables evaluating models on the IIRC setup. We evaluate several state-of-the-art lifelong learning algorithms and highlight their strengths and limitations. For example, distillation-based methods perform relatively well but are prone to incorrectly predicting too many labels per image. We hope that the proposed setup, along with the benchmark, would provide a meaningful problem setting to the practitioners},
archivePrefix = {arXiv},
arxivId = {2012.12477},
author = {Abdelsalam, Mohamed and Faramarzi, Mojtaba and Sodhani, Shagun and Chandar, Sarath},
eprint = {2012.12477},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abdelsalam et al. - 2020 - IIRC Incremental Implicitly-Refined Classification.pdf:pdf},
keywords = {continual learning,new setup},
mendeley-tags = {continual learning,new setup},
title = {{IIRC: Incremental Implicitly-Refined Classification}},
url = {http://arxiv.org/abs/2012.12477},
year = {2020}
}
@article{Gu2020,
abstract = {Neural networks are susceptible to catastrophic forgetting. They fail to preserve previously acquired knowledge when adapting to new tasks. Inspired by human associative memory system, we propose a brain-like approach that imitates the associative learning process to achieve continual learning. We design a heuristics mechanism to potentiatively stimulates the model, which guides the model to recall the historical episodes based on the current circumstance and obtained association experience. Besides, a distillation measure is added to depressively alter the efficacy of synaptic transmission, which dampens the feature reconstruction learning for new task. The framework is mediated by potentiation and depression stimulation that play opposing roles in directing synaptic and behavioral plasticity. It requires no access to the original data and is more similar to human cognitive process. Experiments demonstrate the effectiveness of our method in alleviating catastrophic forgetting on continual image reconstruction problems.},
archivePrefix = {arXiv},
arxivId = {2011.13553},
author = {Gu, Yi and Gao, Yuting and Chen, Ruoxin and Cai, Feiyang and Li, Jie and Wu, Chentao},
eprint = {2011.13553},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gu et al. - 2020 - Association Remind Your GAN not to Forget.pdf:pdf},
pages = {1--15},
title = {{Association: Remind Your GAN not to Forget}},
url = {http://arxiv.org/abs/2011.13553},
year = {2020}
}
@article{Hewitt2017a,
abstract = {As the importance of the ocean in the weather and climate system is increasingly recognised, operational systems are now moving towards coupled prediction not only for seasonal to climate timescales but also for short-range forecasts. A three-way tension exists between the allocation of computing resources to refine model resolution, the expansion of model complexity/capability, and the increase of ensemble size. Here we review evidence for the benefits of increased ocean resolution in global coupled models, where the ocean component explicitly represents transient mesoscale eddies and narrow boundary currents. We consider lessons learned from forced ocean/sea-ice simulations; from studies concerning the SST resolution required to impact atmospheric simulations; and from coupled predictions. Impacts of the mesoscale ocean in western boundary current regions on the large-scale atmospheric state have been identified. Understanding of air-sea feedback in western boundary currents is modifying our view of the dynamics in these key regions. It remains unclear whether variability associated with open ocean mesoscale eddies is equally important to the large-scale atmospheric state. We include a discussion of what processes can presently be parameterised in coupled models with coarse resolution non-eddying ocean models, and where parameterizations may fall short. We discuss the benefits of resolution and identify gaps in the current literature that leave important questions unanswered.},
author = {Hewitt, Helene T. and Bell, Michael J. and Chassignet, Eric P. and Czaja, Arnaud and Ferreira, David and Griffies, Stephen M. and Hyder, Pat and McClean, Julie L. and New, Adrian L. and Roberts, Malcolm J.},
doi = {10.1016/j.ocemod.2017.11.002},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hewitt et al. - 2017 - Will high-resolution global ocean models benefit coupled predictions on short-range to climate timescales.pdf:pdf},
issn = {14635003},
journal = {Ocean Modelling},
keywords = {Atmosphere,Coupled,Ocean,Parameterisation,Resolution},
pages = {120--136},
publisher = {Elsevier Ltd},
title = {{Will high-resolution global ocean models benefit coupled predictions on short-range to climate timescales?}},
url = {https://doi.org/10.1016/j.ocemod.2017.11.002},
volume = {120},
year = {2017}
}
@article{Serra2018,
abstract = {Catastrophic forgetting occurs when a neural network loses the information learned in a previous task after training on subsequent tasks. This problem remains a hurdle for artificial intelligence systems with sequential learning capabilities. In this paper, we propose a task-based hard attention mechanism that preserves previous tasks' information without affecting the current task's learning. A hard attention mask is learned concurrently to every task, through stochastic gradient descent, and previous masks are exploited to condition such learning. We show that the proposed mechanism is effective for reducing catastrophic forgetting, cutting current rates by 45 to 80%. We also show that it is robust to different hyperparameter choices, and that it offers a number of monitoring capabilities. The approach features the possibility to control both the stability and compactness of the learned knowledge, which we believe makes it also attractive for online learning or network compression applications.},
archivePrefix = {arXiv},
arxivId = {1801.01423},
author = {Serra, Joan and Suris, D{\'{i}}dac and Mir{\'{o}}n, Marius and Karatzoglou, Alexandras},
eprint = {1801.01423},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Serra et al. - 2018 - Overcoming Catastrophic forgetting with hard attention to the task.pdf:pdf},
isbn = {9781510867963},
issn = {2640-3498},
journal = {35th International Conference on Machine Learning, ICML 2018},
pages = {7225--7234},
title = {{Overcoming Catastrophic forgetting with hard attention to the task}},
volume = {10},
year = {2018}
}
@article{Agnolucci2013,
abstract = {Hydrogen is widely recognised as an important option for future road transportation, but a widespread infrastructure must be developed if the potential for hydrogen is to be achieved. This paper and related appendices which can be downloaded as Supplementary material present a mixed-integer linear programming model (called SHIPMod) that optimises a hydrogen supply chains for scenarios of hydrogen fuel demand in the UK, including the spatial arrangement of carbon capture and storage infrastructure. In addition to presenting a number of improvements on past practice in the literature, the paper focuses attention on the importance of assumptions regarding hydrogen demand. The paper draws on socio-economic data to develop a spatially detailed scenario of possible hydrogen demand. The paper then shows that assumptions about the level and spatial dispersion of hydrogen demand have a significant impact on costs and on the choice of hydrogen production technologies and distribution mechanisms. Copyright {\textcopyright} 2013, Hydrogen Energy Publications, LLC. Published by Elsevier Ltd. All rights reserved.},
author = {Agnolucci, Paolo and Akgul, Ozlem and McDowall, William and Papageorgiou, Lazaros G.},
doi = {10.1016/j.ijhydene.2013.06.071},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Agnolucci et al. - 2013 - The importance of economies of scale, transport costs and demand patterns in optimising hydrogen fuelling infr.pdf:pdf},
isbn = {0360-3199},
issn = {03603199},
journal = {International Journal of Hydrogen Energy},
keywords = {Hydrogen supply chains,Infrastructure,Mixed-integer linear programming,optimisation modelling},
number = {26},
pages = {11189--11201},
publisher = {Elsevier Ltd},
title = {{The importance of economies of scale, transport costs and demand patterns in optimising hydrogen fuelling infrastructure: An exploration with SHIPMod (Spatial hydrogen infrastructure planning model)}},
url = {http://dx.doi.org/10.1016/j.ijhydene.2013.06.071},
volume = {38},
year = {2013}
}
@article{Goyal2020,
abstract = {A fascinating hypothesis is that human and animal intelligence could be explained by a few principles (rather than an encyclopedic list of heuristics). If that hypothesis was correct, we could more easily both understand our own intelligence and build intelligent machines. Just like in physics, the principles themselves would not be sufficient to predict the behavior of complex systems like brains, and substantial computation might be needed to simulate human-like intelligence. This hypothesis would suggest that studying the kind of inductive biases that humans and animals exploit could help both clarify these principles and provide inspiration for AI research and neuroscience theories. Deep learning already exploits several key inductive biases, and this work considers a larger list, focusing on those which concern mostly higher-level and sequential conscious processing. The objective of clarifying these particular principles is that they could potentially help us build AI systems benefiting from humans' abilities in terms of flexible out-of-distribution and systematic generalization, which is currently an area where a large gap exists between state-of-the-art machine learning and human intelligence.},
archivePrefix = {arXiv},
arxivId = {2011.15091},
author = {Goyal, Anirudh and Bengio, Yoshua},
eprint = {2011.15091},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goyal, Bengio - 2020 - Inductive Biases for Deep Learning of Higher-Level Cognition.pdf:pdf},
pages = {1--40},
title = {{Inductive Biases for Deep Learning of Higher-Level Cognition}},
url = {http://arxiv.org/abs/2011.15091},
year = {2020}
}
@article{Zhou2021,
abstract = {Knowledge distillation is an effective approach to leverage a well-trained network or an ensemble of them, named as the teacher, to guide the training of a student network. The outputs from the teacher network are used as soft labels for supervising the training of a new network. Recent studies \citep{muller2019does,yuan2020revisiting} revealed an intriguing property of the soft labels that making labels soft serves as a good regularization to the student network. From the perspective of statistical learning, regularization aims to reduce the variance, however how bias and variance change is not clear for training with soft labels. In this paper, we investigate the bias-variance tradeoff brought by distillation with soft labels. Specifically, we observe that during training the bias-variance tradeoff varies sample-wisely. Further, under the same distillation temperature setting, we observe that the distillation performance is negatively associated with the number of some specific samples, which are named as regularization samples since these samples lead to bias increasing and variance decreasing. Nevertheless, we empirically find that completely filtering out regularization samples also deteriorates distillation performance. Our discoveries inspired us to propose the novel weighted soft labels to help the network adaptively handle the sample-wise bias-variance tradeoff. Experiments on standard evaluation benchmarks validate the effectiveness of our method. Our code is available at \url{https://github.com/bellymonster/Weighted-Soft-Label-Distillation}.},
archivePrefix = {arXiv},
arxivId = {2102.00650},
author = {Zhou, Helong and Song, Liangchen and Chen, Jiajie and Zhou, Ye and Wang, Guoli and Yuan, Junsong and Zhang, Qian},
eprint = {2102.00650},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou et al. - 2021 - Rethinking Soft Labels for Knowledge Distillation A Bias-Variance Tradeoff Perspective.pdf:pdf},
keywords = {knowledge distillation,soft labels},
mendeley-tags = {knowledge distillation,soft labels},
pages = {1--15},
title = {{Rethinking Soft Labels for Knowledge Distillation: A Bias-Variance Tradeoff Perspective}},
url = {http://arxiv.org/abs/2102.00650},
year = {2021}
}
@article{VenkataRatnam2017,
abstract = {Space weather phenomena cause satellite to ground or satellite to aircraft transmission outages over the VHF to L-band frequency range, particularly in the low latitude region. Global Positioning System (GPS) is primarily susceptible to this form of space weather. Faulty GPS signals are attributed to ionospheric error, which is a function of Total Electron Content (TEC). Importantly, precise forecasts of space weather conditions and appropriate hazard observant cautions required for ionospheric space weather observations are limited. In this paper, a fuzzy logic-based gradient descent method has been proposed to forecast the ionospheric TEC values. In this technique, membership functions have been tuned based on the gradient descent estimated values. The proposed algorithm has been tested with the TEC data of two geomagnetic storms in the low latitude station of KL University, Guntur, India (16.44°N, 80.62°E). It has been found that the gradient descent method performs well and the predicted TEC values are close to the original TEC measurements.},
author = {{Venkata Ratnam}, D. and Vindhya, G. and Dabbakuti, J. R.K.Kumar},
doi = {10.1016/j.geog.2017.05.003},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Venkata Ratnam, Vindhya, Dabbakuti - 2017 - Ionospheric forecasting model using fuzzy logic-based gradient descent method.pdf:pdf},
issn = {16749847},
journal = {Geodesy and Geodynamics},
keywords = {GPS,Gradient descent method,TEC},
number = {5},
pages = {305--310},
publisher = {Elsevier Taiwan LLC},
title = {{Ionospheric forecasting model using fuzzy logic-based gradient descent method}},
url = {https://doi.org/10.1016/j.geog.2017.05.003},
volume = {8},
year = {2017}
}
@article{Britton2012,
abstract = {There has been a significant amount of research done on the effect that advertising in the fashion and beauty industry has on women. By creating advertisements with unrealistic images of beauty, it has resulted in anxiety, low self-esteem, and low self-confidence in many women. Most of these negative emotions stems from unhappiness among body and appearance. Less research has been performed relating to cosmetics and how this can have an influence on women, and how women can use cosmetics to manipulate their appearance. This paper first discusses the existing research that focuses on the cosmetic industry's influence on women. From this research, a general survey was created in order to gather general information about a group of college student's cosmetic usage, habits, and beliefs. The results indicate that college women are high users of cosmetics, are very aware of the cosmetic industry, and that some individual differences can have an effect on the choices a woman makes regarding cosmetics. Keywords},
author = {Britton, Ann Marie},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Britton - 2012 - The Beauty Industry 's Influence on Women in Society.pdf:pdf},
keywords = {Business Administration,Marketing,WSBE,appearance,cosmetics,makeup,self monitoring,self-esteem},
pages = {1--42},
title = {{The Beauty Industry 's Influence on Women in Society}},
url = {https://scholars.unh.edu/honors/86/?utm_source=scholars.unh.edu%2Fhonors%2F86&utm_medium=PDF&utm_campaign=PDFCoverPages},
year = {2012}
}
@article{Wong2019,
abstract = {Object detection remains an active area of research in the field of computer vision, and considerable advances and successes has been achieved in this area through the design of deep convolutional neural networks for tackling object detection. Despite these successes, one of the biggest challenges to widespread deployment of such object detection networks on edge and mobile scenarios is the high computational and memory requirements. As such, there has been growing research interest in the design of efficient deep neural network architectures catered for edge and mobile usage. In this study, we introduce YOLO Nano, a highly compact deep convolutional neural network for the task of object detection. A human-machine collaborative design strategy is leveraged to create YOLO Nano, where principled network design prototyping, based on design principles from the YOLO family of single-shot object detection network architectures, is coupled with machine-driven design exploration to create a compact network with highly customized module-level macroarchitecture and microarchitecture designs tailored for the task of embedded object detection. The proposed YOLO Nano possesses a model size of $\sim$4.0MB (>15.1x and >8.3x smaller than Tiny YOLOv2 and Tiny YOLOv3, respectively) and requires 4.57B operations for inference (>34% and $\sim$17% lower than Tiny YOLOv2 and Tiny YOLOv3, respectively) while still achieving an mAP of $\sim$69.1% on the VOC 2007 dataset ($\sim$12% and $\sim$10.7% higher than Tiny YOLOv2 and Tiny YOLOv3, respectively). Experiments on inference speed and power efficiency on a Jetson AGX Xavier embedded module at different power budgets further demonstrate the efficacy of YOLO Nano for embedded scenarios.},
archivePrefix = {arXiv},
arxivId = {1910.01271},
author = {Wong, Alexander and Famuori, Mahmoud and Shafiee, Mohammad Javad and Li, Francis and Chwyl, Brendan and Chung, Jonathan},
eprint = {1910.01271},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wong et al. - 2019 - YOLO Nano a Highly Compact You Only Look Once Convolutional Neural Network for Object Detection.pdf:pdf},
pages = {1--5},
title = {{YOLO Nano: a Highly Compact You Only Look Once Convolutional Neural Network for Object Detection}},
url = {http://arxiv.org/abs/1910.01271},
year = {2019}
}
@article{Lattner2004,
abstract = {This paper describes LLVM (Low Level Virtual Machine), a compiler framework designed to support transparent, life-long program analysis and transformation for arbitrary programs, by providing high-level information to compiler transformations at compile-time, link-time, run-time, and in idle time between runs. LLVM defines a common, low-level code representation in Static Single Assignment (SSA) form, with several novel features: a simple, language-independent type-system that exposes the primitives commonly used to implement high-level language features; an instruction for typed address arithmetic; and a simple mechanism that can be used to implement the exception handling features of high-level languages (and setjmp/longjmp in C) uniformly and efficiently. The LLVM compiler framework and code representation together provide a combination of key capabilities that are important for practical, lifelong analysis and transformation of programs. To our knowledge, no existing compilation approach provides all these capabilities. We describe the design of the LLVM representation and compiler framework, and evaluate the design in three ways: (a) the size and effectiveness of the representation, including the type information it provides; (b) compiler performance for several interprocedural problems; and (c) illustrative examples of the benefits LLVM provides for several challenging compiler problems.},
author = {Lattner, Chris and Adve, Vikram},
doi = {10.1109/CGO.2004.1281665},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lattner, Adve - 2004 - LLVM A compilation framework for lifelong program analysis & transformation.pdf:pdf},
isbn = {0769521029},
journal = {International Symposium on Code Generation and Optimization, CGO},
number = {c},
pages = {75--86},
title = {{LLVM: A compilation framework for lifelong program analysis & transformation}},
year = {2004}
}
@article{Gu2017a,
abstract = {We propose a compact phase-shifting radial shearing interferometer based on a pixelated micro-retarder array (MRA). The MRA is made of a thin birefringence plate, and is composed of identical units that have pixels of four different thicknesses. We demonstrate that pixelated phase delay between two shearing beams can be introduced by applying the fast axis of birefringence plate in the horizontal or vertical orientation. We also present an approach to extract the wavefront under test with random phase shift, which dramatically reduces the machining difficulty of the MRA. The feasibility and accuracy of the proposed method are further validated through our numerical analysis. With the advantages of vibration immunity, simultaneous phase stepping, and broad spectral range, the presented interferometer is expected to be of potential use in a variety of applications, such as the detection of moving objects and dynamic processes.},
author = {Gu, Naiting and Yao, Benxi and Huang, Linhai and Rao, Changhui},
doi = {10.1364/OL.42.003622},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gu et al. - 2017 - Compact single-shot radial shearing interferometer with random phase shift.pdf:pdf},
issn = {0146-9592},
journal = {Opt. Lett.},
keywords = {Active or adaptive optics,Coherence imaging,Detection},
number = {18},
pages = {3622--3625},
title = {{Compact single-shot radial shearing interferometer with random phase shift}},
url = {http://ol.osa.org/abstract.cfm?URI=ol-42-18-3622},
volume = {42},
year = {2017}
}
@article{Perez2017,
abstract = {In this paper, we explore and compare multiple solutions to the problem of data augmentation in image classification. Previous work has demonstrated the effectiveness of data augmentation through simple techniques, such as cropping, rotating, and flipping input images. We artificially constrain our access to data to a small subset of the ImageNet dataset, and compare each data augmentation technique in turn. One of the more successful data augmentations strategies is the traditional transformations mentioned above. We also experiment with GANs to generate images of different styles. Finally, we propose a method to allow a neural net to learn augmentations that best improve the classifier, which we call neural augmentation. We discuss the successes and shortcomings of this method on various datasets.},
archivePrefix = {arXiv},
arxivId = {1712.04621},
author = {Perez, Luis and Wang, Jason},
eprint = {1712.04621},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Perez, Wang - 2017 - The Effectiveness of Data Augmentation in Image Classification using Deep Learning.pdf:pdf},
title = {{The Effectiveness of Data Augmentation in Image Classification using Deep Learning}},
url = {http://arxiv.org/abs/1712.04621},
year = {2017}
}
@article{Octaviani2014,
abstract = {Accreditation is the recognition of an educational institution given by a competent authority, that is Badan Akreditasi Nasional Sekolah/Madrasah (BAN - S/M) after it is assessed that the institution has met the eight components of the accreditation assessment. An elementary school, as one of the compulsory basic education, should have the status of accreditation to ensure the quality of education. This study aimed to apply the classification method Support Vector Machine (SVM) on the data accreditation SD in Magelang. Support Vector Machine (SVM) is a method that can be used as a predictive classification by using the concept of searching hyperplane (separator functions) that can separate the data according to the class. SVM using the kernel trick for non-linear problems which can transform data into a high dimensional space using a kernel function, so that the data can be classified linearly. The results of this study indicate that the prediction accuracy of SVM classification using Gaussian kernel function RBF is 93.902%. It is calculated from 77 of 82 elementary schools that are classified correctly with the original classes. Keywords},
author = {Octaviani, Pusphita Anna and {Yuciana Wilandari} and Ispriyanti, Dwi},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Octaviani, Yuciana Wilandari, Ispriyanti - 2014 - Penerapan Metode Klasifikasi Support Vector Machine (SVM) pada Data Akreditasi Sekolah.pdf:pdf},
issn = {2339-2541},
journal = {Jurnal Gaussian},
keywords = {accreditation,accuracy,classification,gaussian rbf kernel,hyperplane,support vector machine,svm},
number = {8},
pages = {811--820},
title = {{Penerapan Metode Klasifikasi Support Vector Machine (SVM) pada Data Akreditasi Sekolah Dasar (SD) di Kabupaten Magelang}},
url = {http://download.portalgaruda.org/article.php?article=286497&val=4706&title=PENERAPAN METODE KLASIFIKASI SUPPORT VECTOR MACHINE (SVM)  PADA DATA AKREDITASI SEKOLAH DASAR (SD) DI KABUPATEN MAGELANG},
volume = {3},
year = {2014}
}
@inproceedings{Li2020e,
abstract = {This paper presents Prototypical Contrastive Learning (PCL), an unsupervised representation learning method that addresses the fundamental limitations of the popular instance-wise contrastive learning. PCL implicitly encodes semantic structures of the data into the learned embedding space, and prevents the network from solely relying on low-level cues for solving unsupervised learning tasks. Specifically, we introduce prototypes as latent variables to help find the maximumlikelihood estimation of the network parameters in an Expectation-Maximization framework. We iteratively perform E-step as finding the distribution of prototypes via clustering and M-step as optimizing the network via contrastive learning. We propose ProtoNCE loss, a generalized version of the InfoNCE loss for contrastive learning by encouraging representations to be closer to their assigned prototypes. PCL achieves state-of-The-Art results on multiple unsupervised representation learning benchmarks, with 10% accuracy improvement in low-resource transfer tasks. Our code and pretrained models will be released.},
archivePrefix = {arXiv},
arxivId = {2005.04966},
author = {Li, Junnan and Zhou, Pan and Xiong, Caiming and Socher, Richard and Hoi, Steven C.H.},
booktitle = {Iclr 2021},
eprint = {2005.04966},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2020 - Prototypical contrastive learning of unsupervised representations.pdf:pdf},
issn = {23318422},
keywords = {contrastive learning,prototypical,self-supervised learning,unsupervised learning},
mendeley-tags = {contrastive learning,prototypical,self-supervised learning,unsupervised learning},
pages = {1--16},
title = {{Prototypical contrastive learning of unsupervised representations}},
year = {2020}
}
@article{Tasar2019,
abstract = {In spite of remarkable success of the convolutional neural networks on semantic segmentation, they suffer from catastrophic forgetting: A significant performance drop for the already learned classes when new classes are added on the data having no annotations for the old classes. We propose an incremental learning methodology, enabling to learn segmenting new classes without hindering dense labeling abilities for the previous classes, although the entire previous data are not accessible. The key points of the proposed approach are adapting the network to learn new as well as old classes on the new training data, and allowing it to remember the previously learned information for the old classes. For adaptation, we keep a frozen copy of the previously trained network, which is used as a memory for the updated network in the absence of annotations for the former classes. The updated network minimizes a loss function, which balances the discrepancy between outputs for the previous classes from the memory and updated networks, and the misclassification rate between outputs for the new classes from the updated network and the new ground-Truth. For remembering, we either regularly feed samples from the stored, little fraction of the previous data or use the memory network, depending on whether the new data are collected from completely different geographic areas or from the same city. Our experimental results prove that it is possible to add new classes to the network, while maintaining its performance for the previous classes, despite the whole previous training data are not available.},
archivePrefix = {arXiv},
arxivId = {1810.12448},
author = {Tasar, Onur and Tarabalka, Yuliya and Alliez, Pierre},
doi = {10.1109/JSTARS.2019.2925416},
eprint = {1810.12448},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tasar, Tarabalka, Alliez - 2019 - Incremental Learning for Semantic Segmentation of Large-Scale Remote Sensing Data.pdf:pdf},
issn = {21511535},
journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
keywords = {Catastrophic forgetting,continual learning,convolutional neural networks (CNNs),incremental learning,semantic segmentation},
mendeley-tags = {continual learning,incremental learning,semantic segmentation},
number = {9},
pages = {3524--3537},
title = {{Incremental Learning for Semantic Segmentation of Large-Scale Remote Sensing Data}},
volume = {12},
year = {2019}
}
@article{Golbas2017,
abstract = {In machinery maintenance policies, regular inspection intervals should be specified in such a way that the cumulative of direct and indirect financial consequences of maintenance activities should be minimized while supporting the functional health of system components. This study aims to develop a simulation algorithm, called the time-counter, to optimize inspection intervals. In the algorithm, uptime and downtime behaviors of the system components and production losses in the corrective repairs are considered random values. Delay time concept is regarded when estimating failure detection periods and deciding on the required maintenance type. In addition, the developed model is applied to two active draglines and their inspection intervals are optimized as 232 and 184 h for Dragline-1 and Dragline-2, respectively. The optimized values are observed to decrease the total maintenance costs by 5.9 and 6.2 percent for the given draglines, compared to the current interval of 160 h. The main novelties of the study are that (i) the proposed concept which allows for simultaneous assessment of system components in an incremental time span has not been proposed in the literature when deciding on optimal inspection intervals, (ii) it is the first initiative in inspection optimization of a mining machinery system, and (iii) it uses real datasets on lifetime, repair time, and financial values that are rarely observed in maintenance studies.},
author = {G{\"{o}}lbaşı, Onur and Demirel, Nuray},
doi = {10.1016/j.cie.2017.09.002},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/G{\"{o}}lbaşı, Demirel - 2017 - A cost-effective simulation algorithm for inspection interval optimization An application to mining equipme.pdf:pdf},
issn = {03608352},
journal = {Computers and Industrial Engineering},
keywords = {Delay time,Inspection interval,Maintenance cost,Optimization,Production systems},
pages = {525--540},
title = {{A cost-effective simulation algorithm for inspection interval optimization: An application to mining equipment}},
volume = {113},
year = {2017}
}
@article{Tuli2021,
abstract = {Modern machine learning models for computer vision exceed humans in accuracy on specific visual recognition tasks, notably on datasets like ImageNet. However, high accuracy can be achieved in many ways. The particular decision function found by a machine learning system is determined not only by the data to which the system is exposed, but also the inductive biases of the model, which are typically harder to characterize. In this work, we follow a recent trend of in-depth behavioral analyses of neural network models that go beyond accuracy as an evaluation metric by looking at patterns of errors. Our focus is on comparing a suite of standard Convolutional Neural Networks (CNNs) and a recently-proposed attention-based network, the Vision Transformer (ViT), which relaxes the translation-invariance constraint of CNNs and therefore represents a model with a weaker set of inductive biases. Attention-based networks have previously been shown to achieve higher accuracy than CNNs on vision tasks, and we demonstrate, using new metrics for examining error consistency with more granularity, that their errors are also more consistent with those of humans. These results have implications both for building more human-like vision models, as well as for understanding visual object recognition in humans.},
archivePrefix = {arXiv},
arxivId = {2105.07197},
author = {Tuli, Shikhar and Dasgupta, Ishita and Grant, Erin and Griffiths, Thomas L.},
eprint = {2105.07197},
file = {:home/user/Downloads/2105.07197.pdf:pdf},
keywords = {error consistency,transformer},
mendeley-tags = {error consistency,transformer},
title = {{Are Convolutional Neural Networks or Transformers more like human vision?}},
url = {http://arxiv.org/abs/2105.07197},
volume = {2},
year = {2021}
}
@article{Hu2017,
abstract = {Accurate wind speed prediction is a significant factor in improving and optimizing wind power production. Particularly, reliable short-term wind speed forecasting contributes to the real-time optimization of wind farm operation. However, this short-term forecasting task remains challenging due to the strong stochastic nature and dynamic uncertainty of wind speed. This paper proposes a hybrid model that consists of the Empirical Wavelet Transform (EWT), Expectation Propagation (EP) algorithm and Gaussian process regression with the Student-t Observation Model (GPR-t) for short-term wind speed forecasting. The proposed approach firstly extracts meaningful information from a short-term wind speed series and subsequently models the inherent uncertainty and the dynamic features of the wind speed time-series. Additionally, the wind speed series presents a time-varying characteristic. Thus, this study adopts a moving window approach in the prediction processes, thereby permitting the proposed model to respond quickly to the dynamic characteristic of wind speed. To examine the forecasting performance of the suggested hybrid model, the validation of the proposed model is performed against several other existing models with half-hour and hourly wind speed data obtained from a windmill farm located in northwestern China. The computational results demonstrate that the proposed hybrid approach generates satisfactory point predictive accuracy and interval forecasting performance.},
author = {Hu, Jianming and Wang, Jianzhou and Xiao, Liqun},
doi = {10.1016/j.renene.2017.05.093},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hu, Wang, Xiao - 2017 - A hybrid approach based on the Gaussian process with t-observation model for short-term wind speed forecasts.pdf:pdf},
issn = {18790682},
journal = {Renewable Energy},
keywords = {Expectation propagation (EP) algorithm,Gaussian process regression with the Student-t obs,Wind speed forecasting},
pages = {670--685},
publisher = {Elsevier Ltd},
title = {{A hybrid approach based on the Gaussian process with t-observation model for short-term wind speed forecasts}},
url = {http://dx.doi.org/10.1016/j.renene.2017.05.093},
volume = {114},
year = {2017}
}
@article{Mohamed2009,
abstract = {Deep belief networks (DBN) are generative models with many layers of hidden causal variables, recently introduced by Hinton, Osindero, and Teh 2006 along with a greedy layer-wise unsupervised learning algorithm. Building on Le Roux and Bengio 2008 and Sutskever and Hinton 2008 we show that deep but narrow generative networks do not require more parameters than shallow ones to achieve universal approximation. Exploiting the proof technique, we prove that deep but narrow feedforward neural networks with sigmoidal units can represent any Boolean expression. Related papers},
author = {Mohamed, Abdel-Rahman and Dahl, George and Hinton, Geoffrey},
doi = {10.4249/scholarpedia.5947},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mohamed, Dahl, Hinton - 2009 - Deep Belief Networks for Phone Recognition.pdf:pdf},
isbn = {7845005002},
issn = {19416016},
journal = {Scholarpedia},
number = {5},
pages = {1--9},
pmid = {20337535},
title = {{Deep Belief Networks for Phone Recognition}},
url = {http://www.scholarpedia.org/article/Deep_belief_networks?pagewanted=all},
volume = {4},
year = {2009}
}
@book{Tkac2016,
abstract = {In recent two decades, artificial neural networks have been extensively used in many business applications. Despite the growing number of research papers, only few studies have been presented focusing on the overview of published findings in this important and popular area. Moreover, the majority of these reviews were introduced more than 15 years ago. The aim of this work is to expand the range of earlier surveys and provide a systematic overview of neural network applications in business between 1994 and 2015. We have covered a total of 412 articles and classified them according to the year of publication, application area, type of neural network, learning algorithm, benchmark method, citations and journal. Our investigation revealed that most of the research has aimed at financial distress and bankruptcy problems, stock price forecasting, and decision support, with special attention to classification tasks. Besides conventional multilayer feedforward network with gradient descent backpropagation, various hybrid networks have been developed in order to improve the performance of standard models. Even though neural networks have been established as well-known method in business, there is enormous space for additional research in order to improve their functioning and increase our understanding of this influential area.},
author = {Tk{\'{a}}{\v{c}}, Michal and Verner, Robert},
booktitle = {Applied Soft Computing Journal},
doi = {10.1016/j.asoc.2015.09.040},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tk{\'{a}}{\v{c}}, Verner - 2016 - Artificial neural networks in business Two decades of research.pdf:pdf},
isbn = {4215572231},
issn = {15684946},
keywords = {Business,Finance,Neural networks,Review},
pages = {788--804},
publisher = {Elsevier B.V.},
title = {{Artificial neural networks in business: Two decades of research}},
url = {http://dx.doi.org/10.1016/j.asoc.2015.09.040},
volume = {38},
year = {2016}
}
@article{Atherton2016,
abstract = {<p> <bold>Background:</bold> Paranoia may build directly upon negative thoughts about the self. There have been few direct experimental tests of this hypothesis. <bold>Aims:</bold> The aim of the study was to test the immediate effects of manipulating self-esteem in individuals vulnerable to paranoia. <bold>Method:</bold> A two condition cross-over experimental test was conducted. The participants were 26 males reporting paranoid ideation in the past month. Each participant experienced a neutral immersive virtual reality (VR) social environment twice. Before VR participants received a low self-confidence manipulation or a high self-confidence manipulation. The order of manipulation type was randomized. Paranoia about the VR avatars was assessed. <bold>Results:</bold> The low self-confidence manipulation, relative to the high self-confidence manipulation, led to significantly more negative social comparison in virtual reality and higher levels of paranoia. <bold>Conclusions:</bold> Level of self-confidence affects the occurrence of paranoia in vulnerable individuals. The clinical implication is that interventions designed to improve self-confidence may reduce persecutory ideation. </p>},
author = {Atherton, Stephanie and Antley, Angus and Evans, Nicole and Cernis, Emma and Lister, Rachel and Dunn, Graham and Slater, Mel and Freeman, Daniel},
doi = {10.1017/S1352465814000496},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Atherton et al. - 2016 - Self-Confidence and Paranoia An Experimental Study Using an Immersive Virtual Reality Social Situation.pdf:pdf},
isbn = {1469-1833 (Electronic)\r1352-4658 (Linking)},
issn = {14691833},
journal = {Behavioural and Cognitive Psychotherapy},
keywords = {Delusions,persecutory delusions,self-esteem},
number = {1},
pages = {56--64},
pmid = {25384608},
title = {{Self-Confidence and Paranoia: An Experimental Study Using an Immersive Virtual Reality Social Situation}},
volume = {44},
year = {2016}
}
@article{Nhita2013,
author = {Nhita, Fhira and Adiwijaya},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nhita, Adiwijaya - 2013 - A Rainfall Forecasting using Fuzzy System Based on Genetic Algorithm.pdf:pdf},
isbn = {9781467349925},
journal = {2013 International Conference of Information and Communication Technology (ICoICT) A},
keywords = {fuzzy system,genetic algorithm,prediction,rainfall},
pages = {111--115},
title = {{A Rainfall Forecasting using Fuzzy System Based on Genetic Algorithm}},
year = {2013}
}
@article{Greco2020,
abstract = {We study the issue of catastrophic forgetting in the context of neural multimodal approaches to Visual Question Answering (VQA). Motivated by evidence from psycholinguistics, we devise a set of linguistically-informed VQA tasks, which differ by the types of questions involved (Wh-questions and polar questions). We test what impact task difficulty has on continual learning, and whether the order in which a child acquires question types facilitates computational models. Our results show that dramatic forgetting is at play and that task difficulty and order matter. Two well-known current continual learning methods mitigate the problem only to a limiting degree.},
archivePrefix = {arXiv},
arxivId = {1906.04229},
author = {Greco, Claudio and Plank, Barbara and Fern{\'{a}}ndez, Raquel and Bernardi, Raffaella},
doi = {10.18653/v1/p19-1350},
eprint = {1906.04229},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Greco et al. - 2020 - Psycholinguistics meets continual learning Measuring catastrophic forgetting in visual question answering.pdf:pdf},
isbn = {9781950737482},
journal = {ACL 2019 - 57th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference},
keywords = {continual learning,incremental learning,visual question answering},
mendeley-tags = {continual learning,incremental learning,visual question answering},
pages = {3601--3605},
title = {{Psycholinguistics meets continual learning: Measuring catastrophic forgetting in visual question answering}},
year = {2020}
}
@article{Farulla2017,
abstract = {Despite many years of research, correct and reliable segmentation of touching characters is still a hard task to solve. In the recent years, many methods and algorithms have been proposed; nevertheless the problem is still open. In this paper, we propose a novel method based on fuzzy logic that combines three different techniques to segment touching characters. These techniques have already been used in other studies but they have never been used all together. We propose a 3–input/1–output fuzzy inference system with fuzzy rules that are specifically optimized to segment touching Latin characters. The method is applicable to both printed and handwritten characters. We discuss the performances of our method by comparing it with state of the art. Results show that our method provide a better accuracy to segment characters even with noisy touching characters.},
author = {Farulla, Giuseppe Air{\`{o}} and Murru, Nadir and Rossini, Rosaria},
doi = {10.1016/j.eswa.2017.06.034},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Farulla, Murru, Rossini - 2017 - A fuzzy approach to segment touching characters.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Characters segmentation,Fuzzy logic,OCR,Touching characters},
pages = {1--13},
title = {{A fuzzy approach to segment touching characters}},
volume = {88},
year = {2017}
}
@article{Yu2020b,
abstract = {Class-incremental learning of deep networks sequentially increases the number of classes to be classified. During training, the network has only access to data of one task at a time, where each task contains several classes. In this setting, networks suffer from catastrophic forgetting which refers to the drastic drop in performance on previous tasks. The vast majority of methods have studied this scenario for classification networks, where for each new task the classification layer of the network must be augmented with additional weights to make room for the newly added classes. Embedding networks have the advantage that new classes can be naturally included into the network without adding new weights. Therefore, we study incremental learning for embedding networks. In addition, we propose a new method to estimate the drift, called semantic drift, of features and compensate for it without the need of any exemplars. We approximate the drift of previous tasks based on the drift that is experienced by current task data. We perform experiments on fine-grained datasets, CIFAR100 and ImageNet-Subset. We demonstrate that embedding networks suffer significantly less from catastrophic forgetting. We outperform existing methods which do not require exemplars and obtain competitive results compared to methods which store exemplars. Furthermore, we show that our proposed SDC when combined with existing methods to prevent forgetting consistently improves results.},
archivePrefix = {arXiv},
arxivId = {2004.00440},
author = {Yu, Lu and Twardowski, Bart{\l}omiej and Liu, Xialei and Herranz, Luis and Wang, Kai and Cheng, Yongmei and Jui, Shangling and van de Weijer, Joost},
doi = {10.1109/CVPR42600.2020.00701},
eprint = {2004.00440},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu et al. - 2020 - Semantic drift compensation for class-incremental learning.pdf:pdf},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
keywords = {continual learning,incremental learning,regularization},
mendeley-tags = {continual learning,incremental learning,regularization},
pages = {6980--6989},
title = {{Semantic drift compensation for class-incremental learning}},
url = {https://github.com/yulu0724/SDC-IL},
year = {2020}
}
@article{Singh2018,
abstract = {This study presents a model to forecast the Indian summer monsoon rainfall (ISMR) (June–September) based on monthly and seasonal time scales. The ISMR time series data sets are classified into two parts for modeling purposes, viz., (1) training data set (1871–1960), and (2) testing data set (1961–2014). Statistical analyzes reflect the dynamic nature of the ISMR, which couldn't be predicted efficiently by statistical and mathematical based models. Therefore, this study suggests the usage of three techniques, viz., fuzzy set, entropy and artificial neural network (ANN). Based on these techniques, a novel ISMR time series forecasting model is designed to deal with the dynamic nature of the ISMR. This model is verified and validated with training and testing data sets. Various statistical analyzes and comparison studies demonstrate the effectiveness of the proposed model.},
author = {Singh, Pritpal},
doi = {10.1016/j.gsf.2017.07.011},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Singh - 2018 - Indian summer monsoon rainfall (ISMR) forecasting using time series data A fuzzy-entropy-neuro based expert system.pdf:pdf},
issn = {16749871},
journal = {Geoscience Frontiers},
keywords = {Artificial neural network (ANN),Entropy,Forecasting,Fuzzy set,Indian summer monsoon rainfall (ISMR)},
number = {4},
pages = {1243--1257},
publisher = {Elsevier Ltd},
title = {{Indian summer monsoon rainfall (ISMR) forecasting using time series data: A fuzzy-entropy-neuro based expert system}},
url = {https://doi.org/10.1016/j.gsf.2017.07.011},
volume = {9},
year = {2018}
}
@article{Dhar2019,
abstract = {Incremental learning (IL) is an important task aimed at increasing the capability of a trained model, in terms of the number of classes recognizable by the model. The key problem in this task is the requirement of storing data (e.g. images) associated with existing classes, while teaching the classifier to learn new classes. However, this is impractical as it increases the memory requirement at every incremental step, which makes it impossible to implement IL algorithms on edge devices with limited memory. Hence, we propose a novel approach, called 'Learning without Memorizing (LwM)', to preserve the information about existing (base) classes, without storing any of their data, while making the classifier progressively learn the new classes. In LwM, we present an information preserving penalty: Attention Distillation Loss (L {AD}), and demonstrate that penalizing the changes in classifiers' attention maps helps to retain information of the base classes, as new classes are added. We show that adding L {AD} to the distillation loss which is an existing information preserving loss consistently outperforms the state-of-the-art performance in the iILSVRC-small and iCIFAR-100 datasets in terms of the overall accuracy of base and incrementally learned classes.},
archivePrefix = {arXiv},
arxivId = {1811.08051},
author = {Dhar, Prithviraj and Singh, Rajat Vikram and Peng, Kuan Chuan and Wu, Ziyan and Chellappa, Rama},
doi = {10.1109/CVPR.2019.00528},
eprint = {1811.08051},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dhar et al. - 2019 - Learning without memorizing.pdf:pdf},
isbn = {9781728132938},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
keywords = {Categorization,Deep Learning,Others,Recognition: Detection,Retrieval,Vision Applications and Systems,class incremental learning,continual learning,regularization},
mendeley-tags = {class incremental learning,continual learning,regularization},
pages = {5133--5141},
title = {{Learning without memorizing}},
volume = {2019-June},
year = {2019}
}
@article{Shangguan2017,
abstract = {A dual-frequency direct detection Doppler lidar is demonstrated using a superconducting nanowire single-photon detector (SNSPD) at 1.5 $\mu$m. The so-called double-edge technique is implemented by using a dual-frequency laser pulse, rather than using a double-channel Fabry–Perot interferometer. Such a modification to the reported lidars enhances the frequency stability in the system level. Using the time-division multiplexing method, only one piece of SNSPD is used in the optical receiver, making the system simplified and robust. The SNSPD is adopted to enhance the temporal resolution since it offers merits of high quantum efficiency, low dark count noise, no after-pulsing probability, and a high maximum count rate. Two telescopes that point westward and northward at a zenith angle of 30° are used to detect the line-of-sight wind components, which are used to synthesize the horizontal wind profile. Horizontal wind profiles up to an altitude of about 2.7 km are calculated with vertical spatial/temporal resolution of 10 m/10 s. Wind dynamic evolution and vertical wind shears are observed clearly.},
author = {Shangguan, Mingjia and Xia, Haiyun and Wang, Chong and Qiu, Jiawei and Lin, Shengfu and Dou, Xiankang and Zhang, Qiang and Pan, Jian-Wei},
doi = {10.1364/OL.42.003541},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shangguan et al. - 2017 - Dual-frequency Doppler lidar for wind detection with a superconducting nanowire single-photon detector.pdf:pdf},
issn = {0146-9592},
journal = {Optics Letters},
number = {18},
pages = {3541},
pmid = {28914897},
title = {{Dual-frequency Doppler lidar for wind detection with a superconducting nanowire single-photon detector}},
url = {https://www.osapublishing.org/abstract.cfm?URI=ol-42-18-3541},
volume = {42},
year = {2017}
}
@book{Nguyen1998,
author = {Nguyen, Hung T.},
isbn = {9781461375159},
pages = {531},
publisher = {Springer Science Business Media, LLC},
title = {{Fuzzy Systems - Modeling and Control}},
year = {1998}
}
@article{Li2017a,
abstract = {Assessment of the output power of wind generators is always associated with some uncertainties due to wind speed and other weather parameters alteration, and precise short-term forecasts are essential for their efficient operation. This can efficiently support transmission and distribution system operators and schedulers to improve the power network control and management. In this paper, we propose a double stage hierarchical particle swarm optimization based adaptive neuro-fuzzy inference system (double-stage hybrid PSO-ANFIS) for short-term wind power prediction of a microgrid wind farm in Beijing, China. The approach has two hierarchical stages. The first PSO-ANFIS stage employs numerical weather prediction (NWP) meteorological parameters to forecast wind speed at the wind farm exact site and turbine hub height. The second stage models the actual wind speed and power relationships. Then, the predicted next day's wind speed by the first stage is applied to the second stage to forecast next day's wind power. The influence of input data dependency on prediction accuracy has been analyzed by dividing the input data into five subsets. The proposed approach has attained significant prediction accuracy improvements. The performance of the proposed model is compared with five other prediction approaches and showed the best accuracy improvement of all. {\textcopyright} 2017 IEEE.},
author = {Li, Han and Eseye, Abinet Tesfaye and Zhang, Jianhua and Zheng, Dehua},
doi = {10.1109/GreenTech.2017.56},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2017 - A Double-Stage Hierarchical Hybrid PSO-ANFIS Model for Short-Term Wind Power Forecasting.pdf:pdf},
isbn = {9781509045358},
issn = {21665478},
journal = {IEEE Green Technologies Conference},
keywords = {Forecasting,Fuzzy logic,Neural network,Numerical weather prediction,Particle swarm optimization,Wind power},
pages = {342--349},
title = {{A Double-Stage Hierarchical Hybrid PSO-ANFIS Model for Short-Term Wind Power Forecasting}},
year = {2017}
}
@article{Li2021,
abstract = {Despite that deep neural networks (DNNs) have achieved enormous success in many domains like natural language processing (NLP), they have also been proven to be vulnerable to maliciously generated adversarial examples. Such inherent vulnerability has threatened various real-world deployed DNNs-based applications. To strength the model robustness, several countermeasures have been proposed in the English NLP domain and obtained satisfactory performance. However, due to the unique language properties of Chinese, it is not trivial to extend existing defenses to the Chinese domain. Therefore, we propose AdvGraph, a novel defense which enhances the robustness of Chinese-based NLP models by incorporating adversarial knowledge into the semantic representation of the input. Extensive experiments on two real-world tasks show that AdvGraph exhibits better performance compared with previous work: (i) effective - it significantly strengthens the model robustness even under the adaptive attacks setting without negative impact on model performance over legitimate input; (ii) generic - its key component, i.e., the representation of connotative adversarial knowledge is task-agnostic, which can be reused in any Chinese-based NLP models without retraining; and (iii) efficient - it is a light-weight defense with sub-linear computational complexity, which can guarantee the efficiency required in practical scenarios.},
archivePrefix = {arXiv},
arxivId = {2102.11584},
author = {Li, Jinfeng and Du, Tianyu and Liu, Xiangyu and Zhang, Rong and Xue, Hui and Ji, Shouling},
eprint = {2102.11584},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2021 - Enhancing Model Robustness By Incorporating Adversarial Knowledge Into Semantic Representation.pdf:pdf},
keywords = {adversarial learning,representation learning,robustness},
mendeley-tags = {adversarial learning,representation learning,robustness},
number = {i},
pages = {1--5},
title = {{Enhancing Model Robustness By Incorporating Adversarial Knowledge Into Semantic Representation}},
url = {http://arxiv.org/abs/2102.11584},
year = {2021}
}
@book{Fuente2014a,
abstract = {In Arabic, as in many languages, the future is “ahead” and the past is “behind.” Yet in the research reported here, we showed that Arabic speakers tend to conceptualize the future as behind and the past as ahead of them, despite using spoken metaphors that suggest the opposite. We propose a new account of how space-time mappings become activated in individuals' minds and entrenched in their cultures, the temporal-focus hypothesis: People should conceptualize either the future or the past as in front of them to the extent that their culture (or subculture) is future oriented or past oriented. Results support the temporal-focus hypothesis, demonstrating that the space-time mappings in people's minds are conditioned by their cultural attitudes toward time, that they depend on attentional focus, and that they can vary independently of the space-time mappings enshrined in language. Keywords},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Fuente, Juanma De La and Santiago, Julio and Rom{\'{a}}n, Antonio and Dumitrache, Cristina and Casasanto, Daniel},
booktitle = {Psychological Science},
doi = {10.1007/s13398-014-0173-7.2},
eprint = {arXiv:1011.1669v3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fuente et al. - 2014 - Handbook of dielectric, piezoelectric and ferroelectric materials Synthesis, properties and applications.pdf:pdf},
isbn = {9780874216561},
issn = {1467-9280},
keywords = {conceptual metaphor,cross-cultural differences,mental models,open data,space,time},
number = {9},
pages = {1682--1690},
pmid = {25052830},
title = {{Handbook of dielectric, piezoelectric and ferroelectric materials Synthesis, properties and applications}},
volume = {25},
year = {2014}
}
@article{Wagner2017,
abstract = {The fourth industrial revolution and its Industry 4.0 or connected industry technologies dominates the current discussion of production research. Digital developments like cyber-physical Systems are the key technologies for future, more agile production systems but a common understanding of the term Industry 4.0 is not established in this time. First generic implementation approaches present manifold technical solutions but miss an integrated consideration with existing Lean Production Systems. The actual impact of Industry 4.0 solutions is mostly not clearly specified and a method to evaluate is missing. This paper introduces the Industry 4.0 in an environment of connectability in the Internet of Things and Services with the vision of a smart factory. The initial situation of industrial companies is characterized by Lean Production Systems and Lean Principles. For companies, Industry 4.0 offers an estimated benefit by stabilizing Lean processes with Industry 4.0 applications. To support the development process the presented Concept of an Industry 4.0 impact matrix on lean production systems gives a useable framework. The matrix considers elements of lean production systems with Industry 4.0 technologies and gives a first estimation of impact. In the described development process of a cyber-physical Just-in-Time delivery the matrix is used to find a stabilizing application for a Just-in-Time material supply process.},
author = {Wagner, Tobias and Herrmann, Christoph and Thiede, Sebastian},
doi = {10.1016/j.procir.2017.02.041},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wagner, Herrmann, Thiede - 2017 - Industry 4.0 Impacts on Lean Production Systems.pdf:pdf},
isbn = {22128271 (ISSN)},
issn = {22128271},
journal = {Procedia CIRP},
keywords = {Industry 4.0,Lean Production,connected industry,cyber physical production system,cyber physical system,technology management},
pages = {125--131},
title = {{Industry 4.0 Impacts on Lean Production Systems}},
volume = {63},
year = {2017}
}
@article{TianpingChen2001,
abstract = {In this paper, we discuss dynamical behaviors of recurrently asymmetrically connected neural networks in detail. We propose an effective approach to study global and local stability of the networks. Many of well known existing results are unified in our framework, which gives much better test conditions for global and local stability. Sufficient conditions for the uniqueness of the equilibrium point and its stability conditions are given, too.},
author = {{Tianping Chen} and Amari, S.I.},
doi = {10.1109/72.896806},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tianping Chen, Amari - 2001 - Stability of asymmetric Hopfield networks.pdf:pdf},
issn = {10459227},
journal = {IEEE Transactions on Neural Networks},
number = {1},
pages = {159--163},
title = {{Stability of asymmetric Hopfield networks}},
url = {http://ieeexplore.ieee.org/document/896806/},
volume = {12},
year = {2001}
}
@article{Viriya-empikul2010,
abstract = {The solid oxide catalysts derived from waste shells of egg, golden apple snail, and meretrix venus were employed to produce biodiesel from transesterification of palm olein oil. The shell materials were calcined in air at 800 °C with optimum time of 2-4 h to transform calcium species in the shells into active CaO catalysts. All catalysts showed the high biodiesel production activity over 90% fatty acid methyl ester (FAME) in 2 h, whilst the eggshell-derived catalyst showed comparable activity to the one derived from commercial CaCO3. The catalytic activity was in accordance with the surface area of and the Ca content in the catalysts. {\textcopyright} 2009 Elsevier Ltd. All rights reserved.},
author = {Viriya-empikul, N. and Krasae, P. and Puttasawat, B. and Yoosuk, B. and Chollacoop, N. and Faungnawakij, K.},
doi = {10.1016/j.biortech.2009.12.079},
isbn = {1873-2976 (Electronic)\n0960-8524 (Linking)},
issn = {09608524},
journal = {Bioresource Technology},
keywords = {Biodiesel,CaO,Heterogeneous catalyst,Waste shells of mollusk and egg},
number = {10},
pages = {3765--3767},
pmid = {20079632},
publisher = {Elsevier Ltd},
title = {{Waste shells of mollusk and egg as biodiesel production catalysts}},
url = {http://dx.doi.org/10.1016/j.biortech.2009.12.079},
volume = {101},
year = {2010}
}
@article{Allen-Zhu2020,
abstract = {We formally study how Ensemble of deep learning models can improve test accuracy, and how the superior performance of ensemble can be distilled into a single model using Knowledge Distillation. We consider the challenging case where the ensemble is simply an average of the outputs of a few independently trained neural networks with the SAME architecture, trained using the SAME algorithm on the SAME data set, and they only differ by the random seeds used in the initialization. We empirically show that ensemble/knowledge distillation in deep learning works very differently from traditional learning theory, especially differently from ensemble of random feature mappings or the neural-tangent-kernel feature mappings, and is potentially out of the scope of existing theorems. Thus, to properly understand ensemble and knowledge distillation in deep learning, we develop a theory showing that when data has a structure we refer to as "multi-view", then ensemble of independently trained neural networks can provably improve test accuracy, and such superior test accuracy can also be provably distilled into a single model by training a single model to match the output of the ensemble instead of the true label. Our result sheds light on how ensemble works in deep learning in a way that is completely different from traditional theorems, and how the "dark knowledge" is hidden in the outputs of the ensemble -- that can be used in knowledge distillation -- comparing to the true data labels. In the end, we prove that self-distillation can also be viewed as implicitly combining ensemble and knowledge distillation to improve test accuracy.},
archivePrefix = {arXiv},
arxivId = {2012.09816},
author = {Allen-Zhu, Zeyuan and Li, Yuanzhi},
eprint = {2012.09816},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Allen-Zhu, Li - 2020 - Towards Understanding Ensemble, Knowledge Distillation and Self-Distillation in Deep Learning.pdf:pdf},
keywords = {ensemble,knowledge distillation,self-distillation,transfer learning},
mendeley-tags = {ensemble,knowledge distillation,self-distillation,transfer learning},
month = {dec},
title = {{Towards Understanding Ensemble, Knowledge Distillation and Self-Distillation in Deep Learning}},
url = {http://arxiv.org/abs/2012.09816},
year = {2020}
}
@article{Sosa2013,
author = {Sosa, Alejandro},
doi = {10.3233/978-1-61499-286-8-222},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sosa - 2013 - Genetic Algorithms and Differential Evolution Algorithms Applied to Cyclic Instability Problem in Intelligent Environments.pdf:pdf},
isbn = {9781614992868},
keywords = {cyclic instability,differential,genetic algorithms,nomadic agents},
pages = {222--231},
title = {{Genetic Algorithms and Differential Evolution Algorithms Applied to Cyclic Instability Problem in Intelligent Environments with Nomadics Agents}},
year = {2013}
}
@article{Cohen1990a,
abstract = {Phonon frequencies and eigenvectors have been computed from first principles for the three optic F1u modes in BaTiO3 using the full-potential linearized-augmented-plane-wave method. We find that the ferroelectric instability in BaTiO3 can be understood from calculations for a perfect crystal with periodic boundary conditions. The energy wells for the soft-mode distortion are deeper for rhombohedral [111] displacements relative to tetragonal [001] displacements, but they are relatively shallow and comparable to the transition temperature. The nonrigid part of the charge-density distortion is centered around the Ti ion rather than the O, and the Ti charge is closer to 2.9+ than 4+. There is significant hybridization between the Ti and O, but the Ba is quite ionic and is well described as a Ba2+ ion. The Ti-O hybridization is essential to the ferroelectric instability.},
author = {Cohen, R. E. and Krakauer, H.},
doi = {10.1103/PhysRevB.42.6416},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cohen, Krakauer - 1990 - Lattice dynamics and origin of ferroelectricity in BaTiO3 Linearized-augmented-plane-wave total-energy calculat.pdf:pdf},
isbn = {9891602060},
issn = {01631829},
journal = {Physical Review B},
number = {10},
pages = {6416--6423},
pmid = {9994724},
title = {{Lattice dynamics and origin of ferroelectricity in BaTiO3: Linearized-augmented-plane-wave total-energy calculations}},
volume = {42},
year = {1990}
}
@article{Navianti2012,
author = {Navianti, Dynes Rizky and Widjajati, Farida Agustini and Ngurah, I Gusti and Usadha, Rai and Meteorologi, A Dasar},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Navianti et al. - 2012 - Penerapan Fuzzy Inference System pada Prediksi Curah Hujan di Surabaya Utara.pdf:pdf},
number = {1},
pages = {1--6},
title = {{Penerapan Fuzzy Inference System pada Prediksi Curah Hujan di Surabaya Utara}},
volume = {1},
year = {2012}
}
@book{Bengio2009,
abstract = {Theoretical results suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g., in vision, language, and other AI-level tasks), one may need deep architectures. Deep architectures are composed of multiple levels of non-linear operations, such as in neural nets with many hidden layers or in complicated propositional formulae re-using many sub-formulae. Searching the parameter space of deep architectures is a difficult task, but learning algorithms such as those for Deep Belief Networks have recently been proposed to tackle this problem with notable success, beating the stateof-the-art in certain areas. This monograph discusses the motivations and principles regarding learning algorithms for deep architectures, in particular those exploiting as building blocks unsupervised learning of single-layer models such as Restricted Boltzmann Machines, used to construct deeper models such as Deep Belief Networks. {\textcopyright} 2009 Y. Bengio.},
author = {Bengio, Yoshua},
booktitle = {Foundations and Trends in Machine Learning},
doi = {10.1561/2200000006},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bengio - 2009 - Learning deep architectures for AI.pdf:pdf},
isbn = {2200000006},
issn = {19358237},
number = {1},
pages = {1--27},
title = {{Learning deep architectures for AI}},
volume = {2},
year = {2009}
}
@article{Mbarki2016,
abstract = {Image restoration refers to removal or minimization of known degradations in an image. This includes de-blurring images degraded by the limitations of sensors or source of captures in addition to noise filtering and correction of geometric distortion due to sensors. There are several classical image restoration methods such as Wiener filtering. To find an estimate of the original image, Wiener filter requires the prior knowledge of the degradation phenomenon, the blurred image and the statistical properties of the noise process. In this work, we propose a new rapid and blind algorithm for image restoration that does not require a priori knowledge of the noise distribution. The degraded image is first de-convoluted in Fourier space by parametric Wiener filtering, and then, it is smoothed by the wave atom transform after setting the threshold to its coefficients. Experiment results are significant and show the efficiency of our algorithm compared with other techniques in use.},
author = {Mbarki, Zouhair and Seddik, Hassene and Braiek, Ezzedine Ben},
doi = {10.1016/j.jvcir.2016.08.009},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mbarki, Seddik, Braiek - 2016 - A rapid hybrid algorithm for image restoration combining parametric Wiener filtering and wave atom trans.pdf:pdf},
issn = {10959076},
journal = {Journal of Visual Communication and Image Representation},
keywords = {Image restoration,Parametric Wiener filtering,Wave atom transform},
number = {Part B},
pages = {694--707},
title = {{A rapid hybrid algorithm for image restoration combining parametric Wiener filtering and wave atom transform}},
url = {http://dx.doi.org/10.1016/j.jvcir.2016.08.009},
volume = {40},
year = {2016}
}
@article{Nieuwenhuijsen2016,
abstract = {Background: Many cities across the world are beginning to shift their mobility solution away from the private cars and towards more environmentally friendly and citizen-focused means. Hamburg, Oslo, Helsinki, and Madrid have recently announced their plans to become (partly) private car free cities. Other cities like Paris, Milan, Chengdu, Masdar, Dublin, Brussels, Copenhagen, Bogota, and Hyderabad have measures that aim at reducing motorized traffic including implementing car free days, investing in cycling infrastructure and pedestrianization, restricting parking spaces and considerable increases in public transport provision. Such plans and measures are particularly implemented with the declared aim of reducing greenhouse gas emissions. These reductions are also likely to benefit public health. Aims: We aimed to describe the plans for private car free cities and its likely effects on public health. Methods: We reviewed the grey and scientific literature on plans for private car free cities, restricted car use, related exposures and health. Results: An increasing number of cities are planning to become (partly) private car free. They mainly focus on the reduction of private car use in city centers. The likely effects of such policies are significant reductions in traffic-related air pollution, noise, and temperature in city centers. For example, up to a 40% reduction in NO2levels has been reported on car free days. These reductions are likely to lead to a reduction in premature mortality and morbidity. Furthermore the reduction in the number of cars, and therefore a reduction in the need for parking places and road space, provides opportunities to increase green space and green networks in cities, which in turn can lead to many beneficial health effects. All these measures are likely to lead to higher levels of active mobility and physical activity which may improve public health the most and also provide more opportunities for people to interact with each other in public space. Furthermore, such initiatives, if undertaken at a sufficiently large scale can result in positive distal effects and climate change mitigation through CO2reductions. The potential negative effects which may arise due to motorized traffic detouring around car free zone into their destinations also need further evaluation and the areas in which car free zones are introduced need to be given sufficient attention so as not to become an additional way to exacerbate socioeconomic divides. The extent and magnitude of all the above effects is still unclear and needs further research, including full chain health impact assessment modeling to quantify the potential health benefits of such schemes, and exposure and epidemiological studies to measure any changes when such interventions take place. Conclusions: The introduction of private car free cities is likely to have direct and indirect health benefits, but the exact magnitude and potential conflicting effects are as yet unclear. This paper has overviewed the expected health impacts, which can be useful to underpin policies to reduce car use in cities.},
author = {Nieuwenhuijsen, Mark J. and Khreis, Haneen},
doi = {10.1016/j.envint.2016.05.032},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nieuwenhuijsen, Khreis - 2016 - Car free cities Pathway to healthy urban living.pdf:pdf},
isbn = {0160-4120},
issn = {18736750},
journal = {Environment International},
pages = {251--262},
pmid = {27276440},
publisher = {Elsevier B.V.},
title = {{Car free cities: Pathway to healthy urban living}},
url = {http://dx.doi.org/10.1016/j.envint.2016.05.032},
volume = {94},
year = {2016}
}
@article{Bang,
abstract = {Continual learning is a realistic learning scenario for AI models. Prevalent scenario of continual learning, however, assumes disjoint sets of classes as tasks and is less realistic rather artificial. Instead, we focus on 'blurry' task boundary; where tasks shares classes and is more realistic and practical. To address such task, we argue the importance of diversity of samples in an episodic memory. To enhance the sample diversity in the memory, we propose a novel memory management strategy based on per-sample classification uncertainty and data augmentation, named Rainbow Memory (RM). With extensive empirical validations on MNIST, CIFAR10, CIFAR100, and ImageNet datasets, we show that the proposed method significantly improves the accuracy in blurry continual learning setups, outperforming state of the arts by large margins despite its simplicity. Code and data splits will be available in https://github.com/clovaai/rainbow-memory.},
archivePrefix = {arXiv},
arxivId = {2103.17230},
author = {Bang, Jihwan and Kim, Heesu and Yoo, Youngjoon and Ha, Jung-woo and Choi, Jonghyun},
eprint = {2103.17230},
file = {:home/user/Downloads/2103.17230.pdf:pdf},
keywords = {continual learning,incremental learning},
mendeley-tags = {continual learning,incremental learning},
month = {mar},
title = {{Rainbow Memory: Continual Learning with a Memory of Diverse Samples}},
url = {http://arxiv.org/abs/2103.17230},
year = {2021}
}
@article{Wang2020f,
abstract = {Machine learning has been highly successful in data-intensive applications but is often hampered when the data set is small. Recently, Few-Shot Learning (FSL) is proposed to tackle this problem. Using prior knowledge, FSL can rapidly generalize to new tasks containing only a few samples with supervised information. In this paper, we conduct a thorough survey to fully understand FSL. Starting from a formal definition of FSL, we distinguish FSL from several relevant machine learning problems. We then point out that the core issue in FSL is that the empirical risk minimized is unreliable. Based on how prior knowledge can be used to handle this core issue, we categorize FSL methods from three perspectives: (i) data, which uses prior knowledge to augment the supervised experience; (ii) model, which uses prior knowledge to reduce the size of the hypothesis space; and (iii) algorithm, which uses prior knowledge to alter the search for the best hypothesis in the given hypothesis space. With this taxonomy, we review and discuss the pros and cons of each category. Promising directions, in the aspects of the FSL problem setups, techniques, applications and theories, are also proposed to provide insights for future research.},
author = {Wang, Yaqing and Yao, Quanming and Kwok, James T. and Ni, Lionel M.},
doi = {10.1145/3386252},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2020 - Generalizing from a Few Examples A Survey on Few-shot Learning.pdf:pdf},
issn = {0360-0300},
journal = {ACM Computing Surveys},
month = {jul},
number = {3},
pages = {1--34},
publisher = {Association for Computing Machinery (ACM)},
title = {{Generalizing from a Few Examples: A Survey on Few-shot Learning}},
url = {https://dl.acm.org/doi/10.1145/3386252},
volume = {53},
year = {2020}
}
@article{Fan2020,
author = {Fan, Heng and Wen, Longyin and Du, Dawei and Zhu, Pengfei and Hu, Qinghua and Ling, Haibin and Shah, Mubarak and Wang, Biao and Dong, Bin and Yuan, Di and Wang, Dong and Zhou, Dongjie and Sun, Haoyang and Ghanei-Yakhdan, Hossein and Lu, Huchuan and Khaghani, Javad and Zhou, Jinghao and Wang, Keyang and Pang, Lei and Zhang, Lei and Cheng, Li and Lin, Liting and Ding, Lu and Fan, Nana and Wang, Peng and Zhang, Penghao and Ma, Ruiyan and Marvasti-Zadeh, Seyed Mojtaba and Kasaei, Shohreh and Chen, Shuhao and Lai, Simiao and Xu, Tianyang and He, Wentao and Wu, Xiaojun and Hou, Xin and Zhu, Xuefeng and Gao, Yanjie and Zhao, Yanyun and Wang, Yong and Xu, Yong and Sun, Yubo and Yang, Yuting and Li, Yuxuan and Wang, Zezhou and He, Zhenwei and He, Zhenyu and Luo, Zhipeng and Huang, Zhongjian and Zhang, Zhongzhou and Zhang, Zikai and Yi, Zitong},
doi = {10.1007/978-3-030-66823-5_44},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fan et al. - 2020 - VisDrone-SOT2020 The Vision Meets Drone Single Object Tracking Challenge Results.pdf:pdf},
keywords = {competition,tracking},
mendeley-tags = {competition,tracking},
pages = {728--749},
title = {{VisDrone-SOT2020: The Vision Meets Drone Single Object Tracking Challenge Results}},
year = {2020}
}
@misc{EtsuroSawaguchi1953,
author = {{Etsuro Sawaguchi}},
pages = {615--629},
publisher = {J. Phys. Soc},
title = {{Ferroelectricity versus Antiferroelectricity in the Solid Solutions of PbZrO3 and PbTiO3}},
year = {1953}
}
@incollection{Montufar2018,
abstract = {The restricted Boltzmann machine is a network of stochastic units with undirected interactions between pairs of visible and hidden units. This model was popularized as a building block of deep learning architectures and has continued to play an important role in applied and theoretical machine learning. Restricted Boltzmann machines carry a rich structure, with connections to geometry, applied algebra, probability, statistics, machine learning, and other areas. The analysis of these models is attractive in its own right and also as a platform to combine and generalize mathematical tools for graphical models with hidden variables. This article gives an introduction to the mathematical analysis of restricted Boltzmann machines, reviews recent results on the geometry of the sets of probability distributions representable by these models, and suggests a few directions for further investigation.},
archivePrefix = {arXiv},
arxivId = {1806.07066},
author = {Mont{\'{u}}far, Guido},
booktitle = {Springer Proceedings in Mathematics and Statistics},
doi = {10.1007/978-3-319-97798-0_4},
eprint = {1806.07066},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mont{\'{u}}far - 2018 - Restricted Boltzmann Machines Introduction and Review.pdf:pdf},
issn = {21941017},
keywords = {Divergence maximization,Expected dimension,Exponential family,Hadamard product,Hierarchical model,Kullback–Leibler divergence,Latent variable model,Mixture model,Non-negative tensor rank,Universal approximation},
pages = {75--115},
title = {{Restricted Boltzmann Machines: Introduction and Review}},
url = {http://link.springer.com/10.1007/978-3-319-97798-0_4},
volume = {252},
year = {2018}
}
@article{Gupta2021,
abstract = {The intertwined processes of learning and evolution in complex environmental niches have resulted in a remarkable diversity of morphological forms. Moreover, many aspects of animal intelligence are deeply embodied in these evolved morphologies. However, the principles governing relations between environmental complexity, evolved morphology, and the learnability of intelligent control, remain elusive, partially due to the substantial challenge of performing large-scale in silico experiments on evolution and learning. We introduce Deep Evolutionary Reinforcement Learning (DERL): a novel computational framework which can evolve diverse agent morphologies to learn challenging locomotion and manipulation tasks in complex environments using only low level egocentric sensory information. Leveraging DERL we demonstrate several relations between environmental complexity, morphological intelligence and the learnability of control. First, environmental complexity fosters the evolution of morphological intelligence as quantified by the ability of a morphology to facilitate the learning of novel tasks. Second, evolution rapidly selects morphologies that learn faster, thereby enabling behaviors learned late in the lifetime of early ancestors to be expressed early in the lifetime of their descendants. In agents that learn and evolve in complex environments, this result constitutes the first demonstration of a long-conjectured morphological Baldwin effect. Third, our experiments suggest a mechanistic basis for both the Baldwin effect and the emergence of morphological intelligence through the evolution of morphologies that are more physically stable and energy efficient, and can therefore facilitate learning and control.},
archivePrefix = {arXiv},
arxivId = {2102.02202},
author = {Gupta, Agrim and Savarese, Silvio and Ganguli, Surya and Fei-Fei, Li},
eprint = {2102.02202},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gupta et al. - 2021 - Embodied Intelligence via Learning and Evolution.pdf:pdf},
keywords = {embodied intelligence,reinforcement learning,robotics},
mendeley-tags = {embodied intelligence,reinforcement learning,robotics},
pages = {1--18},
title = {{Embodied Intelligence via Learning and Evolution}},
url = {http://arxiv.org/abs/2102.02202},
volume = {4},
year = {2021}
}
@article{Ning2017,
abstract = {In this paper, in view of the research achievements of domestic and
oversea researchers, the energy-saving manipulation strategies are
designed for the train operation between stations by using the genetic
algorithm, which synthesize the knowledge of train traction calculation
and the characteristic of locomotive traction and braking. The
energy-saving control strategy is based on the train maximum
acceleration traction control, and timely changing into coasting when
reaching the speed limited point in order to make full use of the
kinetic energy of a train and reducing the unnecessary braking between
stations. In general, the energy saving running status sequence is
composed with four parts which are called accelerating and holding and
coasting as well as decelerating. After the determination of control
strategy, in this paper, some different distances and different
gradients as well as speed limits of the station are considered, the
configuration laws are concluded for the coasting times with the
distance of the station and the gradient.},
author = {Ning, Jingjie and Long, Fengchu},
doi = {10.1109/IAEAC.2017.8054428},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ning, Long - 2017 - Studies on the optimization of train using improved genetic algorithm.pdf:pdf},
isbn = {9781467389778},
journal = {Proceedings of 2017 IEEE 2nd Advanced Information Technology, Electronic and Automation Control Conference, IAEAC 2017},
keywords = {Coasting time,Energy saving,Genetic algorithm,Operation strategy},
pages = {2287--2291},
title = {{Studies on the optimization of train using improved genetic algorithm}},
year = {2017}
}
@article{Dincer2008,
abstract = {This paper discusses some crucial energetic, environmental and sustainability issues and the role of hydrogen and fuel celltechnologies as one of the potential solutions to these issues. The commercialization plans in various industrialized countries (USA, Canada, Japan, etc.) for these technologies have started by identifying the most likely early markets for hydrogen as an energy carrier and fuel cells as power producing devices from micro- to macro-applications, and set realistic near-term and mid-term goals for selected market penetration. The plans outline the major barriers to achieving those goals and recommends activities to capitalize on the incentives and overcome the market barriers. The paper also presents possible future hydrogen energy-utilization patterns for better environment and sustainable development, and shows how the principles of thermodynamics via energy can be beneficially used to evaluate hydrogen and fuel cell systems and their role in sustainability. Throughout the paper, current and future perspectives regarding thermodynamics and sustainable development are considered.},
author = {Dincer, Ibrahim},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dincer - 2008 - Hydrogen and Fuel Cell Technologies for Sustainable Future.pdf:pdf},
issn = {19956665},
journal = {Jordan Journal of Mechanical and Industrial Engineering},
keywords = {economics,energy,environment,exergy,fuel cell,hydrogen,life cycle assessment,sustainable development},
number = {1},
pages = {1--14},
title = {{Hydrogen and Fuel Cell Technologies for Sustainable Future}},
url = {http://www.doaj.org/doaj?func=openurl&issn=19956665&date=2008&volume=2&issue=1&spage=1&genre=article},
volume = {2},
year = {2008}
}
@article{Author2020,
author = {Author, Anonymous and Address, Affiliation},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Author, Address - 2020 - Meta-Learning Backpropagation And Improving It.pdf:pdf},
keywords = {backpropagation,meta-learning},
mendeley-tags = {backpropagation,meta-learning},
title = {{Meta-Learning Backpropagation And Improving It}},
url = {http://louiskirsch.com/assets/publications/vsml.pdf},
year = {2020}
}
@article{Wu2020,
abstract = {We present a new loss function called Distribution-Balanced Loss for the multi-label recognition problems that exhibit long-tailed class distributions. Compared to conventional single-label classification problem, multi-label recognition problems are often more challenging due to two significant issues, namely the co-occurrence of labels and the dominance of negative labels (when treated as multiple binary classification problems). The Distribution-Balanced Loss tackles these issues through two key modifications to the standard binary cross-entropy loss: 1) a new way to re-balance the weights that takes into account the impact caused by label co-occurrence, and 2) a negative tolerant regularization to mitigate the over-suppression of negative labels. Experiments on both Pascal VOC and COCO show that the models trained with this new loss function achieve significant performance gains over existing methods. Code and models are available at: https://github.com/wutong16/DistributionBalancedLoss .},
archivePrefix = {arXiv},
arxivId = {2007.09654},
author = {Wu, Tong and Huang, Qingqiu and Liu, Ziwei and Wang, Yu and Lin, Dahua},
doi = {10.1007/978-3-030-58548-8_10},
eprint = {2007.09654},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu et al. - 2020 - Distribution-Balanced Loss for Multi-label Classification in Long-Tailed Datasets.pdf:pdf},
keywords = {distribution-,long-tailed data,multi-label classification},
pages = {162--178},
title = {{Distribution-Balanced Loss for Multi-label Classification in Long-Tailed Datasets}},
year = {2020}
}
@article{Seth2020,
abstract = {The theories of consciousness discussed by Doerig and colleagues tend to monolithically identify consciousness with some other phenomenon, process, or mechanism. But by treating consciousness as singular explanatory target, such theories will struggle to account for the diverse properties that conscious experiences exhibit. We propose that progress in consciousness science will best be achieved by elaborating systematic mappings between physical and biological mechanisms, and the functional and (crucially) phenomenological properties of consciousness. This means we need theories for consciousness science, perhaps more so than theories of consciousness. From this perspective, ‘predictive processing' emerges as a highly promising candidate.},
author = {Seth, Anil K. and Hohwy, Jakob},
doi = {10.1080/17588928.2020.1838467},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Seth, Hohwy - 2020 - Predictive processing as an empirical theory for consciousness science.pdf:pdf},
issn = {17588936},
journal = {Cognitive Neuroscience},
keywords = {Predictive processing,explanatory correlate,neural correlates of consciousness},
number = {00},
pages = {1--2},
publisher = {Routledge},
title = {{Predictive processing as an empirical theory for consciousness science}},
url = {https://doi.org/10.1080/17588928.2020.1838467},
volume = {00},
year = {2020}
}
@article{Marchi2012,
abstract = {This article examines the news behaviors and attitudes of teenagers, an understudied demographic in the research on youth and news media. Based on interviews with 61 racially diverse high school students, it discusses how adolescents become informed about current events and why they prefer certain news formats to others. The results reveal changing ways news information is being accessed, new attitudes about what it means to be informed, and a youth preference for opinionated rather than objective news. This does not indicate that young people disregard the basic ideals of professional journalism but, rather, that they desire more authentic renderings of them.},
author = {Marchi, Regina},
doi = {10.1177/0196859912458700},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Marchi - 2012 - With Facebook, blogs, and fake news, teens reject journalistic objectivity.pdf:pdf},
isbn = {0196-8599},
issn = {01968599},
journal = {Journal of Communication Inquiry},
keywords = {Facebook,civic engagement,fake news,objectivity,youth and news},
number = {3},
pages = {246--262},
title = {{With Facebook, blogs, and fake news, teens reject journalistic "objectivity"}},
volume = {36},
year = {2012}
}
@article{Charpentier2016,
abstract = {Intuitively, how we feel about potential outcomes will determine our decisions. Indeed, one of the most influential theories in psychology, Prospect Theory, implicitly assumes that feelings govern choice. Surprisingly, however, we know very little about the rules by which feelings are transformed into decisions. Here, we characterize a computational model that uses feelings to predict choice. We reveal that this model predicts choice better than existing value-based models, showing a unique contribution of feelings to decisions, over and above value. Similar to Prospect Theory value function, feelings showed diminished sensitivity to outcomes as value increased. However, loss aversion in choice was explained by an asymmetry in how feelings about losses and gains were weighed when making a decision, not by an asymmetry in the feelings themselves. The results provide new insights into how feelings are utilized to reach a decision.},
author = {Charpentier, Caroline J. and {De Neve}, Jan Emmanuel and Li, Xinyi and Roiser, Jonathan P. and Sharot, Tali},
doi = {10.1177/0956797616634654},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Charpentier et al. - 2016 - Models of Affective Decision Making How Do Feelings Predict Choice.pdf:pdf},
isbn = {1467-9280 (Electronic)\r0956-7976 (Linking)},
issn = {14679280},
journal = {Psychological Science},
keywords = {decision making,feelings,prospect theory,subjective well-being,utility,value},
number = {6},
pages = {763--775},
pmid = {27071751},
title = {{Models of Affective Decision Making: How Do Feelings Predict Choice?}},
volume = {27},
year = {2016}
}
@article{Chen2020i,
abstract = {Deep learning models are increasingly popular in many machine learning applications where the training data may contain sensitive information. To provide formal and rigorous privacy guarantee, many learning systems now incorporate differential privacy by training their models with (differentially) private SGD. A key step in each private SGD update is gradient clipping that shrinks the gradient of an individual example whenever its `2 norm exceeds some threshold. We first demonstrate how gradient clipping can prevent SGD from converging to stationary point. We then provide a theoretical analysis that fully quantifies the clipping bias on convergence with a disparity measure between the gradient distribution and a geometrically symmetric distribution. Our empirical evaluation further suggests that the gradient distributions along the trajectory of private SGD indeed exhibit symmetric structure that favors convergence. Together, our results provide an explanation why private SGD with gradient clipping remains effective in practice despite its potential clipping bias. Finally, we develop a new perturbation-based technique that can provably correct the clipping bias even for instances with highly asymmetric gradient distributions.},
archivePrefix = {arXiv},
arxivId = {2006.15429},
author = {Chen, Xiangyi and Wu, Zhiwei Steven and Hong, Mingyi},
eprint = {2006.15429},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Wu, Hong - 2020 - Understanding gradient clipping in private SGD A geometric perspective.pdf:pdf;:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Wu, Hong - 2020 - Understanding gradient clipping in private SGD A geometric perspective(2).pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
pages = {1--3},
title = {{Understanding gradient clipping in private SGD: A geometric perspective}},
volume = {20},
year = {2020}
}
@article{Zihrul2017,
abstract = {Hydrogen bleeding into the cathode inlet of a proton exchange membrane (PEM) fuel cell could be a simple approach to reduce the H 2 concentration in the fuel cell exhaust during transient operating conditions (e.g., start-up or fast transients) of a PEM fuel cell system; it could also serve as an additional heating source during cold start-up. In this experimental study, we address the question whether the chemical stability of the polymer electrolyte membrane is affected negatively by a hydrogen bleed into the cathode inlet of a PEM fuel cell. First, rotating ring disc electrode (RRDE) experiments were carried out to detect whether any additional H 2 O 2 is produced during the oxygen reduction reaction in O 2 saturated electrolytes in the absence and presence of H 2 . Dry open circuit voltage (OCV) experiments were then performed for more than 250 hours in 50 cm 2 single cells at 120 • C and 18% relative humidity (RH) in order to investigate the effect of a 4 vol. % H 2 -bleed into the cathode inlet on membrane stability. Finally, the distribution of membrane pin-holes was determined on membrane electrode assemblies (MEAs) after the dry OCV tests conducted with or without H 2 -bleed using an infrared (IR) camera setup. In addition, the diffusion-limited hydrogen oxidation current on the cathode side was modeled in order to estimate the maximum areal heat flux near the cathode inlet, which would be caused if the H 2 oxidation rate were to be diffusion-limited.},
author = {Zihrul, Patrick and Weber, Philipp and Durst, Julien and Gasteiger, Hubert A. and Hasch{\'{e}}, Fr{\'{e}}d{\'{e}}ric},
doi = {10.1149/2.0161704jes},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zihrul et al. - 2017 - Impact of Hydrogen Bleeding into the Cathode Feed of a PEM Fuel Cell.pdf:pdf},
issn = {0013-4651},
journal = {Journal of The Electrochemical Society},
number = {4},
pages = {F209--F216},
title = {{Impact of Hydrogen Bleeding into the Cathode Feed of a PEM Fuel Cell}},
url = {http://jes.ecsdl.org/lookup/doi/10.1149/2.0161704jes},
volume = {164},
year = {2017}
}
@article{R1997,
author = {R, S{\o} Ren Halkj{\ae} and Winther, Ole},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/R, Winther - 1997 - The Effect of Correlated Input Data on the Dynamics of Learning.pdf:pdf},
journal = {Advances in Neural Information Processing Systems 9},
pages = {169--175},
title = {{The Effect of Correlated Input Data on the Dynamics of Learning}},
url = {http://papers.nips.cc/paper/1254-the-effect-of-correlated-input-data-on-the-dynamics-of-learning.pdf%5Cnfiles/974/r ? Winther - 1997 - The Effect of Correlated Input Data on the Dynamic.pdf%5Cnfiles/975/1254-the-effect-of-correlated-input-data-on-the-dyna},
year = {1997}
}
@inproceedings{Hetherington1989,
author = {Hetherington, P.A. and Seidenberg, M.S.},
booktitle = {Proceedings of the 11th annual conference of the cognitive science society},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hetherington, Seidenberg - 1989 - Is there “catastrophic interference” in connectionist networks.pdf:pdf},
keywords = {catastrophic forgetting,continual learning,neuroscience},
mendeley-tags = {catastrophic forgetting,continual learning,neuroscience},
pages = {33},
title = {{Is there “catastrophic interference” in connectionist networks}},
url = {http://scholar.google.com/scholar?q=related:6OvJaVLsTzwJ:scholar.google.com/&hl=en&as_sdt=0,10#3},
volume = {26},
year = {1989}
}
@article{He2021,
abstract = {Catastrophic forgetting means that a trained neural network model gradually forgets the previously learned tasks when retrained on new tasks. Overcoming the forgetting problem is a major problem in machine learning. Numerous continual learning algorithms are very successful in incremental classification tasks, where new labels appear frequently. However, there is currently no research that addresses the catastrophic forgetting problem in regression tasks as far as we know. This problem has emerged as one of the primary constraints in some applications, such as renewable energy forecasts. This article clarifies the problem-related definitions and proposes a new methodological framework that can forecast regression task targets and update itself by continual learning. The framework consists of forecasting neural networks and buffers, which store newly collected data from a data stream in an application. Changes in the probability distribution of the data stream will be identified by the framework and learned sequentially. The framework is called CLeaR (Continual Learning for Regression Tasks), where components can be flexibly customized for a specific application scenario. We design two sets of experiments to evaluate the CLeaR framework concerning fitting error (training), prediction error (test), and forgetting ratio. The first one is based on an artificial time series to explore how hyperparameters affect the CLeaR framework. The second one is designed with data collected from European wind farms to evaluate the performance of the CLeaR framework in a real-world application. The experimental results demonstrate that the CLeaR framework can efficiently accumulate knowledge in the data stream and improve the prediction accuracy. The article concludes with further research issues arising from requirements to extend the framework.},
archivePrefix = {arXiv},
arxivId = {2101.00926},
author = {He, Yujiang and Sick, Bernhard},
eprint = {2101.00926},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/He, Sick - 2021 - CLeaR An Adaptive Continual Learning Framework for Regression Tasks.pdf:pdf},
keywords = {continual learning,deep neural networks,regression,regression tasks,renewable energy forecasts},
mendeley-tags = {continual learning,regression},
number = {1},
pages = {1--13},
title = {{CLeaR: An Adaptive Continual Learning Framework for Regression Tasks}},
url = {http://arxiv.org/abs/2101.00926},
year = {2021}
}
@article{Seff2017,
abstract = {Developments in deep generative models have allowed for tractable learning of high-dimensional data distributions. While the employed learning procedures typically assume that training data is drawn i.i.d. from the distribution of interest, it may be desirable to model distinct distributions which are observed sequentially, such as when different classes are encountered over time. Although conditional variations of deep generative models permit multiple distributions to be modeled by a single network in a disentangled fashion, they are susceptible to catastrophic forgetting when the distributions are encountered sequentially. In this paper, we adapt recent work in reducing catastrophic forgetting to the task of training generative adversarial networks on a sequence of distinct distributions, enabling continual generative modeling.},
archivePrefix = {arXiv},
arxivId = {1705.08395},
author = {Seff, Ari and Beatson, Alex and Suo, Daniel and Liu, Han},
eprint = {1705.08395},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Seff et al. - 2017 - Continual learning in generative adversarial nets.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {continual learning,gan,generative model,image generation,incremental learning},
mendeley-tags = {continual learning,gan,generative model,image generation,incremental learning},
pages = {1--9},
title = {{Continual learning in generative adversarial nets}},
year = {2017}
}
@article{Easton,
abstract = {Source 5.1 Tpt﻿ RMS Titanic ah hpt﻿ l––kh e–aud y r﻿hepiong –ion ept﻿ –c﻿aion fl––r alm–he 4 kpl–m﻿er﻿h fr–m ept﻿ hsrfac﻿ 5 5.3 Wptae w﻿r﻿ ept﻿ hpt–re-aion﻿ l–iong-e﻿rm pmdaceh –f ept﻿ Iion﻿sherpal R﻿v–lsep–ion? 1 Iion﻿sherpalphaep–ion pta﻿ maionud pmdaceh –ion h–cp﻿eud aion﻿ ept﻿ ﻿ionvpr–ionm﻿ione. Iion daprh –r hmall gr–sdh, brapionhe–rm ah maionud cptaiong﻿h ah ud–s caion eptae w﻿r﻿ br–sgpte ab–se bud ept﻿ Iion﻿sherpal R﻿v–lsep–ion y b–ept pion ept﻿ hpt–re-e﻿rm aion﻿ l–iong-e﻿rm.},
author = {Easton, Mark and Carrouds, Geraldine and Delaney, Tim and McArthur, Kate and Smith, Richard},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Easton et al. - Unknown - Chapter 5 The Industrial Revolution.pdf:pdf},
isbn = {0195522168},
journal = {Oxford Big Ideas Geography/History 9: Australian Curriculum},
pages = {269--313},
title = {{Chapter 5: The Industrial Revolution}},
url = {https://www.oup.com.au/__data/assets/pdf_file/0021/58071/Oxford-Big-Ideas-Geography-History-9-ch5-Industrial-revolution.pdf%0Ahttps://www.oup.com.au/__data/assets/pdf_file/0017/58031/Oxford-Big-Ideas-Geography-History-9-ch5-Industrial-revolution.pdf}
}
@article{Silver2016,
abstract = {The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses 'value networks' to evaluate board positions and 'policy networks' to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.},
author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and {Van Den Driessche}, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
doi = {10.1038/nature16961},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Silver et al. - 2016 - Mastering the game of Go with deep neural networks and tree search.pdf:pdf},
issn = {14764687},
journal = {Nature},
number = {7587},
pages = {484--489},
pmid = {26819042},
publisher = {Nature Publishing Group},
title = {{Mastering the game of Go with deep neural networks and tree search}},
url = {http://dx.doi.org/10.1038/nature16961},
volume = {529},
year = {2016}
}
@article{Dong2018,
author = {Dong, Xuefan and Lian, Ying and Liu, Yijun},
doi = {10.1016/j.ins.2017.09.067},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dong, Lian, Liu - 2018 - Small and multi-peak nonlinear time series forecasting using a hybrid back propagation neural network.pdf:pdf},
keywords = {Public opinion,Nonlinear time series forecasting,B},
pages = {39--54},
publisher = {Elsevier Inc.},
title = {{Small and multi-peak nonlinear time series forecasting using a hybrid back propagation neural network}},
volume = {424},
year = {2018}
}
@article{Gan2019,
archivePrefix = {arXiv},
arxivId = {arXiv:1904.12584v1},
author = {Gan, Chuang and Kohli, Pushmeet},
eprint = {arXiv:1904.12584v1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gan, Kohli - 2019 - THE NEURO-SYMBOLIC CONCEPT LEARNER INTERPRETING SCENES, WORDS, AND SENTENCES FROM NATURAL SUPERVISION.pdf:pdf},
pages = {1--28},
title = {{THE NEURO-SYMBOLIC CONCEPT LEARNER: INTERPRETING SCENES, WORDS, AND SENTENCES FROM NATURAL SUPERVISION}},
year = {2019}
}
@article{Tedjojuwono2017,
abstract = {Any method of counting objects and vehicles using computerized systems in a real live environment needs to have reliable results and flexibility of operation. The proposed work describes a method of counting moving objects and vehicles within a live or recorded video stream using multiple virtual line sensors that give flexibility to the users in analyzing any location for the number of vehicles within the given video, as existing traffic surveillance cameras may be sited in many positions/angles. The proposed research is an improved object counter. The results of this method have shown a promising accuracy of close to 100% detection in daylight and 91% at night.},
author = {Tedjojuwono, Samuel Mahatmaputra},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tedjojuwono - 2017 - Virtual lines sensors for moving object and vehicle counters.pdf:pdf},
issn = {18199224},
journal = {IAENG International Journal of Computer Science},
keywords = {Computer vision,Object and vehicle counters,Video analytics,Virtual sensors},
number = {4},
pages = {421--431},
title = {{Virtual lines sensors for moving object and vehicle counters}},
volume = {44},
year = {2017}
}
@article{Prauzek2015,
abstract = {The importance of renewable energy is increasing rapidly nowadays. Solar energy is one of the most powerful resources that can be used to provide power supply for remote electrical devices. Such remote devices often need batteries replacements and maintenance that raises ex-penses. This contribution describes energy management and power harvesting implementation in a low-power microcontroller integrated within an autonomous solar-powered device with super-capacitor that significantly reduces maintenance needs. The energy management implements a fuzzy logic-based system that allows it to adapt to ambient temperature and sunlight intensity in deployment location. Fuzzy energy management sets device's functional mode that affects the measurement rate of the weather station and subsequent storage rate in SD Card. Both simulation results and real data results obtained in a laboratory located in Ostrava, Czech Republic, are presented in this contribution.},
author = {Prauzek, Michal and Konecny, Jaromir and Hamel, Alan and Hlavica, Jakub},
doi = {10.1016/j.ifacol.2015.07.037},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Prauzek et al. - 2015 - Fuzzy energy management of autonomous weather station.pdf:pdf},
isbn = {2405-8963},
issn = {24058963},
journal = {IFAC-PapersOnLine},
keywords = {Energy management,Fuzzy logic control,Solar energy,Temperature measurement},
number = {4},
pages = {226--229},
publisher = {Elsevier Ltd.},
title = {{Fuzzy energy management of autonomous weather station}},
url = {http://dx.doi.org/10.1016/j.ifacol.2015.07.037},
volume = {28},
year = {2015}
}
@article{Liu2020e,
archivePrefix = {arXiv},
arxivId = {arXiv:2010.05063v2},
author = {Liu, Yaoyao and Schiele, Bernt and Sun, Qianru},
eprint = {arXiv:2010.05063v2},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu, Schiele, Sun - 2020 - Meta-Aggregation Networks for Class-Incremental Learning.pdf:pdf},
keywords = {continual learning,incremental learning,knowledge distillation},
mendeley-tags = {continual learning,incremental learning,knowledge distillation},
number = {ii},
title = {{Meta-Aggregation Networks for Class-Incremental Learning}},
url = {https://github.com/yaoyao-liu/class-incremental-learning/tree/main/meta-aggregation-networks},
year = {2020}
}
@article{Kar2015,
abstract = {We consider the problem of enriching current object detection systems with veridical object sizes and relative depth estimates from a single image. There are several technical challenges to this, such as occlusions, lack of calibration data and the scale ambiguity between object size and distance. These have not been addressed in full generality in previous work. Here we propose to tackle these issues by building upon advances in object recognition and using recently created large-scale datasets. We first introduce the task of amodal bounding box completion, which aims to infer the the full extent of the object instances in the image. We then propose a probabilistic framework for learning category-specific object size distributions from available annotations and leverage these in conjunction with amodal completions to infer veridical sizes of objects in novel images. Finally, we introduce a focal length prediction approach that exploits scene recognition to overcome inherent scale ambiguities and demonstrate qualitative results on challenging real-world scenes.},
archivePrefix = {arXiv},
arxivId = {1509.08147},
author = {Kar, Abhishek and Tulsiani, Shubham and Carreira, Joao and Malik, Jitendra},
doi = {10.1109/ICCV.2015.23},
eprint = {1509.08147},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kar et al. - 2015 - Amodal completion and size constancy in natural scenes.pdf:pdf},
isbn = {9781467383912},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {127--135},
title = {{Amodal completion and size constancy in natural scenes}},
volume = {2015 Inter},
year = {2015}
}
@article{Hull1995a,
abstract = {Abstract People recreating outdoors (at an urban, park) and people recreating indoors (in their homes) assessed their moods at the start, middle, and end of their brief (less than 2?hr) leisure experiences. Moods changed slightly but significantly, and some of these changes were consistent with predictions that leisure reduces stress. Contrary to expectations, recreating near nature produced no more restoration than did recreating indoors, away from nature.\nAbstract People recreating outdoors (at an urban, park) and people recreating indoors (in their homes) assessed their moods at the start, middle, and end of their brief (less than 2?hr) leisure experiences. Moods changed slightly but significantly, and some of these changes were consistent with predictions that leisure reduces stress. Contrary to expectations, recreating near nature produced no more restoration than did recreating indoors, away from nature.},
author = {Hull, R. B. and Michael, Sean E.},
doi = {10.1080/01490409509513239},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hull, Michael - 1995 - Nature‐based Recreation, mood change, and stress restoration.pdf:pdf},
isbn = {1521-0588, Electronic\r0149-0400, Print},
issn = {15210588},
journal = {Leisure Sciences},
keywords = {Arousal,Benefit,Emotion,Experience,Mood regulation,Recreation,Stress},
number = {1},
pages = {1--14},
title = {{Nature‐based Recreation, mood change, and stress restoration}},
volume = {17},
year = {1995}
}
@article{Rosasco2021a,
abstract = {Replay strategies are Continual Learning techniques which mitigate catastrophic forgetting by keeping a buffer of patterns from previous experience, which are interleaved with new data during training. The amount of patterns stored in the buffer is a critical parameter which largely influences the final performance and the memory footprint of the approach. This work introduces Distilled Replay, a novel replay strategy for Continual Learning which is able to mitigate forgetting by keeping a very small buffer (up to $1$ pattern per class) of highly informative samples. Distilled Replay builds the buffer through a distillation process which compresses a large dataset into a tiny set of informative examples. We show the effectiveness of our Distilled Replay against naive replay, which randomly samples patterns from the dataset, on four popular Continual Learning benchmarks.},
archivePrefix = {arXiv},
arxivId = {2103.15851},
author = {Rosasco, Andrea and Carta, Antonio and Cossu, Andrea and Lomonaco, Vincenzo and Bacciu, Davide},
eprint = {2103.15851},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rosasco et al. - 2021 - Distilled Replay Overcoming Forgetting through Synthetic Samples(2).pdf:pdf},
keywords = {continual learning},
mendeley-tags = {continual learning},
title = {{Distilled Replay: Overcoming Forgetting through Synthetic Samples}},
year = {2021}
}
@article{Carvalho2017a,
abstract = {In this paper, we propose a fuzzy forecasting methodology of time series, which is tested on two series: the price of electricity in New South Wales, Australia; and on the futures market index of Taiwan. The method uses a triangular membership function in a fuzzification process, including an $\alpha$-cut, and applies the extended autocorrelation function. The identification algorithm enables optimization of the number of fuzzy sets to be used, to determine the optimal order for the fuzzy prediction model and estimate its parameters with greater accuracy. The fuzzy prediction models of time series found in the scientific literature are compared using mainly trivalent membership functions (0, 0.5 and 1 as membership values), and the proposed method shows more accurate results.},
author = {Carvalho, J. G. and Costa, C. T.},
doi = {10.1016/j.asoc.2016.11.003},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Carvalho, Costa - 2017 - Identification method for fuzzy forecasting models of time series.pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {Autoregressive seasonal fuzzy model,Electrical energy price,Futures market index,Fuzzy prediction,$\alpha$-cut},
pages = {166--182},
publisher = {Elsevier B.V.},
title = {{Identification method for fuzzy forecasting models of time series}},
url = {http://dx.doi.org/10.1016/j.asoc.2016.11.003},
volume = {50},
year = {2017}
}
@article{Kuzniar2015,
abstract = {Two techniques of data pre-processing for neural networks are considered in this paper: (i) data compression with the application of the principal component analysis method, and (ii) various forms of data scaling. The novelty of this paper is associated with compressed input data scaling by the rotation (by the "stretching") in neural network. This approach can be treated as the new proposition for data pre-processing techniques. The influence of various types of input data pre-processing on the accuracy of neural network results is discussed by using numerical examples for the cases of natural frequency predictions of horizontal vibrations of load-bearing walls. It is concluded that a significant reduction in the neural network prediction errors is possible by conducting the appropriate input data transformation.},
author = {Ku{\'{z}}niar, Krystyna and Zaj{\c{a}}c, Maciej},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ku{\'{z}}niar, Zaj{\c{a}}c - 2015 - Some methods of pre-processing input data for neural networks.pdf:pdf},
journal = {Computer Assisted Methods in Engineering and Science},
keywords = {data,data pre-processing,input data,neural networks,principal component analysis method},
pages = {141--151},
title = {{Some methods of pre-processing input data for neural networks}},
url = {http://cames.ippt.gov.pl/index.php/cames/article/view/33},
volume = {22},
year = {2015}
}
@book{Walker1983,
address = {Cambridge},
author = {Walker, J.M. and Gingold, E.B},
publisher = {The Royal Society of Chemistry},
title = {{Molecular Biology and Biotechnology third edition}},
year = {1983}
}
@article{Hasani2020,
abstract = {We introduce a new class of time-continuous recurrent neural network models. Instead of declaring the nonlinearity of a learning system by neurons, we impose specialized nonlinearities on the network connections. The obtained models realize dynamical systems with varying (i.e., liquid) time-constants coupled to their hidden state, and outputs being computed by numerical differential equation solvers. These neural networks exhibit stable and bounded behavior, yield superior expressivity within the family of neural ordinary differential equations, and give rise to improved performance on time-series prediction tasks. To demonstrate these properties, we first take a theoretical approach to find bounds over their dynamics, and compute their expressive power by the trajectory length measure in a latent trajectory representation space. We then conduct a series of time-series prediction experiments to manifest the approximation capability of Liquid Time-Constant Networks (LTCs) compared to classical and modern RNNs.1},
archivePrefix = {arXiv},
arxivId = {2006.04439},
author = {Hasani, Ramin and Lechner, Mathias and Amini, Alexander and Rus, Daniela and Grosu, Radu},
eprint = {2006.04439},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hasani et al. - 2020 - Liquid Time-Constant Networks.pdf:pdf},
journal = {arXiv},
keywords = {time series},
mendeley-tags = {time series},
title = {{Liquid Time-Constant Networks}},
url = {https://arxiv.org/pdf/2006.04439v4.pdf https://github.com/raminmh/liquid_time_constant_networks https://github.com/mlech26l/keras-ncp},
year = {2020}
}
@article{Huang2015a,
abstract = {We demonstrate the first all-fiber mode-group-selective photonic lantern using multimode graded-index fibers. Mode selectivity for mode groups LP(01), LP(11) and LP(21)+LP(02) is 20-dB, 10-dB and 7-dB respectively. The insertion loss when butt coupled to multimode graded-index fiber is below 0.6-dB. The use of the multimode graded-index fibers in the taper can significantly reduce the adiabaticity requirement.},
author = {Huang, Bin and Fontaine, Nicolas K. and Ryf, Roland and Guan, Binbin and Leon-Saval, Sergio G. and Shubochkin, R. and Sun, Y. and Lingle, R. and Li, Guifang},
doi = {10.1364/OE.23.000224},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang et al. - 2015 - All-fiber mode-group-selective photonic lantern using graded-index multimode fibers.pdf:pdf},
isbn = {doi:10.1364/OE.23.000224},
issn = {1094-4087},
journal = {Optics Express},
number = {1},
pages = {224},
pmid = {25835669},
title = {{All-fiber mode-group-selective photonic lantern using graded-index multimode fibers}},
url = {https://www.osapublishing.org/abstract.cfm?URI=oe-23-1-224},
volume = {23},
year = {2015}
}
@article{Liu2015c,
abstract = {Deep neural networks have achieved remarkable performance in both image classification and object detection problems, at the cost of a large number of parameters and computational complexity. In this work, we show how to reduce the redundancy in these parameters using a sparse decomposition. Maximum sparsity is obtained by exploiting both inter-channel and intra-channel redundancy, with a fine-tuning step that minimize the recognition loss caused by maximizing sparsity. This procedure zeros out more than 90% of parameters, with a drop of accuracy that is less than 1% on the ILSVRC2012 dataset. We also propose an efficient sparse matrix multiplication algorithm on CPU for Sparse Convolutional Neural Networks (SCNN) models. Our CPU implementation demonstrates much higher efficiency than the off-the-shelf sparse matrix libraries, with a significant speedup realized over the original dense network. In addition, we apply the SCNN model to the object detection problem, in conjunction with a cascade model and sparse fully connected layers, to achieve significant speedups.},
archivePrefix = {arXiv},
arxivId = {1505.02890},
author = {Liu, Baoyuan and Wang, Min and Foroosh, Hassan and Tappen, Marshall and Penksy, Marianna},
doi = {10.1109/CVPR.2015.7298681},
eprint = {1505.02890},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2015 - Sparse Convolutional Neural Networks.pdf:pdf},
isbn = {9781467369640},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {806--814},
title = {{Sparse Convolutional Neural Networks}},
volume = {07-12-June},
year = {2015}
}
@article{Chen2020j,
abstract = {Different from the traditional classification tasks which assume mutual exclusion of labels, hierarchical multi-label classification (HMLC) aims to assign multiple labels to every instance with the labels organized under hierarchical relations. Besides the labels, since linguistic ontologies are intrinsic hierarchies, the conceptual relations between words can also form hierarchical structures. Thus it can be a challenge to learn mappings from word hierarchies to label hierarchies. We propose to model the word and label hierarchies by embedding them jointly in the hyperbolic space. The main reason is that the tree-likeness of the hyperbolic space matches the complexity of symbolic data with hierarchical structures. A new Hyperbolic Interaction Model (HyperIM) is designed to learn the label-aware document representations and make predictions for HMLC. Extensive experiments are conducted on three benchmark datasets. The results have demonstrated that the new model can realistically capture the complex data structures and further improve the performance for HMLC comparing with the state-of-the-art methods. To facilitate future research, our code is publicly available.},
archivePrefix = {arXiv},
arxivId = {1905.10802},
author = {Chen, Boli and Huang, Xin and Xiao, Lin and Cai, Zixin and Jing, Liping},
doi = {10.1609/aaai.v34i05.6247},
eprint = {1905.10802},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2020 - Hyperbolic Interaction Model for Hierarchical Multi-Label Classification.pdf:pdf},
issn = {2374-3468},
journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
keywords = {Natural Language Processing},
month = {apr},
number = {05},
pages = {7496--7503},
title = {{Hyperbolic Interaction Model for Hierarchical Multi-Label Classification}},
url = {https://aaai.org/ojs/index.php/AAAI/article/view/6247},
volume = {34},
year = {2020}
}
@article{For2020,
abstract = {Large Transformer models routinely achieve state-of-the-art results on a number of tasks but training these models can be prohibitively costly, especially on long sequences. We introduce two techniques to improve the efficiency of Transformers. For one, we replace dot-product attention by one that uses locality-sensitive hashing, changing its complexity from O(L 2) to O(L log L), where L is the length of the sequence. Furthermore, we use reversible residual layers instead of the standard residuals, which allows storing activations only once in the training process instead of N times, where N is the number of layers. The resulting model, the Reformer, performs on par with Transformer models while being much more memory-efficient and much faster on long sequences.},
author = {For, Ransformer},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/For - 2020 - E Fficient T Ransformer.pdf:pdf},
number = {2018},
pages = {1--10},
title = {{E Fficient T Ransformer}},
url = {https://hackingsemantics.xyz/2019/leaderboards/ https://github.com/google/trax/tree/master/trax/models/reformer},
year = {2020}
}
@book{ARUNACHALAM2008,
author = {ARUNACHALAM, V},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/ARUNACHALAM - 2008 - THE UNIVERSITY OF WESTERN ONTARIO Water Resources Research Report.pdf:pdf},
isbn = {9780771426896},
number = {July},
title = {{THE UNIVERSITY OF WESTERN ONTARIO Water Resources Research Report}},
year = {2008}
}
@article{Xu2016,
abstract = {<p>This paper summarizes the recent progress in mesoporous materials as electrocatalysts for applications in polymer electrolyte membrane fuel cells.</p>},
author = {Xu, Wei and Wu, Zucheng and Tao, Shanwen},
doi = {10.1039/c6ta05304a},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu, Wu, Tao - 2016 - Recent progress in electrocatalysts with mesoporous structures for application in polymer electrolyte membrane fuel.pdf:pdf},
issn = {20507496},
journal = {Journal of Materials Chemistry A},
number = {42},
pages = {16272--16287},
publisher = {Royal Society of Chemistry},
title = {{Recent progress in electrocatalysts with mesoporous structures for application in polymer electrolyte membrane fuel cells}},
url = {http://dx.doi.org/10.1039/C6TA05304A},
volume = {4},
year = {2016}
}
@article{Xie2019b,
abstract = {There are two challenging problems in applying standard Deep Neural Networks (DNNs) for incremental learning with a few examples: (i) DNNs do not perform well when little training data is available; (ii) DNNs suffer from catastrophic forgetting when used for incremental class learning. To simultaneously address both problems, we propose Meta Module Generation (MetaMG), a meta-learning method that enables a module generator to rapidly generate a category module from a few examples for a scalable classification network to recognize a new category. The old categories are not forgotten after new categories are added in. Comprehensive experiments conducted on 4 datasets show that our method is promising for fast incremental learning in few-shot setting. Further experiments on the miniImageNet dataset show that even it is not specially designed for the N-wayK-shot learning problem, MetaMG can sitll perform relatively well especially for 20-way K-shot setting.},
author = {Xie, Shudong and Li, Yiqun and Lin, Dongyun and Nwe, Tin Lay and Dong, Sheng},
doi = {10.1109/ICCVW.2019.00174},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xie et al. - 2019 - Meta module generation for fast few-shot incremental learning.pdf:pdf},
isbn = {9781728150239},
journal = {Proceedings - 2019 International Conference on Computer Vision Workshop, ICCVW 2019},
keywords = {Few shot learning,Image classification,Incremental learning,Meta learning,continual learning,few-shot learning,incremental learning},
mendeley-tags = {continual learning,few-shot learning,incremental learning},
pages = {1381--1390},
title = {{Meta module generation for fast few-shot incremental learning}},
year = {2019}
}
@article{Navianti2012a,
author = {Navianti, Dynes Rizky and Widjajati, Farida Agustini and Ngurah, I Gusti and Usadha, Rai and Meteorologi, A Dasar},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Navianti et al. - 2012 - Penerapan Fuzzy Inference System pada Prediksi Curah Hujan di Surabaya Utara(2).pdf:pdf},
number = {1},
pages = {1--6},
title = {{Penerapan Fuzzy Inference System pada Prediksi Curah Hujan di Surabaya Utara}},
volume = {1},
year = {2012}
}
@article{Cohen2017,
abstract = {Industry 4.0 creates what has been called a “smart factory”. The possibility to a wide data collection from industrial processes makes possible to act smart action related to the system changes. Cyber-Physical Systems monitor physical processes and make possible decentralized decisions or even, in the last stage, a self-smart system adaptation. Thanks to the connectivity of the different production resources (machines, work stations, etc.) it is possible to generate information, to share and provide it and finally to create a smart system in which a predictive and automated decision making process with potential self-reconfiguration of the production system is possible to occur. As consequence Industry 4.0 could strongly impact on the actual assembly paradigms, even in the cases in which the human factor is prevailing, as manual assembly. This paper aims to investigate how these transformations are expected to occur. A future state map of the assembly paradigms as effect of the integration with the Industry 4.0 principles is presented. Moreover, a general architecture to implement Industry 4.0 principles into existing assembly systems is provided, highlighting how the final steps of implementation represented by the Operator Support Systems (OSS) and Self-Adapting Smart Assembly System (SASS) are crucial. A detailed report of a real case study derived by an Italian worldwide industrial refrigerator manufacturer represents a further element of interest of the research and demonstrates the practical implication of the study.},
author = {Cohen, Yuval and Faccio, Maurizio and Galizia, Francesco Gabriele and Mora, Cristina and Pilati, Francesco},
doi = {10.1016/j.ifacol.2017.08.2550},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cohen et al. - 2017 - Assembly system configuration through Industry 4.0 principles the expected change in the actual paradigms.pdf:pdf},
isbn = {4961511633},
issn = {24058963},
journal = {IFAC-PapersOnLine},
keywords = {Industry 4.0,flexibility,human factor,smart assembly},
number = {1},
pages = {14958--14963},
publisher = {Elsevier B.V.},
title = {{Assembly system configuration through Industry 4.0 principles: the expected change in the actual paradigms}},
url = {https://doi.org/10.1016/j.ifacol.2017.08.2550},
volume = {50},
year = {2017}
}
@article{Singh2021,
abstract = {Conventional Bayesian Neural Networks (BNNs) are known to be capable of providing multiple outputs for a single input, the variations in which can be utilised to detect Out of Distribution (OOD) inputs. BNNs are difficult to train due to their sensitivity towards the choice of priors. To alleviate this issue, we propose pseudo-BNNs where instead of learning distributions over weights, we use point estimates and perturb weights at the time of inference. We modify the cost function of conventional BNNs and use it to learn parameters for the purpose of injecting right amount of random perturbations to each of the weights of a neural network with point estimate. In order to effectively segregate OOD inputs from In Distribution (ID) inputs using multiple outputs, we further propose two measures, derived from the index of dispersion and entropy of probability distributions, and combine them with the proposed pseudo-BNNs. Overall, this combination results in a principled technique to detect OOD samples at the time of inference. We evaluate our technique on a wide variety of neural network architectures and image classification datasets. We observe that our method achieves state of the art results and beats the related previous work on various metrics such as FPR at 95% TPR, AUROC, AUPR and Detection Error by just using 2 to 5 samples of weights per input.},
archivePrefix = {arXiv},
arxivId = {2102.01336},
author = {Singh, Gagandeep and Mishra, Deepak},
eprint = {2102.01336},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Singh, Mishra - 2021 - pseudo-Bayesian Neural Networks for detecting Out of Distribution Inputs.pdf:pdf},
keywords = {bayesian neural networks,out-of-distribution},
mendeley-tags = {bayesian neural networks,out-of-distribution},
title = {{pseudo-Bayesian Neural Networks for detecting Out of Distribution Inputs}},
url = {http://arxiv.org/abs/2102.01336},
year = {2021}
}
@article{Roy2019,
abstract = {Object detection methods like Single Shot Multibox Detector (SSD) provide highly accurate object detection that run in real-time. However, these approaches require a large number of annotated training images. Evidently, not all of these images are equally useful for training the algorithms. Moreover, obtaining annotations in terms of bounding boxes for each image is costly and tedious. In this paper, we aim to obtain a highly accurate object detector using only a fraction of the training images. We do this by adopting active learning that uses 'human in the loop' paradigm to select the set of images that would be useful if annotated. Towards this goal, we make the following contributions: 1. We develop a novel active learning method which poses the layered architecture used in object detection as a 'query by committee' paradigm to choose the set of images to be queried. 2. We introduce a framework to use the exploration/exploitation trade-off in our methods. 3. We analyze the results on standard object detection datasets which show that with only a third of the training data, we can obtain more than 95% of the localization accuracy of full supervision. Further our methods outperform classical uncertainty-based active learning algorithms like maximum entropy.},
author = {Roy, Soumya and Unmesh, Asim and Namboodiri, Vinay P.},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roy, Unmesh, Namboodiri - 2019 - Deep active learning for object detection.pdf:pdf},
journal = {British Machine Vision Conference 2018, BMVC 2018},
keywords = {active learning,object detection},
mendeley-tags = {active learning,object detection},
pages = {1--12},
title = {{Deep active learning for object detection}},
year = {2019}
}
@article{Such2017,
abstract = {Deep artificial neural networks (DNNs) are typically trained via gradient-based learning algorithms, namely backpropagation. Evolution strategies (ES) can rival backprop-based algorithms such as Q-learning and policy gradients on challenging deep reinforcement learning (RL) problems. However, ES can be considered a gradient-based algorithm because it performs stochastic gradient descent via an operation similar to a finite-difference approximation of the gradient. That raises the question of whether non-gradient-based evolutionary algorithms can work at DNN scales. Here we demonstrate they can: we evolve the weights of a DNN with a simple, gradient-free, populationbased genetic algorithm (GA) and it performs well on hard deep RL problems, including Atari and humanoid locomotion. The Deep GA successfully evolves networks with over four million free parameters, the largest neural networks ever evolved with a traditional evolutionary algorithm. These results (1) expand our sense of the scale at which GAs can operate, (2) suggest intriguingly that in some cases following the gradient is not the best choice for optimizing performance, and (3) make immediately available the multitude of neuroevolution techniques that improve performance. We demonstrate the latter by showing that combining DNNs with novelty search, which encourages exploration on tasks with deceptive or sparse reward functions, can solve a high-dimensional problem on which reward-maximizing algorithms (e.g. DQN, A3C, ES, and the GA) fail. Additionally, the Deep GA is faster than ES, A3C, and DQN (it can train Atari in ∼4 hours on one desktop or ∼1 hour distributed on 720 cores), and enables a stateof-the-art, up to 10,000-fold compact encoding technique.},
archivePrefix = {arXiv},
arxivId = {1712.06567},
author = {Such, Felipe Petroski and Madhavan, Vashisht and Conti, Edoardo and Lehman, Joel and Stanley, Kenneth O. and Clune, Jeff},
eprint = {1712.06567},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Such et al. - 2017 - Deep neuroevolution Genetic algorithms are a competitive alternative for training deep neural networks for reinforc.pdf:pdf},
journal = {arXiv},
keywords = {evolution,genetic algorithm},
mendeley-tags = {evolution,genetic algorithm},
title = {{Deep neuroevolution: Genetic algorithms are a competitive alternative for training deep neural networks for reinforcement learning}},
year = {2017}
}
@article{Rieder2013,
abstract = {This paper describes Netvizz, a data collection and extraction application that allows researchers to export data in standard file formats from different sections of the Facebook social networking service. Friendship networks, groups, and pages can thus be analyzed quantitatively and qualitatively with regards to demographical, post- demographical, and relational characteristics. The paper provides an overview over analytical directions opened up by the data made available, discusses platform specific aspects of data extraction via the official Application Programming Interface, and briefly engages the difficult ethical considerations attached to this type of research.},
author = {Rieder, Bernhard},
doi = {10.1145/2464464.2464475},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rieder - 2013 - Studying Facebook via data extraction.pdf:pdf},
isbn = {9781450318891},
journal = {Proceedings of the 5th Annual ACM Web Science Conference on - WebSci '13},
pages = {346--355},
title = {{Studying Facebook via data extraction}},
url = {http://dl.acm.org/citation.cfm?doid=2464464.2464475},
year = {2013}
}
@article{Arora2019,
abstract = {Recent works have cast some light on the mystery of why deep nets fit any data and generalize despite being very overparametrized. This paper analyzes training and generalization for a simple 2-layer ReLU net with random initialization, and provides the following improvements over recent works: (i) Using a tighter characterization of training speed than recent papers, an explanation for why training a neural net with random labels leads to slower training, as originally observed in [Zhang et al. ICLR' 17]. (ii) Generalization bound independent of network size, using a data-dependent complexity measure. Our measure distinguishes clearly between random labels and true labels on MNIST and CIFAR, as shown by experiments. Moreover, recent papers require sample complexity to increase (slowly) with the size, while our sample complexity is completely independent of the network size. (iii) Leamability of a broad class of smooth functions by 2-laycr ReLU nets trained via gradient descent. The key idea is to track dynamics of training and generalization via properties of a related kernel.},
archivePrefix = {arXiv},
arxivId = {1901.08584},
author = {Arora, Sanjeev and Du, Simon S. and Hu, Wei and Li, Zhiyuan and Wang, Ruosong},
eprint = {1901.08584},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arora et al. - 2019 - Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks.pdf:pdf},
isbn = {9781510886988},
journal = {36th International Conference on Machine Learning, ICML 2019},
keywords = {generalization,optimization,overparameterized,theory},
mendeley-tags = {generalization,optimization,overparameterized,theory},
pages = {477--502},
title = {{Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks}},
volume = {2019-June},
year = {2019}
}
@article{Sazak2016,
abstract = {The world's leading cities are remembered with the structures identified with that city, symbolizing the city alone, creating adequate images concerning the city. Within the scope of the study, the urban silhouette model is created by using three dimensional digital terrain model for the protection of Selimiye Mosque's rapidly disappearing silhouette which is one of the essential elements of the urban identity of Edirne chosen as an example and is on the Unesco World Heritage list. This model, at the same time, contributes to creating the legal basis for restricting the rights of construction intended for the protection of urban silhouette.},
author = {Sazak, Şaduman and Savran, Doğan},
doi = {10.1016/j.sbspro.2016.06.022},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sazak, Savran - 2016 - Three Dimensional Digital Terrain Model Approach for the Projection of Urban Silhoutte – The Case of Edirne.pdf:pdf},
issn = {18770428},
journal = {Procedia - Social and Behavioral Sciences},
keywords = {8uedq vlokrxhwwh 8uedq lghqwlw,gljlwdo whuudlq prgho,gluqh 6holpl,h 0rvtxh 7kuhh glphqvlrqdo},
pages = {226--238},
title = {{Three Dimensional Digital Terrain Model Approach for the Projection of Urban Silhoutte – The Case of Edirne}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877042816307078},
volume = {225},
year = {2016}
}
@article{Chi2015,
abstract = {A TO-38-can packaged Gallium nitride (GaN) blue laser diode (LD) based free-space visible light communication (VLC) with 64-quadrature amplitude modulation (QAM) and 32-subcarrier orthogonal frequency division multiplexing (OFDM) transmission at 9 Gbps is preliminarily demonstrated over a 5-m free-space link. The 3-dB analog modulation bandwidth of the TO-38-can packaged GaN blue LD biased at 65 mA and controlled at 25 degrees C is only 900 MHz, which can be extended to 1.5 GHz for OFDM encoding after throughput intensity optimization. When delivering the 4-Gbps 16-QAM OFDM data within 1-GHz bandwidth, the error vector magnitude (EVM), signal-to-noise ratio (SNR) and bit-error-rate (BER) of the received data are observed as 8.4%, 22.4 dB and 3.5 x 10<sup>-8</sup>, respectively. By increasing the encoded bandwidth to 1.5 GHz, the TO-38-can packaged GaN blue LD enlarges its transmission capacity to 6 Gbps but degrades its transmitted BER to 1.7 x 10<sup>-3</sup>. The same transmission capacity of 6 Gbps can also be achieved with a BER of 1 x 10<sup>-6</sup> by encoding 64-QAM OFDM data within 1-GHz bandwidth. Using the 1.5-GHz full bandwidth of the TO-38-can packaged GaN blue LD provides the 64-QAM OFDM transmission up to 9 Gbps, which successfully delivers data with an EVM of 5.1%, an SNR of 22 dB and a BER of 3.6 x 10<sup>-3</sup> passed the forward error correction (FEC) criterion.},
author = {Chi, Yu-Chieh and Hsieh, Dan-Hua and Tsai, Cheng-Ting and Chen, Hsiang-Yu and Kuo, Hao-Chung and Lin, Gong-Ru},
doi = {10.1364/OE.23.013051},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chi et al. - 2015 - 450-nm GaN laser diode enables high-speed visible light communication with 9-Gbps QAM-OFDM.pdf:pdf},
isbn = {1094-4087 (Electronic)\r1094-4087 (Linking)},
issn = {1094-4087},
journal = {Optics Express},
number = {10},
pages = {13051},
pmid = {26074558},
title = {{450-nm GaN laser diode enables high-speed visible light communication with 9-Gbps QAM-OFDM}},
url = {https://www.osapublishing.org/abstract.cfm?URI=oe-23-10-13051},
volume = {23},
year = {2015}
}
@article{See,
author = {See, M},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/See - Unknown - Appendix A . 1 Derivation of Nesterov ' s Accelerated Gradient as a Momentum Method A . 3 . Autoencoder Problem Detail.pdf:pdf},
isbn = {7841000500250},
pages = {1--5},
title = {{Appendix A . 1 Derivation of Nesterov ' s Accelerated Gradient as a Momentum Method A . 3 . Autoencoder Problem Details}}
}
@inproceedings{Cha2020,
abstract = {We propose a general, yet simple patch that can be applied to existing regularization-based continual learning methods called classifier-projection regularization (CPR). Inspired by both recent results on neural networks with wide local minima and information theory, CPR adds an additional regularization term that maximizes the entropy of a classifier's output probability. We demonstrate that this additional term can be interpreted as a projection of the conditional probability given by a classifier's output to the uniform distribution. By applying the Pythagorean theorem for KL divergence, we then prove that this projection may (in theory) improve the performance of continual learning methods. In our extensive experimental results, we apply CPR to several state-of-the-art regularization-based continual learning methods and benchmark performance on popular image recognition datasets. Our results demonstrate that CPR indeed promotes a wide local minima and significantly improves both accuracy and plasticity while simultaneously mitigating the catastrophic forgetting of baseline continual learning methods.},
archivePrefix = {arXiv},
arxivId = {2006.07326},
author = {Cha, Sungmin and Hsu, Hsiang and Calmon, Flavio P. and Moon, Taesup},
booktitle = {Iclr 2021},
eprint = {2006.07326},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cha et al. - 2020 - CPR Classifier-Projection Regularization for Continual Learning.pdf:pdf},
issn = {23318422},
keywords = {continual learning,regularization},
mendeley-tags = {continual learning,regularization},
title = {{CPR: Classifier-Projection Regularization for Continual Learning}},
year = {2020}
}
@article{Wenzel2020,
abstract = {Ensembles over neural network weights trained from different random initialization, known as deep ensembles, achieve state-of-the-art accuracy and calibration. The recently introduced batch ensembles provide a drop-in replacement that is more parameter efficient. In this paper, we design ensembles not only over weights, but over hyperparameters to improve the state of the art in both settings. For best performance independent of budget, we propose hyper-deep ensembles, a simple procedure that involves a random search over different hyperparameters, themselves stratified across multiple random initializations. Its strong performance highlights the benefit of combining models with both weight and hyperparameter diversity. We further propose a parameter efficient version, hyper-batch ensembles, which builds on the layer structure of batch ensembles and self-tuning networks. The computational and memory costs of our method are notably lower than typical ensembles. On image classification tasks, with MLP, LeNet, and Wide ResNet 28-10 architectures, our methodology improves upon both deep and batch ensembles.},
archivePrefix = {arXiv},
arxivId = {2006.13570},
author = {Wenzel, Florian and Snoek, Jasper and Tran, Dustin and Jenatton, Rodolphe},
eprint = {2006.13570},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wenzel et al. - 2020 - Hyperparameter Ensembles for Robustness and Uncertainty Quantification.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {ensemble,formalism,robustness,uncertainty},
mendeley-tags = {ensemble,formalism,robustness,uncertainty},
number = {NeurIPS},
title = {{Hyperparameter Ensembles for Robustness and Uncertainty Quantification}},
url = {https://github.com/google/uncertainty-baselines},
year = {2020}
}
@book{Buchanan1974,
address = {Baltimore, USA},
author = {Buchanan, R. E. and Gibbons, N. E.},
isbn = {0683011170},
pages = {1264},
publisher = {Williams & Wilkins Company},
title = {{Bergey's manual of determinative bacteriology. 8th Edition}},
year = {1974}
}
@article{Liu2021d,
abstract = {This paper presents a simple and effective approach to solving the multi-label classification problem. The proposed approach leverages Transformer decoders to query the existence of a class label. The use of Transformer is rooted in the need of extracting local discriminative features adaptively for different labels, which is a strongly desired property due to the existence of multiple objects in one image. The built-in cross-attention module in the Transformer decoder offers an effective way to use label embeddings as queries to probe and pool class-related features from a feature map computed by a vision backbone for subsequent binary classifications. Compared with prior works, the new framework is simple, using standard Transformers and vision backbones, and effective, consistently outperforming all previous works on five multi-label classification data sets, including MS-COCO, PASCAL VOC, NUS-WIDE, and Visual Genome. Particularly, we establish $91.3\%$ mAP on MS-COCO. We hope its compact structure, simple implementation, and superior performance serve as a strong baseline for multi-label classification tasks and future studies. The code will be available soon at https://github.com/SlongLiu/query2labels.},
archivePrefix = {arXiv},
arxivId = {2107.10834},
author = {Liu, Shilong and Zhang, Lei and Yang, Xiao and Su, Hang and Zhu, Jun},
eprint = {2107.10834},
file = {:home/user/Downloads/2107.10834.pdf:pdf},
keywords = {multi-label,transformer},
mendeley-tags = {multi-label,transformer},
title = {{Query2Label: A Simple Transformer Way to Multi-Label Classification}},
url = {http://arxiv.org/abs/2107.10834},
year = {2021}
}
@article{Zhu2018,
abstract = {Model pruning seeks to induce sparsity in a deep neural network's various connection matrices, thereby reducing the number of nonzero-valued parameters in the model. Recent reports (Han et al., 2015a; Narang et al., 2017) prune deep networks at the cost of only a marginal loss in accuracy and achieve a sizable reduction in model size. This hints at the possibility that the baseline models in these experiments are perhaps severely over-parameterized at the outset and a viable alternative for model compression might be to simply reduce the number of hidden units while maintaining the model's dense connection structure, exposing a similar trade-off in model size and accuracy. We investigate these two distinct paths for model compression within the context of energy-efficient inference in resource-constrained environments and propose a new gradual pruning technique that is simple and straightforward to apply across a variety of models/datasets with minimal tuning and can be seamlessly incorporated within the training process. We compare the accuracy of large, but pruned models (large-sparse) and their smaller, but dense (small-dense) counterparts with identical memory footprint. Across a broad range of neural network architectures (deep CNNs, stacked LSTM, and seq2seq LSTM models), we find large-sparse models to consistently outperform small-dense models and achieve up to 10x reduction in number of non-zero parameters with minimal loss in accuracy.},
archivePrefix = {arXiv},
arxivId = {1710.01878},
author = {Zhu, Michael H. and Gupta, Suyog},
eprint = {1710.01878},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu, Gupta - 2018 - To prune, or not to prune Exploring the efficacy of pruning for model compression.pdf:pdf},
journal = {6th International Conference on Learning Representations, ICLR 2018 - Workshop Track Proceedings},
title = {{To prune, or not to prune: Exploring the efficacy of pruning for model compression}},
year = {2018}
}
@article{Posada2016,
abstract = {Aiming to develop a cost effective means to store large amounts of electric energy, NiFe batteries were produced and tested under galvanostatic conditions at room temperature. Multiple regression analysis was conducted to develop predictive equations that establish a link between hydrogen evolution and electrode manufacturing conditions, over a wide range of electrode/electrolyte systems. Basically, the intent was to investigate the incidence of lithium hydroxide and potassium sulphide as electrolyte additives on cell performance. With this in mind, in-house built Fe/FeS based electrodes were cycled against commercially available nickel electrodes on a three electrode cell configuration. A 3 × 4 full factorial experimental design was proposed to investigate the combined effect of the aforementioned electrolyte additives on cell performance. As a consequence, data from 144 cells were finally used in conducting the analysis and finding the form of the predictive equations. Our findings suggest that at the level of confidence alpha = 0.05, the presence of relatively large amounts of the soluble bisulphide would enhance the performance of the battery by reducing electrolyte decomposition.},
author = {Posada, Jorge Omar Gil and Hall, Peter J.},
doi = {10.1016/j.ijhydene.2016.04.123},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Posada, Hall - 2016 - Controlling hydrogen evolution on iron electrodes.pdf:pdf},
isbn = {9781467378949},
issn = {03603199},
journal = {International Journal of Hydrogen Energy},
keywords = {Cell performance,Electrolyte decomposition,Hydrogen evolution,Iron electrode,NiFe},
number = {45},
pages = {20807--20817},
publisher = {Elsevier Ltd},
title = {{Controlling hydrogen evolution on iron electrodes}},
url = {http://dx.doi.org/10.1016/j.ijhydene.2016.04.123},
volume = {41},
year = {2016}
}
@article{Hou2020,
abstract = {—Learning low-dimensional topological representation of a network in dynamic environments is attracting much attention due to the time-evolving nature of many real-world networks. The main and common objective of Dynamic Network Embedding (DNE) is to efficiently update node embeddings while preserving network topology at each time step. The idea of most existing DNE methods is to capture the topological changes at or around the most affected nodes (instead of all nodes) and accordingly update node embeddings. Unfortunately, this kind of approximation, although can improve efficiency, cannot effectively preserve the global topology of a dynamic network at each time step, due to not considering the inactive sub-networks that receive accumulated topological changes propagated via the high-order proximity. To tackle this challenge, we propose a novel node selecting strategy to diversely select the representative nodes over a network, which is coordinated with a new incremental learning paradigm of Skip-Gram based embedding approach. The extensive experiments show GloDyNE, with a small fraction of nodes being selected, can already achieve the superior or comparable performance w.r.t. the state-of-the-art DNE methods in three typical downstream tasks. Particularly, GloDyNE significantly outperforms other methods in the graph reconstruction task, which demonstrates its ability of global topology preservation.},
archivePrefix = {arXiv},
arxivId = {2008.01935},
author = {Hou, Chengbin and Zhang, Han and He, Shan and Tang},
eprint = {2008.01935},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hou et al. - 2020 - GloDyNE Global topology preserving dynamic network embedding.pdf:pdf},
journal = {arXiv},
keywords = {Data Mining,Dynamic Networks,Feature Extraction or Construction,Global Topology,Network Embedding,representation learning,topology-preserving embedding},
mendeley-tags = {representation learning,topology-preserving embedding},
number = {Xx},
pages = {1--12},
title = {{GloDyNE: Global topology preserving dynamic network embedding}},
url = {https://github.com/houchengbin/GloDyNE},
volume = {XX},
year = {2020}
}
@article{Bennett2001,
abstract = {Missing data in medical research is a common problem that has long been recognised by statisticians and medical researchers alike. In general, if the effect of missing data is not taken into account the results of the statistical analyses will be biased and the amount of variability in the data will not be correctly estimated. There are three main types of missing data pattern: Missing Completely At Random (MCAR), Missing At Random (MAR) and Not Missing At Random (NMAR). The type of missing data that a researcher has in their dataset determines the appropriate method to use in handling the missing data before a formal statistical analysis begins. The aim of this practice note is to describe these patterns of missing data and how they can occur, as well describing the methods of handling them. Simple and more complex methods are described, including the advantages and disadvantages of each method as well as their availability in routine software. It is good practice to perform a sensitivity analysis employing different missing data techniques in order to assess the robustness of the conclusions drawn from each approach.},
author = {Bennett, D A},
doi = {10.1111/j.1467-842X.2001.tb00294.x},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bennett - 2001 - How can I deal with missing data in my study.pdf:pdf},
isbn = {1326-0200 (Print)\r1326-0200 (Linking)},
issn = {1326-0200 (Print) 1326-0200 (Linking)},
journal = {Aust N Z J Public Health},
keywords = {Bias (Epidemiology) Data Collection/*methods *Data},
number = {5},
pages = {464--469},
pmid = {11688629},
title = {{How can I deal with missing data in my study?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11688629},
volume = {25},
year = {2001}
}
@article{Akyurek2021,
abstract = {Few-shot class incremental learning -- the problem of updating a trained classifier to discriminate among an expanded set of classes with limited labeled data -- is a key challenge for machine learning systems deployed in non-stationary environments. Existing approaches to the problem rely on complex model architectures and training procedures that are difficult to tune and re-use. In this paper, we present an extremely simple approach that enables the use of ordinary logistic regression classifiers for few-shot incremental learning. The key to this approach is a new family of subspace regularization schemes that encourage weight vectors for new classes to lie close to the subspace spanned by the weights of existing classes. When combined with pretrained convolutional feature extractors, logistic regression models trained with subspace regularization outperform specialized, state-of-the-art approaches to few-shot incremental image classification by up to 22% on the miniImageNet dataset. Because of its simplicity, subspace regularization can be straightforwardly extended to incorporate additional background information about the new classes (including class names and descriptions specified in natural language); these further improve accuracy by up to 2%. Our results show that simple geometric regularization of class representations offers an effective tool for continual learning.},
archivePrefix = {arXiv},
arxivId = {2110.07059},
author = {Aky{\"{u}}rek, Afra Feyza and Aky{\"{u}}rek, Ekin and Wijaya, Derry and Andreas, Jacob},
eprint = {2110.07059},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aky{\"{u}}rek et al. - 2021 - Subspace Regularizers for Few-Shot Class Incremental Learning.pdf:pdf},
keywords = {continual learning},
mendeley-tags = {continual learning},
number = {1},
pages = {1--18},
title = {{Subspace Regularizers for Few-Shot Class Incremental Learning}},
url = {http://arxiv.org/abs/2110.07059},
volume = {2},
year = {2021}
}
@article{Lee2016a,
abstract = {{\textcopyright} 2016 by the authors. In this study, an artificial neural network (ANN) model is developed to predict the stability number of breakwater armor stones based on the experimental data reported by Van der Meer in 1988. The harmony search (HS) algorithm is used to determine the near-global optimal initial weights in the training of the model. The stratified sampling is used to sample the training data. A total of 25 HS-ANN hybrid models are tested with different combinations of HS algorithm parameters. The HS-ANN models are compared with the conventional ANN model, which uses a Monte Carlo simulation to determine the initial weights. Each model is run 50 times and the statistical analyses are conducted for the model results. The present models using stratified sampling are shown to be more accurate than those of previous studies. The statistical analyses for the model results show that the HS-ANN model with proper values of HS algorithm parameters can give much better and more stable prediction than the conventional ANN model.},
author = {Lee, Anzy and Geem, Zong and Suh, Kyung-Duck},
doi = {10.3390/app6060164},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee, Geem, Suh - 2016 - Determination of Optimal Initial Weights of an Artificial Neural Network by Using the Harmony Search Algorithm A.pdf:pdf},
issn = {2076-3417},
journal = {Applied Sciences},
keywords = {armor stones,artificial neural network,harmony search algorithm,rubble mound,stability number,structure},
number = {6},
pages = {164},
title = {{Determination of Optimal Initial Weights of an Artificial Neural Network by Using the Harmony Search Algorithm: Application to Breakwater Armor Stones}},
url = {http://www.mdpi.com/2076-3417/6/6/164},
volume = {6},
year = {2016}
}
@article{Doma2010,
author = {Doma, D},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Doma - 2010 - Fuzzy weather forecast in forecasting pollution concentrations.pdf:pdf},
keywords = {air,fuzzy matrix,fuzzy numbers,fuzzy system models,fuzzy weather forecast,pollution forecasting},
pages = {1--8},
title = {{Fuzzy weather forecast in forecasting pollution concentrations}},
year = {2010}
}
@article{Galanti2020,
abstract = {In the context of learning to map an input $I$ to a function $h_I:\mathcal{X}\to \mathbb{R}$, two alternative methods are compared: (i) an embedding-based method, which learns a fixed function in which $I$ is encoded as a conditioning signal $e(I)$ and the learned function takes the form $h_I(x) = q(x,e(I))$, and (ii) hypernetworks, in which the weights $\theta_I$ of the function $h_I(x) = g(x;\theta_I)$ are given by a hypernetwork $f$ as $\theta_I=f(I)$. In this paper, we define the property of modularity as the ability to effectively learn a different function for each input instance $I$. For this purpose, we adopt an expressivity perspective of this property and extend the theory of Devore et al. 1996 and provide a lower bound on the complexity (number of trainable parameters) of neural networks as function approximators, by eliminating the requirements for the approximation method to be robust. Our results are then used to compare the complexities of $q$ and $g$, showing that under certain conditions and when letting the functions $e$ and $f$ be as large as we wish, $g$ can be smaller than $q$ by orders of magnitude. This sheds light on the modularity of hypernetworks in comparison with the embedding-based method. Besides, we show that for a structured target function, the overall number of trainable parameters in a hypernetwork is smaller by orders of magnitude than the number of trainable parameters of a standard neural network and an embedding method.},
archivePrefix = {arXiv},
arxivId = {2002.10006},
author = {Galanti, Tomer and Wolf, Lior},
doi = {10.1215/S0012-7094-01-10914-9},
eprint = {2002.10006},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ellenberg, Skinner - 2001 - On the modularity of Q-curves.pdf:pdf;:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Galanti, Wolf - 2020 - On the Modularity of Hypernetworks.pdf:pdf},
issn = {0012-7094},
journal = {Duke Mathematical Journal},
month = {jul},
number = {NeurIPS},
pages = {97--122},
title = {{On the Modularity of Hypernetworks}},
url = {http://arxiv.org/abs/2002.10006 https://projecteuclid.org/euclid.dmj/1091737223},
volume = {109},
year = {2020}
}
@article{Galanti2020a,
abstract = {In the context of learning to map an input $I$ to a function $h_I:\mathcal{X}\to \mathbb{R}$, two alternative methods are compared: (i) an embedding-based method, which learns a fixed function in which $I$ is encoded as a conditioning signal $e(I)$ and the learned function takes the form $h_I(x) = q(x,e(I))$, and (ii) hypernetworks, in which the weights $\theta_I$ of the function $h_I(x) = g(x;\theta_I)$ are given by a hypernetwork $f$ as $\theta_I=f(I)$. In this paper, we define the property of modularity as the ability to effectively learn a different function for each input instance $I$. For this purpose, we adopt an expressivity perspective of this property and extend the theory of Devore et al. 1996 and provide a lower bound on the complexity (number of trainable parameters) of neural networks as function approximators, by eliminating the requirements for the approximation method to be robust. Our results are then used to compare the complexities of $q$ and $g$, showing that under certain conditions and when letting the functions $e$ and $f$ be as large as we wish, $g$ can be smaller than $q$ by orders of magnitude. This sheds light on the modularity of hypernetworks in comparison with the embedding-based method. Besides, we show that for a structured target function, the overall number of trainable parameters in a hypernetwork is smaller by orders of magnitude than the number of trainable parameters of a standard neural network and an embedding method.},
archivePrefix = {arXiv},
arxivId = {2002.10006},
author = {Galanti, Tomer and Wolf, Lior},
eprint = {2002.10006},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Galanti, Wolf - 2020 - On the Modularity of Hypernetworks.pdf:pdf},
month = {feb},
number = {NeurIPS},
title = {{On the Modularity of Hypernetworks}},
url = {http://arxiv.org/abs/2002.10006},
year = {2020}
}
@article{El-Shafie2011,
abstract = {Runoff prediction still represents an extremely important issue in applied hydrology. On the other hand, rainfall is one of the most complicated effective hydrologic processes in runoff prediction. For a developing country such as Malaysia which is prone to flood disaster having such an expert model for runoff forecasting is a very vital matter. In this article, an adaptive neuro-fuzzy inference system (ANFIS) model is proposed to forecast the rainfall for Klang River in Malaysia on monthly basis. To be able to train and test the ANFIS and ANN models, the statistical data from 1997 to 2008, was obtained from Klang gates dam data. The optimum structure and optimum input pattern of model was determined through trial and error. Different combinations of rainfall were produced as inputs and five different criteria were used in order to evaluate the effectiveness of each network and its ability to make precise prediction. The performance of the ANFIS model is compared to artificial neural network (ANN) model. The five criteria are root mean square error (RMSE), Correlation Coefficient (2R;), and Nash Sutcliffe coefficient (NE), gamma coefficient (GC) Spearman correlation coefficient (SCC). The result indicate that the ANFIS model showed higher rainfall forecasting accuracy and low error compared to the ANN model. Furthermore, the rainfall estimated by this technique was closer to actual data than the other one. {\textcopyright}2011 Academic Journals.},
author = {El-Shafie, A and Jaafer, O and Seyed, A},
doi = {10.5897/IJPS11.515},
issn = {19921950},
journal = {International Journal of Physical Sciences},
keywords = {ANFIS,Forecasting model,Klang gate},
number = {12},
pages = {2875--2888},
title = {{Adaptive neuro-fuzzy inference system based model for rainfall forecasting in Klang River, Malaysia}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79960851974&partnerID=40&md5=aa2f739051084b25ccd8b4815aabcaf6},
volume = {6},
year = {2011}
}
@article{Fayolle2014,
abstract = {Previous research into emotion and time perception has been designed to study the time perception of emotional events themselves (e.g., facial expression). Our aim was to investigate the effect of emotions per se on the subsequent time judgment of a neutral, non-affective event. In the present study, the participants were presented with films inducing a specific mood and were subsequently given a temporal bisection task. More precisely, the participants were given two temporal bisection tasks, one before and the other after viewing the emotional film. Three emotional films were tested: one eliciting fear, another sadness, and a neutral control film. In addition, the direct mood experience was assessed using the Brief Mood Introspective Scale that was administered to the participants at the beginning and the end of the session. The results showed that the perception of time did not change after viewing either the neutral control films or the sad films although the participants reported being sadder and less aroused after than before watching the sad film clips. In contrast, the stimulus durations were judged longer after than before viewing the frightening films that were judged to increase the emotion of fear and arousal level. In combination with findings from previous studies, our data suggest that the selective lengthening effect after watching frightening films was mediated by an effect of arousal on the speed of the internal clock system.},
author = {Fayolle, Sophie and Droit-Volet, Sylvie and Gil, Sandrine},
doi = {10.1016/j.sbspro.2014.02.399},
isbn = {1662-5145},
issn = {18770428},
journal = {Procedia - Social and Behavioral Sciences},
keywords = {emotion,fear,mood,sadness,time perception,time perception, timing, emotion, mood, fear, sadn,timing},
number = {August},
pages = {251--252},
pmid = {21886610},
title = {{Emotion and Time Perception: Effects of Film-induced Mood}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877042814019478},
volume = {126},
year = {2014}
}
@article{N-way2017,
abstract = {We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.},
archivePrefix = {arXiv},
arxivId = {1703.03400},
author = {N-way, For},
eprint = {1703.03400},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/N-way - 2017 - A . Additional Experiment Details B . Additional Sinusoid Results C . Additional Comparisons.pdf:pdf},
number = {2015},
pages = {5--7},
title = {{A . Additional Experiment Details B . Additional Sinusoid Results C . Additional Comparisons}},
year = {2017}
}
@article{Zheng2017,
abstract = {Joint extraction of entities and relations is an important task in information extraction. To tackle this problem, we firstly propose a novel tagging scheme that can convert the joint extraction task to a tagging problem. Then, based on our tagging scheme, we study different end-to-end models to extract entities and their relations directly, without identifying entities and relations separately. We conduct experiments on a public dataset produced by distant supervision method and the experimental results show that the tagging based methods are better than most of the existing pipelined and joint learning methods. What's more, the end-to-end model proposed in this paper, achieves the best results on the public dataset.},
author = {Zheng, Suncong and Wang, Feng and Bao, Hongyun and Hao, Yuexing and Zhou, Peng and Xu, Bo},
doi = {10.18653/v1/P17-1113},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zheng et al. - 2017 - Joint extraction of entities and relations based on a novel tagging scheme(2).pdf:pdf},
isbn = {9781945626753},
journal = {ACL 2017 - 55th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)},
keywords = {information extraction,joint entity and relation extraction,natural language processing},
mendeley-tags = {information extraction,joint entity and relation extraction,natural language processing},
pages = {1227--1236},
title = {{Joint extraction of entities and relations based on a novel tagging scheme}},
volume = {1},
year = {2017}
}
@article{Filik2017,
abstract = {In this study, artificial neural network (ANN) based models, which differently uses multiple local meteorological measurements together such as wind speed, temperature and pressure values, are proposed and it shown ANN based multivariable model's wind speed predictions can be improved for various cases. A data monitoring system are used which can sensitively measures in milliseconds time interval and records the values of weather temperature, wind speed, wind direction and weather pressure in this study. The proposed ANN based multivariable model's root mean square error (RMSE) and mean absolute error (MAE) performances are presented and compared for various cases. The effect of using multiple local variables instead of wind speed only are analyzed and compared with persistence method for benchmark.},
author = {Filik, {\"{U}}mm{\"{u}}han Başaran and Filik, Tansu},
doi = {10.1016/j.egypro.2016.12.147},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Filik, Filik - 2017 - Wind Speed Prediction Using Artificial Neural Networks Based on Multiple Local Measurements in Eskisehir.pdf:pdf},
isbn = {2223239501},
issn = {18766102},
journal = {Energy Procedia},
keywords = {Wind energy,artificial neural network,wind speed prediction},
number = {September 2016},
pages = {264--269},
title = {{Wind Speed Prediction Using Artificial Neural Networks Based on Multiple Local Measurements in Eskisehir}},
volume = {107},
year = {2017}
}
@article{Szeles2017,
abstract = {This paper proposes a weather forecast system which has been implemented into a robot partner in order to support elderly people in their daily life. Using the current weather data, the weather condition, the wind speed and the temperature, the system provides different recommendation to the user by using Fuzzy logic. With the help of the system, the elderly people can organize their daily routine plans in a more convenient way by using the weather information which were received from the internet. The system advices the user to do activities related to the current weather condition. To decide the right recommendation pattern, we use Fuzzy logic to describe the rules. Depending on the current weather condition, temperature and the wind speed, the system is going to advice the user about what should he/she do. The discussed system is implemented into a robot partner but it can be also used as regular smartphone application too.},
author = {Szeles, Julia and Kubota, Naoyuki and Woo, Jinseok},
doi = {10.1109/IFSA-SCIS.2017.8023309},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Szeles, Kubota, Woo - 2017 - Weather forecast support system implemented into robot partner for supporting elderly people using fuzzy lo.pdf:pdf},
isbn = {9781509049172},
journal = {IFSA-SCIS 2017 - Joint 17th World Congress of International Fuzzy Systems Association and 9th International Conference on Soft Computing and Intelligent Systems},
title = {{Weather forecast support system implemented into robot partner for supporting elderly people using fuzzy logic}},
year = {2017}
}
@article{Edelson2011a,
abstract = {Human memory is strikingly susceptible to social influences, yet we know little about the underlying mechanisms. We examined how socially induced memory errors are generated in the brain by studying the memory of individuals exposed to recollections of others. Participants exhibited a strong tendency to conform to erroneous recollections of the group, producing both long-lasting and temporary errors, even when their initial memory was strong and accurate. Functional brain imaging revealed that social influence modified the neuronal representation of memory. Specifically, a particular brain signature of enhanced amygdala activity and enhanced amygdala-hippocampus connectivity predicted long-lasting but not temporary memory alterations. Our findings reveal how social manipulation can alter memory and extend the known functions of the amygdala to encompass socially mediated memory distortions.},
author = {Edelson, Micah and Sharot, Tali and Dolan, Raymond J. and Dudai, Yadin},
doi = {10.1126/science.1203557},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Edelson et al. - 2011 - Following the crowd Brain substrates of long-term memory conformity.pdf:pdf},
isbn = {1095-9203 (Electronic)\n0036-8075 (Linking)},
issn = {00368075},
journal = {Science},
number = {6038},
pages = {108--111},
pmid = {21719681},
title = {{Following the crowd: Brain substrates of long-term memory conformity}},
volume = {333},
year = {2011}
}
@article{Skinner2013a,
abstract = {Abstract This paper presents a genetic algorithm (GA)-based optimisation approach to improve container handling operations at the Patrick AutoStrad container terminal located in Brisbane Australia. In this paper we focus on scheduling for container transfers and encode the problem using a two-part chromosome approach which is then solved using a modified genetic algorithm. In simulation experiments, the performance of the GA-based approach and a sequential job scheduling method are evaluated and compared with different scheduling scenarios. The experimental results show that the GA-based approach can find better solutions which improve the overall performance. The GA-based approach has been implemented in the terminal scheduling system and the live testing results show that the GA-based approach can reduce the overall time-related cost of container transfers at the automated container terminal. Crown Copyright {\textcopyright} 2012 Published by Elsevier Ltd. All rights reserved.},
author = {Skinner, Bradley and Yuan, Shuai and Huang, Shoudong and Liu, Dikai and Cai, Binghuang and Dissanayake, Gamini and Lau, Haye and Bott, Andrew and Pagac, Daniel},
doi = {10.1016/j.cie.2012.08.012},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Skinner et al. - 2013 - Optimisation for job scheduling at automated container terminals using genetic algorithm.pdf:pdf},
isbn = {0360-8352},
issn = {03608352},
journal = {Computers and Industrial Engineering},
keywords = {Automated seaport container terminals,Autonomous straddle carrier,Genetic algorithms,Modelling,Scheduling},
number = {1},
pages = {511--523},
publisher = {Elsevier Ltd},
title = {{Optimisation for job scheduling at automated container terminals using genetic algorithm}},
url = {http://dx.doi.org/10.1016/j.cie.2012.08.012},
volume = {64},
year = {2013}
}
@inproceedings{Amari2020,
abstract = {While second order optimizers such as natural gradient descent (NGD) often speed up optimization, their effect on generalization remains controversial. For instance, it has been pointed out that gradient descent (GD), in contrast to many preconditioned updates, converges to small Euclidean norm solutions in overparameterized models, leading to favorable generalization properties. This work presents a more nuanced view on the comparison of generalization between first- and second-order methods. We provide an exact asymptotic bias-variance decomposition of the generalization error of overparameterized ridgeless regression under a general class of preconditioner P, and consider the inverse population Fisher information matrix (used in NGD) as a particular example. We determine the optimal P for both the bias and variance, and find that the relative generalization performance of different optimizers depends on the label noise and the “shape” of the signal (true parameters): when the labels are noisy, the model is misspecified, or the signal is misaligned with the features, NGD can achieve lower risk; conversely, GD generalizes better than NGD under clean labels, a well-specified model, or aligned signal. Based on this analysis, we discuss several approaches to manage the bias-variance tradeoff, and the potential benefit of interpolating between GD and NGD. We then extend our analysis to regression in the reproducing kernel Hilbert space and demonstrate that preconditioned GD can decrease the population risk faster than GD. Lastly, we empirically compare the generalization performance of first- and second-order optimizers in neural network experiments, and observe robust trends matching our theoretical analysis.},
archivePrefix = {arXiv},
arxivId = {2006.10732},
author = {Amari, Shunichi and Ba, Jimmy and Grosse, Roger and Li, Xuechen and Nitanda, Atsushi and Suzuki, Taiji and Wu, Denny and Xu, Ji},
booktitle = {Iclr 2021},
eprint = {2006.10732},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Amari et al. - 2020 - When Does Preconditioning Help or Hurt Generalization.pdf:pdf},
issn = {23318422},
keywords = {empirical study,generalization,preconditioning,theory},
mendeley-tags = {empirical study,generalization,preconditioning,theory},
title = {{When Does Preconditioning Help or Hurt Generalization}},
year = {2020}
}
@article{Doersch2020,
abstract = {Given new tasks with very little data—such as new classes in a classification problem or a domain shift in the input—performance of modern vision systems degrades remarkably quickly. In this work, we illustrate how the neural network representations which underpin modern vision systems are subject to supervision collapse, whereby they lose any information that is not necessary for performing the training task, including information that may be necessary for transfer to new tasks or domains. We then propose two methods to mitigate this problem. First, we employ self-supervised learning to encourage general-purpose features that transfer better. Second, we propose a novel Transformer based neural network architecture called CrossTransformers, which can take a small number of labeled images and an unlabeled query, find coarse spatial correspondence between the query and the labeled images, and then infer class membership by computing distances between spatially-corresponding features. The result is a classifier that is more robust to task and domain shift, which we demonstrate via state-of-the-art performance on Meta-Dataset, a recent dataset for evaluating transfer from ImageNet to many other vision datasets.},
archivePrefix = {arXiv},
arxivId = {2007.11498},
author = {Doersch, Carl and Gupta, Ankush and Zisserman, Andrew},
eprint = {2007.11498},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Doersch, Gupta, Zisserman - 2020 - CrossTransformers Spatially-aware few-shot transfer.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {few-shot learning,transfer learning},
mendeley-tags = {few-shot learning,transfer learning},
number = {NeurIPS},
title = {{CrossTransformers: Spatially-aware few-shot transfer}},
url = {https://github.com/google-research/meta-dataset},
year = {2020}
}
@article{Yatsalo2017,
abstract = {Uncertainty is one of the main difficulties that increases the complexity of multi-criteria decision analysis (MCDA) problems, and often uncertainty cannot be managed by probabilistic models. In such cases, the use of fuzzy methods has been successfully applied to multi-criteria decision methods in which the ranking of fuzzy quantities is crucial for the decision analysis. This paper aims to introduce a new approach to MCDA problems defined under fuzzy contexts that implements the concept of acceptability analysis, Fuzzy Multi-Criteria Acceptability Analysis (FMAA), based on the Fuzzy Rank Acceptability Analysis (FRAA), that provides a ranking and a confidence degree about the ranking of fuzzy quantities. Based on the fuzzy extension of MAVT method, the FMAA is implemented and then applied to a case study, and its results are compared with other well-known MCDA methods in order to show its validity, interpretability and consistency.},
author = {Yatsalo, Boris and Korobov, Alexander and Mart{\'{i}}nez, L.},
doi = {10.1016/j.eswa.2017.05.005},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yatsalo, Korobov, Mart{\'{i}}nez - 2017 - Fuzzy multi-criteria acceptability analysis A new approach to multi-criteria decision analysis unde.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Fuzzy sets,MAVT,Multi-criteria decision analysis,Ranking fuzzy numbers,Uncertainty},
pages = {262--271},
publisher = {Elsevier Ltd},
title = {{Fuzzy multi-criteria acceptability analysis: A new approach to multi-criteria decision analysis under fuzzy environment}},
url = {http://dx.doi.org/10.1016/j.eswa.2017.05.005},
volume = {84},
year = {2017}
}
@article{Antoniou2020a,
abstract = {Both few-shot and continual learning have seen substantial progress in the last years due to the introduction of proper benchmarks. That being said, the field has still to frame a suite of benchmarks for the highly desirable setting of continual few-shot learning, where the learner is presented a number of few-shot tasks, one after the other, and then asked to perform well on a validation set stemming from all previously seen tasks. Continual few-shot learning has a small computational footprint and is thus an excellent setting for efficient investigation and experimentation. In this paper we first define a theoretical framework for continual few-shot learning, taking into account recent literature, then we propose a range of flexible benchmarks that unify the evaluation criteria and allows exploring the problem from multiple perspectives. As part of the benchmark, we introduce a compact variant of ImageNet, called SlimageNet64, which retains all original 1000 classes but only contains 200 instances of each one (a total of 200K data-points) downscaled to 64 x 64 pixels. We provide baselines for the proposed benchmarks using a number of popular few-shot learning algorithms, as a result, exposing previously unknown strengths and weaknesses of those algorithms in continual and data-limited settings.},
archivePrefix = {arXiv},
arxivId = {2004.11967},
author = {Antoniou, Antreas and Patacchiola, Massimiliano and Ochal, Mateusz and Storkey, Amos},
eprint = {2004.11967},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Antoniou et al. - 2020 - Defining Benchmarks for Continual Few-Shot Learning.pdf:pdf},
journal = {arXiv},
keywords = {[imagenet]},
mendeley-tags = {[imagenet]},
month = {apr},
title = {{Defining Benchmarks for Continual Few-Shot Learning}},
url = {http://arxiv.org/abs/2004.11967},
year = {2020}
}
@book{Ayub2021,
abstract = {For many real-world robotics applications, robots need to continually adapt and learn new concepts. Further, robots need to learn through limited data because of scarcity of labeled data in the real-world environments. To this end, my research focuses on developing robots that continually learn in dynamic unseen environments/scenarios, learn from limited human supervision, remember previously learned knowledge and use that knowledge to learn new concepts. I develop machine learning models that not only produce State-of-the-results on benchmark datasets but also allow robots to learn new objects and scenes in unconstrained environments which lead to a variety of novel robotics applications.},
archivePrefix = {arXiv},
arxivId = {2101.10509},
author = {Ayub, Ali and Wagner, Alan R.},
booktitle = {Proceedings of ACM Conference (Conference'20)},
doi = {10.1145/3434074.3446357},
eprint = {2101.10509},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ayub, Wagner - 2021 - Continual Learning of Visual Concepts for Robots through Limited Supervision.pdf:pdf},
isbn = {9781450382908},
keywords = {continual learning,robotics},
mendeley-tags = {continual learning,robotics},
number = {1},
publisher = {Association for Computing Machinery},
title = {{Continual Learning of Visual Concepts for Robots through Limited Supervision}},
url = {http://arxiv.org/abs/2101.10509},
volume = {1},
year = {2021}
}
@inproceedings{Patrick,
abstract = {In the image domain, excellent representations can be learned by inducing invariance to content-preserving transformations via noise contrastive learning. In this paper, we generalize contrastive learning to a wider set of transformations , and their compositions, for which either invariance or distinctiveness is sought. We show that it is not immediately obvious how existing methods such as SimCLR can be extended to do so. Instead, we introduce a number of formal requirements that all contrastive formulations must satisfy, and propose a practical construction which satisfies these requirements. In order to maximise the reach of this analysis, we express all components of noise contrastive formulations as the choice of certain generalized transformations of the data (GDTs), including data sampling. We then consider videos as an example of data in which a large variety of transformations are applicable, accounting for the extra modalities-for which we analyze audio and text-and the dimension of time. We find that being invariant to certain transformations and distinctive to others is critical to learning effective video representations, improving the state-of-the-art for multiple benchmarks by a large margin , and even surpassing supervised pretraining. Code and pretrained models are available 1 .},
author = {Patrick, Mandela and Asano, Yuki M and Vedaldi, Andrea},
booktitle = {International Conference on Computer Vision},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Patrick, Asano, Vedaldi - 2021 - On Compositions of Transformations in Contrastive Self-Supervised Learning.pdf:pdf},
keywords = {contrastive learning,self-supervised learning},
mendeley-tags = {contrastive learning,self-supervised learning},
pages = {9577--9587},
title = {{On Compositions of Transformations in Contrastive Self-Supervised Learning}},
volume = {1},
year = {2021}
}
@article{Munyazikwiye2017,
abstract = {In this paper, a mathematical model for vehicle-to-vehicle frontal crash is developed. The experimental data are taken from the National Highway Traffic Safety Administration. To model the crash scenario, the two vehicles are represented by two masses moving in opposite directions. The front structures of the vehicles are modeled by Kelvin elements, consisting of springs and dampers in parallel, and estimated as piecewise linear functions of displacements and velocities, respectively. To estimate and optimize the model parameters, a genetic algorithm approach is proposed. Finally, it is observed that the developed model can accurately reproduce the real kinematic results from the crash test.},
author = {Munyazikwiye, Bernard B and Karimi, Hamid Reza and Robbersmyr, Kjell G and Munyazikwiye, B B},
doi = {10.1109/ACCESS.2017.2671357},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Munyazikwiye et al. - 2017 - SPECIAL SECTION ON RECENT ADVANCES ON MODELLING, OPTIMIZATION, AND SIGNAL PROCESSING METHODS IN VEHICLE DYN.pdf:pdf},
keywords = {INDEX TERMS Modeling,genetic algorithm,parameters estimation,vehicle-to-vehicle crash},
pages = {3131--3138},
title = {{SPECIAL SECTION ON RECENT ADVANCES ON MODELLING, OPTIMIZATION, AND SIGNAL PROCESSING METHODS IN VEHICLE DYNAMICS AND CRASH-WORTHINESS Optimization of Vehicle-to-Vehicle Frontal Crash Model Based on Measured Data Using Genetic Algorithm}},
year = {2017}
}
@article{Lee2019,
abstract = {Lifelong learning with deep neural networks is well-known to suffer from catastrophic forgetting: The performance on previous tasks drastically degrades when learning a new task. To alleviate this effect, we propose to leverage a large stream of unlabeled data easily obtainable in the wild. In particular, we design a novel class-incremental learning scheme with (a) a new distillation loss, termed global distillation, (b) a learning strategy to avoid overfitting to the most recent task, and (c) a confidence-based sampling method to effectively leverage unlabeled external data. Our experimental results on various datasets, including CIFAR and ImageNet, demonstrate the superiority of the proposed methods over prior methods, particularly when a stream of unlabeled data is accessible: Our method shows up to 15.8% higher accuracy and 46.5% less forgetting compared to the state-of-the-art method. The code is available at https://github.com/kibok90/iccv2019-inc.},
annote = {
},
archivePrefix = {arXiv},
arxivId = {1903.12648},
author = {Lee, Kibok and Lee, Kimin and Shin, Jinwoo and Lee, Honglak},
doi = {10.1109/ICCV.2019.00040},
eprint = {1903.12648},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee et al. - 2019 - Overcoming catastrophic forgetting with unlabeled data in the wild.pdf:pdf},
isbn = {9781728148038},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
keywords = {continual learning,incremental learning,knowledge distillation,unlabeled data},
mendeley-tags = {continual learning,incremental learning,knowledge distillation,unlabeled data},
pages = {312--321},
title = {{Overcoming catastrophic forgetting with unlabeled data in the wild}},
url = {https://github.com/kibok90/iccv2019-inc},
volume = {2019-Octob},
year = {2019}
}
@article{ForouzandehShahraki2014,
abstract = {In this paper, we present an improved general methodology including four stages to design robust and reliable products under uncertainties. First, as the formulation stage, we consider reliability and robustness simultaneously to propose the new formulation of reliability-based robust design optimization (RBRDO) problems. In order to generate reliable and robust Pareto-optimal solutions, the combination of genetic algorithm with reliability assessment loop based on the performance measure approach is applied as the second stage. Next, we develop two criteria to select a solution from obtained Pareto-optimal set to achieve the best possible implementation. Finally, the result verification is performed with Monte Carlo Simulations and also the quality improvement during manufacturing process is considered by identifying and controlling the critical variables. The effectiveness and applicability of this new proposed methodology is demonstrated through a case study. {\textcopyright} 2014 Elsevier Ltd. All rights reserved.},
author = {{Forouzandeh Shahraki}, Ameneh and Noorossana, Rassoul},
doi = {10.1016/j.cie.2014.05.013},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Forouzandeh Shahraki, Noorossana - 2014 - Reliability-based robust design optimization A general methodology using genetic algorithm.pdf:pdf},
issn = {03608352},
journal = {Computers and Industrial Engineering},
keywords = {Genetic algorithm,Most probable point,Multi-objective optimization,Process capability index,Reliability-based robust design optimization},
number = {1},
pages = {199--207},
publisher = {Elsevier Ltd},
title = {{Reliability-based robust design optimization: A general methodology using genetic algorithm}},
url = {http://dx.doi.org/10.1016/j.cie.2014.05.013},
volume = {74},
year = {2014}
}
@book{Uchino2010b,
abstract = {After the material designing such as solid solution compositions and dopants, we need to consider material fabrication processes. The fabrication of piezoelectric ceramic devices generally involves two steps: preparation of the ceramic powders and sintering of the shaped structures. Wet chemical preparation methods are utilized for producing the ceramic powders in order to ensure reproducibility of the advanced characteristics of the devices. Popular device designs include multilayers, bimorphs and other composite types. Necessary basic knowledge of particle size and film thickness effect on ferroelectricity will also be discussed in conjunction with micro/nano technologies in this chapter. {\textcopyright} 2010 Woodhead Publishing Limited All rights reserved.},
author = {Uchino, Kenji},
booktitle = {Advanced Piezoelectric Materials: Science and Technology},
doi = {10.1533/9781845699758.2.349},
edition = {2},
isbn = {9781845695347},
keywords = {Bimorph,Calcination,Composite,Dopant,Multilayer,Particle size,Sintering,Solid solution},
number = {1},
pages = {349--386},
publisher = {Elsevier Ltd.},
title = {{Manufacturing methods for piezoelectric ceramic materials}},
url = {http://dx.doi.org/10.1016/B978-0-08-102135-4.00010-2},
year = {2010}
}
@article{Chen2017,
abstract = {Despite significant accuracy improvement in convolutional neural networks (CNN) based object detectors, they often require prohibitive runtimes to process an image for real-time applications. State-of-the-art models often use very deep networks with a large number of floating point operations. Efforts such as model compression learn compact models with fewer number of parameters, but with much reduced accuracy. In this work, we propose a new framework to learn compact and fast object detection networks with improved accuracy using knowledge distillation [20] and hint learning [34]. Although knowledge distillation has demonstrated excellent improvements for simpler classification setups, the complexity of detection poses new challenges in the form of regression, region proposals and less voluminous labels. We address this through several innovations such as a weighted cross-entropy loss to address class imbalance, a teacher bounded loss to handle the regression component and adaptation layers to better learn from intermediate teacher distributions. We conduct comprehensive empirical evaluation with different distillation configurations over multiple datasets including PASCAL, KITTI, ILSVRC and MS-COCO. Our results show consistent improvement in accuracy-speed trade-offs for modern multi-class detection models.},
author = {Chen, Guobin and Choi, Wongun and Yu, Xiang and Han, Tony and Chandraker, Manmohan},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2017 - Learning efficient object detection models with knowledge distillation.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {Nips},
pages = {743--752},
title = {{Learning efficient object detection models with knowledge distillation}},
volume = {2017-Decem},
year = {2017}
}
@phdthesis{Kurniawan2018,
author = {Kurniawan, Muhammad Rifki and Arifin, Syamsul and Aisjah, Aulia Siti},
doi = {10.13140/RG.2.2.27518.84803},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kurniawan, Arifin, Aisjah - 2018 - Perancangan Mobile Predictor Cuaca Maritim Menggunakan Metode Hybrid Logika Fuzzy Tipe 2-Jaringan Sya.pdf:pdf},
pages = {1--15},
school = {Institut Teknologi Sepuluh Nopember},
title = {{Perancangan Mobile Predictor Cuaca Maritim Menggunakan Metode Hybrid Logika Fuzzy Tipe 2-Jaringan Syaraf Tiruan dengan Optimasi Algoritma Differential Evolution}},
year = {2018}
}
@article{Liu2016a,
abstract = {We present a method for detecting objects in images using a single deep neural network. Our approach, named SSD, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction time, the network generates scores for the presence of each object category in each default box and produces adjustments to the box to better match the object shape. Additionally, the network combines predictions from multiple feature maps with different resolutions to naturally handle objects of various sizes. Our SSD model is simple relative to methods that require object proposals because it completely eliminates proposal generation and subsequent pixel or feature resampling stage and encapsulates all computation in a single network. This makes SSD easy to train and straightforward to integrate into systems that require a detection component. Experimental results on the PASCAL VOC, MS COCO, and ILSVRC datasets confirm that SSD has comparable accuracy to methods that utilize an additional object proposal step and is much faster, while providing a unified framework for both training and inference. Compared to other single stage methods, SSD has much better accuracy, even with a smaller input image size. For $300\times 300$ input, SSD achieves 72.1% mAP on VOC2007 test at 58 FPS on a Nvidia Titan X and for $500\times 500$ input, SSD achieves 75.1% mAP, outperforming a comparable state of the art Faster R-CNN model. Code is available at https://github.com/weiliu89/caffe/tree/ssd .},
archivePrefix = {arXiv},
arxivId = {arXiv:1512.02325v5},
author = {Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng Yang and Berg, Alexander C.},
doi = {10.1007/978-3-319-46448-0_2},
eprint = {arXiv:1512.02325v5},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - Unknown - SSD Single Shot MultiBox Detector.pdf:pdf},
isbn = {9783319464473},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Convolutional neural network,Real-time object detection},
pages = {21--37},
title = {{SSD: Single shot multibox detector}},
volume = {9905 LNCS},
year = {2016}
}
@article{Arifin2019a,
abstract = {The object the research is to forecast maritime weather variables such wind speed and direction, temperature and wave height for an hour ahead by using artificial intelligence approach. Artificial intelligence is comprised of hybrid neural networks modified by genetic algorithms and particle swarm optimization which are functioned as a model predictor. The hybrid predictor works on every single predictor by weighing both artificial neural network-genetic algorithm (ANN-GA) and artificial neural network-particle swarm optimization (ANN-PSO) which weight is calculated by differential evolution algorithm optimization. When the unsurpassed model is obtained, it will be validated across real-time data that is delivered from type II buoyweather station measurement at the Madura Strait, Java Sea. The prediction results of learning and validation process indicate that the ANN-Hybrid predictor perform more accurate than the ANN-GA and ANN PSO on training and validation. However, the gap of RMSE on real-time test is relatively high compared to validation or training. It can be influenced by the different frequent of weather fluctuation between them. Concurring to real-time test stage, the foremost appropriate variable that predicted by this ANN-Hybrid is temperature.},
author = {Arifin, Syamsul and Mahistha, Dvitiya Srestha Prajna and Ukhti, Magfiroh Fatwaning and Kurniawan, Muhammad Rifki and Aisjah, Aulia Siti},
doi = {10.1063/1.5095287},
journal = {AIP Conference Proceedings },
keywords = {Artificial intelligence,Artificial neural networks,Mathematical optimization,Weather forecasting},
mendeley-tags = {Artificial intelligence,Artificial neural networks,Mathematical optimization,Weather forecasting},
pages = {020035},
title = {{Optimization of neural network based on hybrid method of genetic algorithm and particle swarm optimization for maritime weather forecasting in buoyweather station type II}},
url = {http://aip.scitation.org/doi/abs/10.1063/1.5095287},
volume = {2088},
year = {2019}
}
@article{Wang2015,
abstract = {fuzzy inference process. It is aimed at making the black box of fuzzy inference system to be transparent by adjusting the membership functions to control the relations between input and output variables. Systematic trial and error is implemented based on the Fuzzy Logic Toolbox from MATLAB, and conclusions developed from experiments help eliminate the uncertainties of membership functions, so that the inference process turns to be more precise and reliable. Firstly, Single-Input Single-Output (SISO) Fuzzy Inference System is discussed through the adjustment of membership functions, and the influence on input- output relations are concluded. Next, Two-Input Single-Output (TISO) Fuzzy Inference System is simulated to verify the conclusions from SISO Fuzzy Inference System, and general features of membership functions on affecting input-output relation are developed. Then, an approach using weights on input variables, for practical decision-making process, is derived. Finally, a design problem of timing system of automobile engine is chosen as case study to examine the validity of conclusions on practical decision-making problem.},
author = {Wang, Chonghua},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang - 2015 - A Study of Membership Functions on Mamdani-Type Fuzzy Inference S.pdf:pdf},
isbn = {1321537387},
journal = {Theses and Dissertations},
title = {{A Study of Membership Functions on Mamdani-Type Fuzzy Inference S}},
volume = {Paper 1665},
year = {2015}
}
@article{Arani2019,
abstract = {Inspired by trial-to-trial variability in the brain that can result from multiple noise sources, we introduce variability through noise at different levels in a knowledge distillation framework. We introduce "Fickle Teacher" which provides variable supervision signals to the student for the same input. We observe that the response variability from the teacher results in a significant generalization improvement in the student. We further propose "Soft-Randomization" as a novel technique for improving robustness to input variability in the student. This minimizes the dissimilarity between the student's distribution on noisy data with teacher's distribution on clean data. We show that soft-randomization, even with low noise intensity, improves the robustness significantly with minimal drop in generalization. Lastly, we propose a new technique, "Messy-collaboration", which introduces target variability, whereby student and/or teacher are trained with randomly corrupted labels. We find that supervision from a corrupted teacher improves the adversarial robustness of student significantly while preserving its generalization and natural robustness. Our extensive empirical results verify the effectiveness of adding constructive noise in the knowledge distillation framework for improving the generalization and robustness of the model.},
archivePrefix = {arXiv},
arxivId = {1910.05057},
author = {Arani, Elahe and Sarfraz, Fahad and Zonooz, Bahram},
eprint = {1910.05057},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arani, Sarfraz, Zonooz - 2019 - Improving Generalization and Robustness with Noisy Collaboration in Knowledge Distillation.pdf:pdf},
title = {{Improving Generalization and Robustness with Noisy Collaboration in Knowledge Distillation}},
url = {http://arxiv.org/abs/1910.05057},
year = {2019}
}
@article{Fukuda2012,
author = {Fukuda, Hiroshi and Nakatani, Yoshinobu},
doi = {10.1109/TMAG.2012.2197813},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fukuda, Nakatani - 2012 - Recording density limitation explored by headmedia co-optimization using genetic algorithm and gpu-accelerated.pdf:pdf},
issn = {00189464},
journal = {IEEE Transactions on Magnetics},
keywords = {Genetic algorithm (GA),magnetic recording,micromagnetics},
number = {11},
pages = {3895--3898},
title = {{Recording density limitation explored by head/media co-optimization using genetic algorithm and gpu-accelerated LLG}},
volume = {48},
year = {2012}
}
@inproceedings{DelChiaro2020,
abstract = {Research on continual learning has led to a variety of approaches to mitigating catastrophic forgetting in feed-forward classification networks. Until now surprisingly little attention has been focused on continual learning of recurrent models applied to problems like image captioning. In this paper we take a systematic look at continual learning of LSTM-based models for image captioning. We propose an attention-based approach that explicitly accommodates the transient nature of vocabularies in continual image captioning tasks – i.e. that task vocabularies are not disjoint. We call our method Recurrent Attention to Transient Tasks (RATT), and also show how to adapt continual learning approaches based on weight regularization and knowledge distillation to recurrent continual learning problems. We apply our approaches to incremental image captioning problem on two new continual learning benchmarks we define using the MS-COCO and Flickr30 datasets. Our results demonstrate that RATT is able to sequentially learn five captioning tasks while incurring no forgetting of previously learned ones.},
archivePrefix = {arXiv},
arxivId = {2007.06271},
author = {{Del Chiaro}, Riccardo and Twardowski, Bart{\l}omiej and Bagdanov, Andrew D. and van de Weijer, Joost},
booktitle = {Advances in Neural Information Processing Systems},
eprint = {2007.06271},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Del Chiaro et al. - 2020 - RATT Recurrent Attention to Transient Tasks for Continual Image Captioning(2).pdf:pdf},
issn = {23318422},
keywords = {captioning,continual learning,image captioning,incremental learning},
mendeley-tags = {captioning,continual learning,image captioning,incremental learning},
title = {{RATT: Recurrent Attention to Transient Tasks for Continual Image Captioning}},
year = {2020}
}
@article{Andrzej1999,
author = {Andrzej, Osyczka and Stanislaw, Krenich},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Andrzej, Stanislaw - 1999 - A new constraint tournament selection method for multicriteria optimization using genetic algorithm.pdf:pdf},
isbn = {0780363752},
journal = {Evolutionary Computation, 2000. Proceedings of the 2000 Congress on (Volume:1 )},
keywords = {function approach we waste,genetic algorithm,multicriteria optimization,nonlinear,programming,tournament selection,using a typical panelty},
pages = {501--508},
title = {{A new constraint tournament selection method for multicriteria optimization using genetic algorithm}},
year = {1999}
}
@article{Balaji2020,
abstract = {We study continual learning in the large scale setting where tasks in the input sequence are not limited to classification, and the outputs can be of high dimension. Among multiple state-of-the-art methods, we found vanilla experience replay (ER) still very competitive in terms of both performance and scalability, despite its simplicity. However, a degraded performance is observed for ER with small memory. A further visualization of the feature space reveals that the intermediate representation undergoes a distributional drift. While existing methods usually replay only the input-output pairs, we hypothesize that their regularization effect is inadequate for complex deep models and diverse tasks with small replay buffer size. Following this observation, we propose to replay the activation of the intermediate layers in addition to the input-output pairs. Considering that saving raw activation maps can dramatically increase memory and compute cost, we propose the Compressed Activation Replay technique, where compressed representations of layer activation are saved to the replay buffer. We show that this approach can achieve superior regularization effect while adding negligible memory overhead to replay method. Experiments on both the large-scale Taskonomy benchmark with a diverse set of tasks and standard common datasets (Split-CIFAR and Split-miniImageNet) demonstrate the effectiveness of the proposed method.},
archivePrefix = {arXiv},
arxivId = {2010.02418},
author = {Balaji, Yogesh and Farajtabar, Mehrdad and Yin, Dong and Mott, Alex and Li, Ang},
eprint = {2010.02418},
issn = {23318422},
journal = {arXiv},
keywords = {continual learning,large-scale,memory-replay,rehearsal,replay},
mendeley-tags = {continual learning,large-scale,memory-replay,rehearsal,replay},
pages = {1--15},
title = {{The Effectiveness of Memory Replay in Large Scale Continual Learning}},
year = {2020}
}
@article{Averkin2017,
author = {Averkin, Alexey N},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Averkin - 2017 - Hybrid Approach for Time Series Forecasting Based on ANFIS and Fuzzy Cognitive Maps.pdf:pdf},
isbn = {9781538618103},
keywords = {anfis,cognitive forecasting,cognitive maps,forecasting,hybrid models,series,time},
number = {17},
pages = {379--381},
title = {{Hybrid Approach for Time Series Forecasting Based on ANFIS and Fuzzy Cognitive Maps}},
year = {2017}
}
@article{Schmidt2010,
abstract = {Note: Eric Schmidt is Chair and CEO of Google. Chohen is Director of Google Ideas. There is good and bad in the Internet. Connections for texting and quick communications, even secure communicaitons is growing and used by both parties.\n\nIndependent ideas spread my cell phone can disrupt governments.},
author = {Schmidt, Eric and Cohen, Jared},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schmidt, Cohen - 2010 - The Digital Disruption Battlefield.pdf:pdf},
issn = {00157120},
journal = {Foreign Affairs},
keywords = {Political Science},
number = {6},
pages = {75--84},
title = {{The Digital Disruption Battlefield}},
volume = {89},
year = {2010}
}
@article{Dijk2009,
abstract = {The 24-hour (h) lightdark (LD) cycle is a fundamental characteristic of Earth's environment and so its powerful influence on the behaviour and physiology of animals and humans that evolved on this planet is not surprising. In addition to influencing the perception of visual images, light coordinates the temporal rhythms of physiology and behaviour by sending signals to structures in the brain that contain the central circadian clock. These signals are mediated in part by melanopsin, a photopigment found in the retina. Light affects the brain through these nonvisual pathways, and scientists have recently begun to realize just how pervasive these nonvisual effects are. Mounting evidence supports the view that the effects of light on sleep and brain activity during wakefulness, as well as the duration of sleep and the homeostatic response to sleep loss, depend on both melanopsin and circadian time.},
author = {Dijk, Derk-Jan and Archer, Simon N.},
doi = {10.1371/journal.pbio.1000145},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dijk, Archer - 2009 - Light, Sleep, and Circadian Rhythms Together Again.pdf:pdf},
isbn = {doi:10.1371/journal.pbio.1000145},
issn = {1545-7885},
journal = {PLoS Biology},
number = {6},
pages = {e1000145},
pmid = {19547745},
title = {{Light, Sleep, and Circadian Rhythms: Together Again}},
url = {http://dx.plos.org/10.1371/journal.pbio.1000145},
volume = {7},
year = {2009}
}
@article{Wang2019,
abstract = {object detection framework plays crucial role in autonomous driving. In this paper, we introduce the real-time object detection framework called You Only Look Once (YOLOv1) and the related improvements of YOLOv2. We further explore the capability of YOLOv2 by implementing its pre-trained model to do the object detecting tasks in some specific traffic scenes. The four artificially designed traffic scenes include single-car, single-person, frontperson-rearcar and frontcar-rearperson.},
archivePrefix = {arXiv},
arxivId = {1905.04740},
author = {Wang, Shouyu and Tang, Weitao},
eprint = {1905.04740},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Tang - 2019 - Object Detection in Specific Traffic Scenes using YOLOv2.pdf:pdf},
keywords = {autonomous,computer vision,object detection},
title = {{Object Detection in Specific Traffic Scenes using YOLOv2}},
url = {http://arxiv.org/abs/1905.04740},
year = {2019}
}
@article{Chen2020b,
abstract = {As the computing power of modern hardware is increasing strongly, pre-trained deep learning models (e.g., BERT, GPT-3) learned on large-scale datasets have shown their effectiveness over conventional methods. The big progress is mainly contributed to the representation ability of transformer and its variant architectures. In this paper, we study the low-level computer vision task (e.g., denoising, super-resolution and deraining) and develop a new pre-trained model, namely, image processing transformer (IPT). To maximally excavate the capability of transformer, we present to utilize the well-known ImageNet benchmark for generating a large amount of corrupted image pairs. The IPT model is trained on these images with multi-heads and multi-tails. In addition, the contrastive learning is introduced for well adapting to different image processing tasks. The pre-trained model can therefore efficiently employed on desired task after fine-tuning. With only one pre-trained model, IPT outperforms the current state-of-the-art methods on various low-level benchmarks.},
archivePrefix = {arXiv},
arxivId = {2012.00364},
author = {Chen, Hanting and Wang, Yunhe and Guo, Tianyu and Xu, Chang and Deng, Yiping and Liu, Zhenhua and Ma, Siwei and Xu, Chunjing and Xu, Chao and Gao, Wen},
eprint = {2012.00364},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2020 - Pre-Trained Image Processing Transformer.pdf:pdf},
title = {{Pre-Trained Image Processing Transformer}},
url = {http://arxiv.org/abs/2012.00364},
year = {2020}
}
@article{Tao2020,
abstract = {A well-known issue for class-incremental learning is the catastrophic forgetting phenomenon, where the network's recognition performance on old classes degrades severely when incrementally learning new classes. To alleviate forgetting, we put forward to preserve the old class knowledge by maintaining the topology of the network's feature space. On this basis, we propose a novel topology-preserving class-incremental learning (TPCIL) framework. TPCIL uses an elastic Heb-bian graph (EHG) to model the feature space topology, which is constructed with the competitive Hebbian learning rule. To maintain the topology, we develop the topology-preserving loss (TPL) that penalizes the changes of EHG's neighboring relationships during incremental learning phases. Comprehensive experiments on CIFAR100, ImageNet, and subImageNet datasets demonstrate the power of the TPCIL for continuously learning new classes with less forgetting. The code will be released.},
author = {Tao, Xiaoyu and Chang, Xinyuan and Hong, Xiaopeng and Wei, Xing},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tao et al. - 2020 - Topology-Preserving Class-Incremental Learning.pdf:pdf},
journal = {European Conference on Computer Vision},
keywords = {cil,class-incremental learning,ehg,elastic hebbian graph,preserving loss,topology-,topology-preserving class-incremental learning,tpcil,tpl},
number = {Cil},
title = {{Topology-Preserving Class-Incremental Learning}},
year = {2020}
}
@article{Devlin2018,
abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
author = {Devlin, Jacob and Chang, Ming Wei and Lee, Kenton and Toutanova, Kristina},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Devlin et al. - 2018 - BERT Pre-training of deep bidirectional transformers for language understanding.pdf:pdf},
journal = {arXiv},
pages = {4171--4186},
title = {{BERT: Pre-training of deep bidirectional transformers for language understanding}},
url = {https://github.com/google-research/bert https://arxiv.org/abs/1810.04805},
year = {2018}
}
@article{Makarynskyy2004,
abstract = {Accurate predictions of wind waves with different lead times are necessary for a large scope of coastal and open ocean activities. Attempts to improve wave short-term forecasts based on artificial neural networks are reported. Hourly observations of significant wave heights and zero-up-crossing wave periods from two sites offshore the Atlantic and the Irish Sea coasts of Ireland are used to train and validate these networks. Two different approaches are involved. One of them corrects the predictions solely using the initial simulations of the wave parameters with leading times from 1 to 24 h. Another one allows merging the measurements and initial forecasts. The proposed procedures provide satisfactory results at both locations. {\textcopyright} 2003 Elsevier Ltd. All rights reserved.},
author = {Makarynskyy, O.},
doi = {10.1016/j.oceaneng.2003.05.003},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Makarynskyy - 2004 - Improving wave predictions with artificial neural networks.pdf:pdf},
issn = {00298018},
journal = {Ocean Engineering},
keywords = {Buoy observations,Correction,Neural networks,Oceanic,Semi-enclosed sea,Simulation},
number = {5-6},
pages = {709--724},
title = {{Improving wave predictions with artificial neural networks}},
volume = {31},
year = {2004}
}
@article{Mohamed2012a,
abstract = {In the pattern recognition system, there are many methods used. For speech recognition system, Mel Frequency Cepstral Coefficients (MFCC) becomes a popular feature extraction method but it has various weaknesses especially about the accuracy level and the high of result feature dimension of the extraction method. This paper presents the combination of MFCC feature extraction method with Principal Component Analysis (PCA) to improve the accuracy in Indonesian speech recognition system. By combining MFCC and PCA, it was expected to increase the accuracy system and reduce the feature data dimension. The result of MFCC data features extraction added with delta coefficients formed matrix data that later would be reduced using PCA. PCA method in the process of data reduction was designed to be two versions. Then the result of PCA reduction data was processed to the classification process using K-Nearest Neighbour (KNN) method. Composing the data was formed from 140 speech data that were recorded from 28 speakers. The research findings showed that adding PCA method version 1 could reduce the feature dimension from 26 to 12 by the same accuracy of speech recognition with the conventional MFCC method without PCA, that is 86.43%. Whereas PCA method version 2 could increase the accuracy of speech recognition from the conventional MFCC method without PCA in increasing from 86.43% to 89.29% and decreasing of the data dimension from 26 to 10 feature dimensions.},
author = {Mohamed, Abdel-rahman and Dahl, George E. and Hinton, Geoffrey},
doi = {10.1109/TASL.2011.2109382},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mohamed, Dahl, Hinton - 2012 - Acoustic Modeling Using Deep Belief Networks.pdf:pdf},
isbn = {978-1-5386-0954-5},
issn = {1558-7916},
journal = {IEEE Transactions on Audio, Speech, and Language Processing},
keywords = {KNN,MFCC,PCA,speech recognition},
month = {jan},
number = {1},
pages = {14--22},
publisher = {IEEE},
title = {{Acoustic Modeling Using Deep Belief Networks}},
url = {https://ieeexplore.ieee.org/document/8350748/ http://ieeexplore.ieee.org/document/5704567/},
volume = {20},
year = {2012}
}
@article{Spivey2012,
abstract = {Solid oxide fuel cells are a promising option for distributed energy stationary power generation that offers efficiencies up to 50 in stand-alone applications, 70 in hybrid gas turbine applications and 80 in cogeneration. To advance SOFC technology sufficiently for widespread market penetration, the SOFC must demonstrate improved cell lifetime from the status quo. Much research has been performed to improve SOFC lifetime using advanced geometries and materials, and in this research, we suggest further improving lifetime by designing an advanced control algorithm based upon preexisting mechanical stress analysis [1]. Control algorithms commonly address SOFC lifetime related operability objectives using unconstrained, SISO control algorithms that seek to minimize thermal transients. While thermal fatigue may be one thermal stress driver, these studies often do not consider maximum radial thermal gradients or critical absolute temperatures in the SOFC. In addition, researchers often discuss hot-spots as a critical lifetime reliability issue, but as previous stress work demonstrates, the minimum cell temperature is the primary thermal stress driver in tubular SOFCs modeled after the Siemens Power Generation, Inc. design. In this work, we present a dynamic, quasi-two-dimensional model for a high-temperature tubular SOFC combined with ejector and prereformer models. The model captures dynamics of critical thermal stress drivers and is used as the physical plant for closed-loop simulations with a constrained, MIMO model predictive control algorithm. Closed-loop simulation results demonstrate effective load-following, operability constraint satisfaction, and disturbance rejection. {\textcopyright} 2012 Elsevier Ltd.},
author = {Spivey, Benjamin J. and Edgar, Thomas F.},
doi = {10.1016/j.jprocont.2012.01.015},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Spivey, Edgar - 2012 - Dynamic modeling, simulation, and MIMO predictive control of a tubular solid oxide fuel cell.pdf:pdf},
isbn = {0959-1524},
issn = {09591524},
journal = {Journal of Process Control},
keywords = {Distributed parameter models,Dynamic simulation,Model predictive control,Multi-input multi-output,Nonlinear programming,Solid oxide fuel cell},
number = {8},
pages = {1502--1520},
publisher = {Elsevier Ltd},
title = {{Dynamic modeling, simulation, and MIMO predictive control of a tubular solid oxide fuel cell}},
url = {http://dx.doi.org/10.1016/j.jprocont.2012.01.015},
volume = {22},
year = {2012}
}
@article{Zhou1994,
abstract = {New methods of optical fuzzy-logic operations and optical fuzzy-controller synthesis are proposed and experimentally demonstrated by use of optical fan-out elements to achieve multiple imaging and polarization-space/aperture data encoding to represent fuzzy variables in optics. Sixteen fuzzy-logic operations between two inputs are achieved by use of a simple polarization-space data-encoding and kernel-operation scheme. In addition, a max-min composition-based fuzzy controller is implemented by use of an aperture-data-encoding and a double-multi-imaging approach. Our systems exhibit a high operation speed, a large information throughput, and a high signal-to-noise ratio.},
author = {Zhou, S M and Wu, W S and Campbell, S and Yeh, P C and Yang, X Y and Liu, H K},
doi = {10.1364/AO.33.005335},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou et al. - 1994 - Optical Implementation of Fuzzy-Set Reasoning.pdf:pdf},
isbn = {0003-6935},
issn = {0003-6935},
journal = {Applied Optics},
keywords = {logic},
number = {23},
pages = {5335--5347},
pmid = {20935924},
title = {{Optical Implementation of Fuzzy-Set Reasoning}},
volume = {33},
year = {1994}
}
@book{Mendel2014,
author = {Mendel, Jerry},
pages = {377},
publisher = {IEEE Press},
title = {{Introduction To Type-2 Fuzzy Logic Control}},
year = {2014}
}
@article{Abadi2016,
abstract = {TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.},
archivePrefix = {arXiv},
arxivId = {1603.04467},
author = {Abadi, Mart{\'{i}}n and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S. and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jia, Yangqing and Jozefowicz, Rafal and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Mane, Dan and Monga, Rajat and Moore, Sherry and Murray, Derek and Olah, Chris and Schuster, Mike and Shlens, Jonathon and Steiner, Benoit and Sutskever, Ilya and Talwar, Kunal and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Viegas, Fernanda and Vinyals, Oriol and Warden, Pete and Wattenberg, Martin and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
eprint = {1603.04467},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abadi et al. - 2016 - TensorFlow Large-Scale Machine Learning on Heterogeneous Distributed Systems.pdf:pdf},
title = {{TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems}},
url = {http://arxiv.org/abs/1603.04467},
year = {2016}
}
@inproceedings{Kim2020a,
abstract = {Continual learning from a sequential stream of data is a crucial challenge for machine learning research. Most studies have been conducted on this topic under the single-label classification setting along with an assumption of balanced label distribution. This work expands this research horizon towards multi-label classification. In doing so, we identify unanticipated adversity innately existent in many multi-label datasets, the long-tailed distribution. We jointly address the two independently solved problems, Catastropic Forgetting and the long-tailed label distribution by first empirically showing a new challenge of destructive forgetting of the minority concepts on the tail. Then, we curate two benchmark datasets, COCOseq and NUS-WIDEseq, that allow the study of both intra- and inter-task imbalances. Lastly, we propose a new sampling strategy for replay-based approach named Partitioning Reservoir Sampling (PRS), which allows the model to maintain a balanced knowledge of both head and tail classes. We publicly release the dataset and the code in our project page.},
archivePrefix = {arXiv},
arxivId = {2009.03632},
author = {Kim, Chris Dongjoo and Jeong, Jinseo and Kim, Gunhee},
booktitle = {ECCV},
doi = {10.1007/978-3-030-58601-0_25},
eprint = {2009.03632},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim, Jeong, Kim - 2020 - Imbalanced Continual Learning with Partitioning Reservoir Sampling.pdf:pdf},
isbn = {9783030586003},
issn = {16113349},
keywords = {Continual learning,Imbalanced learning,Long-tailed distribution,Multi-label classification,Online learning},
pages = {411--428},
title = {{Imbalanced Continual Learning with Partitioning Reservoir Sampling}},
volume = {12358 LNCS},
year = {2020}
}
@article{Efendi2017,
abstract = {The statistical models required the large data in the time series forecasting. While, to forecast the limited data or small data cannot be suggested by using these models. In this paper, we are interested to apply fuzzy random auto-regression model to handle the university enrollment data. The accuracy of the forecasting model can be improved through the left-right procedure. The yearly enrollment data of Alabama University are examined as benchmark data to evaluate the performance of proposed model. The results indicate that the smaller left-right spread of triangular fuzzy number produced the higher forecasting accuracy if compared with the existing models.},
author = {Efendi, Riswan and Samsudin, Noor Azah and Arbaiy, Nureize and Deris, Mustafa Mat},
doi = {10.1109/ISCBI.2017.8053545},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Efendi et al. - 2017 - Fuzzy random auto-regression time series model in enrollment university forecasting.pdf:pdf},
isbn = {9781538617717},
journal = {5th International Symposium on Computational and Business Intelligence, ISCBI 2017},
keywords = {auto-regression model,component,enrollment,fuzzy random variable,left-right procedure},
pages = {61--64},
title = {{Fuzzy random auto-regression time series model in enrollment university forecasting}},
year = {2017}
}
@inproceedings{Bender2020,
address = {Stroudsburg, PA, USA},
author = {Bender, Emily M and Koller, Alexander},
booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
doi = {10.18653/v1/2020.acl-main.463},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bender, Koller - 2020 - Climbing towards NLU On Meaning, Form, and Understanding in the Age of Data.pdf:pdf},
number = {2},
pages = {5185--5198},
publisher = {Association for Computational Linguistics},
title = {{Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data}},
url = {https://www.aclweb.org/anthology/2020.acl-main.463},
year = {2020}
}
@article{Tian2020,
abstract = {The focus of recent meta-learning research has been on the development of learning algorithms that can quickly adapt to test time tasks with limited data and low computational cost. Few-shot learning is widely used as one of the standard benchmarks in meta-learning. In this work, we show that a simple baseline: learning a supervised or self-supervised representation on the meta-training set, followed by training a linear classifier on top of this representation, outperforms state-of-the-art few-shot learning methods. An additional boost can be achieved through the use of self-distillation. This demonstrates that using a good learned embedding model can be more effective than sophisticated meta-learning algorithms. We believe that our findings motivate a rethinking of few-shot image classification benchmarks and the associated role of meta-learning algorithms. Code is available at: http://github.com/WangYueFt/rfs/.},
archivePrefix = {arXiv},
arxivId = {2003.11539},
author = {Tian, Yonglong and Wang, Yue and Krishnan, Dilip and Tenenbaum, Joshua B. and Isola, Phillip},
doi = {10.1007/978-3-030-58568-6_16},
eprint = {2003.11539},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tian et al. - 2020 - Rethinking few-shot image classification A good embedding is all you need.pdf:pdf},
journal = {arXiv},
title = {{Rethinking few-shot image classification: A good embedding is all you need?}},
year = {2020}
}
@article{M.N.2013a,
author = {M.N., Noor and Bakri, A.M. Mustafa Al and A.S., Yahaya and N.A., Ramli and N.F.M.Y., Fitri},
keywords = {lognormal distribution,missing values,performance indicators,pm 10},
number = {5},
pages = {336--341},
title = {{Estimation of Missing Values in Environmental Data Set using Interpolation Technique: Fitting on Lognormal Distribution}},
volume = {7},
year = {2013}
}
@article{Fedus2020,
abstract = {Experience replay is central to off-policy algorithms in deep reinforcement learning (RL), but there remain significant gaps in our understanding. We therefore present a systematic and extensive analysis of experience replay in Q-learning methods, focusing on two fundamental properties: the replay capacity and the ratio of learning updates to experience collected (replay ratio). Our additive and ablative studies upend conventional wisdom around experience replay — greater capacity is found to substantially increase the performance of certain algorithms, while leaving others unaffected. Counterintuitively we show that theoretically ungrounded, uncorrected n-step returns are uniquely beneficial while other techniques confer limited benefit for sifting through larger memory. Separately, by directly controlling the replay ratio we contextualize previous observations in the literature and empirically measure its importance across a variety of deep RL algorithms. Finally, we conclude by testing a set of hypotheses on the nature of these performance benefits.},
archivePrefix = {arXiv},
arxivId = {2007.06700},
author = {Fedus, William and Ramachandran, Prajit and Agarwal, Rishabh and Bengio, Yoshua and Larochelle, Hugo and Rowland, Mark and Dabney, Will},
eprint = {2007.06700},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fedus et al. - 2020 - Revisiting Fundamentals of Experience Replay.pdf:pdf},
journal = {arXiv},
keywords = {reinforcement learning},
mendeley-tags = {reinforcement learning},
title = {{Revisiting Fundamentals of Experience Replay}},
year = {2020}
}
@article{Huang2020c,
abstract = {Graph Neural Networks (GNNs) are the predominant technique for learning over graphs. However, there is relatively little understanding of why GNNs are successful in practice and whether they are necessary for good performance. Here, we show that for many standard transductive node classification benchmarks, we can exceed or match the performance of state-of-the-art GNNs by combining shallow models that ignore the graph structure with two simple post-processing steps that exploit correlation in the label structure: (i) an "error correlation" that spreads residual errors in training data to correct errors in test data and (ii) a "prediction correlation" that smooths the predictions on the test data. We call this overall procedure Correct and Smooth (C&S), and the post-processing steps are implemented via simple modifications to standard label propagation techniques from early graph-based semi-supervised learning methods. Our approach exceeds or nearly matches the performance of state-of-the-art GNNs on a wide variety of benchmarks, with just a small fraction of the parameters and orders of magnitude faster runtime. For instance, we exceed the best known GNN performance on the OGB-Products dataset with 137 times fewer parameters and greater than 100 times less training time. The performance of our methods highlights how directly incorporating label information into the learning algorithm (as was done in traditional techniques) yields easy and substantial performance gains. We can also incorporate our techniques into big GNN models, providing modest gains. Our code for the OGB results is at https://github.com/Chillee/CorrectAndSmooth.},
archivePrefix = {arXiv},
arxivId = {2010.13993},
author = {Huang, Qian and He, Horace and Singh, Abhay and Lim, Ser-Nam and Benson, Austin R.},
eprint = {2010.13993},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang et al. - 2020 - Combining Label Propagation and Simple Models Out-performs Graph Neural Networks.pdf:pdf},
keywords = {label propagation},
mendeley-tags = {label propagation},
number = {Figure 1},
title = {{Combining Label Propagation and Simple Models Out-performs Graph Neural Networks}},
url = {http://arxiv.org/abs/2010.13993 https://github.com/CUAI/CorrectAndSmooth},
year = {2020}
}
@article{Chen2014a,
abstract = {In this paper, we present a new method for automatically generating the weather news summary based on fuzzy reasoning and ontology techniques, where the weather ontology, the time ontology and the geography ontology are predefined by domain experts. We slice the original weather news articles into a set of terms. Then, we use two ontological features (i.e., the degree of depth of the ontology and the degree of width of the ontology) and one statistical feature (i.e., frequency) as inputs to the system. The values of those features are represented by fuzzy sets. Then, the fuzzy reasoning algorithm infers the score of each sentence. The summary is composed of candidate sentences which have higher scores, where the experimental data are adopted from the weather news website of Taiwan. The experimental results show that the proposed method outperforms the methods presented in [14,15] for automatically generating the weather news summary. {\textcopyright} 2014 Elsevier Inc. All rights reserved.},
author = {Chen, Shyi Ming and Huang, Ming Hung},
doi = {10.1016/j.ins.2014.04.027},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Huang - 2014 - Automatically generating the weather news summary based on fuzzy reasoning and ontology techniques.pdf:pdf},
isbn = {978-979-756-431-5},
issn = {00200255},
journal = {Information Sciences},
keywords = {Domain ontology,Fuzzy reasoning,Fuzzy rule,Weather news summary},
pages = {746--763},
publisher = {Elsevier Inc.},
title = {{Automatically generating the weather news summary based on fuzzy reasoning and ontology techniques}},
url = {http://dx.doi.org/10.1016/j.ins.2014.04.027},
volume = {279},
year = {2014}
}
@article{Li2021b,
abstract = {Anomaly detection plays a key role in industrial manufacturing for product quality control. Traditional methods for anomaly detection are rule-based with limited generalization ability. Recent methods based on supervised deep learning are more powerful but require large-scale annotated datasets for training. In practice, abnormal products are rare thus it is very difficult to train a deep model in a fully supervised way. In this paper, we propose a novel unsupervised anomaly detection approach based on Self-organizing Map (SOM). Our method, Self-organizing Map for Anomaly Detection (SOMAD) maintains normal characteristics by using topological memory based on multi-scale features. SOMAD achieves state-of the-art performance on unsupervised anomaly detection and localization on the MVTec dataset.},
archivePrefix = {arXiv},
arxivId = {2107.09903},
author = {Li, Ning and Jiang, Kaitao and Ma, Zhiheng and Wei, Xing and Hong, Xiaopeng and Gong, Yihong},
doi = {10.1109/icip42928.2021.9506433},
eprint = {2107.09903},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2021 - Anomaly Detection Via Self-Organizing Map.pdf:pdf},
isbn = {1143958845},
keywords = {anomaly detection,self-organizing map},
mendeley-tags = {anomaly detection,self-organizing map},
pages = {974--978},
title = {{Anomaly Detection Via Self-Organizing Map}},
year = {2021}
}
@article{Velez2017,
abstract = {Collected data from different studies show how users acquire great skills in terms of technology's use, but they don't gain such skills in a safe use of technology. The objective of this study is to identify the level of digital literacy on a sample of teachers and families. It can be observed a lower competence when managing their own identity on the Internet, and in general, lower competences when it comes to take part in conflict situations on the Internet, as well as the ones related to management of digital identity. In terms of children's digital literacy, adults play a very significant role in three main aspects: (1) As direct responsible of their digital literacy. (2) As enablers of behaviour models which promote a positive conviviality and cyber conviviality. (3) As adult referents which children can ask for help.},
author = {V{\'{e}}lez, Alicia Pe{\~{n}}alva and Olivencia, Juan Jos{\'{e}} Leiva and Zuazua, Itziar Irazabal},
doi = {10.1016/j.sbspro.2017.02.124},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/V{\'{e}}lez, Olivencia, Zuazua - 2017 - The Role of Adults in Children Digital Literacy.pdf:pdf},
isbn = {1877-0428},
issn = {18770428},
journal = {Procedia - Social and Behavioral Sciences},
keywords = {digital identity,digital literacy,families,primary education,teachers},
number = {June 2016},
pages = {887--892},
publisher = {Elsevier B.V.},
title = {{The Role of Adults in Children Digital Literacy}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877042817301246},
volume = {237},
year = {2017}
}
@article{Shoup2006,
abstract = {Suppose curb parking is free but all the spaces are occupied, and off-street parking is expensive but immediately available. In this case, you can cruise to find a curb space being vacated by a departing motorist, or pay for off-street parking right away. This paper presents a model of how drivers choose whether to cruise or to pay, and it predicts several results: you are more likely to cruise if curb parking is cheap, off-street parking is expensive, fuel is cheap, you want to park for a long time, you are alone in the car, and you place a low value on saving time. The model also predicts that charging the market price for curb parking-at least equal to the price of adjacent off-street parking-will eliminate cruising. Because the government sets curb parking prices, planners and elected officials strongly influence drivers' decisions to cruise. The failure to charge market rates for curb parking congests traffic, pollutes the air, wastes fuel, and causes accidents. Between 1927 and 2001, studies of cruising in congested downtowns have found that it took between 3.5 and 14 min to find a curb space, and that between 8 and 74 percent of the traffic was cruising for parking. {\textcopyright} 2006 Elsevier Ltd. All rights reserved.},
author = {Shoup, Donald C.},
doi = {10.1016/j.tranpol.2006.05.005},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shoup - 2006 - Cruising for parking.pdf:pdf},
isbn = {0967-070X},
issn = {0967070X},
journal = {Transport Policy},
keywords = {Congestion,Parking,Pricing},
number = {6},
pages = {479--486},
title = {{Cruising for parking}},
volume = {13},
year = {2006}
}
@article{Aslam2007,
abstract = {VTP Working Paper #54},
author = {Aslam, Javed a and Popa, Raluca a and Rivest, Ronald L},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aslam, Popa, Rivest - 2007 - On {E}stimating the {S}ize and {C}onfidence of a {S}tatistical {A}udit.pdf:pdf},
journal = {Proceedings of the USENIX Workshop on Accurate Electronic Voting Technology},
pages = {8},
title = {{On {E}stimating the {S}ize and {C}onfidence of a {S}tatistical {A}udit}},
url = {http://dl.acm.org/citation.cfm?id=1323111.1323119},
year = {2007}
}
@article{Rajabi2019,
abstract = {The main purposes of this study are to distinguish the trends of research in publication exits for the utilisations of the fuzzy expert and knowledge-based systems that is done based on the classification of studies in the last decade. The present investigation covers 60 articles from related scholastic journals, International conference proceedings and some major literature review papers. Our outcomes reveal an upward trend in the up-to-date publications number, that is evidence of growing notoriety on the various applications of fuzzy expert systems. This raise in the reports is mainly in the medical neuro-fuzzy and fuzzy expert systems. Moreover, another most critical observation is that many modern industrial applications are extended, employing knowledge-based systems by extracting the experts' knowledge.},
archivePrefix = {arXiv},
arxivId = {1909.08794},
author = {Rajabi, Mina and Hossani, Saeed and Dehghani, Fatemeh},
eprint = {1909.08794},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rajabi, Hossani, Dehghani - 2019 - A literature review on current approaches and applications of fuzzy expert systems.pdf:pdf},
title = {{A literature review on current approaches and applications of fuzzy expert systems}},
url = {http://arxiv.org/abs/1909.08794},
year = {2019}
}
@article{Koo2017,
abstract = {This paper proposes an improved digital redesign (DR) technique for sampled-data fuzzy controllers in nonlinear systems, based on a Takagi–Sugeno (T–S) fuzzy model. To improve the performance of the DR technique, two methodologies are used: a state-matching error cost function, and a continuous-time fuzzy Lyapunov function. Using these two methodologies, a novel DR technique is proposed to guarantee both the stability and state-matching conditions of the sampled-data fuzzy control system. Further, the proposed DR technique is represented as an optimal problem using the linear matrix inequality (LMI) format. Finally, some simulation examples are provided to verify the effectiveness of the proposed technique in comparison with previous techniques.},
author = {Koo, Geun Bum and Park, Jin Bae and Joo, Young Hoon},
doi = {10.1016/j.ins.2017.04.023},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Koo, Park, Joo - 2017 - An improved digital redesign for sampled-data fuzzy control systems Fuzzy Lyapunov function approach.pdf:pdf},
issn = {00200255},
journal = {Information Sciences},
keywords = {Continuous-time fuzzy Lyapunov function,Digital redesign,Sampled-data fuzzy controller,State-matching error cost function,Takagi–Sugeno fuzzy model},
pages = {71--86},
publisher = {Elsevier Inc.},
title = {{An improved digital redesign for sampled-data fuzzy control systems: Fuzzy Lyapunov function approach}},
volume = {406-407},
year = {2017}
}
@article{Padhia,
author = {Padhi, Radhakant and Du, Y C X},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Padhi, Du - Unknown - Conversion between state space and transfer function representation in linear systems - I.pdf:pdf},
title = {{Conversion between state space and transfer function representation in linear systems - I}}
}
@article{Timon2016,
abstract = {Clustering aims to classify different patterns into groups called clusters. Many algorithms for both hard and fuzzy clustering have been developed to deal with exploratory data analysis in many contexts such as image processing, pattern recognition, etc. However, we are witnessing the era of big data computing where computing resources are becoming the main bottleneck to deal with those large datasets. In this context, sequential algorithms need to be redesigned and even rethought to fully leverage the emergent massively parallel architectures. In this paper, we propose a parallel implementation of the fuzzy minimals clustering algorithm called Parallel Fuzzy Minimal (PFM). Our experimental results reveal linear speed-up of PFM when compared to the sequential counterpart version, keeping very good classification quality.},
author = {Tim{\'{o}}n, Isabel and Soto, Jes{\'{u}}s and P{\'{e}}rez-S{\'{a}}nchez, Horacio and Cecilia, Jos{\'{e}} M.},
doi = {10.1016/j.eswa.2015.11.011},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tim{\'{o}}n et al. - 2016 - Parallel implementation of fuzzy minimals clustering algorithm.pdf:pdf},
isbn = {3496827882},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Fuzzy clustering,Fuzzy minimals,Parallel fuzzy clustering},
pages = {35--41},
title = {{Parallel implementation of fuzzy minimals clustering algorithm}},
volume = {48},
year = {2016}
}
@article{Belouadah2020,
abstract = {Incremental learning is useful if an AI agent needs to integrate data from a stream. The problem is non trivial if the agent runs on a limited computational budget and has a bounded memory of past data. In a deep learning approach, the constant computational budget requires the use of a fixed architecture for all incremental states. The bounded memory generates imbalance in favor of new classes and a prediction bias toward them appears. This bias is commonly countered by introducing a data balancing step in addition to the basic network training. We depart from this approach and propose simple but efficient scaling of past classifiers' weights to make them more comparable to those of new classes. Scaling exploits incremental state statistics and is applied to the classifiers learned in the initial state of classes to profit from all their available data. We also question the utility of the widely used distillation loss component of incremental learning algorithms by comparing it to vanilla fine tuning in presence of a bounded memory. Evaluation is done against competitive baselines using four public datasets. Results show that the classifier weights scaling and the removal of the distillation are both beneficial.},
archivePrefix = {arXiv},
arxivId = {2001.05755},
author = {Belouadah, Eden and Popescu, Adrian},
doi = {10.1109/WACV45572.2020.9093562},
eprint = {2001.05755},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Belouadah, Popescu - 2020 - ScaIL Classifier weights scaling for class incremental learning.pdf:pdf},
isbn = {9781728165530},
journal = {Proceedings - 2020 IEEE Winter Conference on Applications of Computer Vision, WACV 2020},
pages = {1255--1264},
title = {{ScaIL: Classifier weights scaling for class incremental learning}},
year = {2020}
}
@article{Chen2021b,
abstract = {In this paper, we aim to improve the data efficiency of image captioning. We propose VisualGPT, a data-efficient image captioning model that leverages the linguistic knowledge from a large pretrained language model (LM). A crucial challenge is to balance between the use of visual information in the image and prior linguistic knowledge acquired from pretraining.We designed a novel self-resurrecting encoder-decoder attention mechanism to quickly adapt the pretrained LM as the language decoder on a small amount of in-domain training data. The pro-posed self-resurrecting activation unit produces sparse activations but is not susceptible to zero gradients. When trained on 0.1%, 0.5% and 1% of MSCOCO and Conceptual Captions, the proposed model, VisualGPT, surpasses strong image captioning baselines. VisualGPT outperforms the best baseline model by up to 10.8% CIDEr on MS COCO and up to 5.4% CIDEr on Conceptual Captions.We also perform a series of ablation studies to quantify the utility of each system component. To the best of our knowledge, this is the first work that improves data efficiency of image captioning by utilizing LM pretrained on unimodal data. Our code is available at: https://github.com/Vision-CAIR/VisualGPT.},
archivePrefix = {arXiv},
arxivId = {2102.10407},
author = {Chen, Jun and Guo, Han and Yi, Kai and Li, Boyang and Elhoseiny, Mohamed},
eprint = {2102.10407},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2021 - VisualGPT Data-efficient Image Captioning by Balancing Visual Input and Linguistic Knowledge from Pretraining.pdf:pdf},
keywords = {computer vision,image captioning},
mendeley-tags = {computer vision,image captioning},
title = {{VisualGPT: Data-efficient Image Captioning by Balancing Visual Input and Linguistic Knowledge from Pretraining}},
url = {http://arxiv.org/abs/2102.10407},
year = {2021}
}
@article{Taskin2015,
author = {Taskin, Ahmet and Kumbasar, Tufan},
doi = {10.1109/SSCI.2015.220},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Taskin, Kumbasar - 2015 - An Open Source MatlabSimulink Toolbox for Interval Type-2 Fuzzy Logic Systems.pdf:pdf},
isbn = {978-1-4799-7560-0},
journal = {2015 IEEE Symposium Series on Computational Intelligence},
pages = {1561--1568},
title = {{An Open Source Matlab/Simulink Toolbox for Interval Type-2 Fuzzy Logic Systems}},
url = {http://ieeexplore.ieee.org/document/7376796/},
year = {2015}
}
@article{Jevons1931,
abstract = {Purpose – This paper aims to trace the history, application areas and users of Classical Analytics and Big Data Analytics. Design/methodology/approach – The paper discusses different types of Classical and Big Data Analytical techniques and application areas from the early days to present day. Findings – Businesses can benefit from a deeper understanding of Classical and Big Data Analytics to make better and more informed decisions. Originality/value – This is a historical perspective from the early days of analytics to present day use of analytics.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Jevons, H. Stanley},
doi = {10.2307/2224131},
eprint = {arXiv:1011.1669v3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jevons - 1931 - The Second Industrial Revolution.pdf:pdf},
isbn = {0920130437},
issn = {00130133},
journal = {The Economic Journal},
number = {161},
pages = {1},
pmid = {1650590391},
title = {{The Second Industrial Revolution}},
url = {http://www.jstor.org/stable/10.2307/2224131?origin=crossref},
volume = {41},
year = {1931}
}
@article{Rajpurkar2016,
abstract = {We present the Stanford Question Answering Dataset (SQuAD), a new reading comprehension dataset consisting of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage. We analyze the dataset to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees. We build a strong logistic regression model, which achieves an F1 score of 51.0%, a significant improvement over a simple baseline (20%). However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research. The dataset is freely available at https://stanford-qa.com.},
archivePrefix = {arXiv},
arxivId = {1606.05250},
author = {Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},
doi = {10.18653/v1/d16-1264},
eprint = {1606.05250},
file = {:home/user/Downloads/D16-1264.pdf:pdf},
isbn = {9781945626258},
journal = {EMNLP 2016 - Conference on Empirical Methods in Natural Language Processing, Proceedings},
keywords = {nlp,question answering},
mendeley-tags = {nlp,question answering},
pages = {2383--2392},
title = {{SQuad: 100,000+ questions for machine comprehension of text}},
year = {2016}
}
@article{Liu,
archivePrefix = {arXiv},
arxivId = {arXiv:1512.02325v5},
author = {Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-yang and Berg, Alexander C},
eprint = {arXiv:1512.02325v5},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - Unknown - SSD Single Shot MultiBox Detector.pdf:pdf},
keywords = {convolutional neural network,real-time object detection},
title = {{SSD : Single Shot MultiBox Detector}}
}
@phdthesis{AlessioTonioni2019,
author = {{Alessio Tonioni}},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alessio Tonioni - 2019 - Computer Vision and Deep Learning for Retail Store Management.pdf:pdf},
title = {{Computer Vision and Deep Learning for Retail Store Management}},
year = {2019}
}
@article{Bates1969b,
author = {Bates, J. M. and Granger, C. W. J.},
journal = {Operational Research Society},
number = {4},
pages = {451--468},
title = {{The Combination of Forecasts}},
volume = {20},
year = {1969}
}
@article{Sajithabanu2017,
abstract = {{\textcopyright} 2016 IEEE. Use of cloud computing technology and its services have pawed its way into many applications and this is also true in case of Content Delivery Networks. The storage services of cloud environment are replacing the traditional Content Delivery Networks for more reliability and easy availability of contents to users. Most research in Content Delivery Networks mainly focuses on delivering contents to the users with less latency and traffic cost. Apart from this the overall cost incurred for the content providers in cases of bandwidth and storage should also be taken into consideration. Most existing Content Delivery Networks focus only on the bandwidth and in some cases latency. In this paper a novel Content Delivery Model is proposed that makes use of a Genetic Optimization Algorithm (GOA) combined with an efficient storage model that can achieve better content placement and delivery in Cloud based Content Delivery Networks. The proposed approach updates itself dynamically to avoid unwanted use of storage that achieves a much better placement of contents thus reducing the storage cost.},
author = {Sajithabanu, S. and Balasundaram, S.R.},
doi = {10.1109/ANTS.2016.7947822},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sajithabanu, Balasundaram - 2017 - Cloud based Content Delivery Network using Genetic Optimization Algorithm for storage cost.pdf:pdf},
isbn = {9781509021932},
journal = {2016 IEEE International Conference on Advanced Networks and Telecommunications Systems, ANTS 2016},
keywords = {Cloud Computing,Content Delivery Network,Genetic Algorithm,Optimization},
title = {{Cloud based Content Delivery Network using Genetic Optimization Algorithm for storage cost}},
year = {2017}
}
@article{Yang2020b,
abstract = {Modern object detection methods based on convolutional neural network suffer from severe catastrophic forgetting in learning new classes without original data. Due to time consumption, storage burden and privacy of old data, it is inadvisable to train the model from scratch with both old and new data when new object classes emerge after the model trained. In this paper, we propose a novel incremental object detector based on Faster R-CNN to continuously learn from new object classes without using old data. It is a triple network where an old model and a residual model as assistants for helping the incremental model learning on new classes without forgetting the previous learned knowledge. To better maintain the discrimination of features between old and new classes, the residual model is jointly trained on new classes in the incremental learning procedure. In addition, a corresponding distillation scheme is designed to guide the training process, which consists of a two-level residual distillation loss and a joint classification distillation loss. Extensive experiments on VOC2007 and COCO are conducted, and the results demonstrate that the proposed method can effectively learn to incrementally detect objects of new classes, and the problem of catastrophic forgetting is mitigated in this context.},
archivePrefix = {arXiv},
arxivId = {2007.13428},
author = {Yang, Dongbao and Zhou, Yu and Wu, Dayan and Ma, Can and Yang, Fei and Wang, Weiping},
eprint = {2007.13428},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2020 - Two-level residual distillation based triple network for incremental object detection.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {Distillation,Incremental learning,Object detection,continual learning,incremental learning,object detection},
mendeley-tags = {continual learning,incremental learning,object detection},
number = {1},
pages = {1--15},
title = {{Two-level residual distillation based triple network for incremental object detection}},
volume = {1},
year = {2020}
}
@article{Chitra2015a,
abstract = {This paper was an attempt to apply Auto-Regressive Integrated Moving Average (ARIMA) model in Supply Chain management (SCM) of fresh vegetables analysis using SPSS Software.The ARIMA methodology developed by Box and Jenkins was used in this paper. Time Series refers an ordered sequence of values of a variable at equally spaced time intervals. Time series occur frequently when looking at agricultural data applications. The analysis was carried out using time series data on the supply of fresh vegetables during the period from 2002 to 2011 which was collected from the office of the Deputy Directorate of Agri-business situated at Madurai, India. The analysis of monthly supply and price of vegetables data was used to find out seasonal pattern. The seasonal index for vegetable supply was highest in March and April and was lower in the November and December. The seasonal variation in vegetables price was high in the period of November to January and price low in March. It was further inferred that forecast value for the supply of fresh brinjal , Bhendi and Green Chilly was low in January'13 and it was high in December for these vegetables whereas in the forecasted value for the supply of fresh tomato and green chilly variations were found. The study suggested that cold storage capacities may be developed in the needy places to increase the benefits of consumers and farmers to increase the efficiency of Supply Chain Management.},
author = {Chitra, N and Shanmathi, Ra and Rajesh, R},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chitra, Shanmathi, Rajesh - 2015 - Application of ARIMA Model Using SPSS Software - A Case Study in Supply Chain Management.pdf:pdf},
journal = {International Journal of Science Technology & Management},
keywords = {auto-regressive integrated moving average,model,seasonal index,spss software,supply chain management,time series analysis},
number = {01},
pages = {206--215},
title = {{Application of ARIMA Model Using SPSS Software - A Case Study in Supply Chain Management}},
url = {www.ijstm.com},
year = {2015}
}
@article{Weber2014,
abstract = {Polymer-electrolyte fuel cells are a promising energy-conversion technology. Over the last several decades significant progress has been made in increasing their performance and durability, of which continuum-level modeling of the transport processes has played an integral part. In this review, we examine the state-of-the-art modeling approaches, with a goal of elucidating the knowledge gaps and needs going forward in the field. In particular, the focus is on multiphase flow, especially in terms of understanding interactions at interfaces, and catalyst layers with a focus on the impacts of ionomer thin-films and multiscale phenomena. Overall, we highlight where there is consensus in terms of modeling approaches as well as opportunities for further improvement and clarification, including identification of several critical areas for future research.},
author = {Weber, A. Z. and Borup, R. L. and Darling, R. M. and Das, P. K. and Dursch, T. J. and Gu, W. and Harvey, D. and Kusoglu, A. and Litster, S. and Mench, M. M. and Mukundan, R. and Owejan, J. P. and Pharoah, J. G. and Secanell, M. and Zenyuk, I. V.},
doi = {10.1149/2.0751412jes},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Weber et al. - 2014 - A Critical Review of Modeling Transport Phenomena in Polymer-Electrolyte Fuel Cells.pdf:pdf},
isbn = {0013-4651\r1945-7111},
issn = {0013-4651},
journal = {Journal of the Electrochemical Society},
number = {12},
pages = {F1254--F1299},
title = {{A Critical Review of Modeling Transport Phenomena in Polymer-Electrolyte Fuel Cells}},
url = {http://jes.ecsdl.org/cgi/doi/10.1149/2.0751412jes},
volume = {161},
year = {2014}
}
@article{Garg2018,
abstract = {Time-Series data has been of great importance to the research field of prediction models. Over the past two decades, multitudinous fuzzy time series blueprints have been put forth for agricultural yield production. However, most of these predictions were based on 7th interval partitioning. A surprising insight was that nobody gave a sound reason to justify the choice of that particular interval. So, this paper focuses on predicting data values on a large spectrum of fuzzy logic computations based on second and third-degree relationships. This paper showcases work on 4 different types of the fuzzy interval, where each interval is tested with 4 degrees of regression equations. Each of these 16 cases is performed for the fuzzy logic relationship (FLR) 2 and 3 separately. Apart from this, the robustness of algorithm is a testament to an incredible solution for the time series model. In addition to this, A Regression analysis model has been enforced to accomplish the efficient defuzzification operation. To elucidate the process of forecasting, the historical data of wheat yield of University of Agriculture and Technology has been used.},
author = {Garg, Bindu and Aggarwal, Shubham and Sokhal, Jatin},
doi = {10.1016/j.compeleceng.2017.11.015},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garg, Aggarwal, Sokhal - 2018 - Crop yield forecasting using fuzzy logic and regression model.pdf:pdf},
issn = {00457906},
journal = {Computers and Electrical Engineering},
keywords = {Average forecast error rate,Fuzzy time series,Mean Square Error,Prediction,Time series data,Wheat yield},
pages = {383--403},
publisher = {Elsevier Ltd},
title = {{Crop yield forecasting using fuzzy logic and regression model}},
url = {https://doi.org/10.1016/j.compeleceng.2017.11.015},
volume = {67},
year = {2018}
}
@article{Sukhbaatar2015,
abstract = {We introduce a neural network with a recurrent attention model over a possibly large external memory. The architecture is a form of Memory Network [23] but unlike the model in that work, it is trained end-to-end, and hence requires significantly less supervision during training, making it more generally applicable in realistic settings. It can also be seen as an extension of RNNsearch [2] to the case where multiple computational steps (hops) are performed per output symbol. The flexibility of the model allows us to apply it to tasks as diverse as (synthetic) question answering [22] and to language modeling. For the former our approach is competitive with Memory Networks, but with less supervision. For the latter, on the Penn TreeBank and Text8 datasets our approach demonstrates comparable performance to RNNs and LSTMs. In both cases we show that the key concept of multiple computational hops yields improved results.},
archivePrefix = {arXiv},
arxivId = {1503.08895},
author = {Sukhbaatar, Sainbayar and Szlam, Arthur and Weston, Jason and Fergus, Rob},
eprint = {1503.08895},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sukhbaatar et al. - 2015 - End-to-end memory networks.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
keywords = {architecture,memory,memory networks,module,neural networks},
mendeley-tags = {architecture,memory,memory networks,module,neural networks},
pages = {2440--2448},
title = {{End-to-end memory networks}},
url = {https://github.com/facebook/MemNN},
volume = {2015-Janua},
year = {2015}
}
@article{Susanto2015,
author = {Susanto, Heru},
doi = {10.1089/jpm.2008.0228},
title = {{Perancangan Prediktor Cuaca Maritim Menggunakan Adaptive Neuro-Fuzzy Inference System (ANFIS) Sebagai Decision Support Untuk Keselamatan Nelayan}},
url = {http://www.ecu.edu/laupuslibrary/contact.cfm},
year = {2015}
}
@article{Navianti2012b,
author = {Navianti, Dynes Rizky and Widjajati, Farida Agustini and Ngurah, I Gusti and Usadha, Rai and Meteorologi, A Dasar},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Navianti et al. - 2012 - Penerapan Fuzzy Inference System pada Prediksi Curah Hujan di Surabaya Utara.pdf:pdf},
number = {1},
pages = {1--6},
title = {{Penerapan Fuzzy Inference System pada Prediksi Curah Hujan di Surabaya Utara}},
volume = {1},
year = {2012}
}
@article{Topooco2017,
abstract = {Background The integration of digital treatments into national mental health services is on the agenda in the European Union. The E-COMPARED consortium conducted a survey aimed at exploring stakeholders' knowledge, acceptance and expectations of digital treatments for depression, and at identifying factors that might influence their opinions when considering the implementation of these approaches. Method An online survey was conducted in eight European countries: France, Germany, Netherlands, Poland, Spain, Sweden, Switzerland and The United Kingdom. Organisations representing government bodies, care providers, service-users, funding/insurance bodies, technical developers and researchers were invited to participate in the survey. The participating countries and organisations reflect the diversity in health care infrastructures and e-health implementation across Europe. Results A total of 764 organisations were invited to the survey during the period March–June 2014, with 175 of these organisations participating in our survey. The participating stakeholders reported moderate knowledge of digital treatments and considered cost-effectiveness to be the primary incentive for integration into care services. Low feasibility of delivery within existing care services was considered to be a primary barrier. Digital treatments were regarded more suitable for milder forms of depression. Stakeholders showed greater acceptability towards blended treatment (the integration of face-to-face and internet sessions within the same treatment protocol) compared to standalone internet treatments. Organisations in countries with developed e-health solutions reported greater knowledge and acceptability of digital treatments. Conclusion Mental health stakeholders in Europe are aware of the potential benefits of digital interventions. However, there are variations between countries and stakeholders in terms of level of knowledge about such interventions and their feasibility within routine care services. The high acceptance of blended treatments is an interesting finding that indicates a gradual integration of technology into clinical practice may fit the attitudes and needs of stakeholders. The potential of the blended treatment approach, in terms of enhancing acceptance of digital treatment while retaining the benefit of cost-effectiveness in delivery, should be further explored. Funding The E-COMPARED project has received funding from the European Union Seventh Framework Programme (FP7/2007–2013) under grant agreement no. 603098.},
author = {Topooco, Naira and Riper, Heleen and Araya, Ricardo and Berking, Matthias and Brunn, Matthias and Chevreul, Karine and Cieslak, Roman and Ebert, David Daniel and Etchmendy, Ernestina and Herrero, Roc{\'{i}}o and Kleiboer, Annet and Krieger, Tobias and Garc{\'{i}}a-Palacios, Azucena and Cerga-Pashoja, Arlinda and Smoktunowicz, Ewelina and Urech, Antoine and Vis, Christiaan and Andersson, Gerhard},
doi = {10.1016/j.invent.2017.01.001},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Topooco et al. - 2017 - Attitudes towards digital treatment for depression A European stakeholder survey.pdf:pdf},
isbn = {2214-7829},
issn = {22147829},
journal = {Internet Interventions},
keywords = {Blended treatment,Comparative effectiveness research,Depression,Digital treatment,E-mental health,Internet-delivered},
pages = {1--9},
publisher = {The Authors},
title = {{Attitudes towards digital treatment for depression: A European stakeholder survey}},
url = {http://dx.doi.org/10.1016/j.invent.2017.01.001},
volume = {8},
year = {2017}
}
@article{Abati2020,
abstract = {Convolutional Neural Networks experience catastrophic forgetting when optimized on a sequence of learning problems: as they meet the objective of the current training examples, their performance on previous tasks drops drastically. In this work, we introduce a novel framework to tackle this problem with conditional computation. We equip each convolutional layer with task-specific gating modules, selecting which filters to apply on the given input. This way, we achieve two appealing properties. Firstly, the execution patterns of the gates allow to identify and protect important filters, ensuring no loss in the performance of the model for previously learned tasks. Secondly, by using a sparsity objective, we can promote the selection of a limited set of kernels, allowing to retain sufficient model capacity to digest new tasks. Existing solutions require, at test time, awareness of the task to which each example belongs to. This knowledge, however, may not be available in many practical scenarios. Therefore, we additionally introduce a task classifier that predicts the task label of each example, to deal with settings in which a task oracle is not available. We validate our proposal on four continual learning datasets. Results show that our model consistently outperforms existing methods both in the presence and the absence of a task oracle. Notably, on Split SVHN and Imagenet-50 datasets, our model yields up to 23.98% and 17.42% improvement in accuracy w.r.t. competing methods.},
archivePrefix = {arXiv},
arxivId = {2004.00070},
author = {Abati, Davide and Tomczak, Jakub and Blankevoort, Tijmen and Calderara, Simone and Cucchiara, Rita and Bejnordi, Babak Ehteshami},
doi = {10.1109/CVPR42600.2020.00399},
eprint = {2004.00070},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abati et al. - 2020 - Conditional Channel Gated Networks for Task-Aware Continual Learning.pdf:pdf},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
keywords = {architectural,continual learning},
mendeley-tags = {architectural,continual learning},
pages = {3930--3939},
title = {{Conditional Channel Gated Networks for Task-Aware Continual Learning}},
year = {2020}
}
@article{Minhas2017,
author = {Minhas, Daud Mustafa and Khalid, Raja Rehan and Frey, Georg},
doi = {10.1109/PowerAfrica.2017.7991270},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Minhas, Khalid, Frey - 2017 - Short term load forecasting using hybrid adaptive fuzzy neural system The performance evaluation.pdf:pdf},
isbn = {978-1-5090-4746-8},
journal = {2017 IEEE PES PowerAfrica},
pages = {468--473},
title = {{Short term load forecasting using hybrid adaptive fuzzy neural system: The performance evaluation}},
url = {http://ieeexplore.ieee.org/document/7991270/},
year = {2017}
}
@article{Allcott2017,
abstract = {We present new evidence on the role of false stories circulated on social media prior to the 2016 US presidential election. Drawing on audience data, archives of fact-checking websites, and results from a new online survey, we find: (i) social media was an important but not dominant source of news in the run-up to the election, with 14 percent of Americans calling social media their " most important " source of election news; (ii) of the known false news stories that appeared in the three months before the election, those favoring Trump were shared a total of 30 million times on Facebook, while those favoring Clinton were shared eight million times; (iii) the average American saw and remembered 0.92 pro-Trump fake news stories and 0.23 pro-Clinton fake news stories, with just over half of those who recalled seeing fake news stories believing them; (iv) for fake news to have changed the outcome of the election, a single fake article would need to have had the same persuasive effect as 36 television campaign ads.},
archivePrefix = {arXiv},
arxivId = {1704.07506},
author = {Allcott, Hunt and Gentzkow, Matthew},
doi = {10.1257/jep.31.2.211},
eprint = {1704.07506},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Allcott, Gentzkow - 2017 - Social Media and Fake News in the 2016 Election.pdf:pdf},
isbn = {01918869},
issn = {0895-3309},
journal = {Journal of Economic Perspectives},
number = {2},
pages = {211--236},
title = {{Social Media and Fake News in the 2016 Election}},
url = {http://pubs.aeaweb.org/doi/10.1257/jep.31.2.211},
volume = {31},
year = {2017}
}
@article{Xie2020,
abstract = {Contrastive learning methods for unsupervised visual representation learning have reached remarkable levels of transfer performance. We argue that the power of contrastive learning has yet to be fully unleashed, as current methods are trained only on instance-level pretext tasks, leading to representations that may be sub-optimal for downstream tasks requiring dense pixel predictions. In this paper, we introduce pixel-level pretext tasks for learning dense feature representations. The first task directly applies contrastive learning at the pixel level. We additionally propose a pixel-to-propagation consistency task that produces better results, even surpassing the state-of-the-art approaches by a large margin. Specifically, it achieves 60.2 AP, 41.4 / 40.5 mAP and 77.2 mIoU when transferred to Pascal VOC object detection (C4), COCO object detection (FPN / C4) and Cityscapes semantic segmentation using a ResNet-50 backbone network, which are 2.6 AP, 0.8 / 1.0 mAP and 1.0 mIoU better than the previous best methods built on instance-level contrastive learning. Moreover, the pixel-level pretext tasks are found to be effective for pre-training not only regular backbone networks but also head networks used for dense downstream tasks, and are complementary to instance-level contrastive methods. These results demonstrate the strong potential of defining pretext tasks at the pixel level, and suggest a new path forward in unsupervised visual representation learning.},
archivePrefix = {arXiv},
arxivId = {2011.10043},
author = {Xie, Zhenda and Lin, Yutong and Zhang, Zheng and Cao, Yue and Lin, Stephen and Hu, Han},
eprint = {2011.10043},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xie et al. - 2020 - Propagate Yourself Exploring Pixel-Level Consistency for Unsupervised Visual Representation Learning.pdf:pdf},
month = {nov},
title = {{Propagate Yourself: Exploring Pixel-Level Consistency for Unsupervised Visual Representation Learning}},
url = {http://arxiv.org/abs/2011.10043},
year = {2020}
}
@article{Lee2020a,
abstract = {A longstanding goal in deep learning research has been to precisely characterize training and generalization. However, the often complex loss landscapes of neural networks (NNs) have made a theory of learning dynamics elusive. In this work, we show that for wide NNs the learning dynamics simplify considerably and that, in the infinite width limit, they are governed by a linear model obtained from the first-order Taylor expansion of the network around its initial parameters. Furthermore, mirroring the correspondence between wide Bayesian NNs and Gaussian processes (GPs), gradient-based training of wide NNs with a squared loss produces test set predictions drawn from a GP with a particular compositional kernel. While these theoretical results are only exact in the infinite width limit, we nevertheless find excellent empirical agreement between the predictions of the original network and those of the linearized version even for finite practically-sized networks. This agreement is robust across different architectures, optimization methods, and loss functions.},
archivePrefix = {arXiv},
arxivId = {1902.06720},
author = {Lee, Jaehoon and Xiao, Lechao and Schoenholz, Samuel S. and Bahri, Yasaman and Novak, Roman and Sohl-Dickstein, Jascha and Pennington, Jeffrey},
doi = {10.1088/1742-5468/abc62b},
eprint = {1902.06720},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee et al. - 2020 - Wide neural networks of any depth evolve as linear models under gradient descent.pdf:pdf},
issn = {17425468},
journal = {Journal of Statistical Mechanics: Theory and Experiment},
keywords = {machine learning,theory},
mendeley-tags = {theory},
number = {12},
title = {{Wide neural networks of any depth evolve as linear models under gradient descent}},
volume = {2020},
year = {2020}
}
@article{Kuzniar2011a,
abstract = {Two techniques of neural network input data pre-processing are discussed in the paper: (i) data compression with the application of the principal component analysis method, (ii) various forms of data scaling. Neural networks are applied for the prediction of the first natural frequencies of horizontal vibrations of modified medium height load-bearing walls. The small and the large changes of the wall stiffness and mass resulted from the new door openings size and position are taken into account. The influence of the type of data pre-processing technique on the accuracy of the frequencies neural prediction is discussed.},
author = {Ku{\'{z}}niar, Krystyna and Zaj{\c{a}}c, Maciej},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ku{\'{z}}niar, Zaj{\c{a}}c - 2011 - Data pre-processing in the neural network identification of the modified walls natural frequencies.pdf:pdf},
journal = {[Online] CMM-2011 - Computer Methods in Mechanics http://www.cmm.il.pw.edu.pl/cd/pdf/120.pdf},
keywords = {0,11,14m,5 storeys x 2,7m width and 14m,8m,dynamics,height,neural networks,vibrations},
number = {May},
title = {{Data pre-processing in the neural network identification of the modified walls natural frequencies}},
url = {http://www.cmm.il.pw.edu.pl/cd/pdf/120.pdf},
year = {2011}
}
@article{Khan,
author = {Khan, Rahat Nabi and Blackburn, David A and Sequeira, Jean and Rebaylia, Bruno and Sartori, Sergio and Filemon, Elisabeth and Doi, Norihisa and Furukawa, Koichi and Fuchi, Kazuhiro and Boutzev, Christo and Smith, Roger B and Asia, Soviet Central},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khan et al. - Unknown - The third industrial revolution Impact industrial and engineering data.pdf:pdf},
pages = {115--122},
title = {{The third industrial revolution Impact industrial and engineering data}}
}
@article{Tagliaferri2015b,
abstract = {We propose two methods for short term forecasting of wind direction with the aim to provide input for tactic decisions during yacht races. The wind direction measured in the past minutes is used as input and the wind direction for the next two minutes constitutes the output. The two methods are based on artificial neural networks (ANN) and support vector machines (SVM), respectively. For both methods we optimise the length of the moving average that we use to pre-process the input data, the length of the input vector and, for the ANN only, the number of neurons of each layer. The forecast is evaluated by looking at the mean absolute error and at a mean effectiveness index, which assesses the percentage of times that the forecast is accurate enough to predict the correct tactical choice in a sailing yacht race. The ANN forecast based on the ensemble average of ten networks shows a larger mean absolute error and a similar mean effectiveness index than the SVM forecast. However, we showed that the ANN forecast accuracy increases significantly with the size of the ensemble. Therefore increasing the computational power, it can lead to a better forecast.},
author = {Tagliaferri, F. and Viola, I. M. and Flay, R. G J},
doi = {10.1016/j.oceaneng.2014.12.026},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tagliaferri, Viola, Flay - 2015 - Wind direction forecasting with artificial neural networks and support vector machines.pdf:pdf},
isbn = {0029-8018},
issn = {00298018},
journal = {Ocean Engineering},
keywords = {Artificial neural networks,Race,Sailing yacht,Support vector machines,Tactics,Wind forecast},
pages = {65--73},
publisher = {Elsevier},
title = {{Wind direction forecasting with artificial neural networks and support vector machines}},
url = {http://dx.doi.org/10.1016/j.oceaneng.2014.12.026},
volume = {97},
year = {2015}
}
@article{Bliznakova2007,
abstract = {Human skin contains various types of native fluorophores and absorbers with unique absorption and emission spectra, different quantum efficiency, concentration and spatial distribution within the skin. Autofluorescence spectroscopy is applied as diagnostic tool for cutaneous tumor detection that increases the importance of evaluation of natural existing fluorophores and unification of data for given class of pathologies. In the current study, several excitation sources in the region 337–405 nm are applied, to achieve information about typical autofluorescent properties of normal human skin. PACS numbers: 42.72.Bj, 87.15.M–, 87.64.kv},
author = {Bliznakova, I. and Borisova, E. and Avramov, L.},
doi = {10.12693/APhysPolA.112.1131},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bliznakova, Borisova, Avramov - 2007 - Laser- and light-induced autofluorescence spectroscopy of human skin in dependence on excitation.pdf:pdf},
isbn = {0587-4246},
issn = {05874246},
journal = {Acta Physica Polonica A},
number = {5},
pages = {1131--1136},
title = {{Laser- and light-induced autofluorescence spectroscopy of human skin in dependence on excitation wavelengths}},
volume = {112},
year = {2007}
}
@article{Falchi2011,
abstract = {Light pollution is one of the most rapidly increasing types of environmental degradation. Its levels have been growing exponentially over the natural nocturnal lighting levels provided by starlight and moonlight. To limit this pollution several effective practices have been defined: the use of shielding on lighting fixture to prevent direct upward light, particularly at low angles above the horizon; no over lighting, i.e. avoid using higher lighting levels than strictly needed for the task, constraining illumination to the area where it is needed and the time it will be used. Nevertheless, even after the best control of the light distribution is reached and when the proper quantity of light is used, some upward light emission remains, due to reflections from the lit surfaces and atmospheric scatter. The environmental impact of this "residual light pollution", cannot be neglected and should be limited too. Here we propose a new way to limit the effects of this residual light pollution on wildlife, human health and stellar visibility. We performed analysis of the spectra of common types of lamps for external use, including the new LEDs. We evaluated their emissions relative to the spectral response functions of human eye photoreceptors, in the photopic, scotopic and the 'meltopic' melatonin suppressing bands. We found that the amount of pollution is strongly dependent on the spectral characteristics of the lamps, with the more environmentally friendly lamps being low pressure sodium, followed by high pressure sodium. Most polluting are the lamps with a strong blue emission, like Metal Halide and white LEDs. Migration from the now widely used sodium lamps to white lamps (MH and LEDs) would produce an increase of pollution in the scotopic and melatonin suppression bands of more than five times the present levels, supposing the same photopic installed flux. This increase will exacerbate known and possible unknown effects of light pollution on human health, environment and on visual perception of the Universe by humans. We present quantitative criteria to evaluate the lamps based on their spectral emissions and we suggest regulatory limits for future lighting. {\textcopyright} 2011 Elsevier Ltd.},
author = {Falchi, Fabio and Cinzano, Pierantonio and Elvidge, Christopher D. and Keith, David M. and Haim, Abraham},
doi = {10.1016/j.jenvman.2011.06.029},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Falchi et al. - 2011 - Limiting the impact of light pollution on human health, environment and stellar visibility.pdf:pdf},
isbn = {0301-4797},
issn = {03014797},
journal = {Journal of Environmental Management},
keywords = {Health and light at night,Light pollution,Light technology,Sustainable lighting},
number = {10},
pages = {2714--2722},
pmid = {21745709},
publisher = {Elsevier Ltd},
title = {{Limiting the impact of light pollution on human health, environment and stellar visibility}},
url = {http://dx.doi.org/10.1016/j.jenvman.2011.06.029},
volume = {92},
year = {2011}
}
@article{Dekker2010,
abstract = {A recent conversation in the literature asks whether human factors constructs amount to folk modeling or to strong science. In this paper we explore this further in the context of well-known positions on the production of science and scientific rationality. We inquire about the sources of epistemological self-confidence—the extent to which human factors is satisfied with its beliefs and assumptions about how it knows what it knows. We question whether a large body of evidence for a construct is evidence of strong science, or whether critical reflection and skepticism about this is actually what distinguishes scientific knowledge from folk models. We also review pre- sumptions of a-perspectival objectivity, in which researchers believe they are able to take a “view from nowhere” and enjoy an objective window onto an existing reality. Weask whether human factors constructs don't so much reflect but rather create a particular empirical world, which would not even exist without those constructs. This article serves as an invitation to rethink what we mean by epistemological confidence and how we arrive at it.},
author = {Dekker, Sidney W.A. and Nyce, James M. and van Winsen, Roel and Henriqson, Eder},
doi = {10.1518/155534310X495573},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dekker et al. - 2010 - Epistemological Self-Confidence in Human Factors Research.pdf:pdf},
isbn = {1555-3434},
issn = {15553434},
journal = {Journal of Cognitive Engineering and Decision Making},
number = {1},
pages = {27--38},
title = {{Epistemological Self-Confidence in Human Factors Research}},
volume = {4},
year = {2010}
}
@article{Zhang2003,
abstract = {In the present paper, we report on a method to retrieve the pigment concentration in Case I waters from ocean color. The method is derived from radiative transfer (RT) simulations and subsequent application of artificial neural network (ANN) techniques. Information on absorption and total scattering of pure seawater, colored dissolved organic matter, and marine particles are mostly taken from published measurements or parameterizations. Additionally, a new model relating the backscattering of marine particles to pigment concentration and wavelength is introduced. The such defined inherent optical properties are input to a RTcode in order to generate a synthetic data set of remote sensing reflectance spectra. This synthetic data set is then used for the training of a set of ANNs with the aim to approximate the functional relationship between ocean color and pigment concentration. The different ANNs are obtained by systematic variations of input parameters, architecture, and noise level added to the training data. The performance of each individual ANN-based pigment retrieval scheme is assessed by applying it to the remote sensing reflectance spectra contained in the Sea-viewing Wide Field-of-view Sensor (SeaWiFS) Bio-optical Algorithm MiniWorkshop (SeaBAM) data set and comparing the retrieved pigment concentrations to those actually measured. The most successful ANN compares favorably with commonly used empirical pigment retrieval schemes. Compared, e.g., to the SeaWiFS algorithms OC2B and OC4, the square of the correlation coefficient r2 is increased from 0.924 (OC2B), respectively, 0.928 (OC4) to 0.934 (ANN). The root mean square error of the retrieved log-transformed pigment concentration drops from 0.156 for OC2B, respectively, 0.151 for OC4 to 0.148 for the ANN-based pigment retrieval scheme. Furthermore, the latter shows a higher resistance against noisy input data. INDEX},
author = {Zhang, Tinglu},
doi = {10.1029/2002JC001638},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang - 2003 - Evaluating the performance of artificial neural network techniques for pigment retrieval from ocean color in Case I water.pdf:pdf},
isbn = {0148-0227},
issn = {0148-0227},
journal = {Journal of Geophysical Research},
number = {C9},
pages = {3286},
title = {{Evaluating the performance of artificial neural network techniques for pigment retrieval from ocean color in Case I waters}},
url = {http://doi.wiley.com/10.1029/2002JC001638},
volume = {108},
year = {2003}
}
@article{Anonymous2021,
archivePrefix = {arXiv},
arxivId = {arXiv:2012.07463v1},
author = {Anonymous},
eprint = {arXiv:2012.07463v1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Anonymous - 2021 - Parameter-Efficient Transfer Learning with Diff Pruning.pdf:pdf},
journal = {ICLR 2021 Submission},
keywords = {pruning,transfer learning},
mendeley-tags = {pruning,transfer learning},
pages = {1--14},
title = {{Parameter-Efficient Transfer Learning with Diff Pruning}},
year = {2021}
}
@article{DeGirolamo2017,
abstract = {Wave forecasting may represent a useful tool for safety assessment of maritime works and activities. To date, wave forecasting uncertainty is usually corrected by using either the mean calibration factor or the time series method. However, within the frame of maritime work management it is necessary to forecast – with an acceptable probability of error – whether or not the significant wave height at a given location will exceed a prefixed threshold within a specified temporal window, so as to assess the safety of the specified temporal window with respect to the activity to be carried out. The present paper aims to illustrate a general criterion useful to correct wave forecast, i.e. to provide an engineering tool able to assess the safety of the temporal window needed to complete a specified maritime work. The paper provides a detailed description of the method, together with the application to a real case.},
author = {{De Girolamo}, P. and {Di Risio}, M. and Beltrami, G. M. and Bellotti, G. and Pasquali, D.},
doi = {10.1016/j.apor.2016.11.006},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Girolamo et al. - 2017 - The use of wave forecasts for maritime activities safety assessment.pdf:pdf},
issn = {01411187},
journal = {Applied Ocean Research},
keywords = {Maritime activities safety,Probabilistic wave forecasting,Wave forecasting},
pages = {18--26},
publisher = {Elsevier Ltd},
title = {{The use of wave forecasts for maritime activities safety assessment}},
url = {http://dx.doi.org/10.1016/j.apor.2016.11.006},
volume = {62},
year = {2017}
}
@article{Douillard2021a,
abstract = {Deep network architectures struggle to continually learn new tasks without forgetting the previous tasks. A recent trend indicates that dynamic architectures based on an expansion of the parameters can reduce catastrophic forgetting efficiently in continual learning. However, existing approaches often require a task identifier at test-time, need complex tuning to balance the growing number of parameters, and barely share any information across tasks. As a result, they struggle to scale to a large number of tasks without significant overhead. In this paper, we propose a transformer architecture based on a dedicated encoder/decoder framework. Critically, the encoder and decoder are shared among all tasks. Through a dynamic expansion of special tokens, we specialize each forward of our decoder network on a task distribution. Our strategy scales to a large number of tasks while having negligible memory and time overheads due to strict control of the parameters expansion. Moreover, this efficient strategy doesn't need any hyperparameter tuning to control the network's expansion. Our model reaches excellent results on CIFAR100 and state-of-the-art performances on the large-scale ImageNet100 and ImageNet1000 while having less parameters than concurrent dynamic frameworks.},
archivePrefix = {arXiv},
arxivId = {2111.11326},
author = {Douillard, Arthur and Ram{\'{e}}, Alexandre and Couairon, Guillaume and Cord, Matthieu},
eprint = {2111.11326},
file = {:home/user/Downloads/2111.11326.pdf:pdf},
keywords = {continual learning,transformer},
mendeley-tags = {continual learning,transformer},
title = {{DyTox: Transformers for Continual Learning with DYnamic TOken eXpansion}},
url = {http://arxiv.org/abs/2111.11326},
year = {2021}
}
@inproceedings{Riemer2019,
abstract = {Lack of performance when it comes to continual learning over non-stationary distributions of data remains a major challenge in scaling neural network learning to more human realistic settings. In this work we propose a new conceptualization of the continual learning problem in terms of a temporally symmetric trade-off between transfer and interference that can be optimized by enforcing gradient alignment across examples. We then propose a new algorithm, Meta-Experience Replay (MER), that directly exploits this view by combining experience replay with optimization based meta-learning. This method learns parameters that make interference based on future gradients less likely and transfer based on future gradients more likely. We conduct experiments across continual lifelong supervised learning benchmarks and non-stationary reinforcement learning environments demonstrating that our approach consistently outperforms recently proposed baselines for continual learning. Our experiments show that the gap between the performance of MER and baseline algorithms grows both as the environment gets more non-stationary and as the fraction of the total experiences stored gets smaller.},
archivePrefix = {arXiv},
arxivId = {1810.11910},
author = {Riemer, Matthew and Cases, Ignacio and Ajemian, Robert and Liu, Miao and Rish, Irina and Tu, Yuhai and Tesauro, Gerald},
booktitle = {In International Conference on Learning Representations (ICLR)},
eprint = {1810.11910},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Riemer et al. - 2019 - Learning to Learn without Forgetting by Maximizing Transfer and Minimizing Interference.pdf:pdf},
issn = {23318422},
keywords = {continual learning,optimization,rehearsal,replay},
mendeley-tags = {continual learning,optimization,rehearsal,replay},
month = {oct},
title = {{Learning to Learn without Forgetting by Maximizing Transfer and Minimizing Interference}},
url = {http://arxiv.org/abs/1810.11910},
year = {2019}
}
@article{Rahayu1992,
author = {Rahayu, Winniarti Puji and Ma'Oen, S and Suliantari, Fardiaz S},
journal = {Bogor: Pusat Antar Universitas Pangan dan Gizi. IPB},
title = {{Teknologi Fermentasi Produk Perikanan}},
year = {1992}
}
@article{Shi-YuanHan2016,
author = {{Shi-Yuan Han} and {Xiao-Yu Wan} and {Lin Wang} and {Jin Zhou} and {Xiao-Fang Zhong}},
doi = {10.1109/ICCSS.2016.7586422},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shi-Yuan Han et al. - 2016 - Comparison between genetic algorithm and differential evolution algorithm applied to one dimensional bin-pa.pdf:pdf},
isbn = {978-1-5090-3367-6},
journal = {2016 3rd International Conference on Informative and Cybernetics for Computational Social Systems (ICCSS)},
pages = {52--55},
title = {{Comparison between genetic algorithm and differential evolution algorithm applied to one dimensional bin-packing problem}},
url = {http://ieeexplore.ieee.org/document/7586422/},
year = {2016}
}
@article{Khaliq2017a,
abstract = {Piezoelectric composites made from soft and hard lead zirconium titanate (PZT) particles as filler and an epoxy as the matrix were prepared by dielectrophoresis and studied for their piezoelectric properties. It was found that the dielectric constant of the piezoelectric filler plays a significant role in determining the final piezoelectric properties of the composites. Composites with lower dielectric constant for the PZT filler material showed better piezoelectric properties compared to the composites with high dielectric constant filler. This can be ascribed to a more efficient poling of the piezoelectric filler particles. The aging behaviour of these composites was compared to that reported for monolithic ceramics.},
author = {Khaliq, Jibran and Deutz, Daniella Bayle and Frescas, Jesus Alfonso Caraveo and Vollenberg, Peter and Hoeks, Theo and van der Zwaag, Sybrand and Groen, Pim},
doi = {10.1016/j.ceramint.2016.11.108},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khaliq et al. - 2017 - Effect of the piezoelectric ceramic filler dielectric constant on the piezoelectric properties of PZT-epoxy compo.pdf:pdf},
issn = {02728842},
journal = {Ceramics International},
keywords = {Aging rate,Hard/Soft PZT,Piezoelectrics,Structured composites},
number = {2},
pages = {2774--2779},
title = {{Effect of the piezoelectric ceramic filler dielectric constant on the piezoelectric properties of PZT-epoxy composites}},
volume = {43},
year = {2017}
}
@article{Rusu2016a,
abstract = {Learning to solve complex sequences of tasks—while both leveraging transfer and avoiding catastrophic forgetting—remains a key obstacle to achieving human-level intelligence. The progressive networks approach represents a step forward in this direction: they are immune to forgetting and can leverage prior knowledge via lateral connections to previously learned features. We evaluate this architecture extensively on a wide variety of reinforcement learning tasks (Atari and 3D maze games), and show that it outperforms common baselines based on pretraining and ﬁnetuning. Using a novel sensitivity measure, we demonstrate that transfer occurs at both low-level sensory and high-level control layers of the learned policy.},
annote = {The authors rely on a separate feedforward network (column) for each task the model is trained on. Each column is connected through adaptive connections to all the previous ones. The weights of previous columns are frozen once trained. At inference time, given a known task label, the network choose the appropriate column to produce the output, thus preventing forgetting by design.},
author = {Rusu, Andrei A and Rabinowitz, Neil C and Desjardins, Guillaume and Soyer, Hubert and Kirkpatrick, James and Kavukcuoglu, Koray and Pascanu, Razvan and Hadsell, Raia},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rusu et al. - 2016 - Progressive Neural Networks.pdf:pdf},
journal = {arXiv},
keywords = {Computer Science - Machine Learning,[mnist],lifelong learning,modular,progressive},
language = {en},
mendeley-tags = {[mnist]},
month = {jun},
title = {{Progressive Neural Networks}},
url = {http://arxiv.org/abs/1606.04671},
year = {2016}
}
@article{Rajpurkar2018,
abstract = {Extractive reading comprehension systems can often locate the correct answer to a question in a context document, but they also tend to make unreliable guesses on questions for which the correct answer is not stated in the context. Existing datasets either focus exclusively on answerable questions, or use automatically generated unanswerable questions that are easy to identify. To address these weaknesses, we present SQUADRUN, a new dataset that combines the existing Stanford Question Answering Dataset (SQuAD) with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQUADRUN, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering. SQUADRUN is a challenging natural language understanding task for existing models: a strong neural system that gets 86% F1 on SQuAD achieves only 66% F1 on SQUADRUN. We release SQUADRUN to the community as the successor to SQuAD.},
archivePrefix = {arXiv},
arxivId = {1806.03822},
author = {Rajpurkar, Pranav and Jia, Robin and Liang, Percy},
doi = {10.18653/v1/p18-2124},
eprint = {1806.03822},
file = {:home/user/Downloads/P18-2124.pdf:pdf},
isbn = {9781948087346},
journal = {ACL 2018 - 56th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)},
keywords = {nlp,question answering},
mendeley-tags = {nlp,question answering},
pages = {784--789},
title = {{Know what you don't know: Unanswerable questions for SQuAD}},
volume = {2},
year = {2018}
}
@article{Hassan2016,
abstract = {This paper presents a novel design of interval type-2 fuzzy logic systems (IT2FLS) by utilizing the theory of extreme learning machine (ELM) for electricity load demand forecasting. ELM has become a popular learning algorithm for single hidden layer feed-forward neural networks (SLFN). From the functional equivalence between the SLFN and fuzzy inference system, a hybrid of fuzzy-ELM has gained attention of the researchers. This paper extends the concept of fuzzy-ELM to an IT2FLS based on ELM (IT2FELM). In the proposed design the antecedent membership function parameters of the IT2FLS are generated randomly, whereas the consequent part parameters are determined analytically by the Moore-Penrose pseudo inverse. The ELM strategy ensures fast learning of the IT2FLS as well as optimality of the parameters. Effectiveness of the proposed design of IT2FLS is demonstrated with the application of forecasting nonlinear and chaotic data sets. Nonlinear data of electricity load from the Australian National Electricity Market for the Victoria region and from the Ontario Electricity Market are considered here. The proposed model is also applied to forecast Mackey-glass chaotic time series data. Comparative analysis of the proposed model is conducted with some traditional models such as neural networks (NN) and adaptive neuro fuzzy inference system (ANFIS). In order to verify the structure of the proposed design of IT2FLS an alternate design of IT2FLS based on Kalman filter (KF) is also utilized for the comparison purposes.},
author = {Hassan, Saima and Khosravi, Abbas and Jaafar, Jafreezal and Khanesar, Mojtaba Ahmadieh},
doi = {10.1016/j.ijepes.2016.03.001},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hassan et al. - 2016 - A systematic design of interval type-2 fuzzy logic system using extreme learning machine for electricity load dem.pdf:pdf},
isbn = {9781450333771},
issn = {01420615},
journal = {International Journal of Electrical Power and Energy Systems},
keywords = {Electricity load forecasting,Extreme learning machine,Interval type-2 fuzzy logic systems,Learning algorithm,Smart grid},
pages = {1--10},
publisher = {Elsevier Ltd},
title = {{A systematic design of interval type-2 fuzzy logic system using extreme learning machine for electricity load demand forecasting}},
url = {http://dx.doi.org/10.1016/j.ijepes.2016.03.001},
volume = {82},
year = {2016}
}
@article{Ellenberg2001,
abstract = {A Q-curve is an elliptic curve over a number field K which is geometrically isogenous to each of its Galois conjugates. K. Ribet [17] asked whether every Q-curve is modular, and he showed that a positive answer would follow from J.-P. Serre's conjecture on mod p Galois representations. We answer Ribet's question in the affirmative, subject to certain local conditions at 3. {\textcopyright} 2006 Duke University Press.},
author = {Ellenberg, Jordan S. and Skinner, Chris},
doi = {10.1215/S0012-7094-01-10914-9},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ellenberg, Skinner - 2001 - On the modularity of Q-curves.pdf:pdf},
issn = {00127094},
journal = {Duke Mathematical Journal},
number = {1},
pages = {97--122},
title = {{On the modularity of Q-curves}},
volume = {109},
year = {2001}
}
@article{Huang2020,
author = {Huang, Zeyi and Zou, Yang},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang, Zou - 2020 - Comprehensive Attention Self-Distillation for Weakly-Supervised Object Detection Supplementary Material.pdf:pdf},
number = {NeurIPS},
title = {{Comprehensive Attention Self-Distillation for Weakly-Supervised Object Detection Supplementary Material}},
year = {2020}
}
@article{Masse2018,
abstract = {Humans and most animals can learn new tasks without forgetting old ones. However, training artificial neural networks (ANNs) on new tasks typically causes them to forget previously learned tasks. This phenomenon is the result of "catastrophic forgetting," in which training an ANN disrupts connection weights that were important for solving previous tasks, degrading task performance. Several recent studies have proposed methods to stabilize connection weights of ANNs that are deemed most important for solving a task, which helps alleviate catastrophic forgetting. Here, drawing inspiration from algorithms that are believed to be implemented in vivo, we propose a complementary method: Adding a context-dependent gating signal, such that only sparse, mostly nonoverlapping patterns of units are active for any one task. This method is easy to implement, requires little computational overhead, and allows ANNs to maintain high performance across large numbers of sequentially presented tasks, particularly when combined with weight stabilization. We show that this method works for both feedforward and recurrent network architectures, trained using either supervised or reinforcement-based learning. This suggests that using multiple, complementary methods, akin to what is believed to occur in the brain, can be a highly effective strategy to support continual learning.},
archivePrefix = {arXiv},
arxivId = {1802.01569},
author = {Masse, Nicolas Y. and Grant, Gregory D. and Freedman, David J.},
doi = {10.1073/pnas.1803839115},
eprint = {1802.01569},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Masse, Grant, Freedman - 2018 - Alleviating catastrophic forgetting using contextdependent gating and synaptic stabilization.pdf:pdf},
issn = {10916490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Artificial intelligence,Catastrophic forgetting,Context-dependent gating,Continual learning,Synaptic stabilization,artificial intelligence,catastrophic forgetting,context-dependent gating,continual learning,synaptic stabilization},
mendeley-tags = {artificial intelligence,catastrophic forgetting,context-dependent gating,continual learning,synaptic stabilization},
number = {44},
pages = {E104657--E104675},
pmid = {30315147},
title = {{Alleviating catastrophic forgetting using contextdependent gating and synaptic stabilization}},
volume = {115},
year = {2018}
}
@article{Goldin-Meadow2013,
abstract = {When speakers talk, they gesture. The goal of this review is to investigate the contribution that these gestures make to how we communicate and think. Gesture can play a role in communication and thought at many timespans. We explore, in turn, gesture's contribution to how language is produced and understood in the moment; its contribution to how we learn language and other cognitive skills; and its contribution to how language is created over generations, over childhood, and on the spot. We find that the gestures speakers produce when they talk are integral to communication and can be harnessed in a number of ways. (a) Gesture reflects speakers' thoughts, often their unspoken thoughts, and thus can serve as a window onto cognition. Encouraging speakers to gesture can thus provide another route for teachers, clinicians, interviewers, etc., to better understand their communication partners. (b) Gesture can change speakers' thoughts. Encouraging gesture thus has the potential to change how students, patients, witnesses, etc., think about a problem and, as a result, alter the course of learning, therapy, or an interchange. (c) Gesture provides building blocks that can be used to construct a language. By watching how children and adults who do not already have a language put those blocks together, we can observe the process of language creation. Our hands are with us at all times and thus provide researchers and learners with an ever-present tool for understanding how we talk and think.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Goldin-Meadow, Susan and Alibali, Martha Wagner},
doi = {10.1146/annurev-psych-113011-143802},
eprint = {NIHMS150003},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goldin-Meadow, Alibali - 2013 - Gesture's Role in Speaking, Learning, and Creating Language.pdf:pdf},
isbn = {10.1146/annurev-psych-113011-143802},
issn = {0066-4308},
journal = {Ssrn},
pmid = {22830562},
title = {{Gesture's Role in Speaking, Learning, and Creating Language}},
year = {2013}
}
@article{Vitter1985,
abstract = {We introduce fast algorithms for selecting a random sample of n records without replacement from a pool of N records, where the value of N is unknown beforehand. The main result of the paper is the design and analysis of Algorithm Z; it does the sampling in one pass using constant space and in O ( n (1 + log( N/n ))) expected time, which is optimum, up to a constant factor. Several optimizations are studied that collectively improve the speed of the naive version of the algorithm by an order of magnitude. We give an efficient Pascal-like implementation that incorporates these modifications and that is suitable for general use. Theoretical and empirical results indicate that Algorithm Z outperforms current methods by a significant margin.},
author = {Vitter, Jeffrey S.},
doi = {10.1145/3147.3165},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vitter - 1985 - Random sampling with a reservoir.pdf:pdf},
issn = {0098-3500},
journal = {ACM Transactions on Mathematical Software},
keywords = {Analysis of algorithms,optimization,random sampling,rejection method,reservoir},
month = {mar},
number = {1},
pages = {37--57},
title = {{Random sampling with a reservoir}},
url = {https://dl.acm.org/doi/10.1145/3147.3165},
volume = {11},
year = {1985}
}
@article{Hagel2015,
abstract = {Anticipating disruptive strategies in a world of unicorns, black swans, and exponentials Deloitte Consulting LLP's Strategy & Operations practice works with senior executives to help them solve complex problems, bringing an approach to executable strategy that combines deep industry knowledge, rigorous analysis, and insight to enable confident action. Services include corporate strategy, customer and marketing strategy, mergers and acquisitions, social impact strategy, innovation, business model transformation, supply chain and manufacturing operations, sector-specific service operations, and financial management. John Hagel (co-chairman, Deloitte Center for the Edge) has nearly 35 years of experience as a management consultant, author, speaker, and entrepreneur, and has helped companies improve per-formance by applying IT to reshape business strategies. In addition to holding significant positions at leading consulting firms and companies throughout his career, Hagel is the author of bestselling business books such as Net Gain, Net Worth, Out of the Box, The Only Sustainable Edge, and The Power of Pull. John Seely Brown (JSB) (independent co-chairman, Deloitte Center for the Edge) is a prolific writer, speaker, and educator. In addition to his work with the Center for the Edge, JSB is adviser to the provost and a visiting scholar at the University of Southern California. This position followed a lengthy tenure at Xerox Corporation, where JSB was chief scientist and director of the Xerox Palo Alto Research Center. JSB has published more than 100 papers in scientific journals and authored or co-authored seven books, including The Social Life of Information, The Only Sustainable Edge, The Power of Pull, and A New Culture of Learning.},
author = {Hagel, John and Brown, John Seely and Wooll, Maggie and De-Maar, Andrew},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hagel et al. - 2015 - Patterns of disruption - Anticipating disruptive strategies in a world of unicorns, black swans and exponentials.pdf:pdf},
journal = {Deloitte University Press},
pages = {28`},
title = {{Patterns of disruption - Anticipating disruptive strategies in a world of unicorns, black swans and exponentials}},
year = {2015}
}
@inproceedings{Wang2021b,
abstract = {Building reliable object detectors that are robust to domain shifts, such as various changes in context, viewpoint, and object appearances, is critical for real-world applications. In this work, we study the effectiveness of auxiliary self-supervised tasks to improve the out-of-distribution generalization of object detectors. Inspired by the principle of maximum entropy, we introduce a novel self-supervised task, instance-level temporal cycle confusion (CycConf), which operates on the region features of the object detectors. For each object, the task is to find the most different object proposals in the adjacent frame in a video and then cycle back to itself for self-supervision. CycConf encourages the object detector to explore invariant structures across instances under various motions, which leads to improved model robustness in unseen domains at test time. We observe consistent out-of-domain performance improvements when training object detectors in tandem with self-supervised tasks on large-scale video datasets (BDD100K and Waymo open data). The joint training framework also establishes a new state-of-the-art on standard unsupervised domain adaptative detection benchmarks (Cityscapes, Foggy Cityscapes, and Sim10K). The code and models are available at https://github.com/xinw1012/cycle-confusion.},
archivePrefix = {arXiv},
arxivId = {2104.08381},
author = {Wang, Xin and Huang, Thomas E. and Liu, Benlin and Yu, Fisher and Wang, Xiaolong and Gonzalez, Joseph E. and Darrell, Trevor},
booktitle = {International Conference on Computer Vision (ICCV)},
eprint = {2104.08381},
file = {:home/user/Downloads/Wang_Robust_Object_Detection_via_Instance-Level_Temporal_Cycle_Confusion_ICCV_2021_paper.pdf:pdf},
keywords = {distribution shift,object detection,self-supervised learning},
mendeley-tags = {distribution shift,object detection,self-supervised learning},
title = {{Robust Object Detection via Instance-Level Temporal Cycle Confusion}},
url = {http://arxiv.org/abs/2104.08381},
year = {2021}
}
@article{Yoon2020,
author = {Yoon, Jinsung and Jordon, James},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yoon, Jordon - 2020 - VIME Extending the Success of Self- and Semi-supervised Learning to Tabular Domain.pdf:pdf},
number = {NeurIPS},
pages = {1--11},
title = {{VIME : Extending the Success of Self- and Semi-supervised Learning to Tabular Domain}},
url = {https://github.com/jsyoon0823/VIME},
year = {2020}
}
@article{McDaniel1994,
author = {McDaniel, M A and Whetzel, D L and Schmidt, F L and Maurer, S D},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/McDaniel et al. - 1994 - The validity of employment interview A comprehensive review and meta-analysis.pdf:pdf},
journal = {Journal of Applied Psychology,},
number = {4},
pages = {599--616},
title = {{The validity of employment interview:  A comprehensive review and meta-analysis}},
volume = {79},
year = {1994}
}
@book{Forbes2008,
abstract = {For details of our global editorial offices, for customer services and for information about how to apply for permission to reuse the copyright material in this book please see our website at www.wiley.com. The publisher and the author make no representations or warranties with respect to the accuracy or completeness of the contents of this work and specifically disclaim all warranties, including without limitation any implied warranties of fitness for a particular purpose. This work is sold with the understanding that the publisher is not engaged in rendering professional services. The advice and strategies contained herein may not be suitable for every situation. In view of ongoing research, equipment modifications, changes in governmental regulations, and the constant flow of information relating to the use of experimental reagents, equipment, and devices, the reader is urged to review and evaluate the information provided in the package insert or instructions for each chemical, piece of equipment, reagent, or device for, among other things, any changes in the instructions or indication of usage and for added warnings and precautions.},
author = {Forbes, Peter},
booktitle = {Scientific American},
doi = {10.1038/scientificamerican0808-88},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Forbes - 2008 - Self-cleaning materials.pdf:pdf},
isbn = {9781119991779},
issn = {0036-8733},
pages = {88--95},
pmid = {18666684},
title = {{Self-cleaning materials}},
volume = {299},
year = {2008}
}
@article{Grill2020,
abstract = {We introduce Bootstrap Your Own Latent (BYOL), a new approach to self-supervised image representation learning. BYOL relies on two neural networks, referred to as online and target networks, that interact and learn from each other. From an augmented view of an image, we train the online network to predict the target network representation of the same image under a different augmented view. At the same time, we update the target network with a slow-moving average of the online network. While state-of-the art methods intrinsically rely on negative pairs, BYOL achieves a new state of the art without them. BYOL reaches 74.3% top-1 classification accuracy on ImageNet using the standard linear evaluation protocol with a ResNet-50 architecture and 79.6% with a larger ResNet. We show that BYOL performs on par or better than the current state of the art on both transfer and semi-supervised benchmarks.},
archivePrefix = {arXiv},
arxivId = {2006.07733},
author = {Grill, Jean Bastien and Strub, Florian and Altch{\'{e}}, Florent and Tallec, Corentin and Richemond, Pierre H. and Buchatskaya, Elena and Doersch, Carl and Pires, Bernardo Avila and Guo, Zhaohan Daniel and Azar, Mohammad Gheshlaghi and Piot, Bilal and Kavukcuoglu, Koray and Munos, R{\'{e}}mi and Valko, Michal},
eprint = {2006.07733},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Grill et al. - 2020 - Bootstrap Your Own Latent A New Approach to Self-Supervised Learning.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {boostraping,byol,self-supervised learning},
mendeley-tags = {boostraping,byol,self-supervised learning},
title = {{Bootstrap Your Own Latent A New Approach to Self-Supervised Learning}},
url = {https://github.com/lucidrains/byol-pytorch},
volume = {200},
year = {2020}
}
@article{Kajaree2017,
abstract = {Over the past few decades, Machine Learning (ML) has evolved from the endeavour of few computer enthusiasts exploiting the possibility of computers learning to play games, and a part of Mathematics (Statistics) that seldom considered computational approaches, to an independent research discipline that has not only provided the necessary base for statistical-computational principles of learning procedures, but also has developedvarious algorithms that are regularly used for text interpretation, pattern recognition, and a many other commercial purposes and has led to a separate research interest in data mining to identify hidden regularities or irregularities in social data that growing by second. This paper focuses on explaining the concept and evolution of Machine Learning, some of the popular Machine Learning algorithms and try to compare three most popular algorithms based on some basic notions. Sentiment140 dataset was used and performance of each algorithm in terms of training time, prediction time and accuracy of prediction have been documented and compared.},
author = {Kajaree, Das and Behera, R.N},
doi = {10.15680/IJIRCCE.2017.},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kajaree, Behera - 2017 - A Survey on Web Crawler Approaches.pdf:pdf},
isbn = {0000000000},
issn = {2320-9798},
journal = {International Journal of Innovative Research in Computer and Communication Engineering},
keywords = {Algorithm,Data,Machine Learning,Training,accuracy},
number = {2},
pages = {1302--1309},
title = {{A Survey on Web Crawler Approaches}},
volume = {5},
year = {2017}
}
@article{Nguyen2018,
abstract = {This paper develops variational continual learning (VCL), a simple but general framework for continual learning that fuses online variational inference (VI) and recent advances in Monte Carlo VI for neural networks. The framework can successfully train both deep discriminative models and deep generative models in complex continual learning settings where existing tasks evolve over time and entirely new tasks emerge. Experimental results show that VCL outperforms state-of-the-art continual learning methods on a variety of tasks, avoiding catastrophic forgetting in a fully automatic way.},
archivePrefix = {arXiv},
arxivId = {1710.10628},
author = {Nguyen, Cuong V. and Li, Yingzhen and Bui, Thang D. and Turner, Richard E.},
eprint = {1710.10628},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen et al. - 2018 - Variational continual learning.pdf:pdf},
journal = {6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings},
number = {Vi},
pages = {1--18},
title = {{Variational continual learning}},
year = {2018}
}
@article{Gooley2011a,
abstract = {Context: Millions of individuals habitually expose themselves to room light in the hours before bedtime, yet the effects of this behavior on melatonin signaling are not well recognized. Objective:Wetested the hypothesis that exposure toroomlight in the late evening suppresses the onset of melatonin synthesis and shortens the duration of melatonin production. Design: In a retrospective analysis, we compared daily melatonin profiles in individuals living in room light (?200 lux) vs. dim light (?3 lux). Patients: Healthy volunteers (n ? 116, 18–30 yr) were recruited from the general population to participate in one of two studies. Setting: Participants lived in a General Clinical Research Center for at least five consecutive days. Intervention: Individuals were exposed to room light or dim light in the 8 h preceding bedtime. Outcome Measures: Melatonin duration, onset and offset, suppression, and phase angle of en- trainment were determined. Results: Compared with dim light, exposure to room light before bedtime suppressed melatonin, resulting in a later melatonin onset in 99.0% of individuals and shortening melatonin duration by about 90 min. Also, exposure to room light during the usual hours of sleep suppressed melatonin by greater than 50% in most (85%) trials. Conclusions:Thesefindingsindicatethatroomlightexertsaprofoundsuppressiveeffectonmelatonin levels and shortens the body's internal representation of night duration. Hence, chronically exposing oneself to electrical lighting in the late evening disrupts melatonin signaling and could therefore potentially impact sleep, thermoregulation, blood pressure, and glucose homeostasis.},
author = {Gooley, Joshua J. and Chamberlain, Kyle and Smith, Kurt A. and Khalsa, Sat Bir S. and Rajaratnam, Shantha M.W. and {Van Reen}, Eliza and Zeitzer, Jamie M. and Czeisler, Charles A. and Lockley, Steven W.},
doi = {10.1210/jc.2010-2098},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gooley et al. - 2011 - Exposure to room light before bedtime suppresses melatonin onset and shortens melatonin duration in humans.pdf:pdf},
isbn = {1945-7197 (Electronic)\n0021-972X (Linking)},
issn = {0021972X},
journal = {Journal of Clinical Endocrinology and Metabolism},
number = {3},
pages = {463--472},
pmid = {21193540},
title = {{Exposure to room light before bedtime suppresses melatonin onset and shortens melatonin duration in humans}},
volume = {96},
year = {2011}
}
@article{Blum1989,
abstract = {We prove the existence of a manifold of exact solutions (mean-square error E = 0) of weights and thresholds for sigmoidal networks for XOR and other 2-variable Boolean functions. We also prove the existence of a manifold of local minima of E where E ≠ 0.},
author = {Blum, E. K.},
doi = {10.1162/neco.1989.1.4.532},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Blum - 1989 - Approximation of Boolean Functions by Sigmoidal Networks Part I XOR and Other Two-Variable Functions.pdf:pdf},
issn = {0899-7667},
journal = {Neural Computation},
month = {dec},
number = {4},
pages = {532--540},
title = {{Approximation of Boolean Functions by Sigmoidal Networks: Part I: XOR and Other Two-Variable Functions}},
url = {https://www.mitpressjournals.org/doi/abs/10.1162/neco.1989.1.4.532},
volume = {1},
year = {1989}
}
@article{Atadashi2012,
abstract = {Presence of water during biodiesel production and purification processes, storage and use in compression ignition (diesel) engines causes problems that cannot be ignored. These problems include: difficulties in biodiesel processing especially during alkali-catalyzed transesterification process, deterioration of biodiesel quality, decrease in heat of combustion, corrosion of fuel system components, and acceleration of hydrolytic reaction. Beside use of water during biodiesel purification results in wastewater discharges which causes environmental effects, due to high contents of chemical oxygen demand, biological oxygen demand, and higher pH values. Thus, this study critically analyzed and examined the effects of water on biodiesel production and the refining of crude biodiesel. Furthermore the effects of water on the quality of biodiesel were also examined. {\textcopyright} 2012 Elsevier Ltd. All rights reserved.},
author = {Atadashi, I. M. and Aroua, M. K. and {Abdul Aziz}, A. R. and Sulaiman, N. M.N.},
doi = {10.1016/j.rser.2012.03.004},
isbn = {13640321 (ISSN)},
issn = {13640321},
journal = {Renewable and Sustainable Energy Reviews},
keywords = {Biodiesel production,Feedstocks,Homogeneous catalyst and heterogeneous catalyst,Water effects},
number = {5},
pages = {3456--3470},
pmid = {338802400014},
publisher = {Elsevier Ltd},
title = {{The effects of water on biodiesel production and refining technologies: A review}},
url = {http://dx.doi.org/10.1016/j.rser.2012.03.004},
volume = {16},
year = {2012}
}
@article{Matic2017,
abstract = {In this paper, we present two genetic algorithms (GA) for solving the minimum edge-dilation k-center (MEDKC) problem. Up to now, MEDKC has been considered only theoretically, and we present the first heuristic approaches for solving it. In both approaches, the assignment of non-center vertices is based on the distance to the center vertices, while modified crossover and mutation genetic operators, specific for each GA, keep individuals feasible during the entire optimization process. The proposed algorithms were empirically tested and compared by using various sets of differently sized test data: some theoretical classes of graphs with known optimal solutions and some special classes of graphs chosen from the literature for the k-minimum spanning tree and Roman domination problems. Obtained results indicate that newly proposed GAs can be reliably used in constructing routing schemes in complex computer networks.},
author = {Matic, Dragan and Kratica, Jozef and Maksimovic, Z.},
doi = {10.1016/j.cie.2017.09.029},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Matic, Kratica, Maksimovic - 2017 - Solving the minimum edge-dilation k-center problem by genetic algorithms.pdf:pdf},
issn = {03608352},
journal = {Computers and Industrial Engineering},
keywords = {Combinatorial optimization,Edge-dilation k center,Genetic algorithms,Minimum stretch},
number = {May},
pages = {282--293},
publisher = {Elsevier},
title = {{Solving the minimum edge-dilation k-center problem by genetic algorithms}},
url = {http://dx.doi.org/10.1016/j.cie.2017.09.029},
volume = {113},
year = {2017}
}
@inproceedings{Wei2020b,
abstract = {Contrastive learning has been adopted as a core method for unsupervised visual representation learning. Without human annotation, the common practice is to perform an instance discrimination task: Given a query image crop, this task labels crops from the same image as positives, and crops from other randomly sampled images as negatives. An important limitation of this label assignment strategy is that it can not reflect the heterogeneous similarity between the query crop and each crop from other images, taking them as equally negative, while some of them may even belong to the same semantic class as the query. To address this issue, inspired by consistency regularization in semi-supervised learning on unlabeled data, we propose Consistent Contrast (CO2), which introduces a consistency regularization term into the current contrastive learning framework. Regarding the similarity of the query crop to each crop from other images as “unlabeled”, the consistency term takes the corresponding similarity of a positive crop as a pseudo label, and encourages consistency between these two similarities. Empirically, CO2 improves Momentum Contrast (MoCo) by 2.9% top-1 accuracy on ImageNet linear protocol, 3.8% and 1.1% top-5 accuracy on 1% and 10% labeled semi-supervised settings. It also transfers to image classification, object detection, and semantic segmentation on PASCAL VOC. This shows that CO2 learns better visual representations for these downstream tasks.},
archivePrefix = {arXiv},
arxivId = {2010.02217},
author = {Wei, Chen and Wang, Huiyu and Shen, Wei and Yuille, Alan},
booktitle = {Iclr 2021},
eprint = {2010.02217},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wei et al. - 2020 - CO2 Consistent Contrast for Unsupervised Visual Representation Learning.pdf:pdf},
issn = {23318422},
keywords = {contrastive learning,regularization,self-supervised learning,unsupervised learning},
mendeley-tags = {contrastive learning,regularization,self-supervised learning,unsupervised learning},
pages = {1--12},
title = {{CO2: Consistent Contrast for Unsupervised Visual Representation Learning}},
year = {2020}
}
@article{Vujicic2010,
abstract = {Calcium oxide as a heterogeneous catalyst was investigated for its effect on the biodiesel synthesis from refined sunflower oil. Experiments were carried out using a commercial bench stirred tank reactor of 2 dm3 volume, at 200 rpm, with a methanol to oil ratio 6 to 1 and 1 mas.% catalyst loading as constant parameters. Ester yields were followed as a function of temperature (60-120 ??C), pressure (1-15 bars) and reaction time (1.5-5.5 h). The temperature of 100 ??C was found to be optimal for the maximum (91%) conversion to methyl esters, while pressure had a positive impact up to 10 bars at 80 ??C. The catalyst activation in air leading to the formation of strong basic sites was found to occur at 900 ??C. Catalyst particle coalescence took place during the reaction, giving a gum-like structure, and resulted in a significant catalyst deactivation. The pseudo-first order reaction was established, with a "knee" at 80 ??C in the Arrhenius plot separating the kinetic and diffusion regimes. During the reaction progress, an activation energy decrease from 161 to 101 kJ/mol, and from 32 to (-3) kJ/mol, was found for the kinetic and diffusion regimes, respectively. ?? 2010 Elsevier Ltd. All rights reserved.},
author = {Vujicic, Dj and Comic, D. and Zarubica, A. and Micic, R. and Boskovic, G.},
doi = {10.1016/j.fuel.2009.11.043},
isbn = {0016-2361},
issn = {00162361},
journal = {Fuel},
keywords = {Biodiesel,Calcium oxide,Diffusion restrictions,Heterogeneous catalysis,Transesterification of sunflower oil},
number = {8},
pages = {2054--2061},
publisher = {Elsevier Ltd},
title = {{Kinetics of biodiesel synthesis from sunflower oil over CaO heterogeneous catalyst}},
url = {http://dx.doi.org/10.1016/j.fuel.2009.11.043},
volume = {89},
year = {2010}
}
@article{Gontier2020,
abstract = {We are interested in understanding how well Transformer language models (TLMs) can perform reasoning tasks when trained on knowledge encoded in the form of natural language. We investigate their systematic generalization abilities on a logical reasoning task in natural language, which involves reasoning over relationships between entities grounded in first-order logical proofs. Specifically, we perform soft theorem-proving by leveraging TLMs to generate natural language proofs. We test the generated proofs for logical consistency, along with the accuracy of the final inference. We observe length-generalization issues when evaluated on longer-than-trained sequences. However, we observe TLMs improve their generalization performance after being exposed to longer, exhaustive proofs. In addition, we discover that TLMs are able to generalize better using backward-chaining proofs compared to their forward-chaining counterparts, while they find it easier to generate forward chaining proofs. We observe that models that are not trained to generate proofs are better at generalizing to problems based on longer proofs. This suggests that Transformers have efficient internal reasoning strategies that are harder to interpret. These results highlight the systematic generalization behavior of TLMs in the context of logical reasoning, and we believe this work motivates deeper inspection of their underlying reasoning strategies.},
archivePrefix = {arXiv},
arxivId = {2009.14786},
author = {Gontier, Nicolas and Sinha, Koustuv and Reddy, Siva and Pal, Christopher},
eprint = {2009.14786},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gontier et al. - 2020 - Measuring Systematic Generalization in Neural Proof Generation with Transformers.pdf:pdf;:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gontier et al. - Unknown - Measuring Systematic Generalization in Neural Proof Generation with Transformers - Supplementary Material.pdf:pdf},
number = {NeurIPS},
title = {{Measuring Systematic Generalization in Neural Proof Generation with Transformers}},
url = {http://arxiv.org/abs/2009.14786},
year = {2020}
}
@book{Widodo2002,
author = {Widodo, Wahyu},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Widodo - 2002 - Bioteknologi fermentasi susu.pdf:pdf},
publisher = {Malang, Universitas Muhammadiyah},
title = {{Bioteknologi fermentasi susu}},
year = {2002}
}
@article{Luo2020,
abstract = {Tabular data is the most common data format adopted by our customers ranging from retail, finance to E-commerce, and tabular data classification plays an essential role to their businesses. In this paper, we present Network On Network (NON), a practical tabular data classification model based on deep neural network to provide accurate predictions. Various deep methods have been proposed and promising progress has been made. However, most of them use operations like neural network and factorization machines to fuse the embeddings of different features directly, and linearly combine the outputs of those operations to get the final prediction. As a result, the intra-field information and the non-linear interactions between those operations (e.g. neural network and factorization machines) are ignored. Intra-field information is the information that features inside each field belong to the same field. NON is proposed to take full advantage of intra-field information and non-linear interactions. It consists of three components: field-wise network at the bottom to capture the intra-field information, across field network in the middle to choose suitable operations data-drivenly, and operation fusion network on the top to fuse outputs of the chosen operations deeply. Extensive experiments on six real-world datasets demonstrate NON can outperform the state-of-the-art models significantly. Furthermore, both qualitative and quantitative study of the features in the embedding space show NON can capture intra-field information effectively.},
archivePrefix = {arXiv},
arxivId = {2005.10114},
author = {Luo, Yuanfei and Zhou, Hao and Tu, Weiwei and Chen, Yuqiang and Dai, Wenyuan and Yang, Qiang},
doi = {10.1145/3397271.3401437},
eprint = {2005.10114},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Luo et al. - 2020 - Network On Network for Tabular Data Classification in Real-world Applications.pdf:pdf},
isbn = {9781450380164},
keywords = {all or part of,classification,classroom use is granted,copies are not made,deep learning,neural network,or,or distributed,or hard copies of,permission to make digital,tabular data,this work for personal,without fee provided that},
mendeley-tags = {tabular data},
month = {may},
title = {{Network On Network for Tabular Data Classification in Real-world Applications}},
url = {http://arxiv.org/abs/2005.10114 http://dx.doi.org/10.1145/3397271.3401437},
year = {2020}
}
@article{Torrey2009,
abstract = {Transfer learning is the improvement of learning in a new task through the transfer of knowledge from a related task that has al- ready been learned. While most machine learning algorithms are designed to address single tasks, the development of algorithms that facilitate transfer learning is a topic of ongoing interest in the machine-learning community. This chapter provides an introduction to the goals, formu- lations, and challenges of transfer learning. It surveys current research in this area, giving an overview of the state of the art and outlining the open problems. The survey covers transfer in both inductive learning and reinforcement learning, and discusses the issues of negative transfer and task mapping in depth},
author = {Torrey, Lisa and Shavlik, Jude and University},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Torrey, Shavlik, University - 2009 - Transfer Learning.pdf:pdf},
keywords = {transfer learning},
mendeley-tags = {transfer learning},
title = {{Transfer Learning}},
year = {2009}
}
@article{Robins1995,
abstract = {This paper reviews the problem of catastrophic forgetting (the loss or disruption of previously learned information when new information is learned) in neural networks, and explores rehearsal mechanisms (the retraining of some of the previously learned information as the new information is added) as a potential solution. We replicate some of the experiments described by Ratcliff (1990), including those relating to a simple ‘recency' based rehearsal regime. We then develop further rehearsal regimes which are more effective than recency rehearsal. In particular, ‘sweep rehearsal' is very successful at minimizing catastrophic forgetting. One possible limitation of rehearsal in general, however, is that previously learned information may not be available for retraining. We describe a solution to this problem, ‘pseudorehearsal', a method which provides the advantages of rehearsal without actually requiring any access to the previously learned information (the original training population) itself. We then suggest an interpretation of these rehearsal mechanisms in the context of a function approximation based account of neural network learning. Both rehearsal and pseudorehearsal may have practical applications, allowing new information to be integrated into an existing network with minimum disruption of old information. {\textcopyright} 1995, Taylor & Francis Group, LLC. All rights reserved.},
author = {Robins, Anthony},
doi = {10.1080/09540099550039318},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Robins - 1995 - Catastrophic Forgetting, Rehearsal and Pseudorehearsal.pdf:pdf},
issn = {13600494},
journal = {Connection Science},
keywords = {Catastrophic forgetting,catastrophic interference,plasticity,rehearsal,stability},
number = {2},
pages = {123--146},
title = {{Catastrophic Forgetting, Rehearsal and Pseudorehearsal}},
volume = {7},
year = {1995}
}
@article{Lin2021,
abstract = {For artificial learning systems, continual learning over time from a stream of data is essential. The burgeoning studies on supervised continual learning have achieved great progress, while the study of catastrophic forgetting in unsupervised learning is still blank. Among unsupervised learning methods, self-supervise learning method shows tremendous potential on visual representation without any labeled data at scale. To improve the visual representation of self-supervised learning, larger and more varied data is needed. In the real world, unlabeled data is generated at all times. This circumstance provides a huge advantage for the learning of the self-supervised method. However, in the current paradigm, packing previous data and current data together and training it again is a waste of time and resources. Thus, a continual self-supervised learning method is badly needed. In this paper, we make the first attempt to implement the continual contrastive self-supervised learning by proposing a rehearsal method, which keeps a few exemplars from the previous data. Instead of directly combining saved exemplars with the current data set for training, we leverage self-supervised knowledge distillation to transfer contrastive information among previous data to the current network by mimicking similarity score distribution inferred by the old network over a set of saved exemplars. Moreover, we build an extra sample queue to assist the network to distinguish between previous and current data and prevent mutual interference while learning their own feature representation. Experimental results show that our method performs well on CIFAR100 and ImageNet-Sub. Compared with self-supervised baselines, which learning tasks one by one without taking any technique, we improve the image classification top-1 accuracy by 1.60% on CIFAR100 and 2.86% on ImageNet-Sub under 10 incremental steps setting.},
archivePrefix = {arXiv},
arxivId = {2107.01776},
author = {Lin, Zhiwei and Wang, Yongtao and Lin, Hongxiang},
eprint = {2107.01776},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin, Wang, Lin - 2021 - Continual Contrastive Self-supervised Learning for Image Classification.pdf:pdf},
isbn = {2116332613},
keywords = {continual learning,self-supervised learning},
mendeley-tags = {continual learning,self-supervised learning},
pages = {1--14},
title = {{Continual Contrastive Self-supervised Learning for Image Classification}},
url = {http://arxiv.org/abs/2107.01776},
year = {2021}
}
@article{Zadeh1975a,
abstract = {By a linguistic variable we mean a variable whose values are words or sentences in a natural or artificial language. For example, Age is a linguistic variable if its values are linguistic rather than numerical, i.e.,young, not young, very young, quite young, old, not very old and not very young, etc., rather than 20, 21,22, 23, In more specific terms, a linguistic variable is characterized by a quintuple (L>, T(L), U,G,M) in which L is the name of the variable; T(L) is the term-set of L, that is, the collection of its linguistic values; U is a universe of discourse; G is a syntactic rule which generates the terms in T(L); and M is a semantic rule which associates with each linguistic value X its meaning, M(X), where M(X) denotes a fuzzy subset of U. The meaning of a linguistic value X is characterized by a compatibility function, c: U 0,1, which associates with each u in U its compatibility with X. Thus, the compatibility of age 27 with young might be 0.7, while that of 35 might be 0.2. The function of the semantic rule is to relate the compatibilities of the so-called primary terms in a composite linguistic value-e.g., young and old in not very young and not very old-to the compatibility of the composite value. To this end, the hedges such as very, quite, extremely, etc., as well as the connectives and and or are treated as nonlinear operators which modify the meaning of their operands in a specified fashion. The concept of a linguistic variable provides a means of approximate characterization of phenomena which are too complex or too ill-defined to be amenable to description in conventional quantitative terms. In particular, treating Truth as a linguistic variable with values such as true, very true, completely true, not very true, untrue, etc., leads to what is called fuzzy logic. By providing a basis for approximate reasoning, that is, a mode of reasoning which is not exact nor very inexact, such logic may offer a more realistic framework for human reasoning than the traditional two-valued logic. It is shown that probabilities, too, can be treated as linguistic variables with values such as likely, very likely, unlikely, etc. Computation with linguistic probabilities requires the solution of nonlinear programs and leads to results which are imprecise to the same degree as the underlying probabilities. The main applications of the linguistic approach lie in the realm of humanistic systems-especially in the fields of artificial intelligence, linguistics, human decision processes, pattern recognition, psychology, law, medical diagnosis, information retrieval, economics and related areas.},
author = {Zadeh, L.A.},
doi = {10.1007/978-1-4684-2106-4_1},
isbn = {0020-0255},
issn = {00200255},
journal = {Information Sciences},
number = {4},
pages = {199--249},
title = {{The concept of a linguistic variable and its applications to approximate reasoning I}},
url = {http://www.eecs.berkeley.edu/$\sim$zadeh/papers/The Concept of a Linguistic Variable and its Applications to Approximate Reasoning I-1975.pdf},
volume = {8},
year = {1975}
}
@article{Kecerdasan,
author = {Kecerdasan, Inventori and Ikep, Pelbagai},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kecerdasan, Ikep - Unknown - Template for Survey or Review Article.pdf:pdf},
pages = {6},
title = {{Template for Survey or Review Article}}
}
@article{Azizzadenesheli2020,
abstract = {We study generalization under label shift in domain adaptation where the learner has access to labeled samples from the source domain but unlabeled samples from the target domain. Prior works deploy label classifiers and introduce various methods to estimate the importance weights from source to target domains. They use these estimates in importance weighted empirical risk minimization to learn classifiers. In this work, we theoretically compare the prior approaches, relax their strong assumptions, and generalize them from requiring label classifiers to general functions. This latter generalization improves the conditioning on the inverse operator of the induced inverse problems by allowing for broader exploitation of the spectrum of the forward operator. The prior works in the study of label shifts are limited to categorical label spaces. In this work, we propose a series of methods to estimate the importance weight functions for arbitrary normed label spaces. We introduce a new operator learning approach between Hilbert spaces defined on labels (rather than covariates) and show that it induces a perturbed inverse problem of compact operators. We propose a novel approach to solve the inverse problem in the presence of perturbation. This analysis has its own independent interest since such problems commonly arise in partial differential equations and reinforcement learning. For both categorical and general normed spaces, we provide concentration bounds for the proposed estimators. Using the existing generalization analysis based on Rademacher complexity, R\'enyi divergence, and MDFR lemma in Azizzadenesheli et al. [2019], we show the generalization property of the importance weighted empirical risk minimization on the unseen target domain.},
archivePrefix = {arXiv},
arxivId = {2011.14251},
author = {Azizzadenesheli, Kamyar},
eprint = {2011.14251},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Azizzadenesheli - 2020 - Importance Weight Estimation and Generalization in Domain Adaptation under Label Shift.pdf:pdf},
keywords = {domain adaptation,generalization,integral operator,label shift,transfer learning},
mendeley-tags = {domain adaptation,transfer learning},
title = {{Importance Weight Estimation and Generalization in Domain Adaptation under Label Shift}},
url = {http://arxiv.org/abs/2011.14251},
year = {2020}
}
@article{Forbes2016,
abstract = {With the rise of social media, the use of social influencers has become a popular tactic in brand marketing. Research to date regarding the use of social influencers for branding has lacked specific insight regarding the beauty industry. This study identified characteristics of selected beauty social influencers to see how they are utilized in advertorials for brands on YouTube. The study used a content analysis of Maybelline's sponsored videos that three influencers produced and featured on their YouTube channels. Attribution theory and social learning theory were used for analysis of influencers' impact on viewers.},
author = {Forbes, Kristen},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Forbes - 2016 - Examining the Beauty Industry ' s Use of Social Influencers.pdf:pdf},
journal = {Elon Journal of Undergraduate Research in Communications},
keywords = {79,brand marketing,branding,conducted as a partial,course in communications,edu,elon,email,examining the beauty industry,influencers by kristen forbes,kforbes4,maybelline,requirement of a research,s use of social,social influencers,social media,this undergraduate project was},
number = {2},
pages = {78--87},
title = {{Examining the Beauty Industry ' s Use of Social Influencers}},
url = {http://www.cur.org/resources/students/undergraduate_journals/%0Ahttps://www.elon.edu/u/academics/communications/journal/wp-content/uploads/sites/153/2017/06/Fall2016Journal.pdf#page=78},
volume = {7},
year = {2016}
}
@article{Rahimnejad2015,
abstract = {Recently, great attentions have been paid to microbial fuel cells (MFCs) due to their mild operating conditions and using variety of biodegradable substrates as fuel. The traditional MFC consisted of anode and cathode compartments but there are single chamber MFCs. Microorganisms actively catabolize substrate, and bioelectricities are generated. MFCs could be utilized as power generator in small devices such as biosensor. Besides the advantages of this technology, it still faces practical barriers such as low power and current density. In the present article different parts of MFC such as anode, cathode and membrane have been reviewed and to overcome the practical challenges in this field some practical options have been suggested. Also, this research review demonstrates the improvement of MFCs with summarization of their advantageous and possible applications in future application. Also, Different key factors affecting bioelectricity generation on MFCs were investigated and these key parameters are fully discussed.},
author = {Rahimnejad, Mostafa and Adhami, Arash and Darvari, Soheil and Zirepour, Alireza and Oh, Sang Eun},
doi = {10.1016/j.aej.2015.03.031},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rahimnejad et al. - 2015 - Microbial fuel cell as new technol ogy for bioelectricity generation A review.pdf:pdf},
isbn = {11100168},
issn = {11100168},
journal = {Alexandria Engineering Journal},
keywords = {Anaerobic anode,Biocatalyst,Bioelectricity,Biosensor,Microbial fuel cell},
number = {3},
pages = {745--756},
pmid = {21855328},
publisher = {Faculty of Engineering, Alexandria University},
title = {{Microbial fuel cell as new technol ogy for bioelectricity generation: A review}},
url = {http://dx.doi.org/10.1016/j.aej.2015.03.031},
volume = {54},
year = {2015}
}
@article{Simon2019,
abstract = {Accurate detection of 3D objects is a fundamental problem in computer vision and has an enormous impact on autonomous cars, augmented/virtual reality and many applications in robotics. In this work we present a novel fusion of neural network based state-of-the-art 3D detector and visual semantic segmentation in the context of autonomous driving. Additionally, we introduce Scale-Rotation-Translation score (SRTs), a fast and highly parameterizable evaluation metric for comparison of object detections, which speeds up our inference time up to 20\% and halves training time. On top, we apply state-of-the-art online multi target feature tracking on the object measurements to further increase accuracy and robustness utilizing temporal information. Our experiments on KITTI show that we achieve same results as state-of-the-art in all related categories, while maintaining the performance and accuracy trade-off and still run in real-time. Furthermore, our model is the first one that fuses visual semantic with 3D object detection.},
archivePrefix = {arXiv},
arxivId = {1904.07537},
author = {Simon, Martin and Amende, Karl and Kraus, Andrea and Honer, Jens and S{\"{a}}mann, Timo and Kaulbersch, Hauke and Milz, Stefan and Gross, Horst Michael},
eprint = {1904.07537},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Simon et al. - 2019 - Complexer-YOLO Real-Time 3D Object Detection and Tracking on Semantic Point Clouds.pdf:pdf},
title = {{Complexer-YOLO: Real-Time 3D Object Detection and Tracking on Semantic Point Clouds}},
url = {http://arxiv.org/abs/1904.07537},
year = {2019}
}
@article{Noor2013,
author = {Noor, M.N. and Yahaya, A.S. and Ramli, N.A. and {Al Bakri}, Abdullah Mohd Mustafa},
doi = {10.4028/www.scientific.net/KEM.594-595.889},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Noor et al. - 2013 - Filling Missing Data Using Interpolation Methods Study on the Effect of Fitting Distribution.pdf:pdf},
issn = {1662-9795},
journal = {Key Engineering Materials},
number = {May},
pages = {889--895},
title = {{Filling Missing Data Using Interpolation Methods: Study on the Effect of Fitting Distribution}},
url = {http://www.scientific.net/KEM.594-595.889},
volume = {594-595},
year = {2013}
}
@article{Hu2019,
abstract = {Deep learning models have a large number of freeparameters that need to be calculated by effective trainingof the models on a great deal of training data to improvetheir generalization performance. However, data obtaining andlabeling is expensive in practice. Data augmentation is one of themethods to alleviate this problem. In this paper, we conduct apreliminary study on how three variables (augmentation method,augmentation rate and size of basic dataset per label) can affectthe accuracy of deep learning for image classification. The studyprovides some guidelines: (1) it is better to use transformationsthat alter the geometry of the images rather than those justlighting and color. (2) 2-3 times augmentation rate is good enoughfor training. (3) the smaller amount of data, the more obviouscontributions could have.},
archivePrefix = {arXiv},
arxivId = {1906.11887},
author = {Hu, Benlin and Lei, Cheng and Wang, Dong and Zhang, Shu and Chen, Zhenyu},
eprint = {1906.11887},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hu et al. - 2019 - A Preliminary Study on Data Augmentation of Deep Learning for Image Classification.pdf:pdf},
pages = {7--10},
title = {{A Preliminary Study on Data Augmentation of Deep Learning for Image Classification}},
url = {http://arxiv.org/abs/1906.11887},
year = {2019}
}
@article{Liu2017c,
abstract = {In developing nations, many expanding cities are facing challenges that result from the overwhelming numbers of people and vehicles. Collecting real-time, reliable and precise traffic flow information is crucial for urban traffic management. The main purpose of this paper is to develop an adaptive model that can assess the real-time vehicle counts on urban roads using computer vision technologies. This paper proposes an automatic real-time background update algorithm for vehicle detection and an adaptive pattern for vehicle counting based on the virtual loop and detection line methods. In addition, a new robust detection method is introduced to monitor the real-time traffic congestion state of road section. A prototype system has been developed and installed on an urban road for testing. The results show that the system is robust, with a real-time counting accuracy exceeding 99% in most field scenarios.},
author = {Liu, Fei and Zeng, Zhiyuan and Jiang, Rong},
doi = {10.1371/journal.pone.0186098},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu, Zeng, Jiang - 2017 - A video-based real-time adaptive vehicle-counting system for urban roads.pdf:pdf},
isbn = {1111111111},
issn = {19326203},
journal = {PLoS ONE},
number = {11},
pages = {1--16},
title = {{A video-based real-time adaptive vehicle-counting system for urban roads}},
volume = {12},
year = {2017}
}
@article{Ferreira2018,
abstract = {Decision-making processes in private banking must comply with standards for risk management and transparency enforced by banking regulations. Therefore, investors must be supported throughout a risk-informed decision process. This paper contributes to the literature by presenting a hybrid integrated framework that considers personal features of the investor and additional characteristics imposed by regulations, for which linguistic evaluations are used with regard to risk exposure. The proposed approach for personal investment portfolios considers legal aspects and investor's preferences as an input to the novel fuzzy multiple-attribute decision making approach for sorting problems proposed in this paper, called FTOPSIS-Class. Then, the next step of the proposed framework uses the sorting results for a fuzzy multi-objective optimization model that considers the risk and return associated with the investor's profile over three objectives. The contributions of this paper are illustrated and validated by using a numerical application in line with a new trend for modern portfolio theory which enables a real world investor's characteristics to be considered throughout the decision-making process.},
author = {Ferreira, Luciano and Borenstein, Denis and Righi, Marcelo Brutti and {de Almeida Filho}, Adiel Teixeira},
doi = {10.1016/j.eswa.2017.09.055},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ferreira et al. - 2018 - A fuzzy hybrid integrated framework for portfolio optimization in private banking.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Fuzzy sets,Investment analysis,Multiple attribute decision making,Multiple objective programming,OR in banking},
pages = {350--362},
publisher = {Elsevier Ltd},
title = {{A fuzzy hybrid integrated framework for portfolio optimization in private banking}},
url = {https://doi.org/10.1016/j.eswa.2017.09.055},
volume = {92},
year = {2018}
}
@article{Cheng2016,
abstract = {In this paper, we propose a new fuzzy time series forecasting method for forecasting the Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX) based on fuzzy time series, fuzzy logical relationships, particle swarm optimization techniques, the K-means clustering algorithm, and similarity measures between the subscript of the fuzzy set of the fuzzified historical testing datum on the previous trading day and the subscripts of the fuzzy sets appearing in the current states of the fuzzy logical relationships in the chosen fuzzy logical relationship group. The particle swarm optimization techniques are used to get the optimal partition of the intervals in the universe of discourse. The K-means clustering algorithm is used to cluster the subscripts of the fuzzy sets of the current states of the fuzzy logical relationships to get the cluster center of each cluster and to divide the constructed fuzzy logical relationships into fuzzy logical relationship groups. The experimental results show that the proposed fuzzy forecasting method gets higher forecasting accuracy rates than the existing methods. The advantages of the proposed fuzzy forecasting method is that it uses the particle swarm optimization techniques to get the optimal partition of the intervals in the universe of discourse and uses the K-means clustering algorithm to cluster the subscripts of the fuzzy sets of the current states of the fuzzy logical relationships to get the cluster center of each cluster and to divide the constructed fuzzy logical relationships into fuzzy logical relationship groups for increasing the forecasting accuracy rates.},
author = {Cheng, Shou Hsiung and Chen, Shyi Ming and Jian, Wen Shan},
doi = {10.1016/j.ins.2015.08.024},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cheng, Chen, Jian - 2016 - Fuzzy time series forecasting based on fuzzy logical relationships and similarity measures.pdf:pdf},
issn = {00200255},
journal = {Information Sciences},
keywords = {Fuzzy logical relationships,Fuzzy time series,K-means clustering algorithm,Particle swarm optimization,Similarity measures},
pages = {272--287},
publisher = {Elsevier Ltd.},
title = {{Fuzzy time series forecasting based on fuzzy logical relationships and similarity measures}},
url = {http://dx.doi.org/10.1016/j.ins.2015.08.024},
volume = {327},
year = {2016}
}
@article{Ebrahimi2020a,
abstract = {Continual learning aims to learn new tasks without forgetting previously learned ones. We hypothesize that representations learned to solve each task in a sequence have a shared structure while containing some task-specific properties. We show that shared features are significantly less prone to forgetting and propose a novel hybrid continual learning framework that learns a disjoint representation for task-invariant and task-specific features required to solve a sequence of tasks. Our model combines architecture growth to prevent forgetting of task-specific skills and an experience replay approach to preserve shared skills. We demonstrate our hybrid approach is effective in avoiding forgetting and show it is superior to both architecture-based and memory-based approaches on class incrementally learning of a single dataset as well as a sequence of multiple datasets in image classification. Our code is available at https://github.com/facebookresearch/Adversarial-Continual-Learning.},
annote = {hybrid method},
archivePrefix = {arXiv},
arxivId = {2003.09553},
author = {Ebrahimi, Sayna and Meier, Franziska and Calandra, Roberto and Darrell, Trevor and Rohrbach, Marcus},
doi = {10.1007/978-3-030-58621-8_23},
eprint = {2003.09553},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ebrahimi et al. - 2020 - Adversarial Continual Learning.pdf:pdf},
isbn = {9783030586201},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {adversarial learning,architectural,continual learning,experience replay,hybrid,rehearsal,replay},
mendeley-tags = {adversarial learning,architectural,continual learning,experience replay,hybrid,rehearsal,replay},
pages = {386--402},
title = {{Adversarial Continual Learning}},
url = {https://github.com/facebookresearch/Adversarial-Continual-Learning},
volume = {12356 LNCS},
year = {2020}
}
@article{Chan2020,
abstract = {This work attempts to interpret modern deep (convolutional) networks from the principles of rate reduction and (shift) invariant classification. We show that the basic iterative gradient ascent scheme for optimizing the rate reduction of learned features naturally leads to a multi-layer deep network, one iteration per layer. The layered architectures, linear and nonlinear operators, and even parameters of the network are all explicitly constructed layer-by-layer in a forward propagation fashion by emulating the gradient scheme. All components of this "white box" network have precise optimization, statistical, and geometric interpretation. This principled framework also reveals and justifies the role of multi-channel lifting and sparse coding in early stage of deep networks. Moreover, all linear operators of the so-derived network naturally become multi-channel convolutions when we enforce classification to be rigorously shift-invariant. The derivation also indicates that such a convolutional network is significantly more efficient to construct and learn in the spectral domain. Our preliminary simulations and experiments indicate that so constructed deep network can already learn a good discriminative representation even without any back propagation training.},
archivePrefix = {arXiv},
arxivId = {2010.14765},
author = {Chan, Kwan Ho Ryan and Yu, Yaodong and You, Chong and Qi, Haozhi and Wright, John and Ma, Yi},
eprint = {2010.14765},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chan et al. - 2020 - Deep Networks from the Principle of Rate Reduction.pdf:pdf},
pages = {1--34},
title = {{Deep Networks from the Principle of Rate Reduction}},
url = {http://arxiv.org/abs/2010.14765},
year = {2020}
}
@article{Las,
author = {Las, Rub{\'{e}}n R U E},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Las - Unknown - Rz Wr Fkrrvh Phpehuvkls Ixqfwlrqv Iru Ix Prghov Lq DssurLpdwlrq Sureohpv.pdf:pdf},
title = {{+Rz Wr Fkrrvh Phpehuvkls Ixqfwlrqv Iru Ix]]\ Prghov Lq Dssur[Lpdwlrq Sureohpv}}
}
@article{MFSWG2013a,
author = {(MFSWG), Mobile Financial Services Working Group},
number = {2},
title = {{Mobile Financial Services Basic Terminology}},
year = {2013}
}
@book{Cervantes2016,
address = {Warsaw},
author = {Cervantes, Leticia and Castillo, Oscar},
editor = {Kacprzyk, Janusz},
isbn = {9783319266701},
pages = {75},
publisher = {SpringerBriefs in Applied Sciences and Technology},
title = {{Type-2 Fuzzy Aggregation of Fuzzy Controllers}},
year = {2016}
}
@article{Gu2017,
abstract = {The term “fake news” became increasingly common during the past year. While this concept has many synonyms—disinformation campaigns, cyber propaganda, cognitive hacking, and information warfare—it's just one facet of the bigger problem: the manipulation of public opinion to affect the real world. Thanks to the connectivity and digital platforms that make it possible to share and spread information, traditional challenges such as physical borders and the constraints of time and distance do not exist anymore. Unfortunately, it also makes it easier to manipulate the public's perception of reality and thought processes, resulting in the proliferation of fake news that affects our real, non-digital environment. Each new incident shows how much impact the technological manipulation of public opinion can have on people's daily lives. This paper studies and explores the techniques and methods used by actors to spread fake news and manipulate public opinion to serve various motives ranging from personal and financial to political. It also discusses the three legs of the fake news triangle: the services that enable them, their appearance on social media sites, and the motivations behind these activities. We demonstrate several techniques used to identify such campaigns by processing social media data and show how it is possible to trace those campaigns to the original perpetrators.},
author = {Gu, Lion and Kropotov, Vladimir and Yarochkin, Fyodor},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gu, Kropotov, Yarochkin - 2017 - The fake news machine How propagandists abuse the Internet and manipulate the public.pdf:pdf},
journal = {Trend Micro},
keywords = {Fake news,cyber propaganda,deep web,social media},
pages = {1 -- 81},
title = {{The fake news machine: How propagandists abuse the Internet and manipulate the public}},
url = {https://documents.trendmicro.com/assets/white_papers/wp-fake-news-machine-how-propagandists-abuse-the-internet.pdf},
year = {2017}
}
@article{Tvrdk2006,
author = {Tvrdık, J.},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tvrdık - 2006 - Competitive differential evolution and genetic algorithm in GA-DS toolbox.pdf:pdf},
journal = {Technical Computing Prague, Praha, Humusoft},
number = {1},
pages = {99--106},
title = {{Competitive differential evolution and genetic algorithm in GA-DS toolbox}},
url = {http://dsp.vscht.cz/konference_matlab/MATLAB06/prispevky/tvrdik/tvrdik.pdf},
year = {2006}
}
@article{Jung2019,
author = {Pham, Quang and Liu, Chenghao and HOI, Steven},
file = {:home/user/Downloads/continual_normalization_rethin.pdf:pdf},
pages = {1--7},
title = {{Continual Normalization: Rethinking Batch Normalization For Online Continual Learning}},
year = {2022}
}
@article{Barrett2020,
abstract = {Gradient descent can be surprisingly good at optimizing deep neural networks without overfitting and without explicit regularization. We find that the discrete steps of gradient descent implicitly regularize models by penalizing gradient descent trajectories that have large loss gradients. We call this Implicit Gradient Regularization (IGR) and we use backward error analysis to calculate the size of this regularization. We confirm empirically that implicit gradient regularization biases gradient descent toward flat minima, where test errors are small and solutions are robust to noisy parameter perturbations. Furthermore, we demonstrate that the implicit gradient regularization term can be used as an explicit regularizer, allowing us to control this gradient regularization directly. More broadly, our work indicates that backward error analysis is a useful theoretical approach to the perennial question of how learning rate, model size, and parameter regularization interact to determine the properties of overparameterized models optimized with gradient descent.},
archivePrefix = {arXiv},
arxivId = {2009.11162},
author = {Barrett, David G.T. and Dherin, Benoit},
eprint = {2009.11162},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barrett, Dherin - 2020 - Implicit gradient regularization.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {gradient descent,implicit,regularization},
mendeley-tags = {gradient descent,implicit,regularization},
pages = {1--24},
title = {{Implicit gradient regularization}},
year = {2020}
}
@inproceedings{SonglinDong2020,
abstract = {In this paper, we focus on the challenging few-shot class- incremental learning (FSCIL) problem, which requires to transfer knowledge from old tasks to new ones and solves catastrophic forgetting.We propose the exemplar relation dis- tillation incremental learning framework to balance the tasks of old-knowledge preserving and new-knowledge adaptation. First, we construct an exemplar relation graph to represent the knowledge learned by the original network and update gradually for new tasks learning. Then an exemplar relation loss function for discovering the relation knowledge between different classes is introduced to learn and transfer the struc- tural information in relation graph. A large number of ex- periments demonstrate that relation knowledge does exist in the exemplars and our approach outperforms other state-of- the-art class-incremental learning methods on the CIFAR100, miniImageNet, and CUB200 datasets.},
author = {{Songlin Dong} and Hong, Xiaopeng and Tao, Xiaoyu and Chang, Xinyuan and Wei, Xing and Gong, Yihong},
booktitle = {35th AAAI Conference on Artificial Intelligence, AAAI 2021},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Songlin Dong et al. - 2020 - Few-Shot Class-Incremental Learning via Relation Knowledge Distillation.pdf:pdf},
keywords = {continual learning,graph,rehearsal,replay},
mendeley-tags = {continual learning,graph,rehearsal,replay},
title = {{Few-Shot Class-Incremental Learning via Relation Knowledge Distillation}},
year = {2020}
}
@article{Sun2020a,
abstract = {In this paper, we propose Test-Time Training, a general approach for improving the performance of predictive models when training and test data come from different distributions. We turn a single unlabeled test sample into a self-supervised learning problem, on which we update the model parameters before making a prediction. This also extends naturally to data in an online stream. Our simple approach leads to improvements on diverse image classification benchmarks aimed at evaluating robustness to distribution shifts.},
archivePrefix = {arXiv},
arxivId = {1909.13231},
author = {Sun, Yu and Wang, Xiaolong and Liu, Zhuang and Miller, John and Efros, Alexei A. and Hardt, Moritz},
eprint = {1909.13231},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sun et al. - 2020 - Test-time training with self-supervision for generalization under distribution shifts.pdf:pdf},
isbn = {9781713821120},
journal = {37th International Conference on Machine Learning, ICML 2020},
keywords = {distribution shift,self-supervised learning},
mendeley-tags = {distribution shift,self-supervised learning},
pages = {9166--9185},
title = {{Test-time training with self-supervision for generalization under distribution shifts}},
volume = {PartF16814},
year = {2020}
}
@article{Yu2020a,
abstract = {Few-shot meta-learning methods consider the problem of learning new tasks from a small, fixed number of examples, by meta-learning across static data from a set of previous tasks. However, in many real world settings, it is more natural to view the problem as one of minimizing the total amount of supervision --- both the number of examples needed to learn a new task and the amount of data needed for meta-learning. Such a formulation can be studied in a sequential learning setting, where tasks are presented in sequence. When studying meta-learning in this online setting, a critical question arises: can meta-learning improve over the sample complexity and regret of standard empirical risk minimization methods, when considering both meta-training and adaptation together? The answer is particularly non-obvious for meta-learning algorithms with complex bi-level optimizations that may demand large amounts of meta-training data. To answer this question, we extend previous meta-learning algorithms to handle the variable-shot settings that naturally arise in sequential learning: from many-shot learning at the start, to zero-shot learning towards the end. On sequential learning problems, we find that meta-learning solves the full task set with fewer overall labels and achieves greater cumulative performance, compared to standard supervised methods. These results suggest that meta-learning is an important ingredient for building learning systems that continuously learn and improve over a sequence of problems.},
archivePrefix = {arXiv},
arxivId = {2012.07769},
author = {Yu, Tianhe and Geng, Xinyang and Finn, Chelsea and Levine, Sergey},
eprint = {2012.07769},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu et al. - 2020 - Variable-Shot Adaptation for Online Meta-Learning.pdf:pdf},
keywords = {continual learning,meta-learning},
mendeley-tags = {continual learning,meta-learning},
pages = {1--19},
title = {{Variable-Shot Adaptation for Online Meta-Learning}},
url = {http://arxiv.org/abs/2012.07769},
year = {2020}
}
@article{Jin2020a,
abstract = {COVID-19 pandemic has an unprecedented impact all over the world since early 2020. During this public health crisis, reliable forecasting of the disease becomes critical for resource allocation and administrative planning. The results from compartmental models such as SIR and SEIR are popularly referred by CDC and news media. With more and more COVID-19 data becoming available, we examine the following question: Can a direct data-driven approach without modeling the disease spreading dynamics outperform the well referred compartmental models and their variants? In this paper, we show the possibility. It is observed that as COVID-19 spreads at different speed and scale in different geographic regions, it is highly likely that similar progression patterns are shared among these regions within different time periods. This intuition lead us to develop a new neural forecasting model, called Attention Crossing Time Series (\textbf{ACTS}), that makes forecasts via comparing patterns across time series obtained from multiple regions. The attention mechanism originally developed for natural language processing can be leveraged and generalized to materialize this idea. Among 13 out of 18 testings including forecasting newly confirmed cases, hospitalizations and deaths, \textbf{ACTS} outperforms all the leading COVID-19 forecasters highlighted by CDC.},
archivePrefix = {arXiv},
arxivId = {2010.13006},
author = {Jin, Xiaoyong and Wang, Yu-Xiang and Yan, Xifeng},
eprint = {2010.13006},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jin, Wang, Yan - 2020 - Inter-Series Attention Model for COVID-19 Forecasting.pdf:pdf},
keywords = {attention,covid-19,detrending,time series,time series forecasting},
mendeley-tags = {time series},
title = {{Inter-Series Attention Model for COVID-19 Forecasting}},
url = {http://arxiv.org/abs/2010.13006 https://github.com/Gandor26/covid-open},
year = {2020}
}
@article{Gopinath2016,
author = {Gopinath, Deepthi I and Dwarakish, GS},
doi = {10.1177/1759313116642896},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gopinath, Dwarakish - 2016 - Real-time prediction of waves using neural networks trained by particle swarm optimization.pdf:pdf},
issn = {1759-3131},
journal = {The International Journal of Ocean and Climate Systems},
keywords = {4 october 2015,7 december 2015,accepted,artificial neural network,date received,feed-forward back-propagation,levenberg,marquardt algorithm,particle swarm optimization},
number = {2},
pages = {70--79},
title = {{Real-time prediction of waves using neural networks trained by particle swarm optimization}},
url = {http://journals.sagepub.com/doi/10.1177/1759313116642896},
volume = {7},
year = {2016}
}
@inproceedings{Shin2017,
abstract = {Attempts to train a comprehensive artificial intelligence capable of solving multiple tasks have been impeded by a chronic problem called catastrophic forgetting. Although simply replaying all previous data alleviates the problem, it requires large memory and even worse, often infeasible in real world applications where the access to past data is limited. Inspired by the generative nature of hippocampus as a short-term memory system in primate brain, we propose the Deep Generative Replay, a novel framework with a cooperative dual model architecture consisting of a deep generative model ("generator") and a task solving model ("solver"). With only these two models, training data for previous tasks can easily be sampled and interleaved with those for a new task. We test our methods in several sequential learning settings involving image classification tasks.},
archivePrefix = {arXiv},
arxivId = {1705.08690},
author = {Shin, Hanul and Lee, Jung Kwon and Kim, Jaehong and Kim, Jiwon},
booktitle = {Neural Information Processing Systems (NeurIPS)},
eprint = {1705.08690},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shin et al. - 2017 - Continual Learning with Deep Generative Replay.pdf:pdf},
issn = {10495258},
month = {may},
number = {Nips},
title = {{Continual Learning with Deep Generative Replay}},
url = {https://www.zoobarcelona.cat/ca/animals http://arxiv.org/abs/1705.08690},
year = {2017}
}
@article{Douillard2021,
abstract = {Continual learning is a machine learning sub-field specialized in settings with non-iid data. Hence, the training data distribution is not static and drifts through time. Those drifts might cause interferences in the trained model and knowledge learned on previous states of the data distribution might be forgotten. Continual learning's challenge is to create algorithms able to learn an ever-growing amount of knowledge while dealing with data distribution drifts. One implementation difficulty in these field is to create data loaders that simulate non-iid scenarios. Indeed, data loaders are a key component for continual algorithms. They should be carefully designed and reproducible. Small errors in data loaders have a critical impact on algorithm results, e.g. with bad preprocessing, wrong order of data or bad test set. Continuum is a simple and efficient framework with numerous data loaders that avoid researcher to spend time on designing data loader and eliminate time-consuming errors. Using our proposed framework, it is possible to directly focus on the model design by using the multiple scenarios and evaluation metrics implemented. Furthermore the framework is easily extendable to add novel settings for specific needs.},
archivePrefix = {arXiv},
arxivId = {2102.06253},
author = {Douillard, Arthur and Lesort, Timoth{\'{e}}e},
eprint = {2102.06253},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Douillard, Lesort - 2021 - Continuum Simple Management of Complex Continual Learning Scenarios.pdf:pdf},
keywords = {continual learning,dataloader,framework,library,tools},
mendeley-tags = {continual learning,dataloader,framework,library,tools},
pages = {1--8},
title = {{Continuum: Simple Management of Complex Continual Learning Scenarios}},
url = {http://arxiv.org/abs/2102.06253 https://github.com/Continvvm/continuum},
year = {2021}
}
@article{sokar2020a,
abstract = {The continual learning (CL) paradigm aims to enable neural networks to learn tasks continually in a sequential fashion. The fundamental challenge in this learning paradigm is catastrophic forgetting previously learned tasks when the model is optimized for a new task, especially when their data is not accessible. Current architectural-based methods aim at alleviating the catastrophic forgetting problem but at the expense of expanding the capacity of the model. Regularization-based methods maintain a fixed model capacity; however, previous studies showed the huge performance degradation of these methods when the task identity is not available during inference (e.g. class incremental learning scenario). In this work, we propose a novel architectural-based method referred as SpaceNet for class incremental learning scenario where we utilize the available fixed capacity of the model intelligently. SpaceNet trains sparse deep neural networks from scratch in an adaptive way that compresses the sparse connections of each task in a compact number of neurons. The adaptive training of the sparse connections results in sparse representations that reduce the interference between the tasks. Experimental results show the robustness of our proposed method against catastrophic forgetting old tasks and the efficiency of SpaceNet in utilizing the available capacity of the model, leaving space for more tasks to be learned. In particular, when SpaceNet is tested on the well-known benchmarks for CL: split MNIST, split Fashion-MNIST, and CIFAR-10/100, it outperforms regularization-based methods by a big performance gap. Moreover, it achieves better performance than architectural-based methods without model expansion and achieved comparable results with rehearsal-based methods, while offering a huge memory reduction.},
archivePrefix = {arXiv},
arxivId = {2007.07617},
author = {Sokar, Ghada and Mocanu, Decebal Constantin and Pechenizkiy, Mykola},
eprint = {2007.07617},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sokar, Mocanu, Pechenizkiy - 2021 - SpaceNet Make Free Space For Continual Learning.pdf:pdf},
journal = {Neurocomputing},
keywords = {architectural,regularization,sparse network,sparsity},
mendeley-tags = {architectural,regularization,sparse network,sparsity},
title = {{SpaceNet: Make Free Space For Continual Learning}},
url = {http://arxiv.org/abs/2007.07617},
year = {2021}
}
@article{Liu2008,
abstract = {In this study, transesterification of soybean oil to biodiesel using CaO as a solid base catalyst was studied. The reaction mechanism was proposed and the separate effects of the molar ratio of methanol to oil, reaction temperature, mass ratio of catalyst to oil and water content were investigated. The experimental results showed that a 12:1 molar ratio of methanol to oil, addition of 8% CaO catalyst, 65 °C reaction temperature and 2.03% water content in methanol gave the best results, and the biodiesel yield exceeded 95% at 3 h. The catalyst lifetime was longer than that of calcined K2CO3/$\gamma$-Al2O3and KF/$\gamma$-Al2O3catalysts. CaO maintained sustained activity even after being repeatedly used for 20 cycles and the biodiesel yield at 1.5 h was not affected much in the repeated experiments. {\textcopyright} 2007 Elsevier Ltd. All rights reserved.},
author = {Liu, Xuejun and He, Huayang and Wang, Yujun and Zhu, Shenlin and Piao, Xianglan},
doi = {10.1016/j.fuel.2007.04.013},
isbn = {0016-2361},
issn = {00162361},
journal = {Fuel},
keywords = {Biodiesel,Calcium oxide,Solid base catalyst,Soybean oil,Transesterification},
number = {2},
pages = {216--221},
title = {{Transesterification of soybean oil to biodiesel using CaO as a solid base catalyst}},
volume = {87},
year = {2008}
}
@article{Tang2013,
abstract = {A high efficient production of fatty acid methyl ester (FAME) from soybean oil and rapeseed oil was carried out using modified CaO as solid basic catalyst by connecting bromooctane to the surface of CaO chemically in a simple way. It was found that 99.5% yield of the FAME over modified CaO was obtained from soybean oil using 15:1 molar ratio of methanol to oil after 3 h at reaction temperature of 65 °C, which is much higher than the yield of 35.4% over commercial CaO at the same reaction conditions. For the transesterification between rapeseed oil and methanol, the reaction time to its highest yield, 99.8%, was shortened to 2.5 h. The physical and chemical properties of catalysts were characterized by using techniques of X-ray diffraction (XRD), scanning electron microscope (SEM), BET surface area measurement (BET), Fourier transform-infrared (FT-IR) spectroscopy and thermogravimeter (TG). The results indicated that well dispersed CaO with relatively small particle sizes and high surface areas were obtained after modification. Furthermore, the thermal stability of modified CaO is improved and the amount of Ca(OH)2formed during the modifying process is very little. Influence of the amount of modifier and various reaction conditions, such as mass ratio of catalyst to oil, reaction temperature and molar ratio of methanol to oil, were investigated in detail. Furthermore, water-tolerance of the modified CaO was tested by adding water in the reaction system. {\textcopyright} 2012 Elsevier Ltd. All rights reserved.},
author = {Tang, Ying and Xu, Jingfang and Zhang, Jie and Lu, Yong},
doi = {10.1016/j.jclepro.2012.11.001},
isbn = {0959-6526},
issn = {09596526},
journal = {Journal of Cleaner Production},
keywords = {Basic catalyst,Biodiesel,CaO,Modification},
pages = {198--203},
publisher = {Elsevier Ltd},
title = {{Biodiesel production from vegetable oil by using modified CaO as solid basic catalysts}},
url = {http://dx.doi.org/10.1016/j.jclepro.2012.11.001},
volume = {42},
year = {2013}
}
@article{Oliveira2015,
author = {Oliveira, Paloma and Assis, Antonino De and Coelho, Gerlane and Guerra, Bernardo and Fernandes, Daline and Ara{\'{u}}jo, De Souza and Ara{\'{u}}jo, Raimundo Fernandes De and Alc{\^{a}}ntara, Tamires and Gomes, Dourado and Ara{\'{u}}jo, Aurigena Antunes De and Alcoforado, Tamires and Lima, Sena De and Enrique, Hugo and Garcia, Mendez and F{\'{a}}tima, Leylliane De and Interaminense, Leal and C{\'{a}}ssia, Rita De and Queiroga, Egypto},
doi = {10.1016/j.idairyj.2015.11.002},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oliveira et al. - 2015 - Intestinal anti-inflammatory activity of goat milk and goat yoghurt in the acetic acid model of rat colitis.pdf:pdf},
issn = {0958-6946},
journal = {International Dairy Journal},
number = {2016},
publisher = {Elsevier Ltd},
title = {{Intestinal anti-inflammatory activity of goat milk and goat yoghurt in the acetic acid model of rat colitis}},
url = {http://dx.doi.org/10.1016/j.idairyj.2015.11.002},
year = {2015}
}
@article{Cardoso2020,
abstract = {In the past two decades, the field of applied finance has tremendously benefited from graph theory. As a result, novel methods ranging from asset network estimation to hierarchical asset selection and portfolio allocation are now part of practitioners' toolboxes. In this paper, we investigate the fundamental problem of learning undirected graphical models under Laplacian structural constraints from the point of view of financial market times series data. In particular, we present natural justifications, supported by empirical evidence, for the usage of the Laplacian matrix as a model for the precision matrix of financial assets, while also establishing a direct link that reveals how Laplacian constraints are coupled to meaningful physical interpretations related to the market index factor and to conditional correlations between stocks. Those interpretations lead to a set of guidelines that practitioners should be aware of when estimating graphs in financial markets. In addition, we design numerical algorithms based on the alternating direction method of multipliers to learn undirected, weighted graphs that take into account stylized facts that are intrinsic to financial data such as heavy tails and modularity. We illustrate how to leverage the learned graphs into practical scenarios such as stock time series clustering and foreign exchange network estimation. The proposed graph learning algorithms outperform the state-of-the-art methods in an extensive set of practical experiments. Furthermore, we obtain theoretical and empirical convergence results for the proposed algorithms. Along with the developed methodologies for graph learning in financial markets, we release an R package, called fingraph, accommodating the code and data to obtain all the experimental results.},
archivePrefix = {arXiv},
arxivId = {2012.15410},
author = {Cardoso, Jos{\'{e}} Vin{\'{i}}cius de Miranda and Ying, Jiaxi and Palomar, Daniel Perez},
eprint = {2012.15410},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cardoso, Ying, Palomar - 2020 - Algorithms for Learning Graphs in Financial Markets.pdf:pdf},
journal = {arXiv},
keywords = {Graph Laplacian,Index Terms—undirected graphical models,Stock markets,time series},
mendeley-tags = {time series},
month = {dec},
pages = {1--62},
title = {{Algorithms for Learning Graphs in Financial Markets}},
url = {https://arxiv.org/abs/2012.15410 https://github.com/mirca/fingraph},
year = {2020}
}
@article{Martens2020a,
abstract = {Natural gradient descent is an optimization method traditionally motivated from the perspective of information geometry, and works well for many applications as an alternative to stochastic gradient descent. In this paper we critically analyze this method and its properties, and show how it can be viewed as a type of 2nd-order optimization method, with the Fisher information matrix acting as a substitute for the Hessian. In many important cases, the Fisher information matrix is shown to be equivalent to the Generalized Gauss-Newton matrix, which both approximates the Hessian, but also has certain properties that favor its use over the Hessian. This perspective turns out to have significant implications for the design of a practical and robust natural gradient optimizer, as it motivates the use of techniques like trust regions and Tikhonov regularization. Additionally, we make a series of contributions to the understanding of natural gradient and 2nd-order methods, including: a thorough analysis of the convergence speed of stochastic natural gradient descent (and more general stochastic 2nd-order methods) as applied to convex quadratics, a critical examination of the oft-used \empirical"approximation of the Fisher matrix, and an analysis of the (approximate) parameterization invariance property possessed by natural gradient methods (which we show also holds for certain other curvature matrices, but notably not the Hessian).},
archivePrefix = {arXiv},
arxivId = {1412.1193},
author = {Martens, James},
eprint = {1412.1193},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Martens - 2020 - New insights and perspectives on the natural gradient method(2).pdf:pdf},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {2nd-order optimization,Convergence rate,Natural gradient methods,Neural networks,Parameterization invariance},
pages = {1--76},
title = {{New insights and perspectives on the natural gradient method}},
volume = {21},
year = {2020}
}
@article{Munafo2015,
abstract = {Titanium dioxide has been recently used in its nanometric form to develop smart products and coatings on several building components so as to better preserve their visual aspect, mainly by way of its very efficient photocatalytic function. The integration of further nanostructured materials with titanium dioxide may enhance its features or add new properties to these products. The aim of this review is to provide a report on the latest developments in a specific area of the maintenance of architectural surfaces: the use of multifunctional (self-cleaning, de-polluting, biocidal) nanocoatings based on titanium dioxide on architectural stone surfaces. The results of several studies concerning different products containing TiO2nanoparticles, potentially added with other nanometric elements, have been summarised and compared from several points of view focused on their compatibility with treated substrates and their effectiveness against diverse degrading agents (soil, pollution and microorganisms). From the discussed works, the application of TiO2-based products on several architectural stones seems to be feasible and valuable; however several features are in need of deeper analyses before real large-scale use. In addition, possible future developments by scientific research may provide further increased performances and additional features and functions to these treatments.},
author = {Munaf{\`{o}}, Placido and Goffredo, Giovanni Battista and Quagliarini, Enrico},
doi = {10.1016/j.conbuildmat.2015.02.083},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Munaf{\`{o}}, Goffredo, Quagliarini - 2015 - TiO2-based nanocoatings for preserving architectural stone surfaces An overview.pdf:pdf},
isbn = {0950-0618},
issn = {09500618},
journal = {Construction and Building Materials},
keywords = {Biocidal effect,De-polluting products,Nanotechnological building materials,Self-cleaning treatments,Stone conservation,Titanium dioxide},
pages = {201--218},
title = {{TiO2-based nanocoatings for preserving architectural stone surfaces: An overview}},
volume = {84},
year = {2015}
}
@article{Sabour2017,
abstract = {A capsule is a group of neurons whose activity vector represents the instantiation parameters of a specific type of entity such as an object or an object part. We use the length of the activity vector to represent the probability that the entity exists and its orientation to represent the instantiation parameters. Active capsules at one level make predictions, via transformation matrices, for the instantiation parameters of higher-level capsules. When multiple predictions agree, a higher level capsule becomes active. We show that a discrimininatively trained, multi-layer capsule system achieves state-of-the-art performance on MNIST and is considerably better than a convolutional net at recognizing highly overlapping digits. To achieve these results we use an iterative routing-by-agreement mechanism: A lower-level capsule prefers to send its output to higher level capsules whose activity vectors have a big scalar product with the prediction coming from the lower-level capsule.},
archivePrefix = {arXiv},
arxivId = {1710.09829},
author = {Sabour, Sara and Frosst, Nicholas and Hinton, Geoffrey E.},
eprint = {1710.09829},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sabour, Frosst, Hinton - 2017 - Dynamic Routing Between Capsules.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
month = {oct},
number = {Nips},
pages = {3857--3867},
title = {{Dynamic Routing Between Capsules}},
url = {http://arxiv.org/abs/1710.09829},
volume = {2017-Decem},
year = {2017}
}
@article{Wortsman2020a,
abstract = {We present the Supermasks in Superposition (SupSup) model, capable of sequentially learning thousands of tasks without catastrophic forgetting. Our approach uses a randomly initialized, fixed base network and for each task finds a subnetwork (supermask) that achieves good performance. If task identity is given at test time, the correct subnetwork can be retrieved with minimal memory usage. If not provided, SupSup can infer the task using gradient-based optimization to find a linear superposition of learned supermasks which minimizes the output entropy. In practice we find that a single gradient step is often sufficient to identify the correct mask, even among 2500 tasks. We also showcase two promising extensions. First, SupSup models can be trained entirely without task identity information, as they may detect when they are uncertain about new data and allocate an additional supermask for the new training distribution. Finally the entire, growing set of supermasks can be stored in a constant-sized reservoir by implicitly storing them as attractors in a fixed-sized Hopfield network.},
archivePrefix = {arXiv},
arxivId = {2006.14769},
author = {Wortsman, Mitchell and Ramanujan, Vivek and Liu, Rosanne and Kembhavi, Aniruddha and Rastegari, Mohammad and Yosinski, Jason and Farhadi, Ali},
eprint = {2006.14769},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wortsman et al. - 2020 - Supermasks in Superposition.pdf:pdf},
issn = {23318422},
journal = {arXiv},
number = {NeurIPS},
title = {{Supermasks in Superposition}},
year = {2020}
}
@article{Liao2017,
abstract = {In the manufacturing domain, interoperability represents a characteristic of a manufacturing system in which its components are capable of exchanging information with one another, using the information that has been exchanged. Even though the discussion about interoperability issues can trace back to the 1970s, system interoperability is still the “elephant in the room”. Additionally, in the past few years, research topics related to the fourth industrial revolution, also known as Industry 4.0, have been gradually accepted and promoted by governments and organizations all around the world. A research question then arises: what is the role of interoperability in the fourth industrial revolution era? The aim of this paper is to provide a scientific and evidence-based answer to this question. From an academic perspective, a systematic literature review was carried out to discover the main concepts related to interoperability in an Industry 4.0 context. From an industrial perspective, a questionnaire survey was developed to guide the application of a multi-criteria decision analysis method, the Analytic Hierarchy Process, used to analyze and make explicit the relationships of the previously discovered concepts. Results of this study can be used as a basis for future interoperability research in this new industrial revolution wave.},
author = {Liao, Yongxin and Ramos, Luiz Felipe Pierin and Saturno, Maicon and Deschamps, Fernando and {de Freitas Rocha Loures}, Eduardo and Szejka, Anderson Luis},
doi = {10.1016/j.ifacol.2017.08.1248},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liao et al. - 2017 - The Role of Interoperability in The Fourth Industrial Revolution Era.pdf:pdf},
issn = {24058963},
journal = {IFAC-PapersOnLine},
keywords = {Analytic Hierarchy Process,Industry 4.0,Interoperability,Questionnaire Survey,Systematic Literature Review,The Fourth Industrial Revolution},
number = {1},
pages = {12434--12439},
publisher = {Elsevier B.V.},
title = {{The Role of Interoperability in The Fourth Industrial Revolution Era}},
url = {https://doi.org/10.1016/j.ifacol.2017.08.1248},
volume = {50},
year = {2017}
}
@book{Lewis1982,
address = {London},
author = {Lewis, C. D.},
isbn = {0-408-00559-9},
publisher = {Butterworth Scientific},
title = {{Industrial and business forecasting methods: A Radical guide to exponential smoothing and curve fitting}},
year = {1982}
}
@article{Christ2016,
abstract = {The all-relevant problem of feature selection is the identification of all strongly and weakly relevant attributes. This problem is especially hard to solve for time series classification and regression in industrial applications such as predictive maintenance or production line optimization, for which each label or regression target is associated with several time series and meta-information simultaneously. Here, we are proposing an efficient, scalable feature extraction algorithm for time series, which filters the available features in an early stage of the machine learning pipeline with respect to their significance for the classification or regression task, while controlling the expected percentage of selected but irrelevant features. The proposed algorithm combines established feature extraction methods with a feature importance filter. It has a low computational complexity, allows to start on a problem with only limited domain knowledge available, can be trivially parallelized, is highly scalable and based on well studied non-parametric hypothesis tests. We benchmark our proposed algorithm on all binary classification problems of the UCR time series classification archive as well as time series from a production line optimization project and simulated stochastic processes with underlying qualitative change of dynamics.},
archivePrefix = {arXiv},
arxivId = {1610.07717},
author = {Christ, Maximilian and Kempa-Liehr, Andreas W. and Feindt, Michael},
eprint = {1610.07717},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Christ, Kempa-Liehr, Feindt - 2016 - Distributed and parallel time series feature extraction for industrial big data applications.pdf:pdf},
keywords = {feature engineering,feature selection,time series,time series feature},
mendeley-tags = {time series},
title = {{Distributed and parallel time series feature extraction for industrial big data applications}},
url = {http://arxiv.org/abs/1610.07717 https://github.com/blue-yonder/tsfresh},
year = {2016}
}
@article{Howard2018,
abstract = {Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100× more data. We open-source our pretrained models and code1},
archivePrefix = {arXiv},
arxivId = {1801.06146},
author = {Howard, Jeremy and Ruder, Sebastian},
doi = {10.18653/v1/p18-1031},
eprint = {1801.06146},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Howard, Ruder - 2018 - Universal language model fine-tuning for text classification.pdf:pdf},
isbn = {9781948087322},
journal = {ACL 2018 - 56th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)},
pages = {328--339},
title = {{Universal language model fine-tuning for text classification}},
volume = {1},
year = {2018}
}
@article{LeDoux2007,
abstract = {The amygdala is a complex \r\nstructure involved in a wide range \rof normal behavioral functions and \rpsychiatric conditions. Not so long \rago it was an obscure region of the brain that attracted relatively little scientific interest. Today it is one of the most heavily studied brain areas, and practically a household word. Art critics are explaining the impact of a painting by its direct impact on the amygdala; essential oils are said to alter mood by affecting the amygdala; and there is a website where you can unleash your creativity by clicking your amygdala, and thereby popping your frontal cortex. In this Primer, I will focus on the scientific implications of the research, discussing the anatomical structure, connectivity, cellular properties and behavioral functions of the amygdala.},
author = {LeDoux, Joseph},
doi = {10.1016/j.cub.2007.08.005},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/LeDoux - 2007 - The amygdala.pdf:pdf},
isbn = {0960-9822 (Print)\n0960-9822 (Linking)},
issn = {09609822},
journal = {Current Biology},
number = {20},
pages = {868--874},
pmid = {17956742},
title = {{The amygdala}},
volume = {17},
year = {2007}
}
@inproceedings{Sataloff1989,
author = {Sataloff, Robert T and Johns, Michael M and Kost, Karen M},
isbn = {9781626239777},
title = {{The 11th Annual Conference of The Cognitive Science Society}},
year = {1989}
}
@article{Huang2020a,
abstract = {Incorporating relational reasoning into neural networks has greatly expanded their capabilities and scope. One defining trait of relational reasoning is that it operates on a set of entities, as opposed to standard vector representations. Existing end-to-end approaches typically extract entities from inputs by directly interpreting the latent feature representations as a set. We show that these approaches do not respect set permutational invariance and thus have fundamental representational limitations. To resolve this limitation, we propose a simple and general network module called a Set Refiner Network (SRN). We first use synthetic image experiments to demonstrate how our approach effectively decomposes objects without explicit supervision. Then, we insert our module into existing relational reasoning models and show that respecting set invariance leads to substantial gains in prediction performance and robustness on several relational reasoning tasks.},
archivePrefix = {arXiv},
arxivId = {2003.04448},
author = {Huang, Qian and He, Horace and Singh, Abhay and Zhang, Yan and Lim, Ser-Nam and Benson, Austin},
eprint = {2003.04448},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang et al. - 2020 - Better Set Representations For Relational Reasoning.pdf:pdf;:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang et al. - 2020 - Better Set Representations For Relational Reasoning(2).pdf:pdf},
number = {NeurIPS},
pages = {1--12},
title = {{Better Set Representations For Relational Reasoning}},
url = {http://arxiv.org/abs/2003.04448},
year = {2020}
}
@article{Koksoy2015,
author = {Koksoy, Ceyda Er and Ozkan, Mehmet Baris and Buhan, Serkan and Demirci, Turan and Arslan, Yusuf and Birturk, Aysenur and Karagoz, Pinar},
doi = {10.1109/ICMLA.2015.60},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Koksoy et al. - 2015 - Improved Wind Power Forecasting Using Combination Methods.pdf:pdf},
isbn = {978-1-5090-0287-0},
journal = {2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)},
keywords = {forecast combination,fuzzy soft sets,l p -,norm estimators,random forests,regression trees,wind power forecasting},
pages = {1142--1147},
title = {{Improved Wind Power Forecasting Using Combination Methods}},
url = {http://ieeexplore.ieee.org/document/7424473/},
year = {2015}
}
@article{KreithF.andGoswami2007,
author = {{Kreith, F. and Goswami}, Y. D.},
doi = {10.1201/9781420003482},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kreith, F. and Goswami - 2007 - Handbook of Energy Efficiency and Renewable Energy.pdf:pdf},
isbn = {978-0-8493-1730-9},
journal = {Change},
pages = {1--22},
title = {{Handbook of Energy Efficiency and Renewable Energy.}},
year = {2007}
}
@inproceedings{Cao2020a,
abstract = {Developing algorithms that are able to generalize to a novel task given only a few labeled examples represents a fundamental challenge in closing the gap between machine- and human-level performance. The core of human cognition lies in the structured, reusable concepts that help us to rapidly adapt to new tasks and provide reasoning behind our decisions. However, existing meta-learning methods learn complex representations across prior labeled tasks without imposing any structure on the learned representations. Here we propose COMET, a meta-learning method that improves generalization ability by learning to learn along human-interpretable concept dimensions. Instead of learning a joint unstructured metric space, COMET learns mappings of high-level concepts into semi-structured metric spaces, and effectively combines the outputs of independent concept learners. We evaluate our model on few-shot tasks from diverse domains, including fine-grained image classification, document categorization and cell type annotation on a novel dataset from a biological domain developed in our work. COMET significantly outperforms strong meta-learning baselines, achieving 6-15% relative improvement on the most challenging 1-shot learning tasks, while unlike existing methods providing interpretations behind the model's predictions.},
archivePrefix = {arXiv},
arxivId = {2007.07375},
author = {Cao, Kaidi and Brbic, Maria and Leskovec, Jure},
booktitle = {Iclr 2021},
eprint = {2007.07375},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cao, Brbic, Leskovec - 2020 - Concept Learners for Few-Shot Learning.pdf:pdf},
keywords = {concept learning,few-shot learning},
mendeley-tags = {concept learning,few-shot learning},
pages = {1--17},
title = {{Concept Learners for Few-Shot Learning}},
url = {http://arxiv.org/abs/2007.07375},
year = {2020}
}
@article{Tharwat2014,
abstract = {This work presents a method that can be used to enhance the neutron radiography (NR) image for objects with high scattering materials like hydrogen, carbon and other light materials. This method used Monte Carlo code, MCNP5, to simulate the NR process and get the flux distribution for each pixel of the image and determines the scattered neutron distribution that caused image blur, and then uses MATLAB to subtract this scattered neutron distribution from the initial image to improve its quality.This work was performed before the commissioning of digital NR system in Jan. 2013. The MATLAB enhancement method is quite a good technique in the case of static based film neutron radiography, while in neutron imaging (NI) technique, image enhancement and quantitative measurement were efficient by using ImageJ software. The enhanced image quality and quantitative measurements were presented in this work. {\textcopyright} 2014 Elsevier Ltd.},
author = {Tharwat, Montaser and Mohamed, Nader and Mongy, T.},
doi = {10.1016/j.apradiso.2014.02.004},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tharwat, Mohamed, Mongy - 2014 - Image enhancement using MCNP5 code and MATLAB in neutron radiography.pdf:pdf},
issn = {09698043},
journal = {Applied Radiation and Isotopes},
keywords = {Imaging enhancement,MATLAB,MCNP5,Neutron imaging,Quantitative measurements,Static based film neutron radiography},
pages = {30--36},
pmid = {24583508},
publisher = {Elsevier},
title = {{Image enhancement using MCNP5 code and MATLAB in neutron radiography}},
url = {http://dx.doi.org/10.1016/j.apradiso.2014.02.004},
volume = {89},
year = {2014}
}
@article{Ramapuram2020,
abstract = {Lifelong learning is the problem of learning multiple consecutive tasks in a sequential manner, where knowledge gained from previous tasks is retained and used to aid future learning over the lifetime of the learner. It is essential towards the development of intelligent machines that can adapt to their surroundings. In this work we focus on a lifelong learning approach to unsupervised generative modeling, where we continuously incorporate newly observed distributions into a learned model. We do so through a student-teacher Variational Autoencoder architecture which allows us to learn and preserve all the distributions seen so far, without the need to retain the past data nor the past models. Through the introduction of a novel cross-model regularizer, inspired by a Bayesian update rule, the student model leverages the information learned by the teacher, which acts as a probabilistic knowledge store. The regularizer reduces the effect of catastrophic interference that appears when we learn over sequences of distributions. We validate our model's performance on sequential variants of MNIST, FashionMNIST, PermutedMNIST, SVHN and Celeb-A and demonstrate that our model mitigates the effects of catastrophic interference faced by neural networks in sequential learning scenarios.},
archivePrefix = {arXiv},
arxivId = {1705.09847},
author = {Ramapuram, Jason and Gregorova, Magda and Kalousis, Alexandros},
doi = {10.1016/j.neucom.2020.02.115},
eprint = {1705.09847},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramapuram, Gregorova, Kalousis - 2020 - Lifelong generative modeling.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Continual learning,Generative modeling,Lifelong learning,Variational inference,continual learning,generative model,image generation,incremental learning},
mendeley-tags = {continual learning,generative model,image generation,incremental learning},
pages = {381--400},
title = {{Lifelong generative modeling}},
volume = {404},
year = {2020}
}
@article{Zhong2017,
abstract = {Power systems are going through a paradigm change. Centralized large generating facilities are being replaced with millions of widely dispersed, incompatible, non-synchronous and relatively small renewable or alternative power plants, plug-in EVs, and energy storage units. Moreover, the majority of loads are expected to actively regulate system stability as well. This paradigm change, called the democratization of power systems, is comparable to the great historical event of personal computers replacing mainframes in the technology domain or republics replacing monarchies in the political domain. In this paper, some concepts and principles in politics are borrowed to study power systems. The term synchronized and democratized smart grid (in short, SYNDEM) is coined and the most fundamental features of a democratized society, i.e., the rule of law and the legal equality, are established for SYNDEM. The synchronization mechanism of synchronous machines is identified as the natural rule of law to govern SYNDEM and the legal equality is achieved via operating power electronic converters as virtual synchronous machines (VSM) to homogenize all heterogeneous players. Then, a lateral system architecture is presented to implement SYNDEM. This actually offers a technical solution to realize the lateral power to underpin The Third Industrial Revolution envisioned by Jeremy Rifkin. As a result, all active players in a grid, large or small, conventional or renewable, supplying or consuming, can equally and laterally regulate the grid in a synchronous manner to enhance the stability, scalability, operability, reliability, security and resiliency of future power systems. Live discussions and future updates on this subject are available via joining the LinkedIn group at https://www.linkedin.com/groups/7061909.},
author = {Zhong, Qing Chang},
doi = {10.1016/j.ifacol.2017.08.699},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhong - 2017 - Synchronized and Democratized Smart Grids To Underpin The Third Industrial Revolution.pdf:pdf},
issn = {24058963},
journal = {IFAC-PapersOnLine},
keywords = {Synchronized,The Third Industrial Revolution,democratization of power systems,democratized smart grid (SYNDEM),distributed energy resources (DER),grid architecture,grid modernization,lateral power,phase-locked loops,renewable energy,robust droop control,self-synchronization,synchronverter,universal droop control,virtual synchronous machines (VSM)},
number = {1},
pages = {3592--3597},
publisher = {Elsevier B.V.},
title = {{Synchronized and Democratized Smart Grids To Underpin The Third Industrial Revolution}},
url = {https://doi.org/10.1016/j.ifacol.2017.08.699},
volume = {50},
year = {2017}
}
@article{Rosenfeld2020,
abstract = {Given an existing trained neural network, it is often desirable to learn new capabilities without hindering performance of those already learned. Existing approaches either learn sub-optimal solutions, require joint training, or incur a substantial increment in the number of parameters for each added domain, typically as many as the original network. We propose a method called Deep Adaptation Modules (DAM) that constrains newly learned filters to be linear combinations of existing ones. DAMs precisely preserve performance on the original domain, require a fraction (typically 13 percent, dependent on network architecture) of the number of parameters compared to standard fine-tuning procedures and converge in less cycles of training to a comparable or better level of performance. When coupled with standard network quantization techniques, we further reduce the parameter cost to around 3 percent of the original with negligible or no loss in accuracy. The learned architecture can be controlled to switch between various learned representations, enabling a single network to solve a task from multiple different domains. We conduct extensive experiments showing the effectiveness of our method on a range of image classification tasks and explore different aspects of its behavior.},
archivePrefix = {arXiv},
arxivId = {1705.04228},
author = {Rosenfeld, Amir and Tsotsos, John K.},
doi = {10.1109/TPAMI.2018.2884462},
eprint = {1705.04228},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rosenfeld, Tsotsos - 2020 - Incremental Learning through Deep Adaptation.pdf:pdf},
issn = {19393539},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Incremental learning,domain adaptation,transfer learning},
number = {3},
pages = {651--663},
pmid = {30507526},
title = {{Incremental Learning through Deep Adaptation}},
volume = {42},
year = {2020}
}
@book{Levett1991,
author = {Levett, Paul N.},
isbn = {978-0471932369},
pages = {128},
publisher = {Wiley},
title = {{Anaerobic Bacteria: A Functional Biology}},
year = {1991}
}
@article{JothiKumarRa,
abstract = {Organizations are maintaining history of data for future analysis. These huge volume of database is analysed to Predict and improve the benefits and profits of the organization and also for the development. By analysing the history of data, strategic decisions can be made to improve the performance of the organizations by the top level peoples. So organizations are interested in analysing the data which will result in valuable insight. The data subjected to mining consists of inconsistent, blank or null and noisy values which have to be cleaned before mining. Usually the Techniques of Mean, Mode, and Median will be used to clean the data which are inefficient methods. Here I am representing the efficient data pre-processing which is to be carried out before actual mining process can be performed. The data from different databases, different locations and different formats are considered for pre-processing. This results in identification of reasonable patterns to improve the performance of organization. Even the Neural Networks has complex structure, consumes more learning time and difficult to understand the representation of results, it have more acceptance ability to clean impure data with more precise and accuracy in pre-processing which results in efficient data pre-processing for Data Mining. The data pre-processing includes four stages. They are cleaning the Data, Selecting the data, Data Enhancement and Data Transformation. Cleaning the data: is to fill the empty value of the data and to ignore the noisy data and to correct the inconsistencies data. Selecting the data: is choosing the appropriate data which suits for learning. Data Enhancement: is done to enhance the data quality which has been selected. Data Expression: is to transform the data after pre-processing into the form which can be accepted by the data mining algorithm based on neural network. The data mining based on neural network can only handle numerical data, so it is need to transform the sign data into numerical data. The simplest method is to establish a table with one-to-one correspondence between the sign data and the numerical data. The other more complex approach is to adopt the appropriate Hash function to generate a unique numerical data according to given string. Although there are many data types in relational database, but they all basically can be simply come down to sign data, discrete numerical data and serial numerical data. Then, the discrete numerical data can be quantified into continuous numerical data and can also be encoded into coding data which can be easily and efficiently handled by data mining algorithms. KEYWORDS—Data mining; neural networks, data mining process, Pre-processing.},
author = {JothiKumarR and SivabalanRV},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/JothiKumarR, SivabalanRV - Unknown - Efficient Data Pre-Processing for Data Mining Using Neural Networks.pdf:pdf},
journal = {International Journal of Scientific Research and Management Studies},
number = {4},
pages = {2349--3771},
title = {{Efficient Data Pre-Processing for Data Mining Using Neural Networks}},
volume = {1}
}
@article{Sutskever2011,
abstract = {In this note, we show that exponentially deep belief networks can approximate any distribution over binary vectors to arbitrary accuracy, even when thewidth of each layer is limited to the dimensionality of the data. We further show that such networks can be greedily learned in an easy yet impractical way.},
author = {Sutskever, Ilya and Hinton, Geoffrey E},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sutskever, Hinton - 2011 - Deep , Narrow Sigmoid Belief Networks Are Universal.pdf:pdf},
journal = {Neural Computation},
number = {11},
pages = {2629--2636},
title = {{Deep , Narrow Sigmoid Belief Networks Are Universal}},
volume = {20},
year = {2011}
}
@inproceedings{Bai2020,
abstract = {Multi-label classification is the challenging task of predicting the presence and absence of multiple targets, involving representation learning and label correlation modeling. We propose a novel framework for multi-label classification, Multivariate Probit Variational AutoEncoder (MPVAE), that effectively learns latent embedding spaces as well as label correlations. MPVAE learns and aligns two probabilistic embedding spaces for labels and features respectively. The decoder of MPVAE takes in the samples from the embedding spaces and models the joint distribution of output targets under a Multivariate Probit model by learning a shared covariance matrix. We show that MPVAE outperforms the existing state-of-the-art methods on a variety of application domains, using public real-world datasets1. MPVAE is further shown to remain robust under noisy settings. Lastly, we demonstrate the interpretability of the learned covariance by a case study on a bird observation dataset.},
address = {California},
author = {Bai, Junwen and Kong, Shufeng and Gomes, Carla},
booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence},
doi = {10.24963/ijcai.2020/595},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bai, Kong, Gomes - 2020 - Disentangled Variational Autoencoder based Multi-Label Classification with Covariance-Aware Multivariate Probi.pdf:pdf},
isbn = {978-0-9992411-6-5},
keywords = {Machine Learning: Deep Generative Models,Machine Learning: Interpretability,Machine Learning: Multi-instance,Multi-label,Multi-view learning,Uncertainty in AI: Approximate Probabilistic Infer},
month = {jul},
pages = {4313--4321},
publisher = {International Joint Conferences on Artificial Intelligence Organization},
title = {{Disentangled Variational Autoencoder based Multi-Label Classification with Covariance-Aware Multivariate Probit Model}},
url = {https://www.ijcai.org/proceedings/2020/595},
year = {2020}
}
@article{Guo2016,
abstract = {Deep learning has become a ubiquitous technology to improve machine intelligence. However, most of the existing deep models are structurally very complex, making them difficult to be deployed on the mobile platforms with limited computational power. In this paper, we propose a novel network compression method called dynamic network surgery, which can remarkably reduce the network complexity by making on-the-fly connection pruning. Unlike the previous methods which accomplish this task in a greedy way, we properly incorporate connection splicing into the whole process to avoid incorrect pruning and make it as a continual network maintenance. The effectiveness of our method is proved with experiments. Without any accuracy loss, our method can efficiently compress the number of parameters in LeNet-5 and AlexNet by a factor of 108× and 17.7× respectively, proving that it outperforms the recent pruning method by considerable margins. Code and some models are available at https://github.com/yiwenguo/Dynamic-Network-Surgery.},
archivePrefix = {arXiv},
arxivId = {1608.04493},
author = {Guo, Yiwen and Yao, Anbang and Chen, Yurong},
eprint = {1608.04493},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guo, Yao, Chen - 2016 - Dynamic network surgery for efficient DNNs.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {1387--1395},
title = {{Dynamic network surgery for efficient DNNs}},
year = {2016}
}
@article{Mendez2020,
abstract = {Policy gradient methods have shown success in learning control policies for high-dimensional dynamical systems. Their biggest downside is the amount of exploration they require before yielding high-performing policies. In a lifelong learning setting, in which an agent is faced with multiple consecutive tasks over its lifetime, reusing information from previously seen tasks can substantially accelerate the learning of new tasks. We provide a novel method for lifelong policy gradient learning that trains lifelong function approximators directly via policy gradients, allowing the agent to benefit from accumulated knowledge throughout the entire training process. We show empirically that our algorithm learns faster and converges to better policies than single-task and lifelong learning baselines, and completely avoids catastrophic forgetting on a variety of challenging domains.},
archivePrefix = {arXiv},
arxivId = {2007.07011},
author = {Mendez, Jorge A. and Wang, Boyu and Eaton, Eric},
eprint = {2007.07011},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mendez, Wang, Eaton - 2020 - Lifelong Policy Gradient Learning of Factored Policies for Faster Training without Forgetting.pdf:pdf},
journal = {arXiv},
keywords = {continual learning},
mendeley-tags = {continual learning},
title = {{Lifelong Policy Gradient Learning of Factored Policies for Faster Training without Forgetting}},
year = {2020}
}
@article{Management,
author = {Management, Talent},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Management - Unknown - INFORMATIONAL INTERVIEWING – SAMPLE QUESTIONS TO ASK ORGANIZATION and DEPARTMENT.pdf:pdf},
number = {617},
pages = {1--6},
title = {{INFORMATIONAL INTERVIEWING – SAMPLE QUESTIONS TO ASK ORGANIZATION and DEPARTMENT}},
volume = {02142}
}
@article{Evanusa2020,
abstract = {Deep Reservoir Computing has emerged as a new paradigm for deep learning, which is based around the reservoir computing principle of maintaining random pools of neurons combined with hierarchical deep learning. The reservoir paradigm reflects and respects the high degree of recurrence in biological brains, and the role that neuronal dynamics play in learning. However, one issue hampering deep reservoir network development is that one cannot backpropagate through the reservoir layers. Recent deep reservoir architectures do not learn hidden or hierarchical representations in the same manner as deep artificial neural networks, but rather concatenate all hidden reservoirs together to perform traditional regression. Here we present a novel Deep Reservoir Network for time series prediction and classification that learns through the non-differentiable hidden reservoir layers using a biologically-inspired backpropagation alternative called Direct Feedback Alignment, which resembles global dopamine signal broadcasting in the brain. We demonstrate its efficacy on two real world multidimensional time series datasets.},
archivePrefix = {arXiv},
arxivId = {2010.06209},
author = {Evanusa, Matthew and Ferm{\"{u}}ller, Cornelia and Aloimonos, Yiannis},
eprint = {2010.06209},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Evanusa, Ferm{\"{u}}ller, Aloimonos - 2020 - Deep Reservoir Networks with Learned Hidden Reservoir Weights using Direct Feedback Alignment.pdf:pdf},
number = {NeurIPS},
title = {{Deep Reservoir Networks with Learned Hidden Reservoir Weights using Direct Feedback Alignment}},
url = {http://arxiv.org/abs/2010.06209},
year = {2020}
}
@article{Selvaraju2020,
abstract = {Recent advances in self-supervised learning (SSL) have largely closed the gap with supervised ImageNet pretraining. Despite their success these methods have been primarily applied to unlabeled ImageNet images, and show marginal gains when trained on larger sets of uncurated images. We hypothesize that current SSL methods perform best on iconic images, and struggle on complex scene images with many objects. Analyzing contrastive SSL methods shows that they have poor visual grounding and receive poor supervisory signal when trained on scene images. We propose Contrastive Attention-Supervised Tuning(CAST) to overcome these limitations. CAST uses unsupervised saliency maps to intelligently sample crops, and to provide grounding supervision via a Grad-CAM attention loss. Experiments on COCO show that CAST significantly improves the features learned by SSL methods on scene images, and further experiments show that CAST-trained models are more robust to changes in backgrounds.},
archivePrefix = {arXiv},
arxivId = {2012.04630},
author = {Selvaraju, Ramprasaath R. and Desai, Karan and Johnson, Justin and Naik, Nikhil},
eprint = {2012.04630},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Selvaraju et al. - 2020 - CASTing Your Model Learning to Localize Improves Self-Supervised Representations.pdf:pdf},
keywords = {detection,localization,self-supervised learning},
mendeley-tags = {detection,localization,self-supervised learning},
title = {{CASTing Your Model: Learning to Localize Improves Self-Supervised Representations}},
url = {http://arxiv.org/abs/2012.04630},
year = {2020}
}
@article{Akinbinu2014,
abstract = {In today's society, the use of computer as a tool at workplaces, academic institutions, recreation facilities and homes has become very common. It is estimated that globally, about 45 to 70 million people spend hours staring into a video display terminal, popularly known as computer screen. Several studies, mainly in developed countries, have shown an association between computer use and visual health related symptoms (Computer Vision Syndrome, CVS) in both children and adults. In this report, a review of literature on CVS was undertaken to determine the prevalence of CVS and compare the prevalence between studies. The risk factors associated with the syndrome range from individual visual problems and poor ergonomics. The most common symptoms include headache, eye strain, double vision, dry eyes, eye fatigue and other symptoms of eye strain. The prevalence of the symptoms varied between studies. It is concluded that, as computer users are increasing rapidly, they are at risk of CVS. A better understanding of the pathophysiology underlying CVS is necessary to empower practitioners to accurately diagnose and treat patients with CVS; necessary precautions and care should be exercised to prevent serious impact of CVS on productivity and sustainable economic development of countries in Africa. In addition, special attention should be given to the young population including children and students in schools, colleges and universities.},
author = {Akinbinu, T R and Mashalla, Y J},
doi = {10.5897/MPR.2014.0121},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Akinbinu, Mashalla - 2014 - Medical Practice and Review Impact of computer technology on health Computer Vision Syndrome ( CVS ).pdf:pdf},
issn = {2141-2596},
journal = {Academic Journals},
keywords = {computer users,computer vision syndrome,cvs,health impact},
number = {November},
pages = {20--30},
title = {{Medical Practice and Review Impact of computer technology on health : Computer Vision Syndrome ( CVS )}},
volume = {5},
year = {2014}
}
@article{French1999,
abstract = {All natural cognitive systems, and, in particular, our own, gradually forget previously learned information. Plausible models of human cognition should therefore exhibit similar patterns of gradual forgetting of old information as new information is acquired. Only rarely does new learning in natural cognitive systems completely disrupt or erase previously learned information; that is, natural cognitive systems do not, in general, forget ‘catastrophically'. Unfortunately, though, catastrophic forgetting does occur under certain circumstances in distributed connectionist networks. The very features that give these networks their remarkable abilities to generalize, to function in the presence of degraded input, and so on, are found to be the root cause of catastrophic forgetting. The challenge in this field is to discover how to keep the advantages of distributed connectionist networks while avoiding the problem of catastrophic forgetting. In this article the causes, consequences and numerous solutions to the problem of catastrophic forgetting in neural networks are examined. The review will consider how the brain might have overcome this problem and will also explore the consequences of this solution for distributed connectionist networks.},
author = {French, R},
doi = {10.1016/S1364-6613(99)01294-2},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/French - 1999 - Catastrophic forgetting in connectionist networks.pdf:pdf},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
keywords = {continual learning,incremental learning,review,survey},
mendeley-tags = {continual learning,incremental learning,review,survey},
month = {apr},
number = {4},
pages = {128--135},
title = {{Catastrophic forgetting in connectionist networks}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661399012942},
volume = {3},
year = {1999}
}
@article{Awan2011,
abstract = {Discovering and understanding the dynamic phenomena of weather to accurately predict different weather events has been an integral component of scientific investigations worldwide. The weather data, being inherently fuzzy in nature, requires highly complex processing based on human observations, satellite photography, or radar followed by computer simulations. This is further combined with an understanding of the principles of global and local weather dynamics. This paper attempts to solve weather event prediction for Lahore by implementing a fuzzy rule based system. The difficult problem of weather event prediction has been dealt in this paper through two separate experimental settings. In the first experimental setting a smaller dataset consisting of 365 instances with 4 inputs and 8 weather events has been used to develop a fuzzy inference system. In the second experimental setting the developed fuzzy system has been enhanced for a larger dataset consisting of over 2500 data points, having 17 inputs, and 10 weather events. For the later experiments the results of the fuzzy system have been compared with two other models i.e., decision tree (DT) based model and partial least square based regression (PLSR) model. It has been observed in the present study that the performance of the fuzzy system is sensitive to bootstrapping sampling technique that has been used for generating training and test samples for developing the fuzzy, DT and PLSR models. Further the models under consideration have been less sensitive to principal component analysis based dimensionality reduction method. {\textcopyright} 2010 Elsevier B.V. All rights reserved.},
author = {Awan, Malik Shahzad Kaleem and Awais, Mian Muhammad},
doi = {10.1016/j.asoc.2009.10.016},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Awan, Awais - 2011 - Predicting weather events using fuzzy rule based system.pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {Decision tree,Fuzzy rule based system,Lahore,Partial least square regression,Weather events},
number = {1},
pages = {56--63},
title = {{Predicting weather events using fuzzy rule based system}},
volume = {11},
year = {2011}
}
@article{Bachmann2006,
abstract = {Fluorescence of the skin, enamel, dentin, and bone are reviewed. Fluorescence spectroscopy is one of the noninvasive methods that can identify diseases and promote increasing the knowledge in medical diagnosis. The microstructure and composition of biological tissues are presented, followed by a description of chromophores, fluorophores as identified by use of applied fluorescence techniques.},
author = {Bachmann, Luciano and Zezell, Denise Maria and Ribeiro, Adriana da Costa and Gomes, La{\'{e}}rcio and Ito, Amando Siuiti},
doi = {10.1080/05704920600929498},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bachmann et al. - 2006 - Fluorescence Spectroscopy of Biological Tissues—A Review.pdf:pdf},
isbn = {0570492060092},
issn = {0570-4928},
journal = {Applied Spectroscopy Reviews},
number = {6},
pages = {575--590},
title = {{Fluorescence Spectroscopy of Biological Tissues—A Review}},
url = {http://www.tandfonline.com/doi/abs/10.1080/05704920600929498},
volume = {41},
year = {2006}
}
@article{Mittal2021,
abstract = {Contemporary neural networks are limited in their ability to learn from evolving streams of training data. When trained sequentially on new or evolving tasks, their accuracy drops sharply, making them unsuitable for many real-world applications. In this work, we shed light on the causes of this well-known yet unsolved phenomenon - often referred to as catastrophic forgetting - in a class-incremental setup. We show that a combination of simple components and a loss that balances intra-task and inter-task learning can already resolve forgetting to the same extent as more complex measures proposed in literature. Moreover, we identify poor quality of the learned representation as another reason for catastrophic forgetting in class-IL. We show that performance is correlated with secondary class information (dark knowledge) learned by the model and it can be improved by an appropriate regularizer. With these lessons learned, class-incremental learning results on CIFAR-100 and ImageNet improve over the state-of-the-art by a large margin, while keeping the approach simple.},
archivePrefix = {arXiv},
arxivId = {2102.09517},
author = {Mittal, Sudhanshu and Galesso, Silvio and Brox, Thomas},
eprint = {2102.09517},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mittal, Galesso, Brox - 2021 - Essentials for Class Incremental Learning.pdf:pdf},
keywords = {class incremental learning,continual learning,incremental learning,representation learning},
mendeley-tags = {class incremental learning,continual learning,incremental learning,representation learning},
title = {{Essentials for Class Incremental Learning}},
url = {http://arxiv.org/abs/2102.09517},
year = {2021}
}
@article{Eberts2020,
abstract = {We introduce SpERT, an attention model for span-based joint entity and relation extraction. Our key contribution is a light-weight reasoning on BERT embeddings, which features entity recognition and filtering, as well as relation classification with a localized, marker-free context representation. The model is trained using strong within-sentence negative samples, which are efficiently extracted in a single BERT pass. These aspects facilitate a search over all spans in the sentence. In ablation studies, we demonstrate the benefits of pre-training, strong negative sampling and localized context. Our model outperforms prior work by up to 2.6% F1 score on several datasets for joint entity and relation extraction.},
archivePrefix = {arXiv},
arxivId = {1909.07755},
author = {Eberts, Markus and Ulges, Adrian},
doi = {10.3233/FAIA200321},
eprint = {1909.07755},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Eberts, Ulges - 2020 - Span-based joint entity and relation extraction with transformer pre-training.pdf:pdf},
isbn = {9781643681009},
issn = {09226389},
journal = {Frontiers in Artificial Intelligence and Applications},
keywords = {information extraction,joint entity and relation extraction,natural language processing},
mendeley-tags = {information extraction,joint entity and relation extraction,natural language processing},
pages = {2006--2013},
title = {{Span-based joint entity and relation extraction with transformer pre-training}},
volume = {325},
year = {2020}
}
@article{Yang2019,
abstract = {We develop a mean field theory for batch normalization in fully-connected feedforward neural networks. In so doing, we provide a precise characterization of signal propagation and gradient backpropagation in wide batch-normalized networks at initialization. Our theory shows that gradient signals grow exponentially in depth and that these exploding gradients cannot be eliminated by tuning the initial weight variances or by adjusting the nonlinear activation function. Indeed, batch normalization itself is the cause of gradient explosion. As a result, vanilla batch-normalized networks without skip connections are not trainable at large depths for common initialization schemes, a prediction that we verify with a variety of empirical simulations. While gradient explosion cannot be eliminated, it can be reduced by tuning the network close to the linear regime, which improves the trainability of deep batch-normalized networks without residual connections. Finally, we investigate the learning dynamics of batch-normalized networks and observe that after a single step of optimization the networks achieve a relatively stable equilibrium in which gradients have dramatically smaller dynamic range. Our theory leverages Laplace, Fourier, and Gegenbauer transforms and we derive new identities that may be of independent interest.},
archivePrefix = {arXiv},
arxivId = {1902.08129},
author = {Yang, Greg and Pennington, Jeffrey and Rao, Vinay and Sohl-Dickstein, Jascha and Schoenholz, Samuel S.},
eprint = {1902.08129},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2019 - A mean field theory of batch normalization.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {batch normalization,module,theory},
mendeley-tags = {batch normalization,module,theory},
title = {{A mean field theory of batch normalization}},
year = {2019}
}
@article{Mickovski2017,
abstract = {The assessment of the sustainability impacts of eco-engineering strategies can be challenging and remains neglected within the literature and in practice. The challenge lies in achieving a balance between the delivery of project objectives and their alignment with the emerging principles of sustainable design which seek to provide an appropriate and satisfactory environmental and financial performance whilst delivering social benefits. Whilst it is possible to assess various aspects of the long term performance of soil bioengineering measures and the relevant projects in their delivery through cost evaluations, risk assessments and environmental impact assessments, there is currently no agreed means of assessing the sustainability performance of such measures in an integrated framework which captures the environmental, social and economic dimensions of sustainability. To remediate this, we propose an integrated sustainability assessment framework which can be applied on any eco-engineering project. It is underpinned by a review of current sustainability indicators commonly applied in the range of sustainability assessment methods (SAMs) and best practice guidance within construction and geotechnical engineering. The framework comprises a set of key performance indicators (KPIs) reflective of the both engineering and sustainability requirements for eco-engineering in the context of stability, active use of vegetation and long-term sustainability for eco-engineering projects. Recognition is provided of the unique nature of each eco-engineering measure and provision is established within the framework for a contextual KPI subset to be developed through stakeholder engagement. The potential of the framework was explored through an expert workshop highlighting its value to promote benchmarking across the sector between eco-engineering projects and would allow standards to emerge for establishing best practice. Through a real-life case study, we demonstrate the benefits of the adoption of such a framework at an early stage of a project but also the benefits for stakeholders which stem from double-loop learning.},
author = {Mickovski, S. B. and Thomson, C. S.},
doi = {10.1016/j.ecoleng.2017.10.004},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mickovski, Thomson - 2017 - Developing a framework for the sustainability assessment of eco-engineering measures.pdf:pdf},
issn = {09258574},
journal = {Ecological Engineering},
keywords = {Eco-engineering,Ground bio-engineering,Key performance indicators (KPI),Resilience,Sustainability},
number = {January},
pages = {145--160},
publisher = {Elsevier},
title = {{Developing a framework for the sustainability assessment of eco-engineering measures}},
url = {http://dx.doi.org/10.1016/j.ecoleng.2017.10.004},
volume = {109},
year = {2017}
}
@article{Pratama2017,
abstract = {--Most of the real world datasets suffer from the problem of missing data. It may lead data mining analysts to end with wrong inferences about data under study. Many researchers are working on this problem to introduce more sophisticated methods. Eventhough many methods are available, analysts are facing difficulty in searching a suitable method due to lack of knowledge about the methods and their applicability. To bridge this gap, this paper provides a brief overview of the review papers that have been published during last 10 years that deal with missing values. It discusses about the methods that are compared in the literatures and observations that the authors have made. Finally the techniques that are recommended in most of the literatures are implemented in real world datasets and the empirical results are studied.},
author = {Pratama, Irfan and Permanasari, Adhistya Erna and Ardiyanto, Igi and Indrayani, Rini},
doi = {10.1109/ICITSI.2016.7858189},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pratama et al. - 2017 - A review of missing values handling methods on time-series data.pdf:pdf},
isbn = {9781509024490},
journal = {2016 International Conference on Information Technology Systems and Innovation, ICITSI 2016 - Proceedings},
keywords = {deletion,estimation technique,mean imputation,missing values,time series},
title = {{A review of missing values handling methods on time-series data}},
year = {2017}
}
@article{Goyal2021,
abstract = {Recently, self-supervised learning methods like MoCo, SimCLR, BYOL and SwAV have reduced the gap with supervised methods. These results have been achieved in a control environment, that is the highly curated ImageNet dataset. However, the premise of self-supervised learning is that it can learn from any random image and from any unbounded dataset. In this work, we explore if self-supervision lives to its expectation by training large models on random, uncurated images with no supervision. Our final SElf-supERvised (SEER) model, a RegNetY with 1.3B parameters trained on 1B random images with 512 GPUs achieves 84.2% top-1 accuracy, surpassing the best self-supervised pretrained model by 1% and confirming that self-supervised learning works in a real world setting. Interestingly, we also observe that self-supervised models are good few-shot learners achieving 77.9% top-1 with access to only 10% of ImageNet. Code: https://github.com/facebookresearch/vissl},
archivePrefix = {arXiv},
arxivId = {2103.01988},
author = {Goyal, Priya and Caron, Mathilde and Lefaudeux, Benjamin and Xu, Min and Wang, Pengchao and Pai, Vivek and Singh, Mannat and Liptchinsky, Vitaliy and Misra, Ishan and Joulin, Armand and Bojanowski, Piotr},
eprint = {2103.01988},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goyal et al. - 2021 - Self-supervised Pretraining of Visual Features in the Wild.pdf:pdf},
keywords = {large-scale,pre-training,self-supervised learning},
mendeley-tags = {large-scale,pre-training,self-supervised learning},
title = {{Self-supervised Pretraining of Visual Features in the Wild}},
year = {2021}
}
@article{Qin2019,
archivePrefix = {arXiv},
arxivId = {arXiv:1902.09592v1},
author = {Qin, Chongli and Dvijotham, Krishnamurthy Dj and Donoghue, Brendan O and Stanforth, Robert and Gowal, Sven and Uesato, Jonathan and Swirszcz, Grzegorz},
eprint = {arXiv:1902.09592v1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qin et al. - 2019 - VERIFICATION OF NON-LINEAR SPECIFICATIONS FOR NEURAL NETWORKS.pdf:pdf},
pages = {1--21},
title = {{VERIFICATION OF NON-LINEAR SPECIFICATIONS FOR NEURAL NETWORKS}},
year = {2019}
}
@article{Sau2016,
abstract = {The remarkable successes of deep learning models across various applications have resulted in the design of deeper networks that can solve complex problems. However, the increasing depth of such models also results in a higher storage and runtime complexity, which restricts the deployability of such very deep models on mobile and portable devices, which have limited storage and battery capacity. While many methods have been proposed for deep model compression in recent years, almost all of them have focused on reducing storage complexity. In this work, we extend the teacher-student framework for deep model compression, since it has the potential to address runtime and train time complexity too. We propose a simple methodology to include a noise-based regularizer while training the student from the teacher, which provides a healthy improvement in the performance of the student network. Our experiments on the CIFAR-10, SVHN and MNIST datasets show promising improvement, with the best performance on the CIFAR-10 dataset. We also conduct a comprehensive empirical evaluation of the proposed method under related settings on the CIFAR-10 dataset to show the promise of the proposed approach.},
archivePrefix = {arXiv},
arxivId = {1610.09650},
author = {Sau, Bharat Bhusan and Balasubramanian, Vineeth N.},
eprint = {1610.09650},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sau, Balasubramanian - 2016 - Deep Model Compression Distilling Knowledge from Noisy Teachers.pdf:pdf},
issn = {0004-637X},
keywords = {and,chasm between deeper networks,deep learning,model compression,noise,portability,re-,regularization,smaller and smaller in,student learning,sulting in a widening,teacher-,terms of mobility and},
title = {{Deep Model Compression: Distilling Knowledge from Noisy Teachers}},
url = {http://arxiv.org/abs/1610.09650},
year = {2016}
}
@article{Joseph2020a,
abstract = {In a real-world setting, object instances from new classes may be continuously encountered by object detectors. When existing object detectors are applied to such scenarios, their performance on old classes deteriorates significantly. A few efforts have been reported to address this limitation, all of which apply variants of knowledge distillation to avoid catastrophic forgetting. We note that although distillation helps to retain previous learning, it obstructs fast adaptability to new tasks, which is a critical requirement for incremental learning. In this pursuit, we propose a meta-learning approach that learns to reshape model gradients, such that information across incremental tasks is optimally shared. This ensures a seamless information transfer via a meta-learned gradient preconditioning that minimizes forgetting and maximizes knowledge transfer. In comparison to existing meta-learning methods, our approach is task-agnostic, allows incremental addition of new-classes and scales to large-sized models for object detection. We evaluate our approach on a variety of incremental settings defined on PASCAL-VOC and MS COCO datasets, demonstrating significant improvements over state-of-the-art.},
archivePrefix = {arXiv},
arxivId = {2003.08798},
author = {Joseph, K. J. and Rajasegaran, Jathushan and Khan, Salman and Khan, Fahad Shahbaz and Balasubramanian, Vineeth N. and Shao, Ling},
eprint = {2003.08798},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Joseph et al. - 2020 - Incremental object detection via meta-learning.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {Deep Neural Networks,Incremental Object Detection,continual learning,incremental learning,meta-learning,object detection},
mendeley-tags = {continual learning,incremental learning,meta-learning,object detection},
number = {8},
pages = {1--8},
title = {{Incremental object detection via meta-learning}},
volume = {14},
year = {2020}
}
@article{Horton2007,
abstract = {Multimode fibres are widely used in astronomy because of the ease of coupling light into them at a telescope focus. The photonics industry has given rise to a broad range of products but these are almost exclusively restricted to single-mode fibres, although some can be adapted for use in fibres that allow several modes to propagate. Now that astronomical telescopes are moving toward diffraction-limited performance through the use of adaptive optics (AO), we address the problem of coupling light into a few-mode fibre (FMF). We find that fibres with as few as $\sim$5 guided modes share important characterisitcs with multimode fibres, in particular high coupling efficiency.We anticipate that future astronomical instruments at an AO-corrected focus will be able to exploit a broad class of photonic devices.},
archivePrefix = {arXiv},
arxivId = {astro-ph/0606291},
author = {Horton, Anthony J and Bland-Hawthorn, Joss},
doi = {10.1364/OE.15.001443},
eprint = {0606291},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Horton, Bland-Hawthorn - 2007 - Coupling light into few-mode optical fibres I The diffraction limit.pdf:pdf},
isbn = {0819463345},
issn = {1094-4087},
journal = {Optics express},
number = {4},
pages = {1443--1453},
pmid = {19532375},
primaryClass = {astro-ph},
title = {{Coupling light into few-mode optical fibres I: The diffraction limit.}},
volume = {15},
year = {2007}
}
@article{Huang2017,
abstract = {Despite deep neural networks have demonstrated extraordinary power in various applications, their superior performances are at expense of high storage and computational costs. Consequently, the acceleration and compression of neural networks have attracted much attention recently. Knowledge Transfer (KT), which aims at training a smaller student network by transferring knowledge from a larger teacher model, is one of the popular solutions. In this paper, we propose a novel knowledge transfer method by treating it as a distribution matching problem. Particularly, we match the distributions of neuron selectivity patterns between teacher and student networks. To achieve this goal, we devise a new KT loss function by minimizing the Maximum Mean Discrepancy (MMD) metric between these distributions. Combined with the original loss function, our method can significantly improve the performance of student networks. We validate the effectiveness of our method across several datasets, and further combine it with other KT methods to explore the best possible results. Last but not least, we fine-tune the model to other tasks such as object detection. The results are also encouraging, which confirm the transferability of the learned features.},
archivePrefix = {arXiv},
arxivId = {1707.01219},
author = {Huang, Zehao and Wang, Naiyan},
eprint = {1707.01219},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang, Wang - 2017 - Like What You Like Knowledge Distill via Neuron Selectivity Transfer.pdf:pdf},
title = {{Like What You Like: Knowledge Distill via Neuron Selectivity Transfer}},
url = {http://arxiv.org/abs/1707.01219},
year = {2017}
}
@article{Ecker2010,
abstract = {Learn about lidar, a technology that uses high-speed laser pulses to generate three-dimensional structural data about the terrain and landscape features.},
author = {Ecker, Michael},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ecker - 2010 - Light Detection and Ranging ( LiDAR ) Technology Evaluation.pdf:pdf},
journal = {Transportation},
number = {October},
title = {{Light Detection and Ranging ( LiDAR ) Technology Evaluation}},
year = {2010}
}
@article{Karnik1998,
abstract = {This paper introduces a robust fuzzy logic system, one that can handle rule uncertainties. We make use of type-2 fuzzy sets for this purpose. The development of a type-2 fuzzy logic system has led to a new operation that we call type-reduction. In the course of this development, we also study set operations on type-2 sets, properties of membership grades of type-2 sets, type-2 relations and their compositions, and defuzzification},
author = {Karnik, N.N. and Mendel, J.M.},
doi = {10.1109/FUZZY.1998.686240},
isbn = {0-7803-4863-X},
issn = {2152-7806},
journal = {1998 IEEE International Conference on Fuzzy Systems Proceedings. IEEE World Congress on Computational Intelligence (Cat. No.98CH36228)},
keywords = {Fuzzy sets,Marine vehicles,Measurement uncertainty,Robustness,Shape,Terminology,defuzzification,fuzzy logic,fuzzy set theory,inference engines,inference mechanisms,membership grades,type-2 fuzzy logic systems,type-reduction,uncertainty handling},
pages = {915--920},
pmid = {21541006},
title = {{Introduction to type-2 fuzzy logic systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=686240},
volume = {2},
year = {1998}
}
@article{Mohamed2012,
abstract = {The purpose of this paper is to present a new and an alternative differential evolution (ADE) algorithm for solving unconstrained global optimization problems. In the new algorithm, a new directed mutation rule is introduced based on the weighted difference vector between the best and the worst individuals of a particular generation. The mutation rule is combined with the basic mutation strategy through a linear decreasing probability rule. This modification is shown to enhance the local search ability of the basic DE and to increase the convergence rate. Two new scaling factors are introduced as uniform random variables to improve the diversity of the population and to bias the search direction. Additionally, a dynamic non-linear increased crossover probability scheme is utilized to balance the global exploration and local exploitation. Furthermore, a random mutation scheme and a modified Breeder Genetic Algorithm (BGA) mutation scheme are merged to avoid stagnation and/or premature convergence. Numerical experiments and comparisons on a set of well-known high dimensional benchmark functions indicate that the improved algorithm outperforms and is superior to other existing algorithms in terms of final solution quality, success rate, convergence rate, and robustness. {\textcopyright} 2011.},
author = {Mohamed, Ali W. and Sabry, Hegazy Z. and Khorshid, Motaz},
doi = {10.1016/j.jare.2011.06.004},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mohamed, Sabry, Khorshid - 2012 - An alternative differential evolution algorithm for global optimization.pdf:pdf},
issn = {20901232},
journal = {Journal of Advanced Research},
keywords = {Differential evolution,Directed mutation,Dynamic non-linear crossover,Global optimization,Modified BGA mutation},
number = {2},
pages = {149--165},
publisher = {Cairo University},
title = {{An alternative differential evolution algorithm for global optimization}},
url = {http://dx.doi.org/10.1016/j.jare.2011.06.004},
volume = {3},
year = {2012}
}
@article{Wang2020a,
abstract = {Egocentric gestures are the most natural form of communication for humans to interact with wearable devices such as VR/AR helmets and glasses. A major issue in such scenarios for real-world applications is that may easily become necessary to add new gestures to the system e.g., a proper VR system should allow users to customize gestures incrementally. Traditional deep learning methods require storing all previous class samples in the system and training the model again from scratch by incorporating previous samples and new samples, which costs humongous memory and significantly increases computation over time. In this work, we demonstrate a lifelong 3D convolutional framework - c(C)la(a)ss increment(t)al net(Net)works (CatNet), which considers temporal information in videos and enables life-long learning for egocentric gesture video recognition by learning the feature representation of an exemplar set selected from previous class samples. Importantly, we propose a two-stream CatNet, which deploys RGB and depth modalities to train two separate networks. We evaluate Cat- Nets on a publicly available dataset - EgoGesture dataset, and show that CatNets can learn many classes incrementally over a long period of time. Results also demonstrate that the two-stream architecture achieves the best performance on both joint training and class incremental training compared to 3 other one-stream architectures. The codes and pre-trained models used in this work are provided at https://github.com/villawang/CatNet.},
archivePrefix = {arXiv},
arxivId = {2004.09215},
author = {Wang, Zhengwei and She, Qi and Chalasani, Tejo and Smolic, Aljosa},
doi = {10.1109/CVPRW50498.2020.00123},
eprint = {2004.09215},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2020 - CatNet Class Incremental 3D ConvNets for lifelong egocentric gesture recognition.pdf:pdf},
isbn = {9781728193601},
issn = {21607516},
journal = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
keywords = {continual learning,egocentric gesture recognition,gesture recognition,incremental learning},
mendeley-tags = {continual learning,egocentric gesture recognition,gesture recognition,incremental learning},
number = {15},
pages = {935--944},
title = {{CatNet: Class Incremental 3D ConvNets for lifelong egocentric gesture recognition}},
volume = {2020-June},
year = {2020}
}
@article{Khare2013,
abstract = {Particle swarm optimization is a stochastic optimization, evolutionary and simulating algorithm derived from human behaviour and animal behaviour as well. Special property of particle swarm optimization is that it can be operated in continuous real number space directly, does not use gradient of an objective function similar to other algorithms. Particle swarm optimization has few parameters to adjust, is easy to implement and has special characteristic of memory. Paper presents extensive review of literature available on concept, development and modification of Particle swarm optimization. This paper is structured as first concept and development of PSO is discussed then modification with inertia weight and constriction factor is discussed. Issues related to parameter tuning, dynamic environments, stagnation, and hybridization are also discussed, including a brief review of selected works on particle swarm optimization, followed by application of PSO in Solar Photovoltaics. {\textcopyright} 2012 Elsevier B.V. All rights reserved.},
author = {Khare, Anula and Rangnekar, Saroj},
doi = {10.1016/j.asoc.2012.11.033},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khare, Rangnekar - 2013 - A review of particle swarm optimization and its applications in Solar Photovoltaic system.pdf:pdf},
isbn = {1568-4946},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {Linearly decreasing inertia weight,PSO parameters & control,Particle swarm optimization,Solar Photovoltaics,Time varying acceleration coefficients},
number = {5},
pages = {2997--3006},
publisher = {Elsevier B.V.},
title = {{A review of particle swarm optimization and its applications in Solar Photovoltaic system}},
url = {http://dx.doi.org/10.1016/j.asoc.2012.11.033},
volume = {13},
year = {2013}
}
@article{Gopalakrishnan2020,
abstract = {Deep neural networks have shown promise in several domains, and the learned task-specific information is implicitly stored in the network parameters. It will be vital to utilize representations from these networks for downstream tasks such as continual learning. In this paper, we introduce the notion of {\em flashcards} that are visual representations to {\em capture} the encoded knowledge of a network, as a function of random image patterns. We demonstrate the effectiveness of flashcards in capturing representations and show that they are efficient replay methods for general and task agnostic continual learning setting. Thus, while adapting to a new task, a limited number of constructed flashcards, help to prevent catastrophic forgetting of the previously learned tasks. Most interestingly, such flashcards neither require external memory storage nor need to be accumulated over multiple tasks and only need to be constructed just before learning the subsequent new task, irrespective of the number of tasks trained before and are hence task agnostic. We first demonstrate the efficacy of flashcards in capturing knowledge representation from a trained network, and empirically validate the efficacy of flashcards on a variety of continual learning tasks: continual unsupervised reconstruction, continual denoising, and new-instance learning classification, using a number of heterogeneous benchmark datasets. These studies also indicate that continual learning algorithms with flashcards as the replay strategy perform better than other state-of-the-art replay methods, and exhibits on par performance with the best possible baseline using coreset sampling, with the least additional computational complexity and storage.},
archivePrefix = {arXiv},
arxivId = {2012.06789},
author = {Gopalakrishnan, Saisubramaniam and Singh, Pranshu Ranjan and Fayek, Haytham and Ramasamy, Savitha and Ambikapathi, Arulmurugan},
eprint = {2012.06789},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gopalakrishnan et al. - 2020 - Knowledge Capture and Replay for Continual Learning.pdf:pdf},
keywords = {continual learning,rehearsal,replay},
mendeley-tags = {continual learning,rehearsal,replay},
title = {{Knowledge Capture and Replay for Continual Learning}},
url = {http://arxiv.org/abs/2012.06789},
year = {2020}
}
@article{Accenture2013,
author = {Accenture},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Accenture - 2013 - Big Bang Protect Their Power of Big Bang.pdf:pdf},
pages = {12},
title = {{Big Bang Protect Their Power of Big Bang}},
year = {2013}
}
@inproceedings{Kuznietsov2020,
abstract = {While ground truth depth data remains hard to obtain, self-supervised monocular depth estimation methods enjoy growing attention. Much research in this area aims at improving loss functions or network architectures. Most works, however, do not leverage self-supervision to its full potential. They stick to the standard closed world train-test pipeline, assuming the network parameters to be fixed after the training is finished. Such an assumption does not allow to adapt to new scenes, whereas with self-supervision this becomes possible without extra annotations. In this paper, we propose a novel self-supervised Continuous Monocular Depth Adaptation method (CoMoDA), which adapts the pretrained model on a test video on the fly. As opposed to existing test-time refinement methods that use isolated frame triplets, we opt for continuous adaptation, making use of the previous experience from the same scene. We additionally augment the proposed procedure with the experience from the distant past, preventing the model from overfitting and thus forgetting already learnt information. We demonstrate that our method can be used for both intra-and cross-dataset adaptation. By adapting the model from train to test set of the Eigen split of KITTI, we achieve state-of-the-art depth estimation performance and surpass all existing methods using standard architectures. We also show that our method runs 15 times faster than existing test-time refinement methods. The code is available at https://github.com/Yevkuzn/CoMoDA.},
author = {Kuznietsov, Yevhen and Proesmans, Marc and Gool, Luc Van},
booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuznietsov, Proesmans, Gool - 2021 - CoMoDA Continuous Monocular Depth Adaptation Using Past Experiences.pdf:pdf},
keywords = {continual learning,depth estimation,incremental learning},
mendeley-tags = {continual learning,depth estimation,incremental learning},
pages = {2907--2917},
title = {{CoMoDA: Continuous Monocular Depth Adaptation Using Past Experiences}},
year = {2021}
}
@article{Melin2014a,
abstract = {In this paper a review of type-2 fuzzy logic applications in pattern recognition, classification and clustering problems is presented. Recently, type-2 fuzzy logic has gained popularity in a wide range of applications due to its ability to handle higher degrees of uncertainty. In particular, there have been recent applications of type-2 fuzzy logic in the fields of pattern recognition, classification and clustering, where it has helped improving results over type-1 fuzzy logic. In this paper a concise and representative review of the most successful applications of type-2 fuzzy logic in these fields is presented. At the moment, most of the applications in this review use interval type-2 fuzzy logic, which is easier to handle and less computational expensive than generalized type-2 fuzzy logic. {\textcopyright} 2014 Elsevier B.V.},
author = {Melin, Patricia and Castillo, Oscar},
doi = {10.1016/j.asoc.2014.04.017},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Melin, Castillo - 2014 - A review on type-2 fuzzy logic applications in clustering, classification and pattern recognition.pdf:pdf},
isbn = {0957-4174},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {Classification,Clustering,Pattern recognition,Type-2 fuzzy logic},
pages = {568--577},
publisher = {Elsevier B.V.},
title = {{A review on type-2 fuzzy logic applications in clustering, classification and pattern recognition}},
url = {http://dx.doi.org/10.1016/j.asoc.2014.04.017},
volume = {21},
year = {2014}
}
@article{Geva2019,
abstract = {Crowdsourcing has been the prevalent paradigm for creating natural language understanding datasets in recent years. A common crowdsourcing practice is to recruit a small number of high-quality workers, and have them massively generate examples. Having only a few workers generate the majority of examples raises concerns about data diversity, especially when workers freely generate sentences. In this paper, we perform a series of experiments showing these concerns are evident in three recent NLP datasets. We show that model performance improves when training with annotator identifiers as features, and that models are able to recognize the most productive annotators. Moreover, we show that often models do not generalize well to examples from annotators that did not contribute to the training set. Our findings suggest that annotator bias should be monitored during dataset creation, and that test set annotators should be disjoint from training set annotators.},
archivePrefix = {arXiv},
arxivId = {1908.07898},
author = {Geva, Mor and Goldberg, Yoav and Berant, Jonathan},
eprint = {1908.07898},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Geva, Goldberg, Berant - 2019 - Are We Modeling the Task or the Annotator An Investigation of Annotator Bias in Natural Language Underst.pdf:pdf},
title = {{Are We Modeling the Task or the Annotator? An Investigation of Annotator Bias in Natural Language Understanding Datasets}},
url = {http://arxiv.org/abs/1908.07898},
year = {2019}
}
@misc{Shirane1952a,
abstract = {The phase diagram of the whole range of the PbZrO 3 -PbTiO 3 system was determined by the dielectric and dilatometric measurements. According to the reason shown in part I, this phase diagram can be divided into three regiors; paraelectric, ferroelectric and antiferroelectric phases. The crystal structure of this system was determined by the Debye photographs. In the antiferroelectric region solid solutions have a tetragonal modification of perovskite structure with c / a <1 and have some superstructure which seems to have intimate relation to the antiferroelectricity. In the ferroelectric region, except a region near antiferroelectric phase in which pseudocubic structure is observed, they have ordinary tetragonal structure of c / a >1 without any superstructure.},
author = {Shirane, Gen and Suzuki, Kazuo and Takeda, Akitsu},
booktitle = {Journal of the Physical Society of Japan},
doi = {10.1143/JPSJ.7.12},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shirane, Suzuki, Takeda - 1952 - Phase Transitions in Solid Solutions of PbZrO 3 and PbTiO 3 (II) X-ray Study.pdf:pdf},
isbn = {0031-9015},
issn = {0031-9015},
number = {1},
pages = {12--18},
title = {{Phase Transitions in Solid Solutions of PbZrO 3 and PbTiO 3 (II) X-ray Study}},
url = {http://journals.jps.jp/doi/abs/10.1143/JPSJ.7.12},
volume = {7},
year = {1952}
}
@article{Liu2020g,
abstract = {Catastrophic forgetting refers to the tendency that a neural network "forgets" the previous learned knowledge upon learning new tasks. Prior methods have been focused on overcoming this problem on convolutional neural networks (CNNs), where the input samples like images lie in a grid domain, but have largely overlooked graph neural networks (GNNs) that handle non-grid data. In this paper, we propose a novel scheme dedicated to overcoming catastrophic forgetting problem and hence strengthen continual learning in GNNs. At the heart of our approach is a generic module, termed as topology-aware weight preserving$\sim$(TWP), applicable to arbitrary form of GNNs in a plug-and-play fashion. Unlike the main stream of CNN-based continual learning methods that rely on solely slowing down the updates of parameters important to the downstream task, TWP explicitly explores the local structures of the input graph, and attempts to stabilize the parameters playing pivotal roles in the topological aggregation. We evaluate TWP on different GNN backbones over several datasets, and demonstrate that it yields performances superior to the state of the art. Code is publicly available at \url{https://github.com/hhliu79/TWP}.},
archivePrefix = {arXiv},
arxivId = {2012.06002},
author = {Liu, Huihui and Yang, Yiding and Wang, Xinchao},
eprint = {2012.06002},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu, Yang, Wang - 2020 - Overcoming Catastrophic Forgetting in Graph Neural Networks.pdf:pdf},
keywords = {catastrophic forgetting,continual learning,graph neural networks},
mendeley-tags = {catastrophic forgetting,continual learning,graph neural networks},
title = {{Overcoming Catastrophic Forgetting in Graph Neural Networks}},
url = {http://arxiv.org/abs/2012.06002},
year = {2020}
}
@book{Klir1995,
author = {Klir, George J and Yuan, B O},
editor = {Guerrieri, Patti},
keywords = {ISBN-13: 9780131011717},
pages = {590},
publisher = {Prentice Hail P T R},
title = {{Fuzzy Sets And Fuzzy Logic: Theory and Applications}},
year = {1995}
}
@article{Jo2017,
abstract = {Although various clinical imaging modalities have been developed to visualize internal body structures and detect abnormal tissues prior to surgical procedures, most medical imaging modalities do not provide disease-specific images in real-time. Optical imaging can provide the surgeon with real-time visualization of the surgical field for intraoperative image-guided surgery. Imaging in the near-infrared (NIR) window (650-900 nm), also known as the "therapeutic window" has high potential by offering low absorbance and scattering in tissues resulting in minimized background autofluorescence. Clinically, optical fluorescence imaging with the targeted contrast agents provides opportunities for significant advances in intraoperative image-guided surgery. There are only two clinically available NIR fluorophores, indocyanine green (ICG) and methylene blue (MB), that support the image-guided surgery. However, neither of them perform in vivo by providing optimum specificity and stability for targeted image guidance. Therefore, it is of paramount importance to develop targeted NIR fluorophores for unmet clinical needs. Using the right combination of an NIR fluorescence imaging system and a targeted fluorophore, the desired target tissues can be imaged to provide real-time fluorescence guidance without changing the field-of-view during surgery. Thus, in a clinical discipline, the development of NIR fluorophores for 'structure-inherent targeting' is an unmet need for early phase diagnostics with accurate targeting.},
author = {Jo, Danbi and Hyun, Hoon},
doi = {10.4068/cmj.2017.53.2.95},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jo, Hyun - 2017 - Structure-Inherent Targeting of Near-Infrared Fluorophores for Image-Guided Surgery.pdf:pdf},
issn = {2233-7385},
journal = {Chonnam medical journal},
keywords = {Fluorescence,Fluorescent Dyes,Optical Imaging,Surgery},
number = {2},
pages = {95--102},
pmid = {28584787},
title = {{Structure-Inherent Targeting of Near-Infrared Fluorophores for Image-Guided Surgery.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/28584787%0Ahttp://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC5457957},
volume = {53},
year = {2017}
}
@article{Pourahmadi1989a,
author = {Pourahmadi, Mohsen},
doi = {10.1111/j.1467-9892.1989.tb00021.x},
issn = {14679892},
journal = {Journal of Time Series Analysis},
keywords = {EM algorithm,Stationary time series,autoregressive process,missing‐value problem,moving‐average process,multistep‐ahead predictors},
number = {2},
pages = {149--169},
title = {{Estimation and Interpolation of Missing Values of a Stationary Time Series}},
volume = {10},
year = {1989}
}
@article{Yuce2017,
abstract = {This paper presents a hybrid Genetic-Bees Algorithm based optimised solution for the single machine scheduling problem. The enhancement of the Bees Algorithm (BA) is conducted using the Genetic Algorithm's (GA's) operators during the global search stage. The proposed enhancement aims to increase the global search capability of the BA gradually with new additions. Although the BA has very successful implementations on various type of optimisation problems, it has found that the algorithm suffers from weak global search ability which increases the computational complexities on NP-hard type optimisation problems e.g. combinatorial/permutational type optimisation problems. This weakness occurs due to using a simple global random search operation during the search process. To reinforce the global search process in the BA, the proposed enhancement is utilised to increase exploration capability by expanding the number of fittest solutions through the genetical variations of promising solutions. The hybridisation process is realised by including two strategies into the basic BA, named as “reinforced global search” and “jumping function” strategies. The reinforced global search strategy is the first stage of the hybridisation process and contains the mutation operator of the GA. The second strategy, jumping function strategy, consists of four GA operators as single point crossover, multipoint crossover, mutation and randomisation. To demonstrate the strength of the proposed solution, several experiments were carried out on 280 well-known single machine benchmark instances, and the results are presented by comparing to other well-known heuristic algorithms. According to the experiments, the proposed enhancements provides better capability to basic BA to jump from local minima, and GBA performed better compared to BA in terms of convergence and the quality of results. The convergence time reduced about 60% with about 30% better results for highly constrained jobs.},
author = {Yuce, B. and Fruggiero, F. and Packianather, M. S. and Pham, D. T. and Mastrocinque, E. and Lambiase, A. and Fera, M.},
doi = {10.1016/j.cie.2017.07.018},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yuce et al. - 2017 - Hybrid Genetic Bees Algorithm applied to single machine scheduling with earliness and tardiness penalties.pdf:pdf},
issn = {03608352},
journal = {Computers and Industrial Engineering},
keywords = {Bees Algorithm (BA),Genetic Bees Algorithm (GBA),Single Machine Scheduling Problem (SMSP),Swarm-based optimisation},
pages = {842--858},
title = {{Hybrid Genetic Bees Algorithm applied to single machine scheduling with earliness and tardiness penalties}},
url = {http://dx.doi.org/10.1016/j.cie.2017.07.018},
volume = {113},
year = {2017}
}
@article{Mukhoti2021,
abstract = {We show that a single softmax neural net with minimal changes can beat the uncertainty predictions of Deep Ensembles and other more complex single-forward-pass uncertainty approaches. Softmax neural nets cannot capture epistemic uncertainty reliably because for OoD points they extrapolate arbitrarily and suffer from feature collapse. This results in arbitrary softmax entropies for OoD points which can have high entropy, low, or anything in between. We study why, and show that with the right inductive biases, softmax neural nets trained with maximum likelihood reliably capture epistemic uncertainty through the feature-space density. This density is obtained using Gaussian Discriminant Analysis, but it cannot disentangle uncertainties. We show that it is necessary to combine this density with the softmax entropy to disentangle aleatoric and epistemic uncertainty -- crucial e.g. for active learning. We examine the quality of epistemic uncertainty on active learning and OoD detection, where we obtain SOTA $\sim$0.98 AUROC on CIFAR-10 vs SVHN.},
archivePrefix = {arXiv},
arxivId = {2102.11582},
author = {Mukhoti, Jishnu and Kirsch, Andreas and van Amersfoort, Joost and Torr, Philip H. S. and Gal, Yarin},
eprint = {2102.11582},
keywords = {epistemic,inductive bias,uncertainty},
mendeley-tags = {epistemic,inductive bias,uncertainty},
title = {{Deterministic Neural Networks with Appropriate Inductive Biases Capture Epistemic and Aleatoric Uncertainty}},
url = {http://arxiv.org/abs/2102.11582},
year = {2021}
}
@article{Su2020,
abstract = {Lifelong learning is a crucial issue in advanced artificial intelligence. It requires the learning system to learn and accumulate knowledge from sequential tasks. The learning system needs to deal with increasingly more domains and tasks. We consider that the key to an effective and efficient lifelong learning system is the ability to memorize and recall the learned knowledge using neural networks. Following this idea, we propose Generative Memory (GM) as a novel memory module, and the resulting lifelong learning system is referred to as the GM Net (GMNet). To make the GMNet feasible, we propose a novel learning mechanism, referred to as \mathcal {P} -invariant learning method. It replaces the memory of the real data by a memory of the data distribution, which makes it possible for the learning system to accurately and continuously accumulate the learned experiences. We demonstrate that GMNet achieves the state-of-the-art performance on lifelong learning tasks.},
author = {Su, Xin and Guo, Shangqi and Tan, Tian and Chen, Feng},
doi = {10.1109/TNNLS.2019.2927369},
file = {:home/user/Downloads/su2019.pdf:pdf},
issn = {21622388},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {Catastrophic forgetting,continual learning,generative memory (GM),generative replay,incremental learning,lifelong learning,neural network,rehearsal,replay},
mendeley-tags = {continual learning,generative replay,incremental learning,rehearsal,replay},
number = {6},
pages = {1884--1898},
pmid = {31395557},
title = {{Generative Memory for Lifelong Learning}},
volume = {31},
year = {2020}
}
@inproceedings{Choromanski2020,
abstract = {We introduce Performers, Transformer architectures which can estimate regular (softmax) full-rank-attention Transformers with provable accuracy, but using only linear (as opposed to quadratic) space and time complexity, without relying on any priors such as sparsity or low-rankness. To approximate softmax attention-kernels, Performers use a novel Fast Attention Via positive Orthogonal Random features approach (FAVOR+), which may be of independent interest for scalable kernel methods. FAVOR+ can be also used to efficiently model kernelizable attention mechanisms beyond softmax. This representational power is crucial to accurately compare softmax with other kernels for the first time on large-scale tasks, beyond the reach of regular Transformers, and investigate optimal attention-kernels. Performers are linear architectures fully compatible with regular Transformers and with strong theoretical guarantees: unbiased or nearly-unbiased estimation of the attention matrix, uniform convergence and low estimation variance. We tested Performers on a rich set of tasks stretching from pixel-prediction through text models to protein sequence modeling. We demonstrate competitive results with other examined efficient sparse and dense attention methods, showcasing effectiveness of the novel attention-learning paradigm leveraged by Performers.},
archivePrefix = {arXiv},
arxivId = {2009.14794},
author = {Choromanski, Krzysztof and Likhosherstov, Valerii and Dohan, David and Song, Xingyou and Gane, Andreea and Sarlos, Tamas and Hawkins, Peter and Davis, Jared and Mohiuddin, Afroz and Kaiser, Lukasz and Belanger, David and Colwell, Lucy and Weller, Adrian},
booktitle = {Iclr 2021},
eprint = {2009.14794},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Choromanski et al. - 2020 - Rethinking attention with performers.pdf:pdf},
issn = {23318422},
keywords = {attention networks,performers,theory},
mendeley-tags = {attention networks,performers,theory},
pages = {1--38},
title = {{Rethinking attention with performers}},
year = {2020}
}
@book{Itin2017,
author = {Itin, Volya I.},
booktitle = {Concise Encyclopedia of Self-Propagating High-Temperature Synthesis},
doi = {10.1016/B978-0-12-804173-4.00121-6},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Itin - 2017 - Shape-Memory Alloys.pdf:pdf},
isbn = {9780128041734},
keywords = {SHS,combustion,composition,titanium},
pages = {270--271},
publisher = {Elsevier Inc.},
title = {{Shape-Memory Alloys}},
url = {http://linkinghub.elsevier.com/retrieve/pii/B9780128041734001216},
year = {2017}
}
@article{Mahir2008,
abstract = {This paper proposed a new method to estimate the missing data by using the filtering process. We used datasets without missing data and randomly missing data to evaluate the new method of estimation by using the Box - Jenkins modeling technique to predict monthly average rainfall for site 5504035 Lahar Ikan Mati at Kepala Batas, P. Pinang station in Malaysia. The rainfall data was collected from the $1^{st}$ January 1969 to $31^{st}$ December 1997 in the station. The data used in the development of the model to predict rainfall were represented by an autoregressive integrated moving - average (ARIMA) model. The model for both datasets was ARIMA$(1,0,0)(0,1,1)_s$. The result checked with the Naive test, which is the Thiel's statistic and was found to be equal to $U=0.72086$ for the complete data and $U=0.726352$ for the missing data, which mean they were good models.},
archivePrefix = {arXiv},
arxivId = {0811.0659},
author = {Mahir, R. Ahmad and Al-Khazaleh, A. M. H.},
eprint = {0811.0659},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mahir, Al-Khazaleh - 2008 - Estimation of missing data by using the filtering process in a time series modeling.pdf:pdf},
keywords = {and phrases,arima model,filter-,forecasting method,ing process and,monthly average rainfall},
pages = {1--12},
title = {{Estimation of missing data by using the filtering process in a time series modeling}},
url = {http://arxiv.org/abs/0811.0659},
year = {2008}
}
@article{Nguyen2019,
abstract = {While advanced image captioning systems are increasingly describing images coherently and exactly, recent progress in continual learning allows deep learning models to avoid catastrophic forgetting. However, the domain where image captioning working with continual learning has not yet been explored. We define the task in which we consolidate continual learning and image captioning as continual image captioning. In this work, we propose ContCap, a framework generating captions over a series of new tasks coming, seamlessly integrating continual learning into image captioning besides addressing catastrophic forgetting. After proving forgetting in image captioning, we propose various techniques to overcome the forgetting dilemma by taking a simple fine-tuning schema as the baseline. We split MS-COCO 2014 dataset to perform experiments in class-incremental settings without revisiting dataset of previously provided tasks. Experiments show remarkable improvements in the performance on the old tasks while the figures for the new surprisingly surpass fine-tuning. Our framework also offers a scalable solution for continual image or video captioning.},
archivePrefix = {arXiv},
arxivId = {1909.08745},
author = {Nguyen, Giang and Jun, Tae Joon and Tran, Trung and Yalew, Tolcha and Kim, Daeyoung},
eprint = {1909.08745},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen et al. - 2019 - ContCap A scalable framework for continual image captioning(3).pdf:pdf},
keywords = {captioning,continual learning,image captioning,incremental learning},
mendeley-tags = {captioning,continual learning,image captioning,incremental learning},
title = {{ContCap: A scalable framework for continual image captioning}},
url = {http://arxiv.org/abs/1909.08745},
year = {2019}
}
@article{Khokhlov2017,
abstract = {In this Letter, we introduce an approach for manipulation of active
plasmon polaritons via acoustic waves at subterahertz frequency range.
The acoustic structures considered are designed as phononic Fabry-Perot
microresonators where mirrors are presented with an acoustic
superlattice and the structure's surface, and a plasmonic grating is
placed on top of the acoustic cavity so formed. It provides phonon
localization in the vicinity of the plasmonic grating at frequencies
within the phononic stop band enhancing phonon - light interaction. We
consider phonon excitation by shining a femtosecond laser pulse on the
plasmonic grating. Appropriate theoretical model was used to describe
the acoustic process caused by the pump laser pulse in the
GaAs/AlAs-based acoustic cavity with a gold grating on top. Strongest
modulation is achieved upon excitation of propagating surface plasmon
polaritons and hybridization of propagating and localized plasmons. The
relative changes in the optical reflectivity of the structure are more
than an order of magnitude higher than for the structure without the
plasmonic film. (C) 2017 Optical Society of America},
author = {Khokhlov, Nikolai and Knyazev, Grigoriy and Glavin, Boris and Shtykov, Yakov and Romanov, Oleg and Belotelov, Vladimir},
doi = {10.1364/OL.42.003558},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khokhlov et al. - 2017 - Interaction of surface plasmon polaritons and acoustic waves inside an acoustic cavity.pdf:pdf},
issn = {0146-9592},
journal = {Optics Letters},
number = {18},
pages = {3558},
pmid = {28914901},
title = {{Interaction of surface plasmon polaritons and acoustic waves inside an acoustic cavity}},
url = {https://www.osapublishing.org/abstract.cfm?URI=ol-42-18-3558},
volume = {42},
year = {2017}
}
@article{Hardman2015,
abstract = {Fuel Cell Vehicles (FCVs) are a disruptive innovation and are currently looking towards niche market entry. However, commercialisation has been unsuccessful thus far and there is a limited amount of literature that can guide their market entry. In this paper a historical case study is undertaken which looks at Tesla Motors high-end encroachment market entry strategy. FCVs have been compared to Tesla vehicles due to their similarities; both are disruptive innovations, both are high cost and both are zero emission vehicles. Therefore this paper looks at what can be learned form Tesla Motors successful market entry strategy and proposes a market entry strategy for FCVs. It was found that FCVs need to enact a paradigm shift from their current market entry strategy to one of high-end encroachment. When this has been achieved FCVs will have greater potential for market penetration.},
author = {Hardman, Scott and Shiu, Eric and Steinberger-Wilckens, Robert},
doi = {10.1016/j.ijhydene.2014.11.149},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hardman, Shiu, Steinberger-Wilckens - 2015 - Changing the fate of fuel cell vehicles Can lessons be learnt from Tesla Motors.pdf:pdf},
isbn = {0360-3199},
issn = {03603199},
journal = {International Journal of Hydrogen Energy},
keywords = {Electric vehicle marketing,Fuel cell,Market entry,Tesla},
number = {4},
pages = {1625--1638},
publisher = {Elsevier Ltd},
title = {{Changing the fate of fuel cell vehicles: Can lessons be learnt from Tesla Motors?}},
url = {http://dx.doi.org/10.1016/j.ijhydene.2014.11.149},
volume = {40},
year = {2015}
}
@article{Shanahan2019a,
abstract = {With a view to bridging the gap between deep learning and symbolic AI, we present a novel end-to-end neural network architecture that learns to form propositional representations with an explicitly relational structure from raw pixel data. In order to evaluate and analyse the architecture, we introduce a family of simple visual relational reasoning tasks of varying complexity. We show that the proposed architecture, when pre-trained on a curriculum of such tasks, learns to generate reusable representations that better facilitate subsequent learning on previously unseen tasks when compared to a number of baseline architectures. The workings of a successfully trained model are visualised to shed some light on how the architecture functions.},
archivePrefix = {arXiv},
arxivId = {1905.10307},
author = {Shanahan, Murray and Nikiforou, Kyriacos and Creswell, Antonia and Kaplanis, Christos and Barrett, David and Garnelo, Marta},
eprint = {1905.10307},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shanahan et al. - 2019 - An explicitly relational neural network architecture.pdf:pdf;:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shanahan et al. - 2019 - An explicitly relational neural network architecture(2).pdf:pdf},
journal = {arXiv},
title = {{An explicitly relational neural network architecture}},
url = {https://github.com/deepmind/deepmind-research/tree/master/PrediNet},
year = {2019}
}
@article{Georgakis2018,
abstract = {Human behavior and affect is inherently a dynamic phenomenon involving temporal evolution of patterns manifested through a multiplicity of non-verbal behavioral cues including facial expressions, body postures and gestures, and vocal outbursts. A natural assumption for human behavior modeling is that a continuous-time characterization of behavior is the output of a linear time-invariant system when behavioral cues act as the input (e.g., continuous rather than discrete annotations of dimensional affect). Here we study the learning of such dynamical system under real-world conditions, namely in the presence of noisy behavioral cues descriptors and possibly unreliable annotations by employing structured rank minimization. To this end, a novel structured rank minimization method and its scalable variant are proposed. The generalizability of the proposed framework is demonstrated by conducting experiments on 3 distinct dynamic behavior analysis tasks, namely (i) conflict intensity prediction, (ii) prediction of valence and arousal, and (iii) tracklet matching. The attained results outperform those achieved by other state-of-the-art methods for these tasks and, hence, evidence the robustness and effectiveness of the proposed approach. {\textcopyright} 2017, The Author(s).},
author = {Georgakis, Christos and Panagakis, Yannis and Pantic, Maja},
doi = {10.1007/s11263-016-0985-3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Georgakis, Panagakis, Pantic - 2018 - Dynamic Behavior Analysis via Structured Rank Minimization.pdf:pdf},
issn = {15731405},
journal = {International Journal of Computer Vision},
keywords = {Dynamic behavior analysis,Hankel matrix,Linear time-invariant systems,Low-rank,Sparsity,Structured rank minimization},
number = {2-4},
pages = {333--357},
publisher = {Springer US},
title = {{Dynamic Behavior Analysis via Structured Rank Minimization}},
volume = {126},
year = {2018}
}
@book{Varnam1994,
address = {US},
author = {Varnam, A. and {Jane P. Sutherland}},
isbn = {978-0-8342-1955-7},
pages = {452},
publisher = {Springer US},
title = {{Milk and Milk Products}},
year = {1994}
}
@article{Wei2009,
abstract = {Waste eggshell was investigated in triglyceride transesterification with a view to determine its viability as a solid catalyst for use in biodiesel synthesis. Effect of calcination temperature on structure and activity of eggshell catalysts was investigated. Reusability of eggshell catalysts was also examined. It was found that high active, reusable solid catalyst was obtained by just calcining eggshell. Utilization of eggshell as a catalyst for biodiesel production not only provides a cost-effective and environmental friendly way of recycling this solid eggshell waste, significantly reducing its environmental effects, but also reduces the price of biodiesel to make biodiesel competitive with petroleum diesel. {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
author = {Wei, Ziku and Xu, Chunli and Li, Baoxin},
doi = {10.1016/j.biortech.2008.12.039},
isbn = {0960-8524},
issn = {09608524},
journal = {Bioresource Technology},
keywords = {Biodiesel,Catalysis,Eggshell waste,Heterogeneous catalysis,Transesterification},
number = {11},
pages = {2883--2885},
pmid = {19201602},
publisher = {Elsevier Ltd},
title = {{Application of waste eggshell as low-cost solid catalyst for biodiesel production}},
url = {http://dx.doi.org/10.1016/j.biortech.2008.12.039},
volume = {100},
year = {2009}
}
@article{Shmelkov2017,
abstract = {Despite their success for object detection, convolutional neural networks are ill-equipped for incremental learning, i.e., adapting the original model trained on a set of classes to additionally detect objects of new classes, in the absence of the initial training data. They suffer from “catastrophic forgetting”—an abrupt degradation of performance on the original set of classes, when the training objective is adapted to the new classes. We present a method to address this issue, and learn object detectors incrementally, when neither the original training data nor annotations for the original classes in the new training set are available. The core of our proposed solution is a loss function to balance the interplay between predictions on the new classes and a new distillation loss which minimizes the discrepancy between responses for old classes from the original and the updated networks. This incremental learning can be performed multiple times, for a new set of classes in each step, with a moderate drop in performance compared to the baseline network trained on the ensemble of data. We present object detection results on the PASCAL VOC 2007 and COCO datasets, along with a detailed empirical analysis of the approach.},
author = {Shmelkov, Konstantin and Inria, Cordelia Schmid and Alahari, Karteek},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shmelkov, Inria, Alahari - 2017 - Incremental learning of object detectors without catastrophic forgetting.pdf:pdf},
issn = {23318422},
journal = {2017 IEEE International Conference on Computer Vision (ICCV)},
keywords = {continual learning,incremental learning,object detection},
mendeley-tags = {continual learning,incremental learning,object detection},
pages = {3400--3409},
title = {{Incremental learning of object detectors without catastrophic forgetting}},
year = {2017}
}
@article{Pailla2019,
abstract = {Detection and classification of objects in aerial imagery have several applications like urban planning, crop surveillance, and traffic surveillance. However, due to the lower resolution of the objects and the effect of noise in aerial images, extracting distinguishing features for the objects is a challenge. We evaluate CenterNet, a state of the art method for real-time 2D object detection, on the VisDrone2019 dataset. We evaluate the performance of the model with different backbone networks in conjunction with varying resolutions during training and testing.},
archivePrefix = {arXiv},
arxivId = {1908.08244},
author = {Pailla, Dheeraj Reddy and Kollerathu, Varghese and Chennamsetty, Sai Saketh},
eprint = {1908.08244},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pailla, Kollerathu, Chennamsetty - 2019 - Object detection on aerial imagery using CenterNet.pdf:pdf},
title = {{Object detection on aerial imagery using CenterNet}},
url = {http://arxiv.org/abs/1908.08244},
year = {2019}
}
@article{Barnes,
author = {Barnes, Jeff},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barnes - Unknown - Third Industrial Revolution The Impact of the Internet of Everything and Smart Cities across the Supply Chain.pdf:pdf},
keywords = {- smart cities,supply chain management,third industrial revolution},
title = {{Third Industrial Revolution : The Impact of the Internet of Everything and Smart Cities across the Supply Chain}}
}
@article{Brewer2013,
abstract = {This study builds on research about political humor, press metacoverage, and intertextuality to examine the effects of news coverage about political satire on audience members. The analysis uses experimental data to test whether news coverage of Stephen Colbert's Super PAC influenced knowledge and opinion regarding Citizens United, as well as political trust and internal political efficacy. It also tests whether such effects depended on previous exposure to The Colbert Report (Colbert's satirical television show) and traditional news. Results indicate that exposure to news coverage of satire can influence knowledge, opinion, and political trust. Additionally, regular satire viewers may experience stronger effects on opinion, as well as increased internal efficacy, when consuming news coverage about issues previously highlighted in satire programming.},
author = {Brewer, Paul R. and Young, Dannagal Goldthwaite and Morreale, Michelle},
doi = {10.1093/ijpor/edt015},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brewer, Young, Morreale - 2013 - The impact of real news about fake news Intertextual processes and political satire.pdf:pdf},
isbn = {0954-2892},
issn = {09542892},
journal = {International Journal of Public Opinion Research},
number = {3},
pages = {323--343},
title = {{The impact of real news about "fake news": Intertextual processes and political satire}},
volume = {25},
year = {2013}
}
@article{Doshi2019,
archivePrefix = {arXiv},
arxivId = {1907.13576},
author = {Doshi, Keval},
doi = {10.32555/2019.dl.008},
eprint = {1907.13576},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Doshi - 2019 - Synthetic Image Augmentation for Improved Classification using Generative Adversarial Networks.pdf:pdf},
title = {{Synthetic Image Augmentation for Improved Classification using Generative Adversarial Networks}},
year = {2019}
}
@article{McRae1993,
abstract = {this article, we outline the major cause of catastrophic interference in standard networks, describe recent approaches to the problem, and present a novel approach. In contrast to previous work on the sequential learning problem that has manipulated network parameters and architecture (e.g., Hinton & Plaut, 1987; Kortge, 1990; Kruschke, 1992; Lewandowsky, 1991; Sloman & Rumelhart, 1992) we attempt to make the simulation more similar to the human situation that is being modeled. When this is done, catastrophic interference is eliminated.},
author = {McRae, Ken and Hetherington, P.A.},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/McRae, Hetherington - 1993 - Catastrophic interference is eliminated in pretrained networks.pdf:pdf},
journal = {Proceedings of the 15h Annual Conference of the Cognitive Science Society},
number = {March},
pages = {723--728},
title = {{Catastrophic interference is eliminated in pretrained networks}},
url = {https://www.semanticscholar.org/paper/Catastrophic-Interference-is-Eliminated-in-Networks-McRae-Hetherington/eccd66b7940495d40789295239f287d04f922c1f%0Ahttp://amdrae.ssc.uwo.ca/articles/McRae_Heth_CogSci_93.pdf},
year = {1993}
}
@article{Lesort2020,
abstract = {Humans learn all their life long. They accumulate knowledge from a sequence of learning experiences and remember the essential concepts without forgetting what they have learned previously. Artificial neural networks struggle to learn similarly. They often rely on data rigorously preprocessed to learn solutions to specific problems such as classification or regression. In particular, they forget their past learning experiences if trained on new ones. Therefore, artificial neural networks are often inept to deal with real-life settings such as an autonomous-robot that has to learn on-line to adapt to new situations and overcome new problems without forgetting its past learning-experiences. Continual learning (CL) is a branch of machine learning addressing this type of problem. Continual algorithms are designed to accumulate and improve knowledge in a curriculum of learning-experiences without forgetting. In this thesis, we propose to explore continual algorithms with replay processes. Replay processes gather together rehearsal methods and generative replay methods. Generative Replay consists of regenerating past learning experiences with a generative model to remember them. Rehearsal consists of saving a core-set of samples from past learning experiences to rehearse them later. The replay processes make possible a compromise between optimizing the current learning objective and the past ones enabling learning without forgetting in sequences of tasks settings. We show that they are very promising methods for continual learning. Notably, they enable the reevaluation of past data with new knowledge and the confrontation of data from different learning-experiences. We demonstrate their ability to learn continually through unsupervised learning, supervised learning and reinforcement learning tasks.},
archivePrefix = {arXiv},
arxivId = {2007.00487},
author = {Lesort, Timoth{\'{e}}e},
eprint = {2007.00487},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lesort - 2020 - Continual Learning Tackling Catastrophic Forgetting in Deep Neural Networks with Replay Processes.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {Continual Learning,Deep Learning,Generative Replay,Replay Processes,continual learning,rehearsal,replay},
mendeley-tags = {continual learning,rehearsal,replay},
title = {{Continual Learning: Tackling Catastrophic Forgetting in Deep Neural Networks with Replay Processes}},
year = {2020}
}
@article{Li2013,
abstract = {This paper studies the electricity generating capacity of microbial fuel cells (MFCs). Unlike most of MFC research, which targets the long term goals of renewable energy production and wastewater treatment, this paper considers a niche application that may be used immediately in practice, namely powering sensors from soils or sediments. There are two major goals in this study. The first goal is to examine the performance characteristics of MFCs in this application. Specifically we investigate the relationship between the percentage of organic matter in a sample and the electrical ca-pacity of MFCs fueled by that sample. We observe that higher percentage of organic matter in a sample results in higher electricity production of MFCs powered by that sample. We measure the thermal limits that dictate the temperature range in which MFCs can function, and confirm that the upper thermal limit is 40˚C. The new observation is that the lower thermal limit is −5˚C, which is lower than 0˚C reported in the literature. This difference is important for powering environmental sensors. We observe that the electricity production of MFCs decreases almost linearly over a period of 10 days. The second goal is to determine the conditions under which MFCs work most efficiently to generate electricity. We compare the capacity under a variety of conditions of sample types (benthic mud, top soil, and marsh samples), temperatures (0˚C, 40˚C, and room temperature), and sample sizes (measuring 3.5 cm × 3.5 cm × 4.6 cm, 10.2 cm × 10.2 cm × 13.4 cm, and 2.7 cm × 2.7 cm × 3.8 cm), and find that the electricity capacity is greatest at 0˚C, powered by benthic mud sample with the largest chamber size. What seems surprising is that 0˚C outperforms both room tempera-ture and benthic mud sample outperforms marsh sample, which appears to be richer in organic matter. In addition, we notice that although the largest chamber size produces the greatest capacity, it suffers from efficiency loss. The reasons of these observations will be explained in the paper. The study demonstrates that the electricity production of MFCs can be increased by selecting the right condition of sample type, temperature, and chamber size.},
author = {Li, Jessica},
doi = {10.4236/jsbs.2013.33024},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li - 2013 - An Experimental Study of Microbial Fuel Cells for Electricity Generating Performance Characterization and Capacity Improveme.pdf:pdf},
journal = {Journal of Sustainable Bioenergy Systems},
keywords = {Microbial Fuel Cells,Power Source of Environmental Sensors,Renewable Electricity Production Capacity,Sustainable Energy Source},
number = {September},
pages = {171--178},
title = {{An Experimental Study of Microbial Fuel Cells for Electricity Generating: Performance Characterization and Capacity Improvement}},
url = {http://dx.doi.org/10.4236/jsbs.2013.33024%0Ahttp://www.scirp.org/journal/jsbs},
volume = {3},
year = {2013}
}
@article{Sheta2014,
author = {Sheta, A and Alshaer, J},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sheta, Alshaer - 2014 - Development of Temperature-based Weather Forecasting Models Using Neural Networks and Fuzzy Logic.pdf:pdf},
keywords = {forecasting models,fuzzy logic,neural networks,weather},
number = {12},
pages = {343--366},
title = {{Development of Temperature-based Weather Forecasting Models Using Neural Networks and Fuzzy Logic}},
volume = {9},
year = {2014}
}
@article{Konkle2011,
abstract = {Real-world objects can be viewed at a range of distances and thus can be experienced at a range of visual angles within the visual field. Given the large amount of visual size variation possible when observing objects, we examined how internal object representations represent visual size information. In a series of experiments which required observers to access existing object knowledge, we observed that real-world objects have a consistent visual size at which they are drawn, imagined, and preferentially viewed. Importantly, this visual size is proportional to the logarithm of the assumed size of the object in the world, and is best characterized not as a fixed visual angle, but by the ratio of the object and the frame of space around it. Akin to the previous literature on canonical perspective, we term this consistent visual size information the canonical visual size. {\textcopyright} 2010 American Psychological Association.},
author = {Konkle, Talia and Oliva, Aude},
doi = {10.1037/a0020413},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Konkle, Oliva - 2011 - Canonical Visual Size for Real-World Objects.pdf:pdf},
issn = {00961523},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
keywords = {Canonical perspective,Canonical viewpoint,Object representation,Physical size,Visual size},
number = {1},
pages = {23--37},
pmid = {20822298},
title = {{Canonical Visual Size for Real-World Objects}},
volume = {37},
year = {2011}
}
@article{Zhang2019d,
abstract = {We propose BERTScore, an automatic evaluation metric for text generation. Analogous to common metrics, \method computes a similarity score for each token in the candidate sentence with each token in the reference. However, instead of looking for exact matches, we compute similarity using contextualized BERT embeddings. We evaluate on several machine translation and image captioning benchmarks, and show that BERTScore correlates better with human judgments than existing metrics, often significantly outperforming even task-specific supervised metrics.},
archivePrefix = {arXiv},
arxivId = {1904.09675},
author = {Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q. and Artzi, Yoav},
eprint = {1904.09675},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2019 - BERTScore Evaluating Text Generation with BERT.pdf:pdf},
pages = {1--41},
title = {{BERTScore: Evaluating Text Generation with BERT}},
url = {http://arxiv.org/abs/1904.09675},
year = {2019}
}
@article{DelPero2017,
abstract = {We propose an automatic system for organizing the content of a collection of unstructured videos of an articulated object class (e.g. tiger, horse). By exploiting the recurring motion patterns of the class across videos, our system: 1) identifies its characteristic behaviors; and 2) recovers pixel-to-pixel alignments across different instances. Our system can be useful for organizing video collections for indexing and retrieval. Moreover, it can be a platform for learning the appearance or behaviors of object classes from Internet video. Traditional supervised techniques cannot exploit this wealth of data directly, as they require a large amount of time-consuming manual annotations. The behavior discovery stage generates temporal video intervals, each automatically trimmed to one instance of the discovered behavior, clustered by type. It relies on our novel motion representation for articulated motion based on the displacement of ordered pairs of trajectories (PoTs). The alignment stage aligns hundreds of instances of the class to a great accuracy despite considerable appearance variations (e.g. an adult tiger and a cub). It uses a flexible Thin Plate Spline deformation model that can vary through time. We carefully evaluate each step of our system on a new, fully annotated dataset. On behavior discovery, we outperform the state-of-the-art Improved DTF descriptor. On spatial alignment, we outperform the popular SIFT Flow algorithm.},
archivePrefix = {arXiv},
arxivId = {1511.09319},
author = {{Del Pero}, Luca and Ricco, Susanna and Sukthankar, Rahul and Ferrari, Vittorio},
doi = {10.1007/s11263-016-0939-9},
eprint = {1511.09319},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Del Pero et al. - 2017 - Behavior Discovery and Alignment of Articulated Object Classes from Unstructured Video.pdf:pdf},
issn = {15731405},
journal = {International Journal of Computer Vision},
keywords = {Articulated motion,Behavior discovery,Video sequence alignment,Weakly supervised learning from video},
number = {2},
pages = {303--325},
publisher = {Springer US},
title = {{Behavior Discovery and Alignment of Articulated Object Classes from Unstructured Video}},
volume = {121},
year = {2017}
}
@article{Chen2020,
abstract = {Siamese networks have become a common structure in various recent models for unsupervised visual representation learning. These models maximize the similarity between two augmentations of one image, subject to certain conditions for avoiding collapsing solutions. In this paper, we report surprising empirical results that simple Siamese networks can learn meaningful representations even using none of the following: (i) negative sample pairs, (ii) large batches, (iii) momentum encoders. Our experiments show that collapsing solutions do exist for the loss and structure, but a stop-gradient operation plays an essential role in preventing collapsing. We provide a hypothesis on the implication of stop-gradient, and further show proof-of-concept experiments verifying it. Our "SimSiam" method achieves competitive results on ImageNet and downstream tasks. We hope this simple baseline will motivate people to rethink the roles of Siamese architectures for unsupervised representation learning. Code will be made available.},
archivePrefix = {arXiv},
arxivId = {2011.10566},
author = {Chen, Xinlei and He, Kaiming},
eprint = {2011.10566},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, He - 2020 - Exploring Simple Siamese Representation Learning.pdf:pdf},
month = {nov},
number = {Figure 1},
title = {{Exploring Simple Siamese Representation Learning}},
url = {http://arxiv.org/abs/2011.10566},
year = {2020}
}
@article{Tessera2021,
abstract = {Training sparse networks to converge to the same performance as dense neural architectures has proven to be elusive. Recent work suggests that initialization is the key. However, while this direction of research has had some success, focusing on initialization alone appears to be inadequate. In this paper, we take a broader view of training sparse networks and consider the role of regularization, optimization and architecture choices on sparse models. We propose a simple experimental framework, Same Capacity Sparse vs Dense Comparison (SC-SDC), that allows for fair comparison of sparse and dense networks. Furthermore, we propose a new measure of gradient flow, Effective Gradient Flow (EGF), that better correlates to performance in sparse networks. Using top-line metrics, SC-SDC and EGF, we show that default choices of optimizers, activation functions and regularizers used for dense networks can disadvantage sparse networks. Based upon these findings, we show that gradient flow in sparse networks can be improved by reconsidering aspects of the architecture design and the training regime. Our work suggests that initialization is only one piece of the puzzle and taking a wider view of tailoring optimization to sparse networks yields promising results.},
archivePrefix = {arXiv},
arxivId = {2102.01670},
author = {Tessera, Kale-ab and Hooker, Sara and Rosman, Benjamin},
eprint = {2102.01670},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tessera, Hooker, Rosman - 2021 - Keep the Gradients Flowing Using Gradient Flow to Study Sparse Network Optimization.pdf:pdf},
keywords = {gradient flow,optimization,sparse network,sparsity},
mendeley-tags = {gradient flow,optimization,sparse network,sparsity},
title = {{Keep the Gradients Flowing: Using Gradient Flow to Study Sparse Network Optimization}},
url = {http://arxiv.org/abs/2102.01670},
year = {2021}
}
@article{Huang2021,
abstract = {Despite their success for semantic segmentation, convolutional neural networks are ill-equipped for incremental learning, \ie, adapting the original segmentation model as new classes are available but the initial training data is not retained. Actually, they are vulnerable to catastrophic forgetting problem. We try to address this issue by "inverting" the trained segmentation network to synthesize input images starting from random noise. To avoid setting detailed pixel-wise segmentation maps as the supervision manually, we propose the SegInversion to synthesize images using the image-level labels. To increase the diversity of synthetic images, the Scale-Aware Aggregation module is integrated into SegInversion for controlling the scale (the number of pixels) of synthetic objects. Along with real images of new classes, the synthesized images will be fed into the distillation-based framework to train the new segmentation model which retains the information about previously learned classes, whilst updating the current model to learn the new ones. The proposed method significantly outperforms other incremental learning methods and obtains state-of-the-art performance on the PASCAL VOC 2012 and ADE20K datasets. The code and models will be made publicly available.},
archivePrefix = {arXiv},
arxivId = {2104.00875},
author = {Huang, Zilong and Hao, Wentian and Wang, Xinggang and Tao, Mingyuan and Huang, Jianqiang and Liu, Wenyu and Hua, Xian-Sheng},
eprint = {2104.00875},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang et al. - 2021 - Half-Real Half-Fake Distillation for Class-Incremental Semantic Segmentation.pdf:pdf},
keywords = {continual learning,incremental learning,semantic segmentation},
mendeley-tags = {continual learning,incremental learning,semantic segmentation},
title = {{Half-Real Half-Fake Distillation for Class-Incremental Semantic Segmentation}},
url = {http://arxiv.org/abs/2104.00875},
year = {2021}
}
@article{Hou2018,
abstract = {The traditional fuzzy neural network often uses BP algorithm to optimize parameters when conducting parameter identification. However, BP algorithm tends to be trapped in local extremum. In view of the shortcomings of this method, this paper combines the differential evolution algorithm with the BP algorithm, and proposes an improved differential evolution BP algorithm to optimize the fuzzy neural network forecasting network traffic. In order to solve problems such as slow convergence speed and tendency of premature convergence existing in differential evolution algorithm, an improved differential evolution algorithm using the adaptive mutation operator and Gaussian disturbance crossover operator aims to improve the mutation of standard differential evolution algorithm and the design of crossover operators. To validate the effectiveness of it, this optimized fuzzy neural network forecasting algorithm is applied to four standard test functions and the actual network traffic. Simulation results show that the convergence speed and forecasting accuracy of the proposed algorithm are better than those of the traditional fuzzy neural network algorithm. It improves not only the generalization ability of the fuzzy neural network but also the forecasting accuracy of the network traffic.},
author = {Hou, Yue and Zhao, Long and Lu, Huaiwei},
doi = {10.1016/j.future.2017.08.041},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hou, Zhao, Lu - 2018 - Fuzzy neural network optimization and network traffic forecasting based on improved differential evolution.pdf:pdf},
issn = {0167739X},
journal = {Future Generation Computer Systems},
keywords = {Differential evolution algorithm,Fuzzy neural network,Network traffic forecasting},
pages = {425--432},
publisher = {Elsevier B.V.},
title = {{Fuzzy neural network optimization and network traffic forecasting based on improved differential evolution}},
url = {http://dx.doi.org/10.1016/j.future.2017.08.041},
volume = {81},
year = {2018}
}
@inproceedings{Zheng2021,
abstract = {Deep learning models have achieved state-of-the-art perfor- mance in semantic image segmentation, but the results pro- vided by fully automatic algorithms are not always guar- anteed satisfactory to users. Interactive segmentation offers a solution by accepting user annotations on selective areas of the images to refine the segmentation results. However, most existing models only focus on correcting the current im- age's misclassified pixels, with no knowledge carried over to other images. In this work, we formulate interactive image segmentation as a continual learning problem and propose a framework to effectively learn from user annotations, aim- ing to improve the segmentation on both the current image and unseen images in future tasks while avoiding deterio- rated performance on previously-seen images. It employs a probabilistic mask to control the neural network's kernel ac- tivation and extract the most suitable features for segmenting images in each task. We also design a task-aware architec- ture to automatically infer the optimal kernel activation for initial segmentation and subsequent refinement. Interactions with users are guided through multi-source uncertainty esti- mation so that users can focus on the most important areas to minimize the overall manual annotation effort. Extensive experiments are performed on both medical and natural im- age datasets to illustrate the proposed framework's effective- ness on basic segmentation performance, forward knowledge transfer, and backward knowledge transfer. Introduction},
author = {Zheng, Ervine and Yu, Qi and Li, Rui and Shi, Pengcheng and Haake, Anne},
booktitle = {35th AAAI Conference on Artificial Intelligence, AAAI 2021},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zheng et al. - 2021 - A Continual Learning Framework for Uncertainty-Aware Interactive Image Segmentation.pdf:pdf},
keywords = {continual learning,image segmentation,uncertainty-aware},
mendeley-tags = {continual learning,image segmentation,uncertainty-aware},
title = {{A Continual Learning Framework for Uncertainty-Aware Interactive Image Segmentation}},
year = {2021}
}
@inproceedings{Meyers2015,
abstract = {We present a system which can recognize the contents of your meal from a single image, and then predict its nu- tritional contents, such as calories. The simplest version assumes that the user is eating at a restaurant for which we know the menu. In this case, we can collect images offline to train a multi-label classifier. At run time, we apply the classifier (running on your phone) to predict which foods are present in your meal, and we lookup the corresponding nutritional facts. We apply this method to a new dataset of images from 23 different restaurants, using a CNN-based classifier, significantly outperforming previous work. The more challenging setting works outside of restaurants. In this case, we need to estimate the size of the foods, as well as their labels. This requires solving segmentation and depth / volume estimation from a single image. We present CNN-based approaches to these problems, with promising preliminary results.},
author = {Meyers, A and Johnston, N and Rathod, V and Korattikara, A and Gorban, A and Silberman, N and Guadarrama, S and Papandreou, G and Huang, J and KP, Murphy},
booktitle = {International Conference on Computer Vision},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Meyers et al. - 2015 - Im2calories Towards an automated mobile vision food diary. Proceedings of the IEEE International Conference on Co.pdf:pdf},
number = {December},
pages = {pp.--1233--1241},
title = {{Im2calories: Towards an automated mobile vision food diary. Proceedings of the IEEE International Conference on Computer Vision}},
year = {2015}
}
@article{Gunawan2011,
author = {Gunawan, Dodo and Linarka, Utoyo Ajie},
journal = {Jurnal Meteorologi dan Geofisika},
keywords = {dynamical downscaling,singular value decompisition,statistical downscaling},
number = {2},
pages = {93--102},
title = {{PENENTUAN PREDIKTOR UNTUK PREDIKSI CURAH HUJAN BULANAN MENGGUNAKAN METODE STATISTICAL DYNAMICAL DOWNSCALING}},
year = {2011}
}
@book{Castillo2008,
author = {Castillo, Oscar and Melin, Patricia},
editor = {of Sciences, Polish Academy},
isbn = {9783540374190},
pages = {237},
publisher = {Springer-Verlag Berlin Heidelberg},
title = {{Type-2 Fuzzy Logic Theory and Applications}},
year = {2008}
}
@article{DeLange2020,
abstract = {Attaining prototypical features to represent class distributions is well established in representation learning. However, learning prototypes online from streaming data proves a challenging endeavor as they rapidly become outdated, caused by an ever-changing parameter space during the learning process. Additionally, continual learning does not assume the data stream to be stationary, typically resulting in catastrophic forgetting of previous knowledge. As a first, we introduce a system addressing both problems, where prototypes evolve continually in a shared latent space, enabling learning and prediction at any point in time. In contrast to the major body of work in continual learning, data streams are processed in an online fashion, without additional task-information, and an efficient memory scheme provides robustness to imbalanced data streams. Besides nearest neighbor based prediction, learning is facilitated by a novel objective function, encouraging cluster density about the class prototype and increased inter-class variance. Furthermore, the latent space quality is elevated by pseudo-prototypes in each batch, constituted by replay of exemplars from memory. As an additional contribution, we generalize the existing paradigms in continual learning to incorporate data incremental learning from data streams by formalizing a two-agent learner-evaluator framework. We obtain state-of-the-art performance by a significant margin on eight benchmarks, including three highly imbalanced data streams.},
archivePrefix = {arXiv},
arxivId = {2009.00919},
author = {{De Lange}, Matthias and Tuytelaars, Tinne},
eprint = {2009.00919},
file = {:home/user/Downloads/De_Lange_Continual_Prototype_Evolution_Learning_Online_From_Non-Stationary_Data_Streams_ICCV_2021_paper.pdf:pdf},
keywords = {continual learning},
mendeley-tags = {continual learning},
pages = {8250--8259},
title = {{Continual Prototype Evolution: Learning Online from Non-Stationary Data Streams}},
url = {http://arxiv.org/abs/2009.00919},
year = {2020}
}
@article{Eyoh2017,
author = {Eyoh, Imo and Member, Student and John, Robert and Member, Senior and Maere, Geert De},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Eyoh et al. - 2017 - Time Series Forecasting with Interval Type-2 Intuitionistic Fuzzy Logic Systems.pdf:pdf},
isbn = {9781509060344},
journal = {Ieee},
pages = {0--5},
title = {{Time Series Forecasting with Interval Type-2 Intuitionistic Fuzzy Logic Systems}},
year = {2017}
}
@article{Mirza2014,
abstract = {Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.},
archivePrefix = {arXiv},
arxivId = {1411.1784},
author = {Mirza, Mehdi and Osindero, Simon},
eprint = {1411.1784},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mirza, Osindero - 2014 - Conditional Generative Adversarial Nets.pdf:pdf},
pages = {1--7},
title = {{Conditional Generative Adversarial Nets}},
url = {http://arxiv.org/abs/1411.1784},
year = {2014}
}
@book{Lucklum2008a,
abstract = {New understandings underlying the principles of Piezoelectric Transducers, new technological advances in its applications, and new areas of utility for these transducers made a second edition of this book inevitable. The second edition of Piezoelectric Transducers and Applications includes these new developments together with a deep revision and enlargement of the topics already included in the first edition. It provides a guide for graduate students and researchers to the current state of the art of this complex and multidisciplinary area. The book fills an urgent need for a unified source of information on piezoelectric devices and their astounding variety of existing and emerging applications. Some of the chapters focus more on the basic concepts of the different disciplines involved and are presented in a didactic manner. Others go deeper into the complex aspects of specific fields of research, thus reaching the technical level of a scientific paper. Among other topics resonant sensors, especially bulk acoustic wave thickness shear mode resonators, chemical and bio-sensors, as well as broadband ultrasonic systems are treated in-depth.},
author = {Lucklum, Ralf and Soares, David and Kanazawa, Kay},
booktitle = {Piezoelectric Transducers and Applications},
doi = {10.1007/978-3-540-77508-9_3},
isbn = {9783540775072},
pages = {63--96},
title = {{Models for resonant sensors}},
year = {2008}
}
@inproceedings{Kweon2021,
author = {Kweon, Hyeokjun and Yoon, Sung-hoon and Kim, Hyeonseong and Park, Daehee and Yoon, Kuk-jin},
booktitle = {International Conference on Computer Vision},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kweon et al. - 2021 - Unlocking the Potential of Ordinary Classifier Class-specific Adversarial Erasing Framework for Weakly Supervised.pdf:pdf},
keywords = {semantic segmentation,weakly supervised learning},
mendeley-tags = {semantic segmentation,weakly supervised learning},
pages = {6994--7003},
title = {{Unlocking the Potential of Ordinary Classifier : Class-specific Adversarial Erasing Framework for Weakly Supervised Semantic Segmentation}},
year = {2021}
}
@article{Hesamian2017,
abstract = {A large number of accounting studies have focused on parametric or non-parametric forms of fuzzy regression relationships between dependent and independent variables. Notably, semi-parametric partially linear model as a powerful tool to incorporate statistical parametric and non-parametric regression analyses has gained attentions in many real-life applications recently. However, fuzzy data find application in many real studies. This study is an investigation of semi-parametric partially linear model for such cases to improve the conventional fuzzy linear regression models with fuzzy inputs, fuzzy outputs, fuzzy smooth function and non-fuzzy coefficients. For this purpose, a hybrid procedure is suggested based on curve fitting methods and least absolutes deviations to estimate the fuzzy smooth function and fuzzy coefficients. The proposed method is also examined to be compared with a common fuzzy linear regression model via a simulation data set and some real fuzzy data sets. It is shown that the proposed fuzzy regression model performs more convenient and efficient results in regard to six goodness-of-fit criteria which concludes that the proposed model could be a rational substituted model of some common fuzzy regression models in many practical studies of fuzzy regression model in expert and intelligent systems.},
author = {Hesamian, G. and Akbari, M. G. and Asadollahi, M.},
doi = {10.1016/j.eswa.2016.11.032},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hesamian, Akbari, Asadollahi - 2017 - Fuzzy semi-parametric partially linear model with fuzzy inputs and fuzzy outputs.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Fuzzy input,Fuzzy output,Fuzzy semi-parametric partially linear,Goodness-of-fit measure,Kernel method,Least absolute deviation,Non-fuzzy coefficient,Optimal bandwidth},
pages = {230--239},
publisher = {Elsevier Ltd},
title = {{Fuzzy semi-parametric partially linear model with fuzzy inputs and fuzzy outputs}},
url = {http://dx.doi.org/10.1016/j.eswa.2016.11.032},
volume = {71},
year = {2017}
}
@article{Liu2019b,
abstract = {Skin conditions affect an estimated 1.9 billion people worldwide. A shortage of dermatologists causes long wait times and leads patients to seek dermatologic care from general practitioners. However, the diagnostic accuracy of general practitioners has been reported to be only 0.24-0.70 (compared to 0.77-0.96 for dermatologists), resulting in referral errors, delays in care, and errors in diagnosis and treatment. In this paper, we developed a deep learning system (DLS) to provide a differential diagnosis of skin conditions for clinical cases (skin photographs and associated medical histories). The DLS distinguishes between 26 skin conditions that represent roughly 80% of the volume of skin conditions seen in primary care. The DLS was developed and validated using de-identified cases from a teledermatology practice serving 17 clinical sites via a temporal split: the first 14,021 cases for development and the last 3,756 cases for validation. On the validation set, where a panel of three board-certified dermatologists defined the reference standard for every case, the DLS achieved 0.71 and 0.93 top-1 and top-3 accuracies respectively. For a random subset of the validation set (n=963 cases), 18 clinicians reviewed the cases for comparison. On this subset, the DLS achieved a 0.67 top-1 accuracy, non-inferior to board-certified dermatologists (0.63, p<0.001), and higher than primary care physicians (PCPs, 0.45) and nurse practitioners (NPs, 0.41). The top-3 accuracy showed a similar trend: 0.90 DLS, 0.75 dermatologists, 0.60 PCPs, and 0.55 NPs. These results highlight the potential of the DLS to augment general practitioners to accurately diagnose skin conditions by suggesting differential diagnoses that may not have been considered. Future work will be needed to prospectively assess the clinical impact of using this tool in actual clinical workflows.},
archivePrefix = {arXiv},
arxivId = {1909.05382},
author = {Liu, Yuan and Jain, Ayush and Eng, Clara and Way, David H. and Lee, Kang and Bui, Peggy and Kanada, Kimberly and Marinho, Guilherme de Oliveira and Gallegos, Jessica and Gabriele, Sara and Gupta, Vishakha and Singh, Nalini and Natarajan, Vivek and Hofmann-Wellenhof, Rainer and Corrado, Greg S. and Peng, Lily H. and Webster, Dale R. and Ai, Dennis and Huang, Susan and Liu, Yun and Dunn, R. Carter and Coz, David},
eprint = {1909.05382},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2019 - A deep learning system for differential diagnosis of skin diseases.pdf:pdf},
title = {{A deep learning system for differential diagnosis of skin diseases}},
url = {http://arxiv.org/abs/1909.05382},
year = {2019}
}
@article{Novisnky2017,
author = {Novisnky, Fleydi and Stevy, Hesky and Bobanto, Maria D},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Novisnky, Stevy, Bobanto - 2017 - Pemodelan Sistem Prediksi Intensitas Curah Hujan di Kota Manado Dengan Menggunakan Kontrol Logika Fuzz.pdf:pdf},
keywords = {fuzzy logic,prediction,rain},
number = {2},
title = {{Pemodelan Sistem Prediksi Intensitas Curah Hujan di Kota Manado Dengan Menggunakan Kontrol Logika Fuzzy}},
volume = {6},
year = {2017}
}
@article{Kolouri2019,
abstract = {Catastrophic forgetting/interference is a critical problem for lifelong learning machines, which impedes the agents from maintaining their previously learned knowledge while learning new tasks. Neural networks, in particular, suffer plenty from the catastrophic forgetting phenomenon. Recently there has been several efforts towards overcoming catastrophic forgetting in neural networks. Here, we propose a biologically inspired method toward overcoming catastrophic forgetting. Specifically, we define an attention-based selective plasticity of synapses based on the cholinergic neuromodulatory system in the brain. We define synaptic importance parameters in addition to synaptic weights and then use Hebbian learning in parallel with backpropagation algorithm to learn synaptic importances in an online and seamless manner. We test our proposed method on benchmark tasks including the Permuted MNIST and the Split MNIST problems and show competitive performance compared to the state-of-the-art methods.},
archivePrefix = {arXiv},
arxivId = {1903.06070},
author = {Kolouri, Soheil and Ketz, Nicholas and Zou, Xinyun and Krichmar, Jeffrey and Pilly, Praveen},
eprint = {1903.06070},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kolouri et al. - 2019 - Attention-Based Structural-Plasticity.pdf:pdf},
keywords = {attention networks,catastrophic forgetting,continual learning,plasticity},
mendeley-tags = {attention networks,catastrophic forgetting,continual learning,plasticity},
title = {{Attention-Based Structural-Plasticity}},
url = {http://arxiv.org/abs/1903.06070},
year = {2019}
}
@inproceedings{Dosovitskiy2020,
abstract = {While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.},
archivePrefix = {arXiv},
arxivId = {2010.11929},
author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
booktitle = {Iclr 2021},
eprint = {2010.11929},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dosovitskiy et al. - 2020 - An Image is Worth 16x16 Words Transformers for Image Recognition at Scale.pdf:pdf},
keywords = {large-scale,representation learning,transformer,visual representation},
mendeley-tags = {large-scale,representation learning,transformer,visual representation},
pages = {1--21},
title = {{An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}},
url = {http://arxiv.org/abs/2010.11929},
year = {2020}
}
@article{Chen2009,
abstract = {Neural network and genetic algorithm have attracted a great deal of attention as methods and theories realizing artificial intelligence recently. The combination of these two is drawing more and more attention. This paper demonstrates the possibility of combining neural network with genetic algorithm. An improved genetic algorithm for the learning of neural network's connection weights is presented. According to the XOR problem, it has been indicated that the new method has the capability in fast learning of neural network and the capability in escaping local optima and initial weights. The algorithm gets performance far superior to traditional genetic algorithm and BP algorithm in all sides.},
author = {Chen, Zhijun Chen Zhijun},
doi = {10.1109/CISE.2009.5365287},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen - 2009 - Optimization of Neural Network Based on Improved Genetic Algorithm.pdf:pdf},
isbn = {978-1-4244-4507-3},
journal = {2009 International Conference on Computational Intelligence and Software Engineering},
keywords = {- genetic algorithm,1,11,Optimization of Neural Network Based on Improved G,has two ways,in optimizing neural network,network,neural,neural network,one is to optimize,optimization,optimize the structure of,the other is to,the weights in neural,to apply genetic algorithm},
pages = {1--3},
title = {{Optimization of Neural Network Based on Improved Genetic Algorithm}},
year = {2009}
}
@article{Takahashi2017,
author = {Takahashi, Masayoshi},
doi = {10.5334/dsj-2017-037},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Takahashi - 2017 - Statistical inference in missing data by MCMC and ndon-MCMC multiple imputation algorithms assessing the effects of b.pdf:pdf},
issn = {16831470},
journal = {Data Science Journal},
keywords = {conditional modeling,incomplete data,joint modeling,markov chain monte carlo,mcmc,nonresponse},
number = {37},
pages = {1--17},
title = {{Statistical inference in missing data by MCMC and ndon-MCMC multiple imputation algorithms: assessing the effects of between-imputation iterations}},
volume = {16},
year = {2017}
}
@article{Sengodan2018,
abstract = {One of the most attractive routes for the production of hydrogen or syngas for use in fuel cell applications is the reforming and partial oxidation of hydrocarbons. The use of hydrocarbons in high temperature fuel cells is achieved through either external or internal reforming. Reforming and partial oxidation catalysis to convert hydrocarbons to hydrogen rich syngas plays an important role in fuel processing technology. The current research in the area of reforming and partial oxidation of methane, methanol and ethanol includes catalysts for reforming and oxidation, methods of catalyst synthesis, and the effective utilization of fuel for both external and internal reforming processes. In this paper the recent progress in these areas of research is reviewed along with the reforming of liquid hydrocarbons, from this an overview of the current best performing catalysts for the reforming and partial oxidizing of hydrocarbons for hydrogen production is summarized.},
author = {Sengodan, Sivaprakash and Lan, Rong and Humphreys, John and Du, Dongwei and Xu, Wei and Wang, Huanting and Tao, Shanwen},
doi = {10.1016/j.rser.2017.09.071},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sengodan et al. - 2018 - Advances in reforming and partial oxidation of hydrocarbons for hydrogen production and fuel cell applications.pdf:pdf},
issn = {18790690},
journal = {Renewable and Sustainable Energy Reviews},
keywords = {Catalyst,Fuel cells,Hydrogen production,Partial oxidation,Reforming},
number = {July 2016},
pages = {761--780},
publisher = {Elsevier Ltd},
title = {{Advances in reforming and partial oxidation of hydrocarbons for hydrogen production and fuel cell applications}},
url = {http://dx.doi.org/10.1016/j.rser.2017.09.071},
volume = {82},
year = {2018}
}
@article{Wei2020a,
abstract = {Recently, contrastive learning has largely advanced the progress of unsupervised visual representation learning. Pre-trained on ImageNet, some self-supervised algorithms reported higher transfer learning performance compared to fully-supervised methods, seeming to deliver the message that human labels hardly contribute to learning transferrable visual features. In this paper, we defend the usefulness of semantic labels but point out that fully-supervised and self-supervised methods are pursuing different kinds of features. To alleviate this issue, we present a new algorithm named Supervised Contrastive Adjustment in Neighborhood (SCAN) that maximally prevents the semantic guidance from damaging the appearance feature embedding. In a series of downstream tasks, SCAN achieves superior performance compared to previous fully-supervised and self-supervised methods, and sometimes the gain is significant. More importantly, our study reveals that semantic labels are useful in assisting self-supervised methods, opening a new direction for the community.},
archivePrefix = {arXiv},
arxivId = {2011.08621},
author = {Wei, Longhui and Xie, Lingxi and He, Jianzhong and Chang, Jianlong and Zhang, Xiaopeng and Zhou, Wengang and Li, Houqiang and Tian, Qi},
eprint = {2011.08621},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wei et al. - 2020 - Can Semantic Labels Assist Self-Supervised Visual Representation Learning.pdf:pdf},
title = {{Can Semantic Labels Assist Self-Supervised Visual Representation Learning?}},
url = {http://arxiv.org/abs/2011.08621},
year = {2020}
}
@article{Alshejari2017,
author = {Alshejari, Abeer and Kodogiannis, Vassilis S},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alshejari, Kodogiannis - 2017 - Short-Term Electricity Price Forecasting using Asymmetric Fuzzy Neural Network Systems.pdf:pdf},
isbn = {9781509060344},
keywords = {clustering,electricity price forecasting,neural networks,neurofuzzy systems,prediction},
title = {{Short-Term Electricity Price Forecasting using Asymmetric Fuzzy Neural Network Systems}},
year = {2017}
}
@article{History2005,
author = {History, World Economic and Clark, Gregory and Zealand, New},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/History, Clark, Zealand - 2005 - 2 . The British Industrial Revolution , 1760-1860.pdf:pdf},
journal = {World Economic History},
title = {{2 . The British Industrial Revolution , 1760-1860}},
year = {2005}
}
@article{Cohen1992,
abstract = {FERROELECTRIC materials are characterized by a switchable macroscopic polarization. Most technologically important ferroelectrics are oxides with a perovskite structure. The origin of their ferroelectric behaviour is unclear, however, and there is incomplete understanding of why similar, but chemically different, perovskites should display very different ferroelectric behaviour. The great sensitivity of ferroelectrics to chemistry, defects, electrical boundary conditions and pressure arises from a delicate balance between long-range Coulomb forces (which favour the ferroelectric state) and short-range repulsions (which favour the nonpolar cubic structure). To model the transition accurately, total-energy techniques are required which incorporate the effects of charge distortion and covalency. Here I report results of electronic-structure calculations on two classic examples of ferroelectric perovskites, BaTiO3 and PbTiO3, and demonstrate that hybridization between the titanium 3d states and the oxygen 2p states is essential for ferroelectricity. The different ferroelectric phase behaviour of the two materials is also clear: in PbTiO3, the lead and oxygen states hybridize, leading to a large strain that stabilizes the tetragonal phase, whereas in BaTiO3 the interaction between barium and oxygen is completely ionic, favouring a rhombohedral structure.},
archivePrefix = {arXiv},
arxivId = {1108.5819},
author = {Cohen, Ronald E.},
doi = {10.1038/358136a0},
eprint = {1108.5819},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cohen - 1992 - Origin of ferroelectricity in perovskite oxides.pdf:pdf},
isbn = {0028-0836},
issn = {00280836},
journal = {Nature},
number = {6382},
pages = {136--138},
pmid = {1741032},
title = {{Origin of ferroelectricity in perovskite oxides}},
volume = {358},
year = {1992}
}
@article{Prabhu2020b,
abstract = {We discuss a general formulation for the Continual Learning (CL) problem for classification-a learning task where a stream provides samples to a learner and the goal of the learner, depending on the samples it receives, is to continually upgrade its knowledge about the old classes and learn new ones. Our formulation takes inspiration from the open-set recognition problem where test scenarios do not necessarily belong to the training distribution. We also discuss various quirks and assumptions encoded in recently proposed approaches for CL. We argue that some oversimplify the problem to an extent that leaves it with very little practical importance, and makes it extremely easy to perform well on. To validate this, we propose GDumb that (1) greedily stores samples in memory as they come and; (2) at test time, trains a model from scratch using samples only in the memory. We show that even though GDumb is not specifically designed for CL problems, it obtains state-of-the-art accuracies (often with large margins) in almost all the experiments when compared to a multitude of recently proposed algorithms. Surprisingly, it outperforms approaches in CL formulations for which they were specifically designed. This, we believe, raises concerns regarding our progress in CL for classification. Overall, we hope our formulation, characterizations and discussions will help in designing realistically useful CL algorithms, and GDumb will serve as a strong contender for the same.},
author = {Prabhu, Ameya and Torr, Philip H. S. and Dokania, Puneet K.},
doi = {10.1007/978-3-030-58536-5_31},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Prabhu, Torr, Dokania - 2020 - GDumb A Simple Approach that Questions Our Progress in Continual Learning(3).pdf:pdf},
issn = {16113349},
pages = {524--540},
title = {{GDumb: A Simple Approach that Questions Our Progress in Continual Learning}},
year = {2020}
}
@article{Todaro2017,
abstract = {Piezoelectric MEMS energy harvesters based on thin films are compact and cost-effective microgenerators for scavenging environmental vibrations. This technology is promising for the replacement of electrochemical batteries in low power autonomous sensors and microdevices capturing vibrations in the $\mu$W-mW range. Most of piezoelectric MEMS devices, reported in the last few years, exhibit low generated power/voltage and are not suitable for practical applications. This work reviews the current status of MEMS energy harvesters based on piezoelectric thin films, highlighting approaches/strategies to face the two main challenges to be addressed for high performance devices, namely generated power and frequency bandwidth. The paper introduces the theoretical principles and the main figures of merit of energy conversion in piezoelectric thin films and devices. After an overview on piezoelectric thin films for energy harvesting applications, highlighting their key properties, the manuscript reports a comprehensive survey on the state of the art for this device technology. The last section summarizes the review, highlighting key issues to be addressed and providing an insight into the future outlook to realize devices for practical applications.},
author = {Todaro, Maria Teresa and Guido, Francesco and Mastronardi, Vincenzo and Desmaele, Denis and Epifani, Gianmichele and Algieri, Luciana and {De Vittorio}, Massimo},
doi = {10.1016/j.mee.2017.10.005},
issn = {01679317},
journal = {Microelectronic Engineering},
keywords = {Energy harvesting,MEMS,Piezoelectric thin films},
pages = {23--36},
publisher = {Elsevier B.V},
title = {{Piezoelectric MEMS vibrational energy harvesters: Advances and outlook}},
url = {http://dx.doi.org/10.1016/j.mee.2017.10.005},
volume = {183-184},
year = {2017}
}
@inproceedings{Veniat2020,
abstract = {Existing literature in Continual Learning (CL) has focused on overcoming catastrophic forgetting, the inability of the learner to recall how to perform tasks observed in the past. There are however other desirable properties of a CL system, such as the ability to transfer knowledge from previous tasks and to scale memory and compute sub-linearly with the number of tasks. Since most current benchmarks focus only on forgetting using short streams of tasks, we first propose a new suite of benchmarks to probe CL algorithms across these new axes. Finally, we introduce a new modular architecture, whose modules represent atomic skills that can be composed to perform a certain task. Learning a task reduces to figuring out which past modules to re-use, and which new modules to instantiate to solve the current task. Our learning algorithm leverages a task-driven prior over the exponential search space of all possible ways to combine modules, enabling efficient learning on long streams of tasks. Our experiments show that this modular architecture and learning algorithm perform competitively on widely used CL benchmarks while yielding superior performance on the more challenging benchmarks we introduce in this work.},
archivePrefix = {arXiv},
arxivId = {2012.12631},
author = {Veniat, Tom and Denoyer, Ludovic and Ranzato, Marc'Aurelio},
booktitle = {Iclr 2021},
eprint = {2012.12631},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Veniat, Denoyer, Ranzato - 2020 - Efficient Continual Learning with Modular Networks and Task-Driven Priors.pdf:pdf},
keywords = {continual learning,transfer learning},
mendeley-tags = {continual learning,transfer learning},
pages = {1--30},
title = {{Efficient Continual Learning with Modular Networks and Task-Driven Priors}},
url = {http://arxiv.org/abs/2012.12631 https://github.com/facebookresearch/CTrLBenchmark?fbclid=IwAR3XjJDjAivewGDgvqe6B989vTYrdz9PwYhkdd0iAVo1LomhDFQKYoZy9LY},
year = {2020}
}
@article{Niemeyer2021,
abstract = {Deep generative models allow for photorealistic image synthesis at high resolutions. But for many applications, this is not enough: content creation also needs to be controllable. While several recent works investigate how to disentangle underlying factors of variation in the data, most of them operate in 2D and hence ignore that our world is three-dimensional. Further, only few works consider the compositional nature of scenes. Our key hypothesis is that incorporating a compositional 3D scene representation into the generative model leads to more controllable image synthesis. Representing scenes as compositional generative neural feature fields allows us to disentangle one or multiple objects from the background as well as individual objects' shapes and appearances while learning from unstructured and unposed image collections without any additional supervision. Combining this scene representation with a neural rendering pipeline yields a fast and realistic image synthesis model. As evidenced by our experiments, our model is able to disentangle individual objects and allows for translating and rotating them in the scene as well as changing the camera pose.},
archivePrefix = {arXiv},
arxivId = {2011.12100},
author = {Niemeyer, Michael and Geiger, Andreas},
doi = {10.1109/CVPR46437.2021.01129},
eprint = {2011.12100},
file = {:home/user/Downloads/Niemeyer_GIRAFFE_Representing_Scenes_As_Compositional_Generative_Neural_Feature_Fields_CVPR_2021_paper.pdf:pdf},
isbn = {9781665445092},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
keywords = {generative model,representation learning,scene representation},
mendeley-tags = {generative model,representation learning,scene representation},
pages = {11448--11459},
title = {{GIRAFFE: Representing Scenes as Compositional Generative Neural Feature Fields}},
year = {2021}
}
@article{Watson2016,
author = {Watson, Ian and Azhar, Damir and Chuyang, Ya and Pan, Wei and Chen, Gary},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Watson et al. - 2016 - Optimization in Strategy Games Using Genetic Algorithms to Optimize City Development in FreeCiv.pdf:pdf},
journal = {Interim Report},
pages = {1--12},
title = {{Optimization in Strategy Games : Using Genetic Algorithms to Optimize City Development in FreeCiv}},
year = {2016}
}
@article{Kim2004,
abstract = {Biodiesel produced by the transesterification of vegetable oils (VOs) is a promising alternative fuel to diesel regarding the limited resources of fossil fuel and the environmental concerns. In this work, an environmentally benign process for the production of biodiesel from VOs using heterogeneous catalyst was developed. Na/NaOH/$\gamma$-Al2O3heterogeneous base catalyst was firstly adopted for the production of biodiesel. A study for optimizing the reaction conditions such as the reaction time, the stirring speed, the use of co-solvent, the oil to methanol ratio, and the amount of catalyst, was performed. The Na/NaOH/$\gamma$-Al2O3heterogeneous base catalyst showed almost the same activity under the optimized reaction conditions compared to conventional homogeneous NaOH catalyst. The basic strength of Na/NaOH/$\gamma$-Al2O3catalyst was estimated and the correlation with the activity towards transesterification was proposed. {\textcopyright} 2004 Elsevier B.V. All rights reserved.},
author = {Kim, Hak Joo and Kang, Bo Seung and Kim, Min Ju and Park, Young Moo and Kim, Deog Keun and Lee, Jin Suk and Lee, Kwan Young},
doi = {10.1016/j.cattod.2004.06.007},
isbn = {0920-5861},
issn = {09205861},
journal = {Catalysis Today},
keywords = {Biodiesel,Heterogeneous base catalyst,Methyl ester,Transesterification,Vegetable oil},
pages = {315--320},
title = {{Transesterification of vegetable oil to biodiesel using heterogeneous base catalyst}},
volume = {93-95},
year = {2004}
}
@article{Khan2021,
abstract = {Astounding results from Transformer models on natural language tasks have intrigued the vision community to study their application to computer vision problems. Among their salient benefits, Transformers enable modeling long dependencies between input sequence elements and support parallel processing of sequence as compared to recurrent networks e.g., Long short-term memory (LSTM). Different from convolutional networks, Transformers require minimal inductive biases for their design and are naturally suited as set-functions. Furthermore, the straightforward design of Transformers allows processing multiple modalities (e.g., images, videos, text and speech) using similar processing blocks and demonstrates excellent scalability to very large capacity networks and huge datasets. These strengths have led to exciting progress on a number of vision tasks using Transformer networks. This survey aims to provide a comprehensive overview of the Transformer models in the computer vision discipline. We start with an introduction to fundamental concepts behind the success of Transformers i.e., self-attention, large-scale pre-training, and bidirectional encoding. We then cover extensive applications of transformers in vision including popular recognition tasks (e.g., image classification, object detection, action recognition, and segmentation), generative modeling, multi-modal tasks (e.g., visual-question answering, visual reasoning, and visual grounding), video processing (e.g., activity recognition, video forecasting), low-level vision (e.g., image super-resolution, image enhancement, and colorization) and 3D analysis (e.g., point cloud classification and segmentation). We compare the respective advantages and limitations of popular techniques both in terms of architectural design and their experimental value. Finally, we provide an analysis on open research directions and possible future works.},
archivePrefix = {arXiv},
arxivId = {2101.01169},
author = {Khan, Salman and Naseer, Muzammal and Hayat, Munawar and Zamir, Syed Waqas and Khan, Fahad Shahbaz and Shah, Mubarak},
eprint = {2101.01169},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khan et al. - 2021 - Transformers in Vision A Survey.pdf:pdf},
keywords = {review,survey,transformer},
mendeley-tags = {review,survey,transformer},
pages = {1--28},
title = {{Transformers in Vision: A Survey}},
url = {http://arxiv.org/abs/2101.01169},
year = {2021}
}
@article{Ragesh2014a,
abstract = {<p>Self-cleaning and multifunctional materials are used in applications such as windows, solar panels, cements, paints, and textiles. This state-of-the-art review summarizes the materials involved in self-cleaning and multifunctional coatings.</p>},
archivePrefix = {arXiv},
arxivId = {1612.08814},
author = {Ragesh, Prathapan and {Anand Ganesh}, V. and Nair, Shantikumar V. and Nair, A. Sreekumaran},
doi = {10.1039/c4ta02542c},
eprint = {1612.08814},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ragesh et al. - 2014 - A review on 'self-cleaning and multifunctional materials'.pdf:pdf},
isbn = {2050-7488},
issn = {20507496},
journal = {Journal of Materials Chemistry A},
number = {36},
pages = {14773--14797},
pmid = {26204564},
title = {{A review on 'self-cleaning and multifunctional materials'}},
volume = {2},
year = {2014}
}
@inproceedings{Instruction2020,
abstract = {Recent work has described neural-network-based agents that are trained to execute language-like commands in simulated worlds, as a step towards an intelligent agent or robot that can be instructed by human users. However, the instructions that such agents are trained to follow are typically generated from templates (by an environment simulator), and do not reflect the varied or ambiguous expressions used by real people. We address this issue by integrating language encoders that are pretrained on large text corpora into a situated, instruction-following agent. In a procedurally-randomized first-person 3D world, we first train agents to follow synthetic instructions requiring the identification, manipulation and relative positioning of visually-realistic object models. We then show how these abilities can transfer to a context where humans provide instructions in natural language, but only when agents are endowed with language encoding components that were pretrained on text-data. We explore techniques for integrating text-trained and environment-trained components into an agent, observing clear advantages for the fully-contextual phrase representations computed by the well-known BERT model, and additional gains by integrating a self-attention operation optimized to adapt BERT's representations for the agent's tasks and environment. These results bridge the gap between two successful strands of recent AI research: agent-centric behavior optimization and text-based representation learning.},
author = {Instruction, Obust and Agent, Situated and Transfer, V I A and Text, Learning From},
booktitle = {ICLR},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Instruction et al. - 2020 - Robust Instruction-Following in a Situated Agent via Transfer-Learning from Text.pdf:pdf},
pages = {1--18},
title = {{Robust Instruction-Following in a Situated Agent via Transfer-Learning from Text}},
url = {https://openreview.net/pdf?id=rklraTNFwB},
year = {2020}
}
@article{Ogilvie2011,
author = {Ogilvie, Madeleine and Ryan, Maria and Univeristy, Edith Cowan},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ogilvie, Ryan, Univeristy - 2011 - Lipstick More than a Fashion Trend.pdf:pdf},
journal = {Research Journal of Social Science & Management},
number = {6},
pages = {117--128},
title = {{Lipstick : More than a Fashion Trend}},
volume = {1},
year = {2011}
}
@incollection{Li2020,
abstract = {Although significant progress achieved, multi-label classification is still challenging due to the complexity of correlations among different labels. Furthermore, modeling the relationships between input and some (dull) classes further increases the difficulty of accurately predicting all possible labels. In this work, we propose to select a small subset of labels as landmarks which are easy to predict according to input (predictable) and can well recover the other possible labels (representative). Different from existing methods which separate the landmark selection and landmark prediction in the 2-step manner, the proposed algorithm, termed Selecting Predictable Landmarks for Multi-Label Learning (SPL-MLL), jointly conducts landmark selection, landmark prediction, and label recovery in a unified framework, to ensure both the representativeness and predictableness for selected landmarks. We employ the Alternating Direction Method (ADM) to solve our problem. Empirical studies on real-world datasets show that our method achieves superior classification performance over other state-of-the-art methods.},
author = {Li, Junbing and Zhang, Changqing and Zhu, Pengfei and Wu, Baoyuan and Chen, Lei and Hu, Qinghua},
booktitle = {arXiv},
doi = {10.1007/978-3-030-58545-7_45},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2020 - SPL-MLL Selecting Predictable Landmarks for Multi-label Learning.pdf:pdf},
keywords = {A unified framework,Multi-label learning,Predictable landmarks},
pages = {783--799},
title = {{SPL-MLL: Selecting Predictable Landmarks for Multi-label Learning}},
url = {http://link.springer.com/10.1007/978-3-030-58545-7_45},
year = {2020}
}
@article{Suryaputra2013,
abstract = {The waste Capiz shell was utilized as raw material for catalyst production for biodiesel preparation. During calcination process, the calcium carbonate content in the waste capiz shell was converted to CaO. This calcium oxide was used as catalyst for transesterification reaction between palm oil and methanol to produce biodiesel. The biodiesel preparation was conducted under the following conditions: the mole ration between methanol and palm oil was 8:1, stirring speed was 700 rpm, and reaction temperature was 60 °C for 4, 5, and 6 h reaction time. The amount of catalyst was varied at 1, 2, 3, 4, and 5 wt %. The maximum yield of biodiesel was 93 ± 2.2%, obtained at 6 h of reaction time and 3 wt % of amount of catalyst. In order to examine the reusability of catalyst developed from waste of capiz (Amusium cristatum) shell, three transesterification reaction cycles were also performed. {\textcopyright} 2012 Elsevier Ltd.},
author = {Suryaputra, Wijaya and Winata, Indra and Indraswati, Nani and Ismadji, Suryadi},
doi = {10.1016/j.renene.2012.08.060},
isbn = {0960-1481},
issn = {09601481},
journal = {Renewable Energy},
keywords = {Biodiesel,Capiz shell,Catalyst,Palm oil,Transesterification},
pages = {795--799},
publisher = {Elsevier Ltd},
title = {{Waste capiz (Amusium cristatum) shell as a new heterogeneous catalyst for biodiesel production}},
url = {http://dx.doi.org/10.1016/j.renene.2012.08.060},
volume = {50},
year = {2013}
}
@article{Wang2020b,
abstract = {In this paper, we present an implicit feature pyramid network (i-FPN) for object detection. Existing FPNs stack several cross-scale blocks to obtain large receptive field. We propose to use an implicit function, recently introduced in deep equilibrium model (DEQ), to model the transformation of FPN. We develop a residual-like iteration to updates the hidden states efficiently. Experimental results on MS COCO dataset show that i-FPN can significantly boost detection performance compared to baseline detectors with ResNet-50-FPN: +3.4, +3.2, +3.5, +4.2, +3.2 mAP on RetinaNet, Faster-RCNN, FCOS, ATSS and AutoAssign, respectively.},
archivePrefix = {arXiv},
arxivId = {2012.13563},
author = {Wang, Tiancai and Zhang, Xiangyu and Sun, Jian},
eprint = {2012.13563},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Zhang, Sun - 2020 - Implicit Feature Pyramid Network for Object Detection.pdf:pdf},
keywords = {Feature Pyramid Network,Object Detection},
mendeley-tags = {Feature Pyramid Network,Object Detection},
number = {2},
title = {{Implicit Feature Pyramid Network for Object Detection}},
url = {http://arxiv.org/abs/2012.13563},
volume = {1},
year = {2020}
}
@article{JinYe1JunjunHe12XiaojiangPeng1WenhaoWu12020,
abstract = {Recent studies often exploit Graph Convolutional Network (GCN) to model label dependencies to improve recognition accuracy for multi-label image recognition. However, constructing a graph by counting the label co-occurrence possibilities of the training data may degrade model generalizability, especially when there exist occasional co-occurrence objects in test images. Our goal is to eliminate such bias and enhance the robustness of the learnt features. To this end, we propose an Attention-Driven Dynamic Graph Convolutional Network (ADD-GCN) to dynamically generate a specific graph for each image. ADD-GCN adopts a Dynamic Graph Convolutional Network (D-GCN) to model the relation of content-aware category representations that are generated by a Semantic Attention Module (SAM). Extensive experiments on public multi-label benchmarks demonstrate the effectiveness of our method, which achieves mAPs of 85.2%, 96.0%, and 95.5% on MS-COCO, VOC2007, and VOC2012, respectively, and outperforms current state-of-the-art methods with a clear margin.},
author = {{Jin Ye1∗, Junjun He1,2∗, Xiaojiang Peng1∗, Wenhao Wu1}, and Yu Qiao1† 1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jin Ye1∗, Junjun He1,2∗, Xiaojiang Peng1∗, Wenhao Wu1 - 2020 - Attention-Driven Dynamic Graph Convolutional Network for Multi-Labe.pdf:pdf},
journal = {Europeon Conference on Computer Vision},
keywords = {dynamic graph convolutional network,label de-,multi-label image recognition,pendency,semantic attention},
pages = {1--17},
title = {{Attention-Driven Dynamic Graph Convolutional Network for Multi-Label Image Recognition}},
year = {2020}
}
@article{Shi2018,
abstract = {In this paper, a new adaptive fuzzy control scheme with prescribed performance is developed for a class of feedback linearizable uncertain MIMO nonlinear systems with unknown control direction and external disturbances. The fuzzy systems are employed to approximate the unknown nonlinear functions, and a Nussbaum-type function is applied to resolve the unknown control direction problems. By using the prescribed performance bounds, an adaptive fuzzy controller equipped with the Nussbaum-type gain function is developed. The proposed design scheme guarantees that all the signals in the closed-loop systems are bounded and that the tracking errors converge to a prescribed performance bounds by guaranteeing the convergence of the filtered tracking error to a predefine performance bounds. Two simulation examples are used to demonstrate the effectiveness of the proposed scheme.},
author = {Shi, Wuxi and Li, Baoquan},
doi = {10.1016/j.fss.2017.09.001},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shi, Li - 2018 - Adaptive fuzzy control for feedback linearizable MIMO nonlinear systems with prescribed performance.pdf:pdf},
issn = {01650114},
journal = {Fuzzy Sets and Systems},
keywords = {Adaptive fuzzy control,MIMO nonlinear systems,Prescribed performance control,Unknown control direction},
pages = {70--89},
publisher = {Elsevier B.V.},
title = {{Adaptive fuzzy control for feedback linearizable MIMO nonlinear systems with prescribed performance}},
url = {http://dx.doi.org/10.1016/j.fss.2017.09.001},
volume = {344},
year = {2018}
}
@article{Zhang2017a,
abstract = {This paper presents a real-time face detector, named Single Shot Scale-invariant Face Detector (S$^3$FD), which performs superiorly on various scales of faces with a single deep neural network, especially for small faces. Specifically, we try to solve the common problem that anchor-based detectors deteriorate dramatically as the objects become smaller. We make contributions in the following three aspects: 1) proposing a scale-equitable face detection framework to handle different scales of faces well. We tile anchors on a wide range of layers to ensure that all scales of faces have enough features for detection. Besides, we design anchor scales based on the effective receptive field and a proposed equal proportion interval principle; 2) improving the recall rate of small faces by a scale compensation anchor matching strategy; 3) reducing the false positive rate of small faces via a max-out background label. As a consequence, our method achieves state-of-the-art detection performance on all the common face detection benchmarks, including the AFW, PASCAL face, FDDB and WIDER FACE datasets, and can run at 36 FPS on a Nvidia Titan X (Pascal) for VGA-resolution images.},
archivePrefix = {arXiv},
arxivId = {arXiv:1708.05237v3},
author = {Zhang, Shifeng and Zhu, Xiangyu and Lei, Zhen and Shi, Hailin and Wang, Xiaobo and Li, Stan Z.},
doi = {10.1109/ICCV.2017.30},
eprint = {arXiv:1708.05237v3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2017 - S3FD Single Shot Scale-Invariant Face Detector.pdf:pdf},
isbn = {9781538610329},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {192--201},
title = {{S3FD: Single Shot Scale-Invariant Face Detector}},
volume = {2017-Octob},
year = {2017}
}
@article{Zabeti2009,
abstract = {Heterogeneous catalysts are promising for the transesterification reaction of vegetable oils to produce biodiesel. Unlike homogeneous, heterogeneous catalysts are environmentally benign and could be operated in continuous processes. Moreover they can be reused and regenerated. However a high molar ratio of alcohol to oil, large amount of catalyst and high temperature and pressure are required when utilizing heterogeneous catalyst to produce biodiesel. In this paper, the catalytic activity of several solid base and acid catalysts, particularly metal oxides and supported metal oxides, was reviewed. Solid acid catalysts were able to do transesterification and esterification reactions simultaneously and convert oils with high amount of FFA (Free Fatty Acids). However, the reaction rate in the presence of solid base catalysts was faster. The catalyst efficiency depended on several factors such as specific surface area, pore size, pore volume and active site concentration. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
author = {Zabeti, Masoud and {Wan Daud}, Wan Mohd Ashri and Aroua, Mohamed Kheireddine},
doi = {10.1016/j.fuproc.2009.03.010},
isbn = {0378-3820},
issn = {03783820},
journal = {Fuel Processing Technology},
keywords = {Biodiesel,Catalyst activity,Catalyst support,Heterogeneous catalyst,Transesterification},
number = {6},
pages = {770--777},
pmid = {20362044},
publisher = {Elsevier B.V.},
title = {{Activity of solid catalysts for biodiesel production: A review}},
url = {http://dx.doi.org/10.1016/j.fuproc.2009.03.010},
volume = {90},
year = {2009}
}
@article{Shao2020b,
abstract = {Normalization operations are widely used to train deep neural networks, and they can improve both convergence and generalization in most tasks. The theories for normalization's effectiveness and new forms of normalization have always been hot topics in research. To better understand normalization, one question can be whether normalization is indispensable for training deep neural networks? In this paper, we analyze what would happen when normalization layers are removed from the networks, and show how to train deep neural networks without normalization layers and without performance degradation. Our proposed method can achieve the same or even slightly better performance in a variety of tasks: image classification in ImageNet, object detection and segmentation in MS-COCO, video classification in Kinetics, and machine translation in WMT English-German, etc. Our study may help better understand the role of normalization layers and can be a competitive alternative to normalization layers. Codes are available at https://github.com/ hukkai/rescaling.},
author = {Shao, Jie and Hu, Kai and Wang, Changhu and Xue, Xiangyang and Raj, Bhiksha},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shao et al. - 2020 - Is normalization indispensable for training deep neural networks.pdf:pdf;:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shao et al. - 2020 - Is normalization indispensable for training deep neural networks(2).pdf:pdf},
number = {NeurIPS},
pages = {231--240},
title = {{Is normalization indispensable for training deep neural networks?}},
url = {https://github.com/},
year = {2020}
}
@article{Sariyildiz2020,
abstract = {Measuring concept generalization, i.e., the extent to which models trained on a set of (seen) visual concepts can be used to recognize a new set of (unseen) concepts, is a popular way of evaluating visual representations, especially when they are learned with self-supervised learning. Nonetheless, the choice of which unseen concepts to use is usually made arbitrarily, and independently from the seen concepts used to train representations, thus ignoring any semantic relationships between the two. In this paper, we argue that semantic relationships between seen and unseen concepts affect generalization performance and propose ImageNet-CoG, a novel benchmark on the ImageNet dataset that enables measuring concept generalization in a principled way. Our benchmark leverages expert knowledge that comes from WordNet in order to define a sequence of unseen ImageNet concept sets that are semantically more and more distant from the ImageNet-1K subset, a ubiquitous training set. This allows us to benchmark visual representations learned on ImageNet-1K out-of-the box: we analyse a number of such models from supervised, semi-supervised and self-supervised approaches under the prism of concept generalization, and show how our benchmark is able to uncover a number of interesting insights. We will provide resources for the benchmark at https://europe.naverlabs.com/cog-benchmark.},
archivePrefix = {arXiv},
arxivId = {2012.05649},
author = {Sariyildiz, Mert Bulent and Kalantidis, Yannis and Larlus, Diane and Alahari, Karteek},
eprint = {2012.05649},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sariyildiz et al. - 2020 - Concept Generalization in Visual Representation Learning.pdf:pdf},
keywords = {generalization,representation learning},
mendeley-tags = {generalization,representation learning},
title = {{Concept Generalization in Visual Representation Learning}},
url = {http://arxiv.org/abs/2012.05649},
year = {2020}
}
@article{Yu2011a,
abstract = {This paper reports the first development of the Levenberg-Marquardt algorithm for neural networks. It describes the theory and application of the algorithm, which trains neural networks at a rate 10 to 100 times faster than the usual gradient descent backpropagation method.},
author = {Yu, Hao and Wilamowski, Bogdan},
doi = {10.1201/b10604-15},
isbn = {978-1-4398-0283-0},
pages = {1--16},
title = {{Levenberg–Marquardt Training}},
url = {http://www.crcnetbase.com/doi/abs/10.1201/b10604-15},
year = {2011}
}
@article{Correia2014,
abstract = {The catalytic activities of calcium oxide obtained from natural sources (crab shell and eggshell) were characterized and evaluated in the transesterification of vegetable oil. These catalysts are mainly composed of calcium carbonate, which is partially converted into CaO after calcination (900°C for 2h). The catalysts have some advantages, such as abundant occurrence, low cost, porous structure, and nontoxic. The materials were characterized by XRD, FTIR, TG/DTG, CO2-TPD, XPS, SEM, and BET methods. The thermal treatment produces small particles of CaCO3and CaO that are responsible for the catalytic activity. The conversion from triglycerides to methyl ester was not observed in transesterification carried out using natural crab shell and eggshell. Under optimized reaction conditions, the conversions to YFAMEusing the calcined catalysts were: crab shell (83.10±0.27wt.%) and eggshell (97.75±0.02wt.%). These results, showed that these materials have promising viability in transesterification for biodiesel production. {\textcopyright} 2013 Elsevier Ltd.},
author = {Correia, Leandro Marques and Saboya, Rosana Maria Alves and {de Sousa Campelo}, Nat{\'{a}}lia and Cecilia, Juan Antonio and Rodr{\'{i}}guez-Castell{\'{o}}n, Enrique and Cavalcante, C{\'{e}}lio Loureiro and Vieira, Rodrigo Silveira},
doi = {10.1016/j.biortech.2013.10.046},
isbn = {1873-2976 (Electronic)\r0960-8524 (Linking)},
issn = {18732976},
journal = {Bioresource Technology},
keywords = {Biodiesel,Calcium oxide,Crab shell,Eggshell},
pages = {207--213},
pmid = {24240148},
publisher = {Elsevier Ltd},
title = {{Characterization of calcium oxide catalysts from natural sources and their application in the transesterification of sunflower oil}},
url = {http://dx.doi.org/10.1016/j.biortech.2013.10.046},
volume = {151},
year = {2014}
}
@article{Peng2017,
author = {Peng, Gang and Tang, Songping and Lin, Zhiming and Zhang, Yun},
doi = {10.1109/IAEAC.2017.8054056},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Peng et al. - 2017 - Applications of fuzzy multilayer support vector machines in fault diagnosis and forecast of electric power equipmen.pdf:pdf},
isbn = {9781467389778},
journal = {Proceedings of 2017 IEEE 2nd Advanced Information Technology, Electronic and Automation Control Conference, IAEAC 2017},
keywords = {Diagnosis,Fuzzy logic algorithm,Multilayer,Power equipment,SVM},
pages = {457--461},
title = {{Applications of fuzzy multilayer support vector machines in fault diagnosis and forecast of electric power equipment}},
year = {2017}
}
@article{Allen-Zhu2019,
abstract = {Deep neural networks (DNNs) have demonstrated dominating performance in many fields; since AlexNet, networks used in practice are going wider and deeper. On the theoretical side, a long line of works have been focusing on why we can train neural networks when there is only one hidden layer. The theory of multi-layer networks remains unsettled. In this work, we prove simple algorithms such as stochastic gradient descent (SGD) can find global minima on the training objective of DNNs in polynomial time. We only make two assumptions: the inputs do not degenerate and the network is over-parameterized. The latter means the number of hidden neurons is sufficiently large: polynomial in L, the number of DNN layers and in n, the number of training samples. As concrete examples, starting from randomly initialized weights, we show that SGD attains 100% training accuracy in classification tasks, or minimizes regression loss in linear convergence speed $\epsilon$ e-$\Omega$(T) with running time polynomial in n and L. Our theory applies to the widely-used but non-smooth ReLU activation, and to any smooth and possibly non-convex loss functions. In terms of network architectures, our theory at least applies to fully-connected neural networks, convolutional neural networks (CNN), and residual neural networks (ResNet).},
archivePrefix = {arXiv},
arxivId = {1811.03962},
author = {Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
eprint = {1811.03962},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Allen-Zhu, Li, Song - 2019 - A convergence theory for deep learning via over-parameterization.pdf:pdf},
journal = {36th International Conference on Machine Learning, ICML 2019},
keywords = {convergence,optimization,over,theory},
mendeley-tags = {convergence,optimization,over,theory},
pages = {362--372},
title = {{A convergence theory for deep learning via over-parameterization}},
volume = {2019-June},
year = {2019}
}
@article{Enke2013a,
abstract = {The following paper discusses the use of a hybrid model for the prediction of short-term US interest rates. The model consists of a differential evolution-based fuzzy type-2 clustering with a fuzzy type-2 inference neural network, after input preprocessing with multiple regression analysis. The model was applied to forecast the US 3- Month T-bill rates. Promising model performance was obtained as measured using root mean square error. {\textcopyright} 2013 The Authors. Published by Elsevier B.V.},
author = {Enke, David and Mehdiyev, Nijat},
doi = {10.1016/j.procs.2013.09.248},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Enke, Mehdiyev - 2013 - Type-2 fuzzy clustering and a type-2 fuzzy inference neural network for the prediction of short-term interest ra.pdf:pdf},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {Differential evoultion,Interest rate forecasting,Multiple regression analysis,Type-2 fuzzy systems},
pages = {115--120},
title = {{Type-2 fuzzy clustering and a type-2 fuzzy inference neural network for the prediction of short-term interest rates}},
volume = {20},
year = {2013}
}
@article{Lim2017,
abstract = {Parking is an issue at the forefront of transportation planning in the core of any urban area. As public and private sectors invest in city development, particularly in the high density and mixed-use central business districts, forecasting parking volumes for multiple facilities throughout urban transformation is critical to parking supply decision-making. Most previous studies have limitations that may yield inaccurate predictions and cannot precisely analyze the impact to area parking facilities, due to model simplicity and limited data accessibility. In order to provide accurate estimation with detailed information and account for technological improvements in data availability, this study provides an alternative method by utilizing an assignment model with a generalized cost approach. This enables more detailed information of forecasting parking volumes and assessing parking accessibility with consideration of shared parking and time-of-day distribution of parking demand. A case study was conducted in downtown Knoxville, Tennessee providing a sensitivity analysis for investigating the effects of parameters in the model. The sensitivity analysis includes parking generation rates, walking speed, and cruising time. Additionally, the results of three alternative scenarios are provided to show the advantages of this model to examine the impact of parking facility development on adjacent facilities. Manual adjustments and surveys may be required to apply this model for other cities, but it would provide more useful information for their (policymakers, developers, and planners) decision making.},
author = {Lim, Hyeonsup and Williams, Grant T. and Abdelqader, Dua and Amagliani, Joseph and Ling, Ziwen and Priester, Davis William and Cherry, Christopher R.},
doi = {10.1016/j.trpro.2017.05.360},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lim et al. - 2017 - Alternative Approach for Forecasting Parking Volumes.pdf:pdf},
issn = {23521465},
journal = {Transportation Research Procedia},
keywords = {Cruising,Generalized Cost,Parking Demand,Walking},
pages = {4175--4188},
publisher = {Elsevier B.V.},
title = {{Alternative Approach for Forecasting Parking Volumes}},
url = {http://dx.doi.org/10.1016/j.trpro.2017.05.360},
volume = {25},
year = {2017}
}
@article{Romero2015,
abstract = {While depth tends to improve network performances, it also makes gradient-based training more difficult since deeper networks tend to be more non-linear. The recently proposed knowledge distillation approach is aimed at obtaining small and fast-to-execute models, and it has shown that a student network could imitate the soft output of a larger teacher network or ensemble of networks. In this paper, we extend this idea to allow the training of a student that is deeper and thinner than the teacher, using not only the outputs but also the intermediate representations learned by the teacher as hints to improve the training process and final performance of the student. Because the student intermediate hidden layer will generally be smaller than the teacher's intermediate hidden layer, additional parameters are introduced to map the student hidden layer to the prediction of the teacher hidden layer. This allows one to train deeper students that can generalize better or run faster, a trade-off that is controlled by the chosen student capacity. For example, on CIFAR-10, a deep student network with almost 10.4 times less parameters outperforms a larger, state-of-the-art teacher network.},
archivePrefix = {arXiv},
arxivId = {1412.6550},
author = {Romero, Adriana and Ballas, Nicolas and Kahou, Samira Ebrahimi and Chassang, Antoine and Gatta, Carlo and Bengio, Yoshua},
eprint = {1412.6550},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Romero et al. - 2015 - FitNets Hints for thin deep nets.pdf:pdf},
journal = {3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings},
pages = {1--13},
title = {{FitNets: Hints for thin deep nets}},
year = {2015}
}
@article{Yoosuk2010,
abstract = {The study of solid basic catalyst is a promising route for developing a better understanding and contributes to the development of better heterogeneous catalytic system capable of carrying the transesterification of oils proficiently under mild reaction conditions in short reaction times. This paper reports a simple and flexible method for increasing the activity and improving the properties of calcined natural calcites via a hydration-dehydration approach in order to make them highly suitable for biodiesel production. The ensuing transformations of the calcite during synthesis were monitored by XRD, TPD, BET, and SEM techniques. The characterization results indicate that this synthesis offers a new calcium oxide with less crystallinity. The new CaO has higher surface area and amount of basic sites than CaO generated from the decomposition of calcite. The calcination of calcite changed the pore shape of catalyst but the water treatment did not alter the pore characteristics of CaO. With these characteristics, our CaO exhibits higher catalytic activity than the decomposed calcite as observed from the transesterification of palm olein with methanol. The methyl ester content was enhanced to 93.9. wt.% from 75.5. wt.% of calcined calcite. This present study also provides new fundamental insight into the effect of water on properties and activity of CaO prepared by new hydration and subsequent thermal decomposition method of calcined calcite. {\textcopyright} 2010 Elsevier B.V.},
author = {Yoosuk, Boonyawan and Udomsap, Parncheewa and Puttasawat, Buppa and Krasae, Pawnprapa},
doi = {10.1016/j.cej.2010.05.013},
isbn = {1385-8947},
issn = {13858947},
journal = {Chemical Engineering Journal},
keywords = {CaO,Calcite,Catalyst,Hydration-dehydration,Transesterification},
number = {1},
pages = {135--141},
publisher = {Elsevier B.V.},
title = {{Modification of calcite by hydration-dehydration method for heterogeneous biodiesel production process: The effects of water on properties and activity}},
url = {http://dx.doi.org/10.1016/j.cej.2010.05.013},
volume = {162},
year = {2010}
}
@article{Riyanto2006,
author = {Riyanto, Bambang and Dwiono, Wakhyu},
doi = {10.5614/itbj.sci.2006.38.2.7},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Riyanto, Dwiono - 2006 - Sistem Kendali Fuzzy Bertipe-2 Interval dengan Struktur Adaptif Beracuan Model.pdf:pdf},
issn = {19783043},
journal = {Proc ITB Sains dan Tek},
keywords = {control,control system,interval type-2 fuzzy system,inverted pendulum,model reference adaptive},
number = {2},
pages = {181--200},
title = {{Sistem Kendali Fuzzy Bertipe-2 Interval dengan Struktur Adaptif Beracuan Model}},
volume = {38},
year = {2006}
}
@article{Gul2016,
abstract = {Multi criteria decision making (MCDM) is one of the research areas of operations research and management science which has widely studied by researchers and practitioners. It finds a compromise solution for evaluating and ranking alternatives from the best to the worst under conflicting criteria with respect to decision maker(s) preferences. In a compromise approach, the VlseKriterijumska Optimizacija I Kompromisno Resenje (VIKOR; that means multi-criteria optimization and compromise solution) continues to be applied satisfactorily across different application areas. This paper conducts a state-of-the-art literature review to categorize, analyze and interpret the current research on VIKOR applications. It also discusses the extensions of VIKOR applied in fuzzy environments. A total of 343 papers are classified into 13 different application areas and a number of sub-application areas. Furthermore, all papers are also categorized with respect to publication year, published journal, country of origin, application type (real case study vs empirical study), and version of fuzzy sets used. This comprehensive literature review provides an insight for researchers and practitioners on VIKOR applications in terms of showing current state and potential areas for future attempts to be focused in the future.},
author = {Gul, Muhammet and Celik, Erkan and Aydin, Nezir and {Taskin Gumus}, Alev and Guneri, Ali Fuat},
doi = {10.1016/j.asoc.2016.04.040},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gul et al. - 2016 - A state of the art literature review of VIKOR and its fuzzy extensions on applications.pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {Fuzzy sets,Multi criteria decision making,State-of-the-art review,VIKOR},
pages = {60--89},
publisher = {Elsevier B.V.},
title = {{A state of the art literature review of VIKOR and its fuzzy extensions on applications}},
url = {http://dx.doi.org/10.1016/j.asoc.2016.04.040},
volume = {46},
year = {2016}
}
@article{Li2013a,
abstract = {A sulfonated carbon-based solid acid catalyst was prepared by sulfonating rice husk char with concentrated sulfuric acid. The as-prepared catalyst was characterized using X-ray diffraction, X-ray photoelectron spectroscopy, ultimate analysis, specific surface area analysis, and thermogravimetry-mass spectrometry. The effects of the sulfonation temperature and time on the catalytic performance were investigated using the esterification of oleic acid and methanol as the probe reaction. The effects of the reaction conditions on the esterification catalyzed by sulfonated rice husk char were also studied. The stability of the catalyst was examined. The results showed that 90 °C and 0.25 h were suitable sulfonation temperature and time, respectively. The catalyst prepared under these conditions had an amorphous carbon structure with a sulfonic group concentration of 0.7 mmol/g. It exhibited high catalytic performance. The conversion of oleic acid was 98.7% under the optimal reaction conditions with a catalyst amount of 5%, a methanol to oleic acid molar ratio of 4:1, and a reaction temperature and time of 110 °C and 2 h, respectively. The esterification conversion still reached 96.0% after seven cycles of successive reuse, which indicated that the catalyst stability was excellent.},
author = {Li, Ming and Chen, Dengyu and Zhu, Xifeng},
doi = {10.1016/S1872-2067(12)60634-2},
isbn = {0253-9837},
issn = {18722067},
journal = {Chinese Journal of Catalysis},
number = {9},
pages = {1674--1682},
pmid = {23953130},
title = {{Preparation of solid acid catalyst from rice husk char and its catalytic performance in esterification}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1872206712606342},
volume = {34},
year = {2013}
}
@inproceedings{Ehret2020,
abstract = {While a diverse collection of continual learning (CL) methods has been proposed to prevent catastrophic forgetting, a thorough investigation of their effectiveness for processing sequential data with recurrent neural networks (RNNs) is lacking. Here, we provide the first comprehensive evaluation of established CL methods on a variety of sequential data benchmarks. Specifically, we shed light on the particularities that arise when applying weight-importance methods, such as elastic weight consolidation, to RNNs. In contrast to feedforward networks, RNNs iteratively reuse a shared set of weights and require working memory to process input samples. We show that the performance of weight-importance methods is not directly affected by the length of the processed sequences, but rather by high working memory requirements, which lead to an increased need for stability at the cost of decreased plasticity for learning subsequent tasks. We additionally provide theoretical arguments supporting this interpretation by studying linear RNNs. Our study shows that established CL methods can be successfully ported to the recurrent case, and that a recent regularization approach based on hypernetworks outperforms weight-importance methods, thus emerging as a promising candidate for CL in RNNs. Overall, we provide insights on the differences between CL in feedforward networks and RNNs, while guiding towards effective solutions to tackle CL on sequential data.},
archivePrefix = {arXiv},
arxivId = {2006.12109},
author = {Ehret, Benjamin and Henning, Christian and Cervera, Maria R. and Meulemans, Alexander and von Oswald, Johannes and Grewe, Benjamin F.},
booktitle = {Iclr 2021},
eprint = {2006.12109},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ehret et al. - 2020 - Continual Learning in Recurrent Neural Networks.pdf:pdf},
month = {jun},
number = {2017},
title = {{Continual Learning in Recurrent Neural Networks}},
url = {http://arxiv.org/abs/2003.13947 http://arxiv.org/abs/2006.12109},
year = {2020}
}
@book{Stuart2004,
abstract = {Analytical Techniques in the SciencesThis series of books provides coverage of all of the major analytical techniques and their application in the most important areas of physical, life and materials science. Each text is presented in an open learning/distance learning style, in which the learning objectives are clearly identified. The reader's understanding of the material is constantly evaluated by the use of self-assessment and discussion questions. Series Editor: David J. AndoINFRARED SPECTROSCOPY: FUNDAMENTALS AND APPLICATIONSInfrared spectroscopy is one of the most important and widely used analytical techniques available to scientists working in a whole range of fields. This book aims to provide an introduction to those needing to use infrared spectroscopy for the first time, explaining the fundamental aspects of this technique, how to obtain a spectrum and how to analyse infrared data covering a wide range of applications.This text contains chapters covering the following aspects: The background theory of infrared spectroscopy. Instrumentation and sampling techniques. Spectral analysis. Organic molecules. Inorganic molecules. Polymers. Biological applications. Industrial applications. Suitable questions and problems are included in each chapter to assist in the analysis and interpretation of representative infrared spectra.This book is aimed at undergraduate and graduate chemistry students, as well as researchers in both academia and industry, and should provide a valuable addition to student coursework material and to those companies providing in-house training in the field of infrared spectroscopy.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Stuart, Barbara H},
booktitle = {Methods},
doi = {10.1002/0470011149},
eprint = {arXiv:1011.1669v3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stuart - 2004 - Infrared Spectroscopy Fundamentals and Applications.pdf:pdf},
isbn = {9780470011140},
issn = {1098-6596},
pages = {224},
pmid = {25246403},
title = {{Infrared Spectroscopy: Fundamentals and Applications}},
url = {http://doi.wiley.com/10.1002/0470011149},
volume = {8},
year = {2004}
}
@article{Tepper2015,
abstract = {This paper introduces a simple dynamic model to examine the breakout from a Malthusian economy to a modern growth regime. It identifies several factors that determine the fastest rate at which the population can grow without engendering declining living standards. We then apply the framework to Britain and find a dramatic increase in sustainable population growth at the time of the Industrial Revolution, well before the beginning of modern levels of income growth. The main contributions to the British breakout were technological improvements and structural change away from agricultural production, while coal, capital, and trade played a minor role. In addition to solidifying the link between the Industrial Revolution and rising living standards, this research reconciles the gradualist and limited Crafts-Harley view of the Industrial Revolution with a dramatic and rapid change in Britain's macroeconomic character.},
author = {Tepper, Alexander and Borowiecki, Karol Jan},
doi = {10.1016/j.jmacro.2015.01.006},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tepper, Borowiecki - 2015 - Accounting for breakout in Britain The industrial revolution through a Malthusian lens.pdf:pdf},
issn = {01640704},
journal = {Journal of Macroeconomics},
keywords = {Demographics,Development,Industrial Revolution,Malthusian dynamics,Maximum sustainable population growth},
pages = {219--233},
publisher = {Elsevier Inc.},
title = {{Accounting for breakout in Britain: The industrial revolution through a Malthusian lens}},
url = {http://dx.doi.org/10.1016/j.jmacro.2015.01.006},
volume = {44},
year = {2015}
}
@article{Lau2006,
abstract = {In this paper, we review two recently developed kernel self-organising maps (SOMs) for classification and further establish their link with an energy function. We demonstrate that the kernel SOM can be derived naturally by minimising the energy function, and the resulting kernel SOM unifies the approaches to kernelise the SOM and can be performed entirely in the feature space. Different forms of kernel functions can be readily adopted. Various kernel SOMs, as well as the original SOM, are compared on classifying several benchmark datasets. The performance of the kernel SOMs depends on the choices of kernel functions and their parameters, as well as the ways to classify the neurons. Although the proposed energy based kernel SOM can produce better classification results than other SOMs in some cases, there is no clear evidence showing that the kernel SOMs are always superior to the common SOM. The computational cost to kernelise the SOM, however, increases significantly. {\textcopyright} 2006 Elsevier B.V. All rights reserved.},
author = {Lau, K.W. and Yin, H. and Hubbard, S.},
doi = {10.1016/j.neucom.2005.10.003},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lau, Yin, Hubbard - 2006 - Kernel self-organising maps for classification.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Classification,Kernel methods,Self-organising maps},
month = {oct},
number = {16-18},
pages = {2033--2040},
title = {{Kernel self-organising maps for classification}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0925231205003498},
volume = {69},
year = {2006}
}
@article{Liu2017d,
abstract = {This review is focused on the most recent research on multifunctional shape memory polymer nanocomposites reinforced by various nanoparticles. Different multifunctional shape memory nanocomposites responsive to different kinds of stimulation methods, including thermal responsive, electro-activated, alternating magnetic field responsive, light sensitive and water induced SMPs, are discussed separately. This review offers a comprehensive discussion on the mechanism, advantages and disadvantages of each actuation methods. In addition to presenting the micro- and macro- morphology and mechanical properties of shape memory polymer nanocomposites, this review demonstrates the shape memory performance and the potential applications of multifunctional shape memory polymer nanocomposites under different stimulation methods.},
author = {Liu, Tianzhen and Zhou, Tianyang and Yao, Yongtao and Zhang, Fenghua and Liu, Liwu and Liu, Yanju and Leng, Jinsong},
doi = {10.1016/j.compositesa.2017.04.022},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2017 - Stimulus methods of multi-functional shape memory polymer nanocomposites A review.pdf:pdf},
issn = {1359835X},
journal = {Composites Part A: Applied Science and Manufacturing},
keywords = {Actuation,Multifunctional,Nanocomposites,Shape memory polymer},
pages = {20--30},
publisher = {Elsevier Ltd},
title = {{Stimulus methods of multi-functional shape memory polymer nanocomposites: A review}},
url = {http://dx.doi.org/10.1016/j.compositesa.2017.04.022},
volume = {100},
year = {2017}
}
@article{Sumerling2011,
abstract = {Foresters use light detection and ranging (lidar) data to understand the forest canopy and terrain, which helps them with forest management and operational activities. Combining lidar data with Esri{\textregistered} ArcGIS{\textregistered} helps analysts assess forest health, calculate forest biomass, classify terrain, identify drainage patterns, and plan forest management activities such as fertilization, harvesting programs, development activities, and more. This paper will step through processes to convert lidar data into a format ArcGIS can process, explain methods to interpret the lidar data, and show how ArcGIS can disseminate the data to those who are not geospatial analysts. It will present methods for reading raw classified lidar data and demonstrate methods for ■ Analyzing and validating lidar data with ArcGIS before any extensive processing occurs ■ Storing and managing millions or billions of lidar points within the geodatabase in a seamless dataset, regardless of the number of original lidar files ■ Processing to extract digital elevation models (DEMs) and digital surface models (DSMs) from the lidar data and store them as terrains in a geodatabase or as raster elevation files ■ Extracting vegetation density estimates and tree height estimates from lidar, which aid in growth analysis, fertilization regimes, and logging operations ■ Serving and analyzing large amounts of lidar data as a seamless dataset to geographic information system (GIS) clients In all areas, ArcGIS is a complete system for managing, storing, and analyzing lidar data. Coupling ArcGIS Desktop with ArcGIS Server, the forestry professional is able to access large amounts of lidar data quickly and efficiently without the need to produce additional resultant datasets.},
author = {Sumerling, Gordon},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sumerling - 2011 - Lidar Analysis in ArcGIS10 for forestry applications.pdf:pdf},
journal = {ESRI White Paper},
keywords = {ArcGIS,ArcGIS Server Image extension,Lidar,geodatabase,mosaic dataset,terrains},
number = {January},
pages = {53},
title = {{Lidar Analysis in ArcGIS10 for forestry applications}},
url = {http://www.esri.com/library/whitepapers/pdfs/lidar-analysis-forestry.pdf},
year = {2011}
}
@article{Choi2021,
abstract = {Active learning aims to reduce labeling costs by selecting only the most informative samples on a dataset. Few existing works have addressed active learning for object detection. Most of these methods are based on multiple models or are straightforward extensions of classification methods, hence estimate an image's informativeness using only the classification head. In this paper, we propose a novel deep active learning approach for object detection. Our approach relies on mixture density networks that estimate a probabilistic distribution for each localization and classification head's output. We explicitly estimate the aleatoric and epistemic uncertainty in a single forward pass of a single model. Our method uses a scoring function that aggregates these two types of uncertainties for both heads to obtain every image's informativeness score. We demonstrate the efficacy of our approach in PASCAL VOC and MS-COCO datasets. Our approach outperforms single-model based methods and performs on par with multi-model based methods at a fraction of the computing cost.},
archivePrefix = {arXiv},
arxivId = {2103.16130},
author = {Choi, Jiwoong and Elezi, Ismail and Lee, Hyuk-Jae and Farabet, Clement and Alvarez, Jose M.},
eprint = {2103.16130},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Choi et al. - 2021 - Active Learning for Deep Object Detection via Probabilistic Modeling.pdf:pdf},
keywords = {active learning,object detection,probabilistic},
mendeley-tags = {active learning,object detection,probabilistic},
title = {{Active Learning for Deep Object Detection via Probabilistic Modeling}},
url = {http://arxiv.org/abs/2103.16130},
year = {2021}
}
@article{Fang2021,
abstract = {This paper is concerned with self-supervised learning for small models. The problem is motivated by our empirical studies that while the widely used contrastive self-supervised learning method has shown great progress on large model training, it does not work well for small models. To address this problem, we propose a new learning paradigm, named SElf-SupErvised Distillation (SEED), where we leverage a larger network (as Teacher) to transfer its representational knowledge into a smaller architecture (as Student) in a self-supervised fashion. Instead of directly learning from unlabeled data, we train a student encoder to mimic the similarity score distribution inferred by a teacher over a set of instances. We show that SEED dramatically boosts the performance of small networks on downstream tasks. Compared with self-supervised baselines, SEED improves the top-1 accuracy from 42.2% to 67.6% on EfficientNet-B0 and from 36.3% to 68.2% on MobileNet-v3-Large on the ImageNet-1k dataset.},
archivePrefix = {arXiv},
arxivId = {2101.04731},
author = {Fang, Zhiyuan and Wang, Jianfeng and Wang, Lijuan and Zhang, Lei and Yang, Yezhou and Liu, Zicheng},
eprint = {2101.04731},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fang et al. - 2021 - SEED Self-supervised Distillation For Visual Representation.pdf:pdf},
keywords = {knowledge distillation,self-supervised learning},
mendeley-tags = {knowledge distillation,self-supervised learning},
title = {{SEED: Self-supervised Distillation For Visual Representation}},
url = {http://arxiv.org/abs/2101.04731},
year = {2021}
}
@article{Allen-Zhu2018,
abstract = {The fundamental learning theory behind neural networks remains largely open. What classes of functions can neural networks actually learn? Why doesn't the trained neural networks overfit when the it is overparameterized (namely, having more parameters than statistically needed to overfit training data)? In this work, we prove that overparameterized neural networks can learn some notable concept classes, including two and three-layer networks with fewer parameters and smooth activations. Moreover, the learning can be simply done by SGD (stochastic gradient descent) or its variants in polynomial time using polynomially many samples. The sample complexity can also be almost independent of the number of parameters in the overparameterized network.},
archivePrefix = {arXiv},
arxivId = {1811.04918},
author = {Allen-Zhu, Zeyuan and Li, Yuanzhi and Liang, Yingyu},
eprint = {1811.04918},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Allen-Zhu, Li, Liang - 2018 - Learning and generalization in overparameterized neural networks, going beyond two layers.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {generalization,optimization,overparameterized,theory},
mendeley-tags = {generalization,optimization,overparameterized,theory},
title = {{Learning and generalization in overparameterized neural networks, going beyond two layers}},
year = {2018}
}
@article{Diethe2019,
abstract = {This paper describes a reference architecture for self-maintaining systems that can learn continually, as data arrives. In environments where data evolves, we need architectures that manage Machine Learning (ML) models in production, adapt to shifting data distributions, cope with outliers, retrain when necessary, and adapt to new tasks. This represents continual AutoML or Automatically Adaptive Machine Learning. We describe the challenges and proposes a reference architecture.},
archivePrefix = {arXiv},
arxivId = {1903.05202},
author = {Diethe, Tom and Borchert, Tom and Thereska, Eno and Balle, Borja and Lawrence, Neil},
eprint = {1903.05202},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Diethe et al. - 2019 - Continual Learning in Practice.pdf:pdf},
number = {Nips},
title = {{Continual Learning in Practice}},
url = {http://arxiv.org/abs/1903.05202},
year = {2019}
}
@article{Wang2020,
abstract = {In lifelong learning, we wish to maintain and update a model (e.g., a neural network classifier) in the presence of new classification tasks that arrive sequentially. In this paper, we propose a learn-prune-share (LPS) algorithm which addresses the challenges of catastrophic forgetting, parsimony, and knowledge reuse simultaneously. LPS splits the network into task-specific partitions via an ADMM-based pruning strategy. This leads to no forgetting, while maintaining parsimony. Moreover, LPS integrates a novel selective knowledge sharing scheme into this ADMM optimization framework. This enables adaptive knowledge sharing in an end-to-end fashion. Comprehensive experimental results on two lifelong learning benchmark datasets and a challenging real-world radio frequency fingerprinting dataset are provided to demonstrate the effectiveness of our approach. Our experiments show that LPS consistently outperforms multiple state-of-the-art competitors.},
annote = {
},
archivePrefix = {arXiv},
arxivId = {2012.06956},
author = {Wang, Zifeng and Jian, Tong and Chowdhury, Kaushik and Wang, Yanzhi and Dy, Jennifer and Ioannidis, Stratis},
eprint = {2012.06956},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2020 - Learn-Prune-Share for Lifelong Learning.pdf:pdf},
issn = {23318422},
keywords = {architectural,continual learning,pruning,sparse network,sparsity},
mendeley-tags = {architectural,continual learning,pruning,sparse network,sparsity},
title = {{Learn-Prune-Share for Lifelong Learning}},
url = {http://arxiv.org/abs/2012.06956 https://github.com/neu-spiral/LPSforLifelong},
year = {2020}
}
@article{Legg2007,
abstract = {A fundamental problem in artificial intelligence is that nobody really knows what intelligence is. The problem is especially acute when we need to consider artificial systems which are significantly different to humans. In this paper we approach this problem in the following way: we take a number of well known informal definitions of human intelligence that have been given by experts, and extract their essential features. These are then mathematically formalised to produce a general measure of intelligence for arbitrary machines. We believe that this equation formally captures the concept of machine intelligence in the broadest reasonable sense. We then show how this formal definition is related to the theory of universal optimal learning agents. Finally, we survey the many other tests and definitions of intelligence that have been proposed for machines. {\textcopyright} 2007 Springer Science+Business Media B.V.},
archivePrefix = {arXiv},
arxivId = {0712.3329},
author = {Legg, Shane and Hutter, Marcus},
doi = {10.1007/s11023-007-9079-x},
eprint = {0712.3329},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Legg, Hutter - 2007 - Universal intelligence A definition of machine intelligence.pdf:pdf},
issn = {09246495},
journal = {Minds and Machines},
keywords = {AIXI,Complexity theory,Definitions,Intelligence,Intelligence tests,Measures,Theoretical foundations,Turing test},
number = {4},
pages = {391--444},
title = {{Universal intelligence: A definition of machine intelligence}},
volume = {17},
year = {2007}
}
@article{Joseph2020,
abstract = {The ability to continuously learn and adapt itself to new tasks, without losing grasp of already acquired knowledge is a hallmark of biological learning systems, which current deep learning systems fall short of. In this work, we present a novel methodology for continual learning called MERLIN: Meta-Consolidation for Continual Learning. We assume that weights of a neural network $\boldsymbol \psi$, for solving task $\boldsymbol t$, come from a meta-distribution $p(\boldsymbol{\psi|t})$. This meta-distribution is learned and consolidated incrementally. We operate in the challenging online continual learning setting, where a data point is seen by the model only once. Our experiments with continual learning benchmarks of MNIST, CIFAR-10, CIFAR-100 and Mini-ImageNet datasets show consistent improvement over five baselines, including a recent state-of-the-art, corroborating the promise of MERLIN.},
archivePrefix = {arXiv},
arxivId = {2010.00352},
author = {Joseph, K J and Balasubramanian, Vineeth N},
eprint = {2010.00352},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Joseph, Balasubramanian - 2020 - Meta-Consolidation for Continual Learning.pdf:pdf},
journal = {Neural Information Processing Systems (NeurIPS)},
keywords = {continual learning,meta-learning},
mendeley-tags = {continual learning,meta-learning},
month = {oct},
title = {{Meta-Consolidation for Continual Learning}},
url = {http://arxiv.org/abs/2010.00352},
year = {2020}
}
@article{Elhoseiny2019,
abstract = {Zero-shot learning (ZSL) aims at understanding unseen categories with no training examples from class-level descriptions. To improve the discriminative power of zero-shot learning, we model the visual learning process of unseen categories with an inspiration from the psychology of human creativity for producing novel art. We relate ZSL to human creativity by observing that zero-shot learning is about recognizing the unseen and creativity is about creating a likable unseen. We introduce a learning signal inspired by creativity literature that explores the unseen space with hallucinated class-descriptions and encourages careful deviation of their visual feature generations from seen classes while allowing knowledge transfer from seen to unseen classes. Empirically, we show consistent improvement over the state of the art of several percents on the largest available benchmarks on the challenging task or generalized ZSL from a noisy text that we focus on, using the CUB and NABirds datasets. We also show the advantage of our approach on Attribute-based ZSL on three additional datasets (AwA2, aPY, and SUN). Code is available at https://github.com/mhelhoseiny/CIZSL.},
archivePrefix = {arXiv},
arxivId = {2101.00173},
author = {Elhoseiny, Mohamed and Elfeki, Mohamed},
eprint = {2101.00173},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elhoseiny, Elfeki - 2019 - Creativity Inspired Zero-Shot Learning.pdf:pdf},
journal = {arXiv},
keywords = {creativity-inspired,zero-shot learning},
mendeley-tags = {creativity-inspired,zero-shot learning},
title = {{Creativity Inspired Zero-Shot Learning}},
url = {https://github.com/Elhoseiny-VisionCAIR-Lab/CIZSL.v2},
year = {2019}
}
@article{Zaman2014,
author = {Zaman, Muhammad},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zaman - 2014 - Using Particle Swarm Optimization and Genetic Algorithm.pdf:pdf},
isbn = {9781479951512},
keywords = {- pso,anjiang,ga,hydropower generation,optimization,pso-ga,xin},
pages = {534--539},
title = {{Using Particle Swarm Optimization and Genetic Algorithm}},
volume = {limi},
year = {2014}
}
@article{Li2010,
abstract = {Many recent research studies have proposed stem cell therapy as a treatment for cancer, spinal cord injuries, brain damage, cardiovascular disease, and other conditions. Some of these experimental therapies have been tested in small animals and, in rare cases, in humans. Medical researchers anticipate extensive clinical applications of stem cell therapy in the future. The lack of basic knowledge concerning basic stem cell biology-survival, migration, differentiation, integration in a real time manner when transplanted into damaged CNS remains an absolute bottleneck for attempt to design stem cell therapies for CNS diseases. A major challenge to the development of clinical applied stem cell therapy in medical practice remains the lack of efficient stem cell tracking methods. As a result, the fate of the vast majority of stem cells transplanted in the human central nervous system (CNS), particularly in the detrimental effects, remains unknown. The paucity of knowledge concerning basic stem cell biology--survival, migration, differentiation, integration in real-time when transplanted into damaged CNS remains a bottleneck in the attempt to design stem cell therapies for CNS diseases. Even though excellent histological techniques remain as the gold standard, no good in vivo techniques are currently available to assess the transplanted graft for migration, differentiation, or survival. To address these issues, herein we propose strategies to investigate the lineage fate determination of derived human embryonic stem cells (hESC) transplanted in vivo into the CNS. Here, we describe a comprehensive biological Global Positioning System (bGPS) to track transplanted stem cells. But, first, we review, four currently used standard methods for tracking stem cells in vivo: magnetic resonance imaging (MRI), bioluminescence imaging (BLI), positron emission tomography (PET) imaging and fluorescence imaging (FLI) with quantum dots. We summarize these modalities and propose criteria that can be employed to rank the practical usefulness for specific applications. Based on the results of this review, we argue that additional qualities are still needed to advance these modalities toward clinical applications. We then discuss an ideal procedure for labeling and tracking stem cells in vivo, finally, we present a novel imaging system based on our experiments.},
author = {Li, Shengwen Calvin and Tachiki, Lisa May Ling and Luo, Jane and Dethlefs, Brent A. and Chen, Zhongping and Loudon, William G.},
doi = {10.1007/s12015-010-9130-9},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2010 - A biological global positioning system Considerations for tracking stem cell behaviors in the whole body.pdf:pdf},
isbn = {1201501091309},
issn = {15508943},
journal = {Stem Cell Reviews and Reports},
keywords = {Biological Global Positioning System (bGPS),Stem cells,Tracking system},
number = {2},
pages = {317--333},
pmid = {20237964},
title = {{A biological global positioning system: Considerations for tracking stem cell behaviors in the whole body}},
volume = {6},
year = {2010}
}
@book{Safranski2017,
author = {Safranski, David L. and Griffis, Jack C.},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Safranski, Griffis - 2017 - Shape-memory polymer device design.pdf:pdf},
isbn = {9780323377973},
title = {{Shape-memory polymer device design}},
year = {2017}
}
@article{The,
author = {The, Introduction and Horiba, The and Yvon, Jobin and Fluorolog, The},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/The et al. - Unknown - F L - 1 2 Endogenous Skin Fluorescence In Vivo on Human Skin.pdf:pdf},
title = {{F L - 1 2 Endogenous Skin Fluorescence In Vivo on Human Skin}}
}
@article{Piper2013,
abstract = {Dynamic near-infrared fluorescence (DNIF) whole-body imaging of small animals has become a popular tool in experimental biomedical research. In humans, however, the field of view has been limited to body parts, such as rheumatoid hands, diabetic feet or sentinel lymph nodes. Here we present a new whole-body DNIF-system suitable for adult subjects. We explored whether this system (i) allows dynamic whole-body fluorescence imaging and (ii) can detect modulations in skin perfusion. The non-specific fluorescent probe indocyanine green (ICG) was injected intravenously into two subjects, and fluorescence images were obtained at 5 Hz. The in- and out-flow kinetics of ICG have been shown to correlate with tissue perfusion. To validate the system, skin perfusion was modulated by warming and cooling distinct areas on the chest and the abdomen. Movies of fluorescence images show a bolus passage first in the face, then in the chest, abdomen and finally in the periphery ($\sim$10, 15, 20 and 30 seconds, respectively). When skin perfusion is augmented by warming, bolus arrives about 5 seconds earlier than when the skin is cooled and perfusion decreased. Calculating bolus arrival times and spatial fitting of basis time courses extracted from different regions of interest allowed a mapping of local differences in subcutaneous skin perfusion. This experiment is the first to demonstrate the feasibility of whole-body dynamic fluorescence imaging in humans. Since the whole-body approach demonstrates sensitivity to circumscribed alterations in skinperfusion, it may be used to target autonomous changes in polyneuropathy and to screen for peripheral vascular diseases.},
author = {Piper, Sophie K. and Habermehl, Christina and Schmitz, Christoph H. and Kuebler, Wolfgang M. and Obrig, Hellmuth and Steinbrink, Jens and Mehnert, Jan},
doi = {10.1371/journal.pone.0083749},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Piper et al. - 2013 - Towards whole-body fluorescence imaging in humans.pdf:pdf},
isbn = {1932-6203 (Electronic)\r1932-6203 (Linking)},
issn = {19326203},
journal = {PLoS ONE},
number = {12},
pages = {1--8},
pmid = {24391820},
title = {{Towards whole-body fluorescence imaging in humans}},
volume = {8},
year = {2013}
}
@article{Melin2014,
abstract = {This paper describes an optimization method based on genetic algorithms for designing ensemble neural networks with fuzzy response aggregation to forecast complex time series. The time series that was considered in this paper, to compare the hybrid approach with traditional methods, is the Dow Jones data, and the results are presented for the optimization of the structure of the ensemble neural network with type-1 and type-2 fuzzy response integration. Simulation results show that the ensemble approach produces 99% prediction accuracy for the Dow Jones time series and that using type-2 fuzzy logic improves the performance of the predictor. {\textcopyright} 2014 TSI{\textregistered} Press.},
author = {Melin, Patricia and Pulido, Martha},
doi = {10.1080/10798587.2014.893047},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Melin, Pulido - 2014 - Optimization of Ensemble Neural Networks with Type-2 Fuzzy Integration of Responses for the Dow Jones Time Series.pdf:pdf},
isbn = {9781467323383},
issn = {2326005X},
journal = {Intelligent Automation and Soft Computing},
keywords = {Ensemble Neural Networks,Genetic Algorithms,Optimization,Time Series Prediction},
number = {3},
pages = {403--418},
title = {{Optimization of Ensemble Neural Networks with Type-2 Fuzzy Integration of Responses for the Dow Jones Time Series Prediction}},
volume = {20},
year = {2014}
}
@article{Brzustowski1987,
abstract = {This text is a reduced English version of the material prepared for my combustion class at the RWTH Aachen Technical University. It is intended as an introduction to the fundamentals of com- bustion science with the aim to supply the basic notions and equations formore detailed numerical investigations. With modern computational tools and facilities numerical calculations with large codes aiming to predict the performance of combustion devices such as furnaces, reciprocative engines and gas turbines are feasible. Whether they will partly or fully replace experimental in- vestigations will largely depend on the reliability of the combustion models used.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Brzustowski, T.A.},
doi = {10.1016/0010-2180(87)90105-2},
eprint = {arXiv:1011.1669v3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brzustowski - 1987 - Combustion theory.pdf:pdf},
isbn = {9780201407778},
issn = {00102180},
journal = {Combustion and Flame},
number = {3},
pages = {273--275},
pmid = {184595},
title = {{Combustion theory}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0010218087901052},
volume = {67},
year = {1987}
}
@article{Taufiq-Yap2014,
abstract = {Heterogeneous solid mixed oxide (CaO-La2O3) catalysts with different molar ratios of calcium to lanthanum (Ca-to-La) were synthesized by co-precipitation method. The synthesized solid CaO-La2O3mixed metal oxide catalysts were utilized in transesterification of Jatropha curcus oil as feedstock to produce biodiesel. Under the optimized conditions at 65 °C, 4% catalyst dose with 24:1 MeOH to Jatropha oil molar ratio, the transesterification reaction exhibited 86.51% of biodiesel yield. The prepared catalysts were characterized using various techniques such as X-ray diffraction (XRD), nitrogen sorption with Brunauer-Emmer-Teller (BET) method, temperature-programmed desorption of CO2(CO2-TPD) and scanning electron microscopy (SEM). Influence of Ca-to-La atomic ratio in the mixed metal oxide catalyst, catalyst amount, methanol to oil molar ratio, reaction time, different oils on the fatty acid methyl ester (FAME) yield were appraised. Different catalyst regeneration procedures were also performed to investigate the reusability of the CaO-La2O3catalyst.},
author = {Taufiq-Yap, Yun Hin and Teo, Siow Hwa and Rashid, Umer and Islam, Aminul and Hussien, Mohd Zobir and Lee, Keat Teong},
doi = {10.1016/j.enconman.2013.12.075},
isbn = {0196-8904},
issn = {01968904},
journal = {Energy Conversion and Management},
keywords = {Biodiesel production Jatropha curcas Heterogeneous},
pages = {1290--1296},
publisher = {Elsevier Ltd},
title = {{Transesterification of Jatropha curcas crude oil to biodiesel on calcium lanthanum mixed oxide catalyst: Effect of stoichiometric composition}},
url = {http://dx.doi.org/10.1016/j.enconman.2013.12.075},
volume = {88},
year = {2014}
}
@article{Shaifee2017,
abstract = {Object detection is considered one of the most challenging problemsin this field of computer vision, as it involves the combinationof object classification and object localization within a scene. Recently,deep neural networks (DNNs) have been demonstrated toachieve superior object detection performance compared to otherapproaches, with YOLOv2 (an improved You Only Look Once model)being one of the state-of-the-art in DNN-based object detectionmethods in terms of both speed and accuracy. Although YOLOv2can achieve real-time performance on a powerful GPU, it still remainsvery challenging for leveraging this approach for real-timeobject detection in video on embedded computing devices withlimited computational power and limited memory. In this paper,we propose a new framework called Fast YOLO, a fast You OnlyLook Once framework which accelerates YOLOv2 to be able toperform object detection in video on embedded devices in a realtimemanner. First, we leverage the evolutionary deep intelligenceframework to evolve the YOLOv2 network architecture and producean optimized architecture (referred to as O-YOLOv2 here) that has2.8X fewer parameters with just a 2% IOU drop. To further reducepower consumption on embedded devices while maintaining performance,a motion-adaptive inference method is introduced intothe proposed Fast YOLO framework to reduce the frequency ofdeep inference with O-YOLOv2 based on temporal motion characteristics.Experimental results show that the proposed Fast YOLOframework can reduce the number of deep inferences by an averageof 38.13%, and an average speedup of 3.3X for objectiondetection in video compared to the original YOLOv2, leading FastYOLO to run an average of 18FPS on a Nvidia Jetson TX1 embeddedsystem.},
archivePrefix = {arXiv},
arxivId = {arXiv:1709.05943v1},
author = {Shaifee, Mohammad Javad and Chywl, Brendan and Li, Francis and Wong, Alexander},
doi = {10.15353/vsnl.v3i1.171},
eprint = {arXiv:1709.05943v1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shaifee et al. - 2017 - Fast YOLO A Fast You Only Look Once System for Real-time Embedded Object Detection in Video.pdf:pdf},
journal = {Journal of Computational Vision and Imaging Systems},
number = {1},
title = {{Fast YOLO: A Fast You Only Look Once System for Real-time Embedded Object Detection in Video}},
volume = {3},
year = {2017}
}
@inproceedings{Michieli2019,
abstract = {Deep learning architectures exhibit a critical drop of performance due to catastrophic forgetting when they are required to incrementally learn new tasks. Contemporary incremental learning frameworks focus on image classification and object detection while in this work we formally introduce the incremental learning problem for semantic segmentation in which a pixel-wise labeling is considered. To tackle this task we propose to distill the knowledge of the previous model to retain the information about previously learned classes, whilst updating the current model to learn the new ones. We propose various approaches working both on the output logits and on intermediate features. In opposition to some recent frameworks, we do not store any image from previously learned classes and only the last model is needed to preserve high accuracy on these classes. The experimental evaluation on the Pascal VOC2012 dataset shows the effectiveness of the proposed approaches.},
archivePrefix = {arXiv},
arxivId = {1907.13372},
author = {Michieli, Umberto and Zanuttigh, Pietro},
booktitle = {2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)},
doi = {10.1109/ICCVW.2019.00400},
eprint = {1907.13372},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Michieli, Zanuttigh - 2019 - Incremental Learning Techniques for Semantic Segmentation.pdf:pdf},
isbn = {978-1-7281-5023-9},
issn = {23318422},
keywords = {continual learning,incremental learning,semantic segmentation},
mendeley-tags = {continual learning,incremental learning,semantic segmentation},
month = {oct},
pages = {3205--3212},
publisher = {IEEE},
title = {{Incremental Learning Techniques for Semantic Segmentation}},
url = {https://ieeexplore.ieee.org/document/9022296/},
year = {2019}
}
@article{Ying2017,
abstract = {Magneto-rheological visco-elastomer (MRVE) as a new smart material developed in recent years has several significant advantages over magneto-rheological liquid. The adjustability of structural dynamics to random environmental excitations is required in vibration control. MRVE can supply considerably adjustable damping and stiffness for structures, and the adjustment of dynamic properties is achieved only by applied magnetic fields with changeless structure design. Increasing researches on MRVE dynamic properties, modeling, and vibration control application are presented. Recent advances in MRVE dynamic properties and structural vibration control application including composite structural vibration mitigation under uniform magnetic fields, vibration response characteristics improvement through harmonic parameter distribution, and optimal bounded parametric control design based on the dynamical programming principle are reviewed. Relevant main methods and results introduced are beneficial to understanding and researches on MRVE application and development.},
author = {Ying, Zuguang and Ni, Yiqing},
doi = {10.1016/j.taml.2017.01.003},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ying, Ni - 2017 - Advances in structural vibration control application of magneto-rheological visco-elastomer.pdf:pdf},
issn = {20950349},
journal = {Theoretical and Applied Mechanics Letters},
keywords = {Controllable sandwich structures,Magneto-rheological visco-elastomer,Nonlinear stochastic vibration,Optimal control,Periodic parameter distribution},
number = {2},
pages = {61--66},
publisher = {Elsevier Ltd},
title = {{Advances in structural vibration control application of magneto-rheological visco-elastomer}},
url = {http://dx.doi.org/10.1016/j.taml.2017.01.003},
volume = {7},
year = {2017}
}
@article{Sadaei2017,
abstract = {Seasonal Auto Regressive Fractionally Integrated Moving Average (SARFIMA) is a well-known model for forecasting of seasonal time series that follow a long memory process. However, to better boost the accuracy of forecasts inside such data for nonlinear problem, in this study, a combination of Fuzzy Time Series (FTS) with SARFIMA is proposed. To build the proposed model, certain parameters requires to be estimated. Therefore, a reliable Evolutionary Algorithm namely Particle Swarm Optimization (PSO) is employed. As a case study, a seasonal long memory time series, i.e., short term load consumption historical data, is selected. In fact, Short Term Load Forecasting (STLF) plays a key role in energy management systems (EMS) and in the decision making process of every power supply organization. In order to evaluate the proposed method, some experiments, using eight datasets of half-hourly load data from England and France for the year 2005 and four data sets of hourly load data from Malaysia for the year 2007, are designed. Although the focus of this research is STLF, six other seasonal long memory time series from several interesting case studies are employed to better evaluate the performance of the proposed method. The results are compared with some novel FTS methods and new state-of-the-art forecasting methods. The analysis of the results indicates that the proposed method presents higher accuracy than its counterparts, representing an efficient hybrid method for load forecasting problems.},
author = {Sadaei, Hossein Javedani and Guimar{\"{i}}¿½es, Frederico Gadelha and {Jos{\"{i}}¿½ da Silva}, Cidiney and Lee, Muhammad Hisyam and Eslami, Tayyebeh},
doi = {10.1016/j.ijar.2017.01.006},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sadaei et al. - 2017 - Short-term load forecasting method based on fuzzy time series, seasonality and long memory process.pdf:pdf},
issn = {0888613X},
journal = {International Journal of Approximate Reasoning},
keywords = {Fuzzy time series,Particle swarm optimization,SARFIMA,Short Term Load Forecasting (STLF)},
pages = {196--217},
publisher = {Elsevier Inc.},
title = {{Short-term load forecasting method based on fuzzy time series, seasonality and long memory process}},
url = {http://dx.doi.org/10.1016/j.ijar.2017.01.006},
volume = {83},
year = {2017}
}
@article{Phung2016,
abstract = {Automatic detection of the pedestrian lane in a scene is an important task in assistive and autonomous navigation. This paper presents a vision-based algorithm for pedestrian lane detection in unstructured scenes, where lanes vary significantly in color, texture, and shape and are not indicated by any painted markers. In the proposed method, a lane appearance model is constructed adaptively from a sample image region, which is identified automatically from the image vanishing point. This paper also introduces a fast and robust vanishing point estimation method based on the color tensor and dominant orientations of color edge pixels. The proposed pedestrian lane detection method is evaluated on a new benchmark dataset that contains images from various indoor and outdoor scenes with different types of unmarked lanes. Experimental results are presented which demonstrate its efficiency and robustness in comparison with several existing methods.},
author = {Phung, Son Lam and Le, Manh Cuong and Bouzerdoum, Abdesselam},
doi = {10.1016/j.cviu.2016.01.011},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Phung, Le, Bouzerdoum - 2016 - Pedestrian lane detection in unstructured scenes for assistive navigation.pdf:pdf},
isbn = {9781479954094},
issn = {1090235X},
journal = {Computer Vision and Image Understanding},
keywords = {Assistive and autonomous navigation,Benchmark dataset,Pedestrian lane detection,Vanishing point estimation},
pages = {186--196},
publisher = {Elsevier Inc.},
title = {{Pedestrian lane detection in unstructured scenes for assistive navigation}},
volume = {149},
year = {2016}
}
@article{Parker2009a,
abstract = {Drawing on evidence from the United Kingdom and elsewhere in Europe, this paper explores how people have responded to flood warning information and how these responses impact upon the effectiveness of a flood warning through saving lives and injuries, and reducing economic damages. Methods of flood warning that the public rely upon are discussed alongside empirical evidence of how flood victims prepare for, and respond to, flood warnings in rapid to medium-onset floods. The paper investigates why some members of the public fail to act appropriately, or most effectively, to flood warning information, touching on ideas of a lack of understanding, mistrust in authority and a lack of ownership of flood reducing actions. The paper examines the styles of public learning about flood warning response which might be most appropriate and effective, and how recent positive steps to increase the public's understanding of effective response might be further enhanced in the United Kingdom.},
author = {Parker, D J and Priest, S J and Tapsell, S M},
doi = {10.1002/met},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Parker, Priest, Tapsell - 2009 - Understanding and enhancing the public ' s behavioural response to flood warning information.pdf:pdf},
isbn = {1469-8080},
issn = {13504827},
journal = {Meteorological Applications},
keywords = {accepted 26 november 2008,behavioural response,effective response,flood warning,public understanding,received 24 october 2008,revised 21 november 2008,styles of learning},
number = {January},
pages = {103--114},
title = {{Understanding and enhancing the public ' s behavioural response to flood warning information}},
volume = {114},
year = {2009}
}
@article{Luo2018,
abstract = {As the internet's footprint continues to expand, cybersecurity is becoming a major concern for both governments and the private sector. One such cybersecurity issue relates to data integrity attacks. This paper focuses on the power industry, where the forecasting processes rely heavily on the quality of the data. Data integrity attacks are expected to harm the performances of forecasting systems, which will have a major impact on both the financial bottom line of power companies and the resilience of power grids. This paper reveals the effect of data integrity attacks on the accuracy of four representative load forecasting models (multiple linear regression, support vector regression, artificial neural networks, and fuzzy interaction regression). We begin by simulating some data integrity attacks through the random injection of some multipliers that follow a normal or uniform distribution into the load series. Then, the four aforementioned load forecasting models are used to generate one-year-ahead ex post point forecasts in order to provide a comparison of their forecast errors. The results show that the support vector regression model is most robust, followed closely by the multiple linear regression model, while the fuzzy interaction regression model is the least robust of the four. Nevertheless, all four models fail to provide satisfying forecasts when the scale of the data integrity attacks becomes large. This presents a serious challenge to both load forecasters and the broader forecasting community: the generation of accurate forecasts under data integrity attacks. We construct our case study using the publicly-available data from Global Energy Forecasting Competition 2012. At the end, we also offer an overview of potential research topics for future studies.},
author = {Luo, Jian and Hong, Tao and Fang, Shu Cherng},
doi = {10.1016/j.ijforecast.2017.08.004},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Luo, Hong, Fang - 2018 - Benchmarking robustness of load forecasting models under data integrity attacks.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Cybersecurity,Data integrity attack,Electric load forecasting,Fuzzy regression,Linear regression,Neural network,Support vector regression},
number = {1},
pages = {89--104},
publisher = {Elsevier B.V.},
title = {{Benchmarking robustness of load forecasting models under data integrity attacks}},
url = {http://dx.doi.org/10.1016/j.ijforecast.2017.08.004},
volume = {34},
year = {2018}
}
@article{Taufiq-Yap2009,
abstract = {Heterogeneous catalysts are promising for the transesterification reaction of vegetable oils to produce biodiesel. Unlike homogeneous, heterogeneous catalysts are environmentally benign and could be operated in continuous processes. Moreover they can be reused and regenerated. However a high molar ratio of alcohol to oil, large amount of catalyst and high temperature and pressure are required when utilizing heterogeneous catalyst to produce biodiesel. In this paper, the catalytic activity of several solid base and acid catalysts, particularly metal oxides and supported metal oxides, was reviewed. Solid acid catalysts were able to do transesterification and esterification reactions simultaneously and convert oils with high amount of FFA (Free Fatty Acids). However, the reaction rate in the presence of solid base catalysts was faster. The catalyst efficiency depended on several factors such as specific surface area, pore size, pore volume and active site concentration. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
author = {Taufiq-Yap, Yun Hin and Teo, Siow Hwa and Rashid, Umer and Islam, Aminul and Hussien, Mohd Zobir and Lee, Keat Teong and Zabeti, Masoud and {Wan Daud}, Wan Mohd Ashri and Aroua, Mohamed Kheireddine},
doi = {10.1016/j.fuproc.2009.03.010},
isbn = {0378-3820},
issn = {03783820},
journal = {Fuel Processing Technology},
keywords = {Biodiesel,Biodiesel production Jatropha curcas Heterogeneous,Catalyst activity,Catalyst support,Heterogeneous catalyst,Transesterification},
number = {6},
pages = {770--777},
pmid = {20362044},
publisher = {Elsevier B.V.},
title = {{Activity of solid catalysts for biodiesel production: A review}},
url = {http://dx.doi.org/10.1016/j.fuproc.2009.03.010 http://dx.doi.org/10.1016/j.enconman.2013.12.075},
volume = {88},
year = {2009}
}
@article{Bentayeb2006,
author = {Bentayeb, Abdelmadjid and Maamri, Nezha and Trigeassou, Jean Claude},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bentayeb, Maamri, Trigeassou - 2006 - Design of PID controllers for delayed MIMO plants using moments based approach.pdf:pdf},
issn = {13353632},
journal = {Journal of Electrical Engineering},
keywords = {Delay,Moments,PID control,Reference model},
number = {6},
pages = {318--328},
title = {{Design of PID controllers for delayed MIMO plants using moments based approach}},
volume = {57},
year = {2006}
}
@article{Qi2020,
abstract = {Initialization, normalization, and skip connections are believed to be three indispensable techniques for training very deep convolutional neural networks and obtaining state-of-the-art performance. This paper shows that deep vanilla ConvNets without normalization nor skip connections can also be trained to achieve surprisingly good performance on standard image recognition benchmarks. This is achieved by enforcing the convolution kernels to be near isometric during initialization and training, as well as by using a variant of ReLU that is shifted towards being isometric. Further experiments show that if combined with skip connections, such near isometric networks can achieve performances on par with (for ImageNet) and better than (for COCO) the standard ResNet, even without normalization at all. Our code is available at https://github.com/HaozhiQi/ISONet.},
archivePrefix = {arXiv},
arxivId = {2006.16992},
author = {Qi, Haozhi and You, Chong and Wang, Xiaolong and Ma, Yi and Malik, Jitendra},
eprint = {2006.16992},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qi et al. - 2020 - Deep isometric learning for visual recognition.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {architecture,backbone,deep learning,isometric},
mendeley-tags = {architecture,backbone,deep learning,isometric},
title = {{Deep isometric learning for visual recognition}},
url = {https://github.com/HaozhiQi/ISONet},
year = {2020}
}
@article{Han2015,
abstract = {Neural networks are both computationally intensive and memory intensive, making them difficult to deploy on embedded systems. Also, conventional networks fix the architecture before training starts; as a result, training cannot improve the architecture. To address these limitations, we describe a method to reduce the storage and computation required by neural networks by an order of magnitude without affecting their accuracy by learning only the important connections. Our method prunes redundant connections using a three-step method. First, we train the network to learn which connections are important. Next, we prune the unimportant connections. Finally, we retrain the network to fine tune the weights of the remaining connections. On the ImageNet dataset, our method reduced the number of parameters of AlexNet by a factor of 9×, from 61 million to 6.7 million, without incurring accuracy loss. Similar experiments with VGG-16 found that the total number of parameters can be reduced by 13×, from 138 million to 10.3 million, again with no loss of accuracy.},
archivePrefix = {arXiv},
arxivId = {1506.02626},
author = {Han, Song and Pool, Jeff and Tran, John and Dally, William J.},
eprint = {1506.02626},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Han et al. - 2015 - Learning both weights and connections for efficient neural networks.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {1135--1143},
title = {{Learning both weights and connections for efficient neural networks}},
volume = {2015-Janua},
year = {2015}
}
@article{Ryou2019,
abstract = {We propose a novel loss function that dynamically re-scales the cross entropy based on prediction difficulty regarding a sample. Deep neural network architectures in image classification tasks struggle to disambiguate visually similar objects. Likewise, in human pose estimation symmetric body parts often confuse the network with assigning indiscriminative scores to them. This is due to the output prediction, in which only the highest confidence label is selected without taking into consideration a measure of uncertainty. In this work, we define the prediction difficulty as a relative property coming from the confidence score gap between positive and negative labels. More precisely, the proposed loss function penalizes the network to avoid the score of a false prediction being significant. To demonstrate the efficacy of our loss function, we evaluate it on two different domains: Image classification and human pose estimation. We find improvements in both applications by achieving higher accuracy compared to the baseline methods.},
archivePrefix = {arXiv},
arxivId = {1909.11155},
author = {Ryou, Serim and Jeong, Seong Gyun and Perona, Pietro},
doi = {10.1109/ICCV.2019.00609},
eprint = {1909.11155},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ryou, Jeong, Perona - 2019 - Anchor loss Modulating loss scale based on prediction difficulty.pdf:pdf},
isbn = {9781728148038},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {5991--6000},
title = {{Anchor loss: Modulating loss scale based on prediction difficulty}},
url = {https://github.com/slryou41/AnchorLoss},
volume = {2019-Octob},
year = {2019}
}
@article{Kouvaros2016,
abstract = {We study the problem of verifying role-based multi-agent systems, where the number of components cannot be determined at design time. We give a semantics that captures parameterised, generic multi-agent systems and identify three notable classes that represent different ways in which the agents may interact among themselves and with the environment. While the verification problem is undecidable in general we put forward cutoff procedures for the classes identified. The methodology is based on the existence of a notion of simulation between the templates for the agents and the template for the environment in the system. We show that the cutoff identification procedures as well as the general algorithms that we propose are sound; for one class we show the decidability of the verification problem and present a complete cutoff procedure. We report experimental results obtained on MCMAS-P, a novel model checker implementing the parameterised model checking methodologies here devised.},
author = {Kouvaros, Panagiotis and Lomuscio, Alessio},
doi = {10.1016/j.artint.2016.01.008},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kouvaros, Lomuscio - 2016 - Parameterised verification for multi-agent systems.pdf:pdf},
isbn = {0004-3702},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {Cutoffs,Multi-agent systems,Parameterised verification,Validation},
pages = {152--189},
publisher = {Elsevier B.V.},
title = {{Parameterised verification for multi-agent systems}},
url = {http://dx.doi.org/10.1016/j.artint.2016.01.008},
volume = {234},
year = {2016}
}
@article{Castro2016,
abstract = {A method for Higher Order polynomial Sugeno Fuzzy Inference Systems formation is presented. Compared to other existing Higher Order Sugeno implementations, it uses fewer parameters; and compared to Zero and 1st Order Sugeno Fuzzy Systems it has overall improved model performance. While best models are not always obtained via a Higher Order representation, in our proposed method it is possible to choose the polynomial Order which best fits the desired data. Its input is a previously established model found by a clustering algorithm (subtractive algorithm in this case). Afterward, parameters of all Higher Order polynomials are adjusted using Recursive Least Square algorithm. For experimental validation, multiple benchmark datasets are tested using Hold-Out and K-fold validation as well as data forecasting. Various performance measures are used, although Akaike Information Criterion is used as a primary measure to demonstrate that our proposed Higher Order polynomials have overall better model performance over Zero and 1st Order polynomials.},
author = {Castro, Juan R. and Castillo, Oscar and Sanchez, Mauricio A. and Mendoza, Olivia and Rodr{\'{i}}guez-Diaz, Antonio and Melin, Patricia},
doi = {10.1016/j.ins.2016.02.045},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Castro et al. - 2016 - Method for Higher Order polynomial Sugeno Fuzzy Inference Systems.pdf:pdf},
issn = {00200255},
journal = {Information Sciences},
keywords = {Higher Order,Polynomial,Sugeno,Type-1 fuzzy system},
pages = {76--89},
title = {{Method for Higher Order polynomial Sugeno Fuzzy Inference Systems}},
volume = {351},
year = {2016}
}
@article{Balmat2011,
abstract = {In this study, we propose a fuzzy approach in order to evaluate the maritime risk assessment applied to safety at sea and more particularly, the pollution prevention on the open sea. The work is based on the decision-making system, named MARISA, presented in Balmat et al. (2009). This system allowed defining a risk factor for each ship according to ship's characteristics and weather conditions. In this novel paper, the proposed system takes into account the ship speed evolution and the ship position with respect to maritime shipping lanes is developed. To validate the method, we present an example of results with real data. ?? 2010 Elsevier Ltd. All rights reserved.},
author = {Balmat, Jean Franois and Lafont, Frdric and Maifret, Robert and Pessel, Nathalie},
doi = {10.1016/j.oceaneng.2010.10.012},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Balmat et al. - 2011 - A decision-making system to maritime risk assessment.pdf:pdf},
isbn = {0029-8018},
issn = {00298018},
journal = {Ocean Engineering},
keywords = {Fuzzy risk factor,Maritime risk assessment,Maritime safety},
number = {1},
pages = {171--176},
title = {{A decision-making system to maritime risk assessment}},
volume = {38},
year = {2011}
}
@article{Makinski2020,
abstract = {For a long time the ability to solve abstract reasoning tasks was considered one of the hallmarks of human intelligence. Recent advances in application of deep learning (DL) methods led, as in many other domains, to surpassing human abstract reasoning performance, specifically in the most popular type of such problems - the Raven's Progressive Matrices (RPMs). While the efficacy of DL systems is indeed impressive, the way they approach the RPMs is very different from that of humans. State-of-the-art systems solving RPMs rely on massive pattern-based training and sometimes on exploiting biases in the dataset, whereas humans concentrate on identification of the rules / concepts underlying the RPM (or generally a visual reasoning task) to be solved. Motivated by this cognitive difference, this work aims at combining DL with human way of solving RPMs and getting the best of both worlds. Specifically, we cast the problem of solving RPMs into multi-label classification framework where each RPM is viewed as a multi-label data point, with labels determined by the set of abstract rules underlying the RPM. For efficient training of the system we introduce a generalisation of the Noise Contrastive Estimation algorithm to the case of multi-label samples. Furthermore, we propose a new sparse rule encoding scheme for RPMs which, besides the new training algorithm, is the key factor contributing to the state-of-the-art performance. The proposed approach is evaluated on two most popular benchmark datasets (Balanced-RAVEN and PGM) and on both of them demonstrates an advantage over the current state-of-the-art results. Contrary to applications of contrastive learning methods reported in other domains, the state-of-the-art performance reported in the paper is achieved with no need for large batch sizes or strong data augmentation.},
archivePrefix = {arXiv},
arxivId = {2012.01944},
author = {Ma{\l}ki{\'{n}}ski, Miko{\l}aj and Ma{\'{n}}dziuk, Jacek},
eprint = {2012.01944},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ma{\l}ki{\'{n}}ski, Ma{\'{n}}dziuk - 2020 - Multi-Label Contrastive Learning for Abstract Visual Reasoning.pdf:pdf},
keywords = {contrastive learning,multi-label,reasoning,visual reasoning},
mendeley-tags = {contrastive learning,multi-label,reasoning,visual reasoning},
pages = {1--21},
title = {{Multi-Label Contrastive Learning for Abstract Visual Reasoning}},
url = {http://arxiv.org/abs/2012.01944},
year = {2020}
}
@article{Kumar2016,
abstract = {{\textcopyright} 2016 IEEE. Statistical Forecasting Methods are most suitable for rapid-deployed systems as they can predict extreme weather conditions that could have occurred previously and needs negligible time to deploy the algorithm compared to ANN or Fuzzy forecasting that require adjustments and training. We use a modified version of the Sliding Window Algorithm to fit the requirements of the Irrigation System, which has a very low computational complexity compared to ANN and requires smaller data set to predict weather conditions. This not only makes the method simple but also has low hardware requirements.},
author = {Kumar, Jayendra and Mishra, Srinath and Hansdah, Anurag and Kumar, Rajiv},
doi = {10.1109/TIAR.2016.7801234},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kumar et al. - 2016 - Modified sliding window alogrithm for weather forecasting.pdf:pdf},
isbn = {9781509006151},
journal = {Proceedings - 2016 IEEE International Conference on Technological Innovations in ICT for Agriculture and Rural Development, TIAR 2016},
keywords = {Euclidean Distance,Max-Min normalization,Statistical Forecasting,Variation Trend Matching},
number = {Tiar},
pages = {175--180},
title = {{Modified sliding window alogrithm for weather forecasting}},
year = {2016}
}
@article{Kita2017,
author = {Kita, Yasuyo and Ishikawa, Hiroshi and Masuda, Takeshi},
doi = {10.1007/s11263-017-0990-1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kita, Ishikawa, Masuda - 2017 - Guest Editorial Machine Vision Applications.pdf:pdf},
issn = {15731405},
journal = {International Journal of Computer Vision},
number = {2},
pages = {191--192},
title = {{Guest Editorial: Machine Vision Applications}},
volume = {122},
year = {2017}
}
@article{Yu2020d,
abstract = {We study incremental learning for semantic segmentation where when learning new classes we have no access to the labeled data of previous tasks. When incrementally learning new classes, deep neural networks suffer from catastrophic forgetting of previous learned knowledge. To address this problem, we propose to apply a self-training approach that leverages unlabeled data, which is used for rehearsal of previous knowledge. Additionally, conflict reduction is proposed to resolve the conflicts of pseudo labels generated from both the old and new models. We show that maximizing self-entropy can further improve results by smoothing the overconfident predictions. The experiments demonstrate state-of-the-art results: obtaining a relative gain of up to 114% on Pascal-VOC 2012 and 8.5% on the more challenging ADE20K compared to previous state-of-the-art methods.},
archivePrefix = {arXiv},
arxivId = {2012.03362},
author = {Yu, Lu and Liu, Xialei and van de Weijer, Joost},
eprint = {2012.03362},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu, Liu, van de Weijer - 2020 - Self-training for class-incremental semantic segmentation.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {continual learning,incremental learning,semantic segmentation},
mendeley-tags = {continual learning,incremental learning,semantic segmentation},
pages = {1--11},
title = {{Self-training for class-incremental semantic segmentation}},
year = {2020}
}
@article{M.N.2013,
author = {M.N., Noor and Bakri, A.M. Mustafa Al and A.S., Yahaya and N.A., Ramli and N.F.M.Y., Fitri},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/M.N. et al. - 2013 - Estimation of Missing Values in Environmental Data Set using Interpolation Technique Fitting on Lognormal Distribut.pdf:pdf},
keywords = {lognormal distribution,missing values,performance indicators,pm 10},
number = {5},
pages = {336--341},
title = {{Estimation of Missing Values in Environmental Data Set using Interpolation Technique: Fitting on Lognormal Distribution}},
volume = {7},
year = {2013}
}
@article{Himmelsbach2009,
abstract = {This paper describes a LIDAR-based perception system for ground robot mobility, consisting of 3D object detection, classification and tracking. The presented system was demonstrated on-board our autonomous ground vehicle MuCAR-3, enabling it to safely navigate in urban traffic-like scenarios as well as in off-road convoy scenarios. The efficiency of our approach stems from the unique combination of 2D and 3D data processing techniques. Whereas fast segmentation of point clouds into objects is done in a 2 1/2D occupancy grid, classifying the objects is done on raw 3D point clouds. For fast object feature extraction, we advocate the use of statistics of local point cloud properties, captured by histograms over point features. In contrast to most existing work on 3D point cloud classification, where real-time operation is often impossible, this combination allows our system to perform in real-time at 0.1s frame-rate.},
author = {Himmelsbach, M. and Luettel, T. and Wuensche, H.-J.},
doi = {10.1109/IROS.2009.5354493},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Himmelsbach, Luettel, Wuensche - 2009 - Real-time object classification in 3D point clouds using point feature histograms.pdf:pdf},
isbn = {978-1-4244-3803-7},
journal = {2009 IEEE/RSJ International Conference on Intelligent Robots and Systems},
pages = {994--1000},
title = {{Real-time object classification in 3D point clouds using point feature histograms}},
url = {http://ieeexplore.ieee.org/document/5354493/},
year = {2009}
}
@article{Chen2020f,
abstract = {Online continual learning is a challenging scenario where a model needs to learn 1 from a continuous stream of data without revisiting any previously encountered 2 data instances. The phenomenon of catastrophic forgetting is worsened since the 3 model should not only address the forgetting at the task-level but also at the data 4 instance-level within the same task. To mitigate this, we leverage the concept of 5 "instance awareness" in the neural network, where each data instance is classified 6 by a path in the network searched by the controller from a meta-graph. To preserve 7 the knowledge we learn from previous instances, we proposed a method to protect 8 the path by restricting the gradient updates of one instance from overriding past 9 updates calculated from previous instances if these instances are not similar. On 10},
author = {Chen, Hung-Jen and Cheng, An-Chieh and Juan, Da-Cheng and Wei, Wei and Sun, Min},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2020 - Mitigating Forgetting in Online Continual Learning via Instance-Aware Parameterization.pdf:pdf},
number = {NeurIPS},
pages = {1--12},
title = {{Mitigating Forgetting in Online Continual Learning via Instance-Aware Parameterization}},
year = {2020}
}
@article{Edelson2011,
abstract = {Human memory is strikingly susceptible to social influences, yet we know little about the underlying mechanisms. We examined how socially induced memory errors are generated in the brain by studying the memory of individuals exposed to recollections of others. Participants exhibited a strong tendency to conform to erroneous recollections of the group, producing both long-lasting and temporary errors, even when their initial memory was strong and accurate. Functional brain imaging revealed that social influence modified the neuronal representation of memory. Specifically, a particular brain signature of enhanced amygdala activity and enhanced amygdala-hippocampus connectivity predicted long-lasting but not temporary memory alterations. Our findings reveal how social manipulation can alter memory and extend the known functions of the amygdala to encompass socially mediated memory distortions.},
author = {Edelson, Micah and Sharot, Tali and Dolan, Raymond J. and Dudai, Yadin},
doi = {10.1126/science.1203557},
isbn = {1095-9203 (Electronic)\n0036-8075 (Linking)},
issn = {00368075},
journal = {Science},
number = {6038},
pages = {108--111},
pmid = {21719681},
title = {{Following the crowd: Brain substrates of long-term memory conformity}},
volume = {333},
year = {2011}
}
@article{Beyaz2017,
abstract = {The aim of this research was to identify some Spanish olive cultivars using image processing techniques. For this purpose, Lechin De Granada, Arbequina, Picual, Verdial De V-M, Picudo, Hojiblanca and Empeltre Olive cultivars were identified utilizing the image processing and analysis techniques. Therefore, images of olives taken as 300 dpi with the 2896 × 1944 pixels, were captured using a DSLR camera, and evaluations of pixels were used for considering the pixel distribution and dimension measurements. LabVIEW Vision Assistant v2013 (NI) and Image j (NIH) software were used for image analysis procedures. Artificial Neural Network analysis were used to assess information of the length, width and color data results obtained from the fruits and stones (olive stones). All cultivars were identified. In addition, different classification techniques were applied to the olive stone and fruit data with the help of SPSS v22. Clementine v12 was used as a data mining software package from SPSS. The cultivars were identified 90% from dimensions with Artificial Neural Networks.},
author = {Beyaz, Abdullah and {\"{O}}zkaya, M{\"{u}}cahit Taha and İ{\c{c}}en, Duygu},
doi = {10.1016/j.scienta.2017.06.041},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Beyaz, {\"{O}}zkaya, İ{\c{c}}en - 2017 - Identification of some spanish olive cultivars using image processing techniques.pdf:pdf},
issn = {03044238},
journal = {Scientia Horticulturae},
keywords = {Artificial vision,Image analysis,Olive fruit,Olive stone,Varietal identification},
number = {March},
pages = {286--292},
title = {{Identification of some spanish olive cultivars using image processing techniques}},
volume = {225},
year = {2017}
}
@inproceedings{Wu2018,
abstract = {Previous works on sequential learning address the problem of forgetting in discriminative models. In this paper we consider the case of generative models. In particular, we investigate generative adversarial networks (GANs) in the task of learning new categories in a sequential fashion. We first show that sequential fine tuning renders the network unable to properly generate images from previous categories (i.e. forgetting). Addressing this problem, we propose Memory Replay GANs (MeRGANs), a conditional GAN framework that integrates a memory replay generator. We study two methods to prevent forgetting by leveraging these replays, namely joint training with replay and replay alignment. Qualitative and quantitative experimental results in MNIST, SVHN and LSUN datasets show that our memory replay approach can generate competitive images while significantly mitigating the forgetting of previous categories. 1.},
author = {Wu, Chenshen and Herranz, Luis and Liu, Xialei and Wang, Yaxing and {Van de Weijer}, Joost and Raducanu, Bogdan},
booktitle = {Advances in Neural Information Processing Systems},
editor = {Garnett, S. Bengio and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N.},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu et al. - 2018 - Memory replay GANs Learning to generate images from new categories without forgetting.pdf:pdf},
issn = {23318422},
keywords = {continual learning,gan,generative model,image generation,incremental learning},
mendeley-tags = {continual learning,gan,generative model,image generation,incremental learning},
number = {NeurIPS},
publisher = {Curran Associates, Inc.},
title = {{Memory replay GANs: Learning to generate images from new categories without forgetting}},
year = {2018}
}
@article{Bernstein2010,
abstract = {This paper presents evidence that supports the valid use of scores from fully automatic tests of spoken language ability to indicate a person's effectiveness in spoken communication. The paper reviews the constructs, scoring, and the concurrent validity evidence of ‘facility-in-L2' tests, a family of automated spoken language tests in Spanish, Dutch, Arabic, and English. The facility-in-L2 tests are designed to measure receptive and productive language ability as test-takers engage in a succession of tasks with meaningful language. Concurrent validity studies indicate that scores from the automated tests are strongly correlated with the scores from oral proficiency interviews. In separate studies with learners from each of the four languages the automated tests predict scores from the live interview tests as well as those tests predict themselves in a test-retest protocol (r = 0.77 to 0.92). Although it might be assumed that the interactive nature of the oral interview elicits performances that manifest a distinct construct, the closeness of the results suggests that the constructs underlying the two approaches to oral assessment have a stable relationship across languages.},
author = {Bernstein, Jared and van Moere, Alistair and Cheng, Jian},
doi = {10.1177/0265532210364404},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bernstein, van Moere, Cheng - 2010 - Validating automated speaking tests.pdf:pdf},
isbn = {0265-5322\r1477-0946},
issn = {02655322},
journal = {Language Testing},
keywords = {Automated scoring,Language testing,Speech recognition,Test validity,Versant},
number = {3},
pages = {355--377},
title = {{Validating automated speaking tests}},
volume = {27},
year = {2010}
}
@article{Rajabi2015a,
abstract = {The discovery of piezoelectricity, endogenous electric fields and transmembrane potentials in biological tissues raised the question whether or not electric fields play an important role in cell function. It has kindled research and the development of technologies in emulating biological electricity for tissue regeneration. Promising effects of electrical stimulation on cell growth and differentiation and tissue growth has led to interest in using piezoelectric scaffolds for tissue repair. Piezoelectric materials can generate electrical activity when deformed. Hence, an external source to apply electrical stimulation or implantation of electrodes is not needed. Various piezoelectric materials have been employed for different tissue repair applications, particularly in bone repair, where charges induced by mechanical stress can enhance bone formation; and in neural tissue engineering, in which electric pulses can stimulate neurite directional outgrowth to fill gaps in nervous tissue injuries. In this review, a summary of piezoelectricity in different biological tissues, mechanisms through which electrical stimulation may affect cellular response, and recent advances in the fabrication and application of piezoelectric scaffolds will be discussed. Statement of Significance The discovery of piezoelectricity, endogenous electric fields and transmembrane potentials in biological tissues has kindled research and the development of technologies using electrical stimulation for tissue regeneration. Piezoelectric materials generate electrical activity in response to deformations and allow for the delivery of an electrical stimulus without the need for an external power source. As a scaffold for tissue engineering, growing interest exists due to its potential of providing electrical stimulation to cells to promote tissue formation. In this review, we cover the discovery of piezoelectricity in biological tissues, its connection to streaming potentials, biological response to electrical stimulation and commonly used piezoelectric materials for tissue regeneration. This review summarizes their potential as a promising scaffold in the tissue engineering field.},
author = {Rajabi, Amir Hossein and Jaffe, Michael and Arinzeh, Treena Livingston},
doi = {10.1016/j.actbio.2015.07.010},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rajabi, Jaffe, Arinzeh - 2015 - Piezoelectric materials for tissue regeneration A review.pdf:pdf},
isbn = {1742-7061},
issn = {18787568},
journal = {Acta Biomaterialia},
keywords = {Electrical stimulation,Piezoelectric,Scaffolds,Tissue engineering,Tissue regeneration},
number = {July},
pages = {12--23},
pmid = {26162587},
publisher = {Acta Materialia Inc.},
title = {{Piezoelectric materials for tissue regeneration: A review}},
url = {http://dx.doi.org/10.1016/j.actbio.2015.07.010},
volume = {24},
year = {2015}
}
@article{Murli2002,
author = {Murli, Almerico and Amore, Luisa D and Simone, Valentina De and Angelo, Complesso Monte S and Cintia, Via and {\~{A}}{\`{u}}, {\`{U}} {\`{O}} and {\'{Y}}, {\"{U}} {\"{U}} {\'{Y}} {\'{Y}} {\`{U}} {\"{U}} and {\AE}, {\'{I}} {\~{A}} {\'{I}}},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Murli et al. - 2002 - The Wiener Filter and Regularization Methods for Image Restoration Problems.pdf:pdf},
journal = {Ieee},
number = {2},
title = {{The Wiener Filter and Regularization Methods for Image Restoration Problems}},
year = {2002}
}
@article{Le2011,
abstract = {Independent Components Analysis (ICA) and its variants have been successfully used for unsupervised feature learning. However, standard ICA requires an orthonoramlity constraint to be enforced, which makes it difficult to learn overcomplete features. In addition, ICA is sensitive to whitening. These properties make it challenging to scale ICA to high dimensional data. In this paper, we propose a robust soft reconstruction cost for ICA that allows us to learn highly overcomplete sparse features even on unwhitened data. Our formulation reveals formal connections between ICA and sparse autoencoders, which have previously been observed only empirically. Our algorithm can be used in conjunction with off-the-shelf fast unconstrained optimizers. We show that the soft reconstruction cost can also be used to prevent replicated features in tiled convolutional neural networks. Using our method to learn highly overcomplete sparse features and tiled convolutional neural networks, we obtain competitive performances on a wide variety of object recognition tasks. We achieve state-of-the-art test accuracies on the STL-10 and Hollywood2 datasets.},
author = {Le, Quoc V. and Karpenko, Alexandre and Ngiam, Jiquan and Ng, Andrew Y.},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Le et al. - 2011 - ICA with reconstruction cost for efficient overcomplete feature learning.pdf:pdf},
isbn = {9781618395993},
journal = {Advances in Neural Information Processing Systems 24: 25th Annual Conference on Neural Information Processing Systems 2011, NIPS 2011},
pages = {1--9},
title = {{ICA with reconstruction cost for efficient overcomplete feature learning}},
year = {2011}
}
@article{Sung1996,
abstract = {The mitotic cells from an asynchronous population of Chinese hamster ovary cells exposed to 41.5 degrees for 7 hr were examined by light and electron microscopy to determine if there were any morphological abnormalities related to cell death or lengthening of metaphase induced by hyperthermia. All components of the mitotic apparatus were formed during exposure to heat, and the mitotic apparatus was functional as demonstrated by eventual cell division. However, heat caused the nuclear envelope to reform precociously around the chromosomes except in the region of the kinetochores, and the nuclear envelope remained associated with the chromatids during segregation. The precocious reformation of the nuclear envelope may be responsible for the lengthening of metaphase. Cells undergoing mitosis during the heat treatment possessed large evaginations of the plasma membrane, and the ubiquitous cortical microfilaments were absent in the region of these evaginations. Possibly related to the membrane damage were osmotic changes resulting in swollen mitochondria observed in heated cells entering mitosis. Since hyperthermic damage to the plasma membrane-microfilament complex was not observed in interphase cells or in cells completing division but was morphologically expressed during mitosis, the thermal lability of the plasma membrane must increase as the cells enter mitosis.},
archivePrefix = {arXiv},
arxivId = {1572},
author = {Sung, Kah-kay},
eprint = {1572},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sung - 1996 - Learning and Example Selection for Object and Pattern Detection.pdf:pdf},
issn = {0008-5472},
journal = {PhD thesis},
pages = {195},
title = {{Learning and Example Selection for Object and Pattern Detection}},
year = {1996}
}
@article{Krizhevsky2017,
abstract = {Delineating the tremendous growth in this area, the Handbook of Approximation Algorithms and Metaheuristics covers fundamental, theoretical topics as well as advanced, practical applications. It is the first book to comprehensively study both approximation algorithms and metaheuristics. Starting with basic approaches, the handbook presents the methodologies to design and analyze efficient approximation algorithms for a large class of problems, and to establish inapproximability results for another class of problems. It also discusses local search, neural networks, and metaheuristics, as well as multiobjective problems, sensitivity analysis, and stability. After laying this foundation, the book applies the methodologies to classical problems in combinatorial optimization, computational geometry, and graph problems. In addition, it explores large-scale and emerging applications in networks, bioinformatics, VLSI, game theory, and data analysis. Undoubtedly sparking further developments in the field, this handbook provides the essential techniques to apply approximation algorithms and metaheuristics to a wide range of problems in computer science, operations research, computer engineering, and economics. Armed with this information, researchers can design and analyze efficient algorithms to generate near-optimal solutions for a wide range of computational intractable problems.},
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
doi = {10.1145/3065386},
editor = {Gonzalez, Teofilo F.},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krizhevsky, Sutskever, Hinton - 2017 - ImageNet classification with deep convolutional neural networks.pdf:pdf},
isbn = {9780429143793},
issn = {0001-0782},
journal = {Communications of the ACM},
month = {may},
number = {6},
pages = {84--90},
publisher = {Chapman and Hall/CRC},
title = {{ImageNet classification with deep convolutional neural networks}},
url = {https://www.taylorfrancis.com/books/9781420010749 https://dl.acm.org/doi/10.1145/3065386},
volume = {60},
year = {2017}
}
@article{Hu2016,
abstract = {Combining deep neural networks with structured logic rules is desirable to harness flexibility and reduce uninterpretability of the neural models. We propose a general framework capable of enhancing various types of neural networks (e.g., CNNs and RNNs) with declarative first-order logic rules. Specifically, we develop an iterative distillation method that transfers the structured information of logic rules into the weights of neural networks. We deploy the framework on a CNN for sentiment analysis, and an RNN for named entity recognition. With a few highly intuitive rules, we obtain substantial improvements and achieve state-of-the-art or comparable results to previous best-performing systems.},
archivePrefix = {arXiv},
arxivId = {1603.06318},
author = {Hu, Zhiting and Ma, Xuezhe and Liu, Zhengzhong and Hovy, Eduard and Xing, Eric P.},
doi = {10.18653/v1/p16-1228},
eprint = {1603.06318},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hu et al. - 2016 - Harnessing deep neural networks with logic rules.pdf:pdf},
isbn = {9781510827585},
journal = {54th Annual Meeting of the Association for Computational Linguistics, ACL 2016 - Long Papers},
pages = {2410--2420},
title = {{Harnessing deep neural networks with logic rules}},
volume = {4},
year = {2016}
}
@inproceedings{Hao2019,
author = {Hao, Yu and Fu, Yanwei and Jiang, Yu-gang and Tian, Qi},
booktitle = {2019 IEEE International Conference on Multimedia and Expo (ICME)},
doi = {10.1109/ICME.2019.00009},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hao et al. - 2019 - An End-to-End Architecture for Class-Incremental Object Detection with Knowledge Distillation.pdf:pdf},
isbn = {978-1-5386-9552-4},
keywords = {continual learning,incremental learning,object detection},
mendeley-tags = {continual learning,incremental learning,object detection},
month = {jul},
pages = {1--6},
publisher = {IEEE},
title = {{An End-to-End Architecture for Class-Incremental Object Detection with Knowledge Distillation}},
url = {https://ieeexplore.ieee.org/document/8784755/},
year = {2019}
}
@article{Bellon-Maurel2011,
abstract = {This paper is an extensive review of the research that has been undertaken on near-infrared (NIR) and mid-infrared (MIR) spectroscopy applied to soil particularly for determining carbon (C) content. The objective is to determine which acquisition method (NIR, MIR, in the field or in the laboratory) might be recommended for the purpose of C stock measurement with a particular interest in carbon credit trading. For this purpose, an optimal method has to satisfy the dual constraints of low-cost and high throughput analysis. The various methods proposed in the literature are compared. In order to make comparisons as reliable as possible, special attention has been paid to the conditions of data acquisition (sample preparation), and to calibration and validation procedures. In particular, whether the validation has been carried out on fully independent samples or on samples similar to the ones of the calibration set greatly influences the results. Also, for C stock measurement, it is absolutely necessary to measure the bias of the prediction in order to be conclusive about the feasibility of the method. However, only few researchers provide this parameter and we recommend including it as a matter of course in future reports. Finally, although MIR on dried and ground samples is the most accurate method, on-the-go and in-field sensors provide predictions accurate enough to show promise in being a valuable component of technologies that would be used for C-credit purposes. But in order to meet the cost/accuracy trade-off, the main issue using such field sensors is to be able to simultaneously measure the bulk density or, better, to directly measure the volumetric concentration of C in soil. This circumvents the costs of field extraction and laboratory analysis. This is the next great challenge to be met by soil scientists. {\textcopyright} 2011 Elsevier Ltd.},
author = {Bellon-Maurel, V{\'{e}}ronique and McBratney, Alex},
doi = {10.1016/j.soilbio.2011.02.019},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bellon-Maurel, McBratney - 2011 - Near-infrared (NIR) and mid-infrared (MIR) spectroscopic techniques for assessing the amount of carbon.pdf:pdf},
isbn = {0038-0717},
issn = {00380717},
journal = {Soil Biology and Biochemistry},
keywords = {Carbon,Infrared,MIR,NIR,Near-infrared,Spectrometry},
number = {7},
pages = {1398--1410},
pmid = {23112620},
publisher = {Elsevier Ltd},
title = {{Near-infrared (NIR) and mid-infrared (MIR) spectroscopic techniques for assessing the amount of carbon stock in soils - Critical review and research perspectives}},
url = {http://dx.doi.org/10.1016/j.soilbio.2011.02.019},
volume = {43},
year = {2011}
}
@article{Peng2020a,
abstract = {The human vision and perception system is inherently incremental where new knowledge is continually learned over time whilst existing knowledge is retained. On the other hand, deep learning networks are ill-equipped for incremental learning. When a well-trained network is adapted to new categories, its performance on the old categories will dramatically degrade. To address this problem, incremental learning methods have been explored which preserve the old knowledge of deep learning models. However, the state-of-the-art incremental object detector employs an external fixed region proposal method that increases overall computation time and reduces accuracy comparing to Region Proposal Network (RPN) based object detectors such as Faster RCNN. The purpose of this paper is to design an efficient end-to-end incremental object detector using knowledge distillation. We first evaluate and analyze the performance of the RPN-based detector with classic distillation on incremental detection tasks. Then, we introduce multi-network adaptive distillation that properly retains knowledge from the old categories when fine-tuning the model for new task. Experiments on the benchmark datasets, PASCAL VOC and COCO, demonstrate that the proposed incremental detector based on Faster RCNN is more accurate as well as being 13 times faster than the baseline detector.},
archivePrefix = {arXiv},
arxivId = {2003.03901},
author = {Peng, Can and Zhao, Kun and Lovell, Brian C.},
doi = {10.1016/j.patrec.2020.09.030},
eprint = {2003.03901},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Peng, Zhao, Lovell - 2020 - Faster ILOD Incremental learning for object detectors based on faster RCNN.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Deep learning,Incremental learning,Object detection,continual learning,incremental learning,object detection},
mendeley-tags = {continual learning,incremental learning,object detection},
pages = {109--115},
title = {{Faster ILOD: Incremental learning for object detectors based on faster RCNN}},
volume = {140},
year = {2020}
}
@article{Kondratenko2003,
abstract = {This paper reports empirical evidence that a neural networks model is applicable to the statistically reliable prediction of foreign exchange rates. Time series data and technical indicators such as moving average, are fed to neural nets to capture the underlying "rules" of the movement in currency exchange rates. The trained recurrent neural networks forecast the exchange rates between American Dollar and four other major currencies, Japanese Yen, Swiss Frank, British Pound and EURO. Various statistical estimates of forecast quality have been carried out. Obtained results show, that neural networks are able to give forecast with coefficient of multiple determination not worse then 0.65. Linear and nonlinear statistical data preprocessing, such as Kolmogorov-Smirnov test and Hurst exponents for each currency were calculated and analyzed.},
archivePrefix = {arXiv},
arxivId = {cond-mat/0304469},
author = {Kondratenko, V V and Kuperin, Yu a},
doi = {10.2298/CSIS140728005B},
eprint = {0304469},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kondratenko, Kuperin - 2003 - Using Recurrent Neural Networks To Forecasting of Forex.pdf:pdf},
isbn = {9780956494443},
issn = {1820-0214},
journal = {Time},
keywords = {complex systems theory,foreign exchange rate,hurst exponent,neural networks,statistical tests},
pages = {23},
primaryClass = {cond-mat},
title = {{Using Recurrent Neural Networks To Forecasting of Forex}},
url = {http://arxiv.org/abs/cond-mat/0304469},
year = {2003}
}
@article{Cossu2021a,
archivePrefix = {arXiv},
arxivId = {2105.07674},
author = {Cossu, Andrea and Bacciu, Davide and Carta, Antonio},
eprint = {2105.07674},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cossu, Bacciu, Carta - 2021 - Continual Learning with Echo State Networks.pdf:pdf},
keywords = {continual learning},
mendeley-tags = {continual learning},
number = {Ga 871385},
title = {{Continual Learning with Echo State Networks}},
year = {2021}
}
@article{Feng2017,
abstract = {High-content screening is commonly used in studies of the DNA damage response. The double-strand break (DSB) is one of the most harmful types of DNA damage lesions. The conventional method used to quantify DSBs is $\gamma$H2AX foci counting, which requires manual adjustment and preset parameters and is usually regarded as imprecise, time-consuming, poorly reproducible, and inaccurate. Therefore, a robust automatic alternative method is highly desired. In this manuscript, we present a new method for quantifying DSBs which involves automatic image cropping, automatic foci-segmentation and fluorescent intensity measurement. Furthermore, an additional function was added for standardizing the measurement of DSB response inhibition based on co-localization analysis. We tested the method with a well-known inhibitor of DSB response. The new method requires only one preset parameter, which effectively minimizes operator-dependent variations. Compared with conventional methods, the new method detected a higher percentage difference of foci formation between different cells, which can improve measurement accuracy. The effects of the inhibitor on DSB response were successfully quantified with the new method (p = 0.000). The advantages of this method in terms of reliability, automation and simplicity show its potential in quantitative fluorescence imaging studies and high-content screening for compounds and factors involved in DSB response.},
author = {Feng, Jingwen and Lin, Jie and Zhang, Pengquan and Yang, Songnan and Sa, Yu and Feng, Yuanming},
doi = {10.1038/s41598-017-10063-0},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Feng et al. - 2017 - A novel automatic quantification method for high-content screening analysis of DNA double strand-break response.pdf:pdf},
issn = {20452322},
journal = {Scientific Reports},
number = {1},
pages = {1--10},
title = {{A novel automatic quantification method for high-content screening analysis of DNA double strand-break response}},
volume = {7},
year = {2017}
}
@article{Liu2020i,
abstract = {Multi-task learns multiple tasks, while sharing knowledge and computation among them. However, it suffers from catastrophic forgetting of previous knowledge when learned incrementally without access to the old data. Most existing object detectors are domain-specific and static, while some are learned incrementally but only within a single domain. Training an object detector incrementally across various domains has rarely been explored. In this work, we propose three incremental learning scenarios across various domains and categories for object detection. To mitigate catastrophic forgetting, attentive feature distillation is proposed to leverages both bottom-up and top-down attentions to extract important information for distillation. We then systematically analyze the proposed distillation method in different scenarios. We find out that, contrary to common understanding, domain gaps have smaller negative impact on incremental detection, while category differences are problematic. For the difficult cases, where the domain gaps and especially category differences are large, we explore three different exemplar sampling methods and show the proposed adaptive sampling method is effective to select diverse and informative samples from entire datasets, to further prevent forgetting. Experimental results show that we achieve the significant improvement in three different scenarios across seven object detection benchmark datasets.},
archivePrefix = {arXiv},
arxivId = {2002.05347},
author = {Liu, Xialei and Yang, Hao and Ravichandran, Avinash and Bhotika, Rahul and Soatto, Stefano},
eprint = {2002.05347},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2020 - Multi-Task Incremental Learning for Object Detection.pdf:pdf},
keywords = {continual learning,incremental learning,object detection},
mendeley-tags = {continual learning,incremental learning,object detection},
pages = {1--17},
title = {{Multi-Task Incremental Learning for Object Detection}},
url = {http://arxiv.org/abs/2002.05347},
year = {2020}
}
@article{Togliatti2017,
abstract = {Accurately forecasting crop yield in advance of harvest could greatly benefit decision makers when making management decisions. However, few evaluations have been conducted to determine the impact of including weather forecasts, as opposed to using historical weather data (commonly used) in crop models. We tested a combination of short-term weather forecasts from the Weather Research and Forecasting Model (WRF) to predict in season weather variables, such as, maximum and minimum temperature, precipitation, and radiation at four different forecast lengths (14 days, 7 days, 3 days, and 0 days). This forecasted weather data along with the current and historic (previous 35 years) data were combined to drive Agricultural Production Systems sIMulator (APSIM) in-season corn [Zea mays L] and soybean [Glycine max] grain yield and phenology forecasts for 16 field trials in Iowa, USA. The overall goal was to determine how the inclusion of weather forecasting impacts in-season crop model predictions. We had two objectives 1) determine the impact of weather forecast length on WRF accuracy, and 2) quantify the impact of weather forecasts accuracy on APSIM prediction accuracy. We found that the most accurate weather forecast length varied greatly among the 16 treatments (2 years × 2 sites × 2 crops × 2 management practices), but that the 0 day and 3 day forecasts were, on average, the most accurate when compared to the other forecast lengths. Overall, the accuracy of the in-season crop yield forecast was inversely proportional to forecast length (p = 0.026), but there was variation among treatments. The accuracy of the in-season flowering and maturity forecasts were not significantly affected by inclusion of weather forecast length (p = 0.065). The 14 day forecast provided enough lead time to improve flowering prediction in 8 out of the 16 treatments. The fact that maximum temperature was the most accurate predicted variable by WRF was the reason for improvements in flowering predictions. Our results suggest that a weather forecast from WRF was not better than historical weather for yield prediction.},
author = {Togliatti, Kaitlin and Archontoulis, Sotirios V. and Dietzel, Ranae and Puntel, Laila and VanLoocke, Andy},
doi = {10.1016/j.fcr.2017.09.008},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Togliatti et al. - 2017 - How does inclusion of weather forecasting impact in-season crop model predictions.pdf:pdf},
issn = {03784290},
journal = {Field Crops Research},
keywords = {Apsim,Corn,Soybean,WRF,Yield forecasting},
number = {March},
pages = {261--272},
publisher = {Elsevier},
title = {{How does inclusion of weather forecasting impact in-season crop model predictions?}},
url = {http://dx.doi.org/10.1016/j.fcr.2017.09.008},
volume = {214},
year = {2017}
}
@article{Anshari2013,
abstract = {—Pola iklim dan cuaca di Indonesia yang tidak ber- aturan dan eskstrim akan mengganggu transportasi laut. Pada penelitian ini telah dilakukan perancangan prediktor cuaca maritim berbasis logika fuzzy takagi sugeno menggunakan user interface smartphone android. User interface smartphone an- droid dipilih karena android banyak digunakan masyarakat indonesia. Data yang digunakan untuk membangun basis aturan dan fungsi keanggotaan berasal dari data BMKG II Perak yang direkam perjam selama 6 tahun yaitu dari januari 2007 hingga desember 2012. Digunakan data cuaca maritim dari tahun 2007 hingga 2012 untuk membangun basis aturan dan fungsi keanggotaan logika fuzzy. Validasi prediksi cuaca maritim di- lakukan dengan menggunakan data BMKG bulan februari 2013. Selain menggunakan data BMKG juga dilakukan validasi real- time menggunakan data maritim buoyweather. Hasil penelitian didapatkan akurasi prediksi cuaca maritim tertinggi, yaitu: suhu udara, kelembaban udara, kecepatan arus laut, tinggi gelombang dan curah hujan adalah 83%, 84.5%, 87 %, 85.7% dan 95%. Kata},
author = {Anshari, M Kahfi and Arifin, Syamsul and Iklim, A Cuaca},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Anshari, Arifin, Iklim - 2013 - Perancangan Prediktor Cuaca Maritim Berbasis Logika Fuzzy Menggunakan User Interface Android.pdf:pdf},
journal = {Teknik Pomits},
keywords = {Android,Cuaca Maritim,Maritim Prediksi Cuaca I.},
number = {2},
pages = {324--328},
title = {{Perancangan Prediktor Cuaca Maritim Berbasis Logika Fuzzy Menggunakan User Interface Android}},
volume = {2},
year = {2013}
}
@article{Biedermann2016,
abstract = {In this paper we discuss the use of digital data by the Swiss Federal Criminal Court in a recent case of attempted homicide. We use this case to examine drawbacks for the defense when the presentation of scientific evidence is partial, especially when the only perspective mentioned is that of the prosecution. We tackle this discussion at two distinct levels. First, we pursue an essentially non-technical presentation of the topic by drawing parallels between the court's summing up of the case and flawed patterns of reasoning commonly seen in other forensic disciplines, such as DNA and particle traces (e.g., gunshot residues). Then, we propose a formal analysis of the case, using elements of probability and graphical probability models, to justify our main claim that the partial presentation of digital evidence poses a risk to the administration of justice in that it keeps vital information from the defense. We will argue that such practice constitutes a violation of general principles of forensic interpretation as established by forensic science literature and current recommendations by forensic science interest groups (e.g., the European Network of Forensic Science Institutes). Finally, we posit that argument construction and analysis using formal methods can help replace digital evidence appropriately into context and thus support a sound evaluation of the evidence.},
author = {Biedermann, Alex and Vuille, Jo{\"{e}}lle},
doi = {10.1016/j.diin.2016.01.011},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Biedermann, Vuille - 2016 - Digital evidence, 'absence' of data and ambiguous patterns of reasoning.pdf:pdf},
issn = {17422876},
journal = {Digital Investigation},
keywords = {Case discussion,Digital traces and the law,Forensic interpretation,Likelihood ratio,Qualitative probabilistic networks},
pages = {S86--S95},
title = {{Digital evidence, 'absence' of data and ambiguous patterns of reasoning}},
volume = {16},
year = {2016}
}
@article{Gatys2016,
abstract = {Rendering the semantic content of an image in different styles is a difficult image processing task. Arguably, a major limiting factor for previous approaches has been the lack of image representations that explicitly represent semantic information and, thus, allow to separate image content from style. Here we use image representations derived from Convolutional Neural Networks optimised for object recognition, which make high level image information explicit. We introduce A Neural Algorithm of Artistic Style that can separate and recombine the image content and style of natural images. The algorithm allows us to produce new images of high perceptual quality that combine the content of an arbitrary photograph with the appearance of numerous wellknown artworks. Our results provide new insights into the deep image representations learned by Convolutional Neural Networks and demonstrate their potential for high level image synthesis and manipulation.},
author = {Gatys, Leon A. and Ecker, Alexander S. and Bethge, Matthias},
doi = {10.1109/CVPR.2016.265},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gatys, Ecker, Bethge - 2016 - Image Style Transfer Using Convolutional Neural Networks.pdf:pdf},
isbn = {9781467388504},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {2414--2423},
title = {{Image Style Transfer Using Convolutional Neural Networks}},
volume = {2016-Decem},
year = {2016}
}
@inproceedings{Kurakin2019,
abstract = {Most existing machine learning classifiers are highly vulnerable to adversarial examples. An adversarial example is a sample of input data which has been modified very slightly in a way that is intended to cause a machine learning classifier to misclassify it. In many cases, these modifications can be so subtle that a human observer does not even notice the modification at all, yet the classifier still makes a mistake. Adversarial examples pose security concerns because they could be used to perform an attack on machine learning systems, even if the adversary has no access to the underlying model. Up to now, all previous work has assumed a threat model in which the adversary can feed data directly into the machine learning classifier. This is not always the case for systems operating in the physical world, for example those which are using signals from cameras and other sensors as input. This paper shows that even in such physical world scenarios, machine learning systems are vulnerable to adversarial examples. We demonstrate this by feeding adversarial images obtained from a cell-phone camera to an ImageNet Inception classifier and measuring the classification accuracy of the system. We find that a large fraction of adversarial examples are classified incorrectly even when perceived through the camera.},
archivePrefix = {arXiv},
arxivId = {1607.02533},
author = {Kurakin, Alexey and Goodfellow, Ian J. and Bengio, Samy},
booktitle = {5th International Conference on Learning Representations, ICLR 2017 - Workshop Track Proceedings},
eprint = {1607.02533},
title = {{Adversarial examples in the physical world}},
year = {2019}
}
@article{Tan2016,
author = {Tan, Min Keng and Sin, Helen and Chuo, Ee and Ka, Renee and Chin, Yin and Yeo, Kiam and Tze, Kenneth and Teo, Kin},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tan et al. - 2016 - Optimization of Urban Traffic Network Signalization using Genetic Algorithm.pdf:pdf},
isbn = {9781509026036},
keywords = {genetic algorithm,oversaturated traffic condition,traffic model,traffic signal optimization},
pages = {87--92},
title = {{Optimization of Urban Traffic Network Signalization using Genetic Algorithm}},
year = {2016}
}
@article{Yang2021a,
author = {Yang, Shuo and Liu, Lu and Xu, Min},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang, Liu, Xu - 2021 - Free Lunch for Few-shot Learning Distribution Calibration.pdf:pdf},
keywords = {few-shot learning},
mendeley-tags = {few-shot learning},
pages = {1--13},
title = {{Free Lunch for Few-shot Learning: Distribution Calibration}},
year = {2021}
}
@article{Hazon2013,
abstract = {This paper considers the problem of an agent or a team of agents searching for a resource or tangible good in a physical environment, where the resource or good may possibly be obtained at one of several locations. The cost of acquiring the resource or good at a given location is uncertain (a priori), and the agents can observe the true cost only when physically arriving at this location. Sample applications include agents in exploration and patrol missions (e.g., an agent seeking to find the best location to deploy sensing equipment along its path). The uniqueness of these settings is in that the cost of observing a new location is determined by distance from the current one, impacting the consideration for the optimal search order. Although this model captures many real world scenarios, it has not been investigated so far. We analyze three variants of the problem, differing in their objective: minimizing the total expected cost, maximizing the success probability given an initial budget, and minimizing the budget necessary to obtain a given success probability. For each variant, we first introduce and analyze the problem with a single agent, either providing a polynomial solution to the problem or proving it is NP-complete. We also introduce a fully polynomial time approximation scheme algorithm for the minimum budget variant. In the multi-agent case, we analyze two models for managing resources, shared and private budget models. We present polynomial algorithms that work for any fixed number of agents, in the shared or private budget model. For non-communicating agents in the private budget model, we present a polynomial algorithm that is suitable for any number of agents. We also analyze the difference between homogeneous and heterogeneous agents, both with respect to their allotted resources and with respect to their capabilities. Finally, we define our problem in an environment with self-interested agents. We show how to find a Nash equilibrium in polynomial time, and prove that the bound on the performance of our algorithms, with respect to the social welfare, is tight. {\textcopyright} 2013 Elsevier B.V.},
author = {Hazon, Noam and Aumann, Yonatan and Kraus, Sarit and Sarne, David},
doi = {10.1016/j.artint.2012.12.003},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hazon et al. - 2013 - Physical search problems with probabilistic knowledge.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {Economic search,Graph search},
pages = {26--52},
publisher = {Elsevier B.V.},
title = {{Physical search problems with probabilistic knowledge}},
url = {http://dx.doi.org/10.1016/j.artint.2012.12.003},
volume = {196},
year = {2013}
}
@article{Huang2019a,
abstract = {This paper focuses on YOLO-LITE, a real-time object detection model developed to run on portable devices such as a laptop or cellphone lacking a Graphics Processing Unit (GPU). The model was first trained on the PASCAL VOC dataset then on the COCO dataset, achieving a mAP of 33.81% and 12.26% respectively. YOLO-LITE runs at about 21 FPS on a non-GPU computer and 10 FPS after implemented onto a website with only 7 layers and 482 million FLOPS. This speed is 3.8x faster than the fastest state of art model, SSD MobilenetvI. Based on the original object detection algorithm YOLOV2, YOLO- LITE was designed to create a smaller, faster, and more efficient model increasing the accessibility of real-time object detection to a variety of devices.},
archivePrefix = {arXiv},
arxivId = {arXiv:1811.05588v1},
author = {Huang, Rachel and Pedoeem, Jonathan and Chen, Cuixian},
doi = {10.1109/BigData.2018.8621865},
eprint = {arXiv:1811.05588v1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang, Pedoeem, Chen - 2019 - YOLO-LITE A Real-Time Object Detection Algorithm Optimized for Non-GPU Computers.pdf:pdf},
isbn = {9781538650356},
journal = {Proceedings - 2018 IEEE International Conference on Big Data, Big Data 2018},
keywords = {YOLO,deep learning,mobile,neural networks,non-GPU,object detection},
pages = {2503--2510},
title = {{YOLO-LITE: A Real-Time Object Detection Algorithm Optimized for Non-GPU Computers}},
year = {2019}
}
@article{Jing2020,
abstract = {Large-scale labeled data are generally required to train deep neural networks in order to obtain better performance in visual feature learning from images or videos for computer vision applications. To avoid extensive cost of collecting and annotating large-scale datasets, as a subset of unsupervised learning methods, self-supervised learning methods are proposed to learn general image and video features from large-scale unlabeled data without using any human-annotated labels. This paper provides an extensive review of deep learning-based self-supervised general visual feature learning methods from images or videos. First, the motivation, general pipeline, and terminologies of this field are described. Then the common deep neural network architectures that used for self-supervised learning are summarized. Next, the main components and evaluation metrics of self-supervised learning methods are reviewed followed by the commonly used image and video datasets and the existing self-supervised visual feature learning methods. Finally, quantitative performance comparisons of the reviewed methods on benchmark datasets are summarized and discussed for both image and video feature learning. At last, this paper is concluded and lists a set of promising future directions for self-supervised visual feature learning.},
archivePrefix = {arXiv},
arxivId = {1902.06162},
author = {Jing, Longlong and Tian, Yingli},
doi = {10.1109/TPAMI.2020.2992393},
eprint = {1902.06162},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jing, Tian - 2020 - Self-supervised Visual Feature Learning with Deep Neural Networks A Survey.pdf:pdf},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {review,self-supervised learning,survey},
mendeley-tags = {review,self-supervised learning,survey},
month = {feb},
pages = {1--1},
title = {{Self-supervised Visual Feature Learning with Deep Neural Networks: A Survey}},
url = {http://arxiv.org/abs/1902.06162 https://ieeexplore.ieee.org/document/9086055/},
year = {2020}
}
@article{Parisi2019a,
abstract = {Humans and animals have the ability to continually acquire, fine-tune, and transfer knowledge and skills throughout their lifespan. This ability, referred to as lifelong learning, is mediated by a rich set of neurocognitive mechanisms that together contribute to the development and specialization of our sensorimotor skills as well as to long-term memory consolidation and retrieval. Consequently, lifelong learning capabilities are crucial for computational learning systems and autonomous agents interacting in the real world and processing continuous streams of information. However, lifelong learning remains a long-standing challenge for machine learning and neural network models since the continual acquisition of incrementally available information from non-stationary data distributions generally leads to catastrophic forgetting or interference. This limitation represents a major drawback for state-of-the-art deep neural network models that typically learn representations from stationary batches of training data, thus without accounting for situations in which information becomes incrementally available over time. In this review, we critically summarize the main challenges linked to lifelong learning for artificial learning systems and compare existing neural network approaches that alleviate, to different extents, catastrophic forgetting. Although significant advances have been made in domain-specific learning with neural networks, extensive research efforts are required for the development of robust lifelong learning on autonomous agents and robots. We discuss well-established and emerging research motivated by lifelong learning factors in biological systems such as structural plasticity, memory replay, curriculum and transfer learning, intrinsic motivation, and multisensory integration.},
annote = {A general survey of the most important and used CL techniques, with a characterisation of the catastrophic forgetting phenomenon.},
author = {Parisi, German I and Kemker, Ronald and Part, Jose L and Kanan, Christopher and Wermter, Stefan},
doi = {10.1016/j.neunet.2019.01.012},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Parisi et al. - 2019 - Continual lifelong learning with neural networks A review.pdf:pdf},
issn = {0893-6080},
journal = {Neural Networks},
keywords = {Catastrophic forgetting,Continual learning,Developmental systems,Lifelong learning,Memory consolidation,continual learning,incremental learning,neural networks,review,survey},
language = {en},
mendeley-tags = {continual learning,incremental learning,neural networks,review,survey},
month = {may},
pages = {54--71},
shorttitle = {Continual lifelong learning with neural networks},
title = {{Continual lifelong learning with neural networks: A review}},
url = {http://www.sciencedirect.com/science/article/pii/S0893608019300231},
volume = {113},
year = {2019}
}
@article{VandeVen2018,
abstract = {A major obstacle to developing artificial intelligence applications capable of true lifelong learning is that artificial neural networks quickly or catastrophically forget previously learned tasks when trained on a new one. Numerous methods for alleviating catastrophic forgetting are currently being proposed, but differences in evaluation protocols make it difficult to directly compare their performance. To enable more meaningful comparisons, here we identified three distinct scenarios for continual learning based on whether task identity is known and, if it is not, whether it needs to be inferred. Performing the split and permuted MNIST task protocols according to each of these scenarios, we found that regularization-based approaches (e.g., elastic weight consolidation) failed when task identity needed to be inferred. In contrast, generative replay combined with distillation (i.e., using class probabilities as "soft targets") achieved superior performance in all three scenarios. Addressing the issue of efficiency, we reduced the computational cost of generative replay by integrating the generative model into the main model by equipping it with generative feedback or backward connections. This Replay-through-Feedback approach substantially shortened training time with no or negligible loss in performance. We believe this to be an important first step towards making the powerful technique of generative replay scalable to real-world continual learning applications.},
archivePrefix = {arXiv},
arxivId = {1809.10635},
author = {van de Ven, Gido M. and Tolias, Andreas S.},
eprint = {1809.10635},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/van de Ven, Tolias - 2018 - Generative replay with feedback connections as a general strategy for continual learning.pdf:pdf},
number = {April},
pages = {1--17},
title = {{Generative replay with feedback connections as a general strategy for continual learning}},
url = {http://arxiv.org/abs/1809.10635},
year = {2018}
}
@inproceedings{Chen2020d,
abstract = {In this paper, we consider the problem of fine-grained image retrieval in an incremental setting, when new categories are added over time. On the one hand, repeatedly training the representation on the extended dataset is time-consuming. On the other hand, fine-tuning the learned representation only with the new classes leads to catastrophic forgetting. To this end, we propose an incremental learning method to mitigate retrieval performance degradation caused by the forgetting issue. Without accessing any samples of the original classes, the classifier of the original network provides soft “labels” to transfer knowledge to train the adaptive network, so as to preserve the previous capability for classification. More importantly, a regularization function based on Maximum Mean Discrepancy is devised to minimize the discrepancy of new classes features from the original network and the adaptive network, respectively. Extensive experiments on two datasets show that our method effectively mitigates the catastrophic forgetting on the original classes while achieving high performance on the new classes.},
archivePrefix = {arXiv},
arxivId = {2010.08020},
author = {Chen, Wei and Liu, Yu and Wang, Weiping and Tuytelaars, Tinne and Bakker, Erwin M. and Lew, Michael},
booktitle = {Proceedings BMVC 2020},
eprint = {2010.08020},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2020 - On the exploration of incremental learning for fine-grained image retrieval.pdf:pdf},
issn = {23318422},
keywords = {continual learning,fine-grained,image retrieval,incremental learning},
mendeley-tags = {continual learning,fine-grained,image retrieval,incremental learning},
publisher = {BMVC},
title = {{On the exploration of incremental learning for fine-grained image retrieval}},
year = {2020}
}
@article{Jenni2018,
abstract = {We introduce a novel self-supervised learning method based on adversarial training. Our objective is to train a discriminator network to distinguish real images from images with synthetic artifacts, and then to extract features from its intermediate layers that can be transferred to other data domains and tasks. To generate images with artifacts, we pre-train a high-capacity autoencoder and then we use a damage and repair strategy: First, we freeze the autoencoder and damage the output of the encoder by randomly dropping its entries. Second, we augment the decoder with a repair network, and train it in an adversarial manner against the discriminator. The repair network helps generate more realistic images by inpainting the dropped feature entries. To make the discriminator focus on the artifacts, we also make it predict what entries in the feature were dropped. We demonstrate experimentally that features learned by creating and spotting artifacts achieve state of the art performance in several benchmarks.},
archivePrefix = {arXiv},
arxivId = {1806.05024},
author = {Jenni, Simon and Favaro, Paolo},
doi = {10.1109/CVPR.2018.00289},
eprint = {1806.05024},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jenni, Favaro - 2018 - Self-Supervised Feature Learning by Learning to Spot Artifacts.pdf:pdf},
isbn = {9781538664209},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {2733--2742},
title = {{Self-Supervised Feature Learning by Learning to Spot Artifacts}},
year = {2018}
}
@article{Xiao2011,
abstract = {Image thresholding is one of the most important approaches for image segmentation and it has been extensively used in many image processing or computer vision applications. In this paper, a new image thresholding method is presented using type-2 fuzzy sets based on GLSC histogram of human visual nonlinearity characteristics (HVNC).The traditional GLSC histogram takes the image spatial information into account in a different way from two-dimensional histogram. This work refines the GLSC histogram by embedding HVNC into GLSC histogram. To select threshold based on the redefined GLSC histogram, we employ the type-2 fuzzy set, whose membership function integrates the effect of pixel gray value and local spatial information to membership value. The type-2 fuzzy set is subsequently transformed into a type-1 fuzzy set for fuzziness measure computation via type reduction. Finally, the optimal threshold is obtained by minimizing the fuzziness of the type-1 fuzzy set after an exhaustive search. The experiment on different types of images demonstrates the effectiveness and the robustness of our proposed thresholding technique.},
author = {Xiao, Yang and Cao, Zhiguo and Zhuo, Wen},
doi = {10.1364/OE.19.010656},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xiao, Cao, Zhuo - 2011 - Type-2 fuzzy thresholding using GLSC histogram of human visual nonlinearity characteristics.pdf:pdf},
isbn = {1094-4087 (Electronic)\r1094-4087 (Linking)},
issn = {1094-4087},
journal = {Optics Express},
number = {11},
pages = {10656},
pmid = {21643321},
title = {{Type-2 fuzzy thresholding using GLSC histogram of human visual nonlinearity characteristics}},
url = {https://www.osapublishing.org/oe/abstract.cfm?uri=oe-19-11-10656},
volume = {19},
year = {2011}
}
@article{CarvalhoeFerreira2017,
abstract = {Cruising for parking represents a loss of efficiency to the private car. It generates a waste of time and fuel, worsens congestion and increases pollutant emissions. Most approaches trying to mitigate cruising on the street use price to manage demand. Here, an online system of curb parking space reservations is proposed. Reservations eliminate the uncertainties that lead to cruising, and by designing the system within the new paradigm of parking planning and management, transport policy objectives of equity and sustainability can be pursued. To evaluate the effectiveness of the proposed system, a case study in Lisbon was conducted. Firstly, cruising for parking was assessed, and showed a daily average of 10% of observed traffic to be cruising, in an area with several transit alternatives. Then, potential demand for the reservations service was also addressed. Next, a model of traffic and cruising behavior was developed and calibrated with the observed data, and a stochastic discrete-event micro-simulator was implemented and validated. Finally, simulations were used to compare scenarios of variable allocation of parking spaces to reservations. The results show a statistically significant reduction of total travel time of up to 3% of the value without reservations.},
author = {{Carvalho e Ferreira}, Diana and {de Abreu e Silva}, Jo{\~{a}}o},
doi = {10.1016/j.cstp.2016.11.004},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Carvalho e Ferreira, de Abreu e Silva - 2017 - Tackling cruising for parking with an online system of curb parking space reservations.pdf:pdf},
issn = {22136258},
journal = {Case Studies on Transport Policy},
keywords = {Cruising for parking,Discrete event simulation,Parking management,Parking space reservations,Transport simulation,Urban mobility},
number = {2},
pages = {179--187},
publisher = {World Conference on Transport Research Society},
title = {{Tackling cruising for parking with an online system of curb parking space reservations}},
url = {http://dx.doi.org/10.1016/j.cstp.2016.11.004},
volume = {5},
year = {2017}
}
@article{Nandy2020a,
abstract = {Among the existing uncertainty estimations approaches , only Dirichlet Prior Network (DPN) distinctly models different uncertainty types. However , in this paper, we show that for in-domain examples with high data uncertainties among multiple classes, a DPN also produces almost indistinguishable representations from the out-of-distribution (OOD) examples, compromising their OOD detection performance. We address this shortcoming by proposing a new loss function for DPN models that maximizes the representation gaps between the in-domain and OOD examples. Experimental results suggest that our proposed technique consistently improves OOD detection performance by solving this issue.},
archivePrefix = {arXiv},
arxivId = {arXiv:2010.10474v1},
author = {Nandy, Jay and Hsu, Wynne and Lee, Mong Li},
eprint = {arXiv:2010.10474v1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nandy, Hsu, Lee - 2020 - Towards Maximizing the Representation Gap between In-domain & OOD examples.pdf:pdf},
journal = {ICML 2020 Workshop on Uncertainty & Robustness in Deep Learning},
number = {NeurIPS},
title = {{Towards Maximizing the Representation Gap between In-domain & OOD examples}},
url = {https://www.researchgate.net/publication/344387147},
year = {2020}
}
@article{Lahsasna2017,
abstract = {Interpretability of classification systems, which refers to the ability of these systems to express their behavior in an understandable way, has recently gained more attention and it is considered as an important requirement especially for knowledge-based systems. The main objective of this study is to improve the ability of a well-known fuzzy classifier proposed in Ishibuchi and Nojima (2007) to maximize the accuracy while preserve its interpretability. To achieve the above-mentioned objective, we propose two variants of the original fuzzy classifier. In the first variant classifier, the same components of the original classifier were used except NSGA-II which was replaced by an enhanced version called Controlled Elitism NSGA-II. This replacement aims at improving the ability of the first variant classifier to find non-dominated solutions with better interpretability-accuracy trade-off. In the second variant classifier, we further improve the first variant classifier by enhancing the selection method of the antecedent conditions of the rules generated in the initial population of genetic algorithm. Unlike the method applied in the original classifier and the first variant classifier, which uses a random selection of the antecedent conditions, we proposed a feature-based selection method to favor the antecedent conditions associated with the most relevant features. The results show that the two variant classifiers find more non-dominated fuzzy rule-based systems with better generalization ability than the original method which suggests that Controlled Elitism NSGA-II algorithm is more efficient than NSGA-II. In addition, feature-based selection method applied in the second variant classifier allowed this method to successfully obtain high-quality solutions as it has consistently achieved the best error rates for all the data sets compared to the original method and the first variant classifier.},
author = {Lahsasna, Adel and Seng, Woo Chaw},
doi = {10.1016/j.eswa.2017.04.022},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lahsasna, Seng - 2017 - An improved genetic-fuzzy system for classification and data analysis.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Fuzzy rule-based systems,Interpretability,Multi-objective genetic algorithms,NSGA-II},
pages = {49--62},
publisher = {Elsevier Ltd},
title = {{An improved genetic-fuzzy system for classification and data analysis}},
url = {http://dx.doi.org/10.1016/j.eswa.2017.04.022},
volume = {83},
year = {2017}
}
@article{Dineva2014,
abstract = {Dynamic Fracture of Piezoelectric Materials focuses on the Boundary Integral Equation Method as an efficient computational tool. The presentation of the theoretical basis of piezoelectricity is followed by sections on fundamental solutions and the numerical realization of the boundary value problems. Two major parts of the book are devoted to the solution of problems in homogeneous and inhomogeneous solids. The book includes contributions on coupled electro-mechanical models, computational methods, its validation and the simulation results, which reveal different effects useful for engineering design and practice. The book is self-contained and well-illustrated, and it serves as a graduate-level textbook or as extra reading material for students and researchers. Piezoelectric materials -- Fundamental solutions -- Numerical realization by BIEM -- Steady-state problems in a cracked anisotropic domain -- 2D wave scattering by cracks in a piezoelectric plane -- Piezoelectric cracked finite solids under time-harmonic loading -- Dynamic crack interaction in piezoelectric and anisotropic solids -- Different electric boundary conditions -- Part III Functionally graded PEM -- In-plane crack problems in functionally graded piezoelectric solids -- Functionally graded piezoelectric media with a single anti-plane crack -- Multiple anti-plane cracks in quadratically inhomogeneous piezoelectric finite solids -- Anti-plane cracks in exponentially inhomogeneous finite piezoelectric solid -- Exponentially inhomogeneous piezoelectric solid with a circular anti-plane hole -- Anti-plane dynamic crack-hole interaction in a functionally graded piezoelectric medium.},
author = {Dineva, Petia and Gross, Dietmar and M{\"{u}}ller, Ralf and Rangelov, Tsviatko},
doi = {10.1007/978-3-319-03961-9},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dineva et al. - 2014 - Dynamic Fracture of Piezoelectric Materials.pdf:pdf},
isbn = {978-3-319-03960-2},
title = {{Dynamic Fracture of Piezoelectric Materials}},
url = {http://link.springer.com/10.1007/978-3-319-03961-9},
volume = {212},
year = {2014}
}
@article{Golkar2020,
abstract = {The backpropagation algorithm is an invaluable tool for training artificial neural networks; however, because of a weight sharing requirement, it does not provide a plausible model of brain function. Here, in the context of a two-layer network, we derive an algorithm for training a neural network which avoids this problem by not requiring explicit error computation and backpropagation. Furthermore, our algorithm maps onto a neural network that bears a remarkable resemblance to the connectivity structure and learning rules of the cortex. We find that our algorithm empirically performs comparably to backprop on a number of datasets.},
archivePrefix = {arXiv},
arxivId = {2011.15031},
author = {Golkar, Siavash and Lipshutz, David and Bahroun, Yanis and Sengupta, Anirvan M. and Chklovskii, Dmitri B.},
eprint = {2011.15031},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Golkar et al. - 2020 - A biologically plausible neural network for local supervision in cortical microcircuits.pdf:pdf},
number = {NeurIPS 2020},
pages = {1--10},
title = {{A biologically plausible neural network for local supervision in cortical microcircuits}},
url = {http://arxiv.org/abs/2011.15031},
year = {2020}
}
@article{MALMOConference20162016,
author = {{MALMO Conference 2016}},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/MALMO Conference 2016 - 2016 - Social consequences of the fourth industrial revolution.pdf:pdf},
title = {{Social consequences of the fourth industrial revolution}},
year = {2016}
}
@article{Liew2011a,
abstract = {Microarray gene expression data generally suffers from missing value problem due to a variety of experimental reasons. Since the missing data points can adversely affect downstream analysis, many algorithms have been proposed to impute missing values. In this survey, we provide a comprehensive review of existing missing value imputation algorithms, focusing on their underlying algorithmic techniques and how they utilize local or global information from within the data, or their use of domain knowledge during imputation. In addition, we describe how the imputation results can be validated and the different ways to assess the performance of different imputation algorithms, as well as a discussion on some possible future research directions. It is hoped that this review will give the readers a good understanding of the current development in this field and inspire them to come up with the next generation of imputation algorithms.},
author = {Liew, AlanWee Chung and Law, Ngai Fong and Yan, Hong},
doi = {10.1093/bib/bbq080},
isbn = {1477-4054},
issn = {14675463},
journal = {Briefings in Bioinformatics},
keywords = {Gene expression analysis,Gene expression data,Information recovery,Missing value imputation},
number = {5},
pages = {498--513},
pmid = {21156727},
title = {{Missing value imputation for gene expression data: Computational techniques to recover missing data from available information}},
volume = {12},
year = {2011}
}
@article{Girish2020,
abstract = {Recognition tasks, such as object recognition and keypoint estimation, have seen widespread adoption in recent years. Most state-of-the-art methods for these tasks use deep networks that are computationally expensive and have huge memory footprints. This makes it exceedingly difficult to deploy these systems on low power embedded devices. Hence, the importance of decreasing the storage requirements and the amount of computation in such models is paramount. The recently proposed Lottery Ticket Hypothesis (LTH) states that deep neural networks trained on large datasets contain smaller subnetworks that achieve on par performance as the dense networks. In this work, we perform the first empirical study investigating LTH for model pruning in the context of object detection, instance segmentation, and keypoint estimation. Our studies reveal that lottery tickets obtained from ImageNet pretraining do not transfer well to the downstream tasks. We provide guidance on how to find lottery tickets with up to 80% overall sparsity on different sub-tasks without incurring any drop in the performance. Finally, we analyse the behavior of trained tickets with respect to various task attributes such as object size, frequency, and difficulty of detection.},
archivePrefix = {arXiv},
arxivId = {2012.04643},
author = {Girish, Sharath and Maiya, Shishira R. and Gupta, Kamal and Chen, Hao and Davis, Larry and Shrivastava, Abhinav},
eprint = {2012.04643},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Girish et al. - 2020 - The Lottery Ticket Hypothesis for Object Recognition.pdf:pdf},
month = {dec},
number = {NeurIPS},
pages = {1--19},
title = {{The Lottery Ticket Hypothesis for Object Recognition}},
url = {http://arxiv.org/abs/2007.12223 http://arxiv.org/abs/2012.04643},
year = {2020}
}
@article{Luo2015,
abstract = {Few-layer black phosphorus (BP), as the most alluring graphene analogue owing to its similar structure as graphene and thickness dependent direct band-gap, has now triggered a new wave of research on two-dimensional (2D) materials based photonics and optoelectronics. However, a major obstacle of practical applications for few-layer BPs comes from their instabilities of laser-induced optical damage. Herein, we demonstrate that, few-layer BPs, fabricated through the liquid exfoliation approach, can be developed as a new and practical saturable absorber (SA) by depositing few-layer BPs with microfiber. The saturable absorption property of few-layer BPs had been verified through an open-aperture z-scan measurement at the telecommunication band and the microfiber-based BP device had been found to show a saturable average power of $\sim$4.5 mW and a modulation depth of 10.9%, which is further confirmed through a balanced twin detection measurement. By further integrating this optical SA device into an erbium-doped fiber laser, it was found that it can deliver the mode-locked pulse with duration down to 940 fs with central wavelength tunable from 1532 nm to 1570 nm. The prevention of BP from oxidation through the 'lateral interaction scheme' owing to this microfiber-based few-layer BP SA device might partially mitigate the optical damage problem of BP. Our results not only demonstrate that black phosphorus might be another promising SA material for ultrafast photonics, but also provide a practical solution to solve the optical damage problem of black phosphorus by assembling with waveguide structures such as microfiber.},
archivePrefix = {arXiv},
arxivId = {1505.03035},
author = {Luo, Zhi-Chao and Liu, Meng and Guo, Zhi-Nan and Jiang, Xiao-Fang and Luo, Ai-Ping and Zhao, Chu-Jun and Yu, Xue-Feng and Xu, Wen-Cheng and Zhang, Han},
doi = {10.1364/OE.23.020030},
eprint = {1505.03035},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Luo et al. - 2015 - Microfiber-based few-layer black phosphorus saturable absorber for ultra-fast fiber laser.pdf:pdf},
isbn = {978-1-943580-11-8},
issn = {1094-4087},
journal = {Optics Express},
number = {15},
pages = {20030},
pmid = {26367661},
title = {{Microfiber-based few-layer black phosphorus saturable absorber for ultra-fast fiber laser}},
url = {https://www.osapublishing.org/abstract.cfm?URI=oe-23-15-20030},
volume = {23},
year = {2015}
}
@inproceedings{Mirzadeh2020a,
abstract = {Continual (sequential) training and multitask (simultaneous) training are often attempting to solve the same overall objective: to find a solution that performs well on all considered tasks. The main difference is in the training regimes, where continual learning can only have access to one task at a time, which for neural networks typically leads to catastrophic forgetting. That is, the solution found for a subsequent task does not perform well on the previous ones anymore. However, the relationship between the different minima that the two training regimes arrive at is not well understood. What sets them apart? Is there a local structure that could explain the difference in performance achieved by the two different schemes? Motivated by recent work showing that different minima of the same task are typically connected by very simple curves of low error, we investigate whether multitask and continual solutions are similarly connected. We empirically find that indeed such connectivity can be reliably achieved and, more interestingly, it can be done by a linear path, conditioned on having the same initialization for both. We thoroughly analyze this observation and discuss its significance for the continual learning process. Furthermore, we exploit this finding to propose an effective algorithm that constrains the sequentially learned minima to behave as the multitask solution. We show that our method outperforms several state of the art continual learning algorithms on various vision benchmarks1},
archivePrefix = {arXiv},
arxivId = {2010.04495},
author = {Mirzadeh, Seyed Iman and Farajtabar, Mehrdad and Gorur, Dilan and Pascanu, Razvan and Ghasemzadeh, Hassan},
booktitle = {Iclr 2021},
eprint = {2010.04495},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mirzadeh et al. - 2020 - Linear mode connectivity in multitask and continual learning.pdf:pdf},
issn = {23318422},
keywords = {continual learning,multi-task learning},
mendeley-tags = {continual learning,multi-task learning},
title = {{Linear mode connectivity in multitask and continual learning}},
url = {https://arxiv.org/abs/2010.04495 https://github.com/imirzadeh/MC-SGD},
year = {2020}
}
@article{Dimililer2017,
abstract = {Development of automated in-row weed control is one of the costliest and complicated tasks in agricultural industry despite the rapid development of agricultural robotics. Hence, this study proposes an easy-To-implement and accurate system capable of real-Time maize plant detection, which is the key part of the entire weeding machine. Mediterranean farmers use mechanized equipment for dominant crops, however, they suffer a labor-intensive in-row hand weeding. Therefore, this work focuses on a Back propagation neural network system to be a framework for a real-Time maize plant classifier utilizing advanced machine-vision (single-lens vision) techniques. Back Propagation Neural Network (BPNN) incorporates a single-board computer platform. The proposed framework is tested on images that on images that have no-specific distinguishing geometric pattern, varying light conditions. The obtained BPNN results were found to be encouraging considering the time consuming occurs manually to differentiate the maize plant from the other harmful herbs.},
author = {Dimililer, Kamil and Kiani, Ehsan},
doi = {10.1016/j.procs.2017.11.253},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dimililer, Kiani - 2017 - Application of back propagation neural networks on maize plant detection.pdf:pdf},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {Back propagation neural networks,agriculture robotics,maize detection,pattern recognition},
pages = {376--381},
publisher = {Elsevier B.V.},
title = {{Application of back propagation neural networks on maize plant detection}},
url = {https://doi.org/10.1016/j.procs.2017.11.253},
volume = {120},
year = {2017}
}
@article{Zimmer2020,
abstract = {While early AutoML frameworks focused on optimizing traditional ML pipelines and their hyperparameters, a recent trend in AutoML is to focus on neural architecture search. In this paper, we introduce Auto-PyTorch, which brings the best of these two worlds together by jointly and robustly optimizing the architecture of networks and the training hyperparameters to enable fully automated deep learning (AutoDL). Auto-PyTorch achieves state-of-the-art performance on several tabular benchmarks by combining multi-fidelity optimization with portfolio construction for warmstarting and ensembling of deep neural networks (DNNs) and common baselines for tabular data. To thoroughly study our assumptions on how to design such an AutoDL system, we additionally introduce a new benchmark on learning curves for DNNs, dubbed LCBench, and run extensive ablation studies of the full Auto-PyTorch on typical AutoML benchmarks, eventually showing that Auto-PyTorch performs better than several state-of-the-art competitors on average.},
archivePrefix = {arXiv},
arxivId = {2006.13799},
author = {Zimmer, Lucas and Lindauer, Marius and Hutter, Frank},
eprint = {2006.13799},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zimmer, Lindauer, Hutter - 2020 - Auto-PyTorch Tabular Multi-Fidelity MetaLearning for Efficient and Robust AutoDL.pdf:pdf},
keywords = {auto ml,tabular data},
mendeley-tags = {auto ml,tabular data},
month = {jun},
pages = {1--15},
title = {{Auto-PyTorch Tabular: Multi-Fidelity MetaLearning for Efficient and Robust AutoDL}},
url = {http://arxiv.org/abs/2006.13799 https://github.com/automl/Auto-PyTorch},
year = {2020}
}
@book{Castillo2011,
author = {Castillo, Oscar},
isbn = {3642246621},
pages = {199},
publisher = {Springer},
title = {{Type-2 Fuzzy Logic in Intelligent Control Applications}},
year = {2011}
}
@inproceedings{Hsu2018,
abstract = {Continual learning has received a great deal of attention recently with several approaches being proposed. However, evaluations involve a diverse set of scenarios making meaningful comparison difficult. This work provides a systematic categorization of the scenarios and evaluates them within a consistent framework including strong baselines and state-of-the-art methods. The results provide an understanding of the relative difficulty of the scenarios and that simple baselines (Adagrad, L2 regularization, and naive rehearsal strategies) can surprisingly achieve similar performance to current mainstream methods. We conclude with several suggestions for creating harder evaluation scenarios and future research directions. The code is available at https://github.com/GT-RIPL/Continual-Learning-Benchmark},
archivePrefix = {arXiv},
arxivId = {1810.12488},
author = {Hsu, Yen-Chang and Liu, Yen-Cheng and Ramasamy, Anita and Kira, Zsolt},
booktitle = {NeurIPS Continual learning Workshop},
eprint = {1810.12488},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hsu et al. - 2018 - Re-evaluating Continual Learning Scenarios A Categorization and Case for Strong Baselines.pdf:pdf},
issn = {23318422},
keywords = {continual learning,review,survey},
mendeley-tags = {continual learning,review,survey},
month = {oct},
title = {{Re-evaluating Continual Learning Scenarios: A Categorization and Case for Strong Baselines}},
url = {https://arxiv.org/abs/1810.12488},
year = {2018}
}
@article{Dong2008,
abstract = {To overcome the "curse of dimensionality" (which plagues most predictors (predictive models) when carrying out long-term forecasts) and cope with uncertainty present in many time series, in this study, we introduce a concept of granular time series which are used to long-term forecasting and trend forecasting. A technique of fuzzy clustering is used to construct information granules on a basis of available numeric data present in the original time series. In the sequel, we develop a forecasting model which captures the essential relationships between such information granules and in this manner constructs a fundamental forecasting mechanism. It is demonstrated that the proposed model comes with a number of advantages which manifest when processing a large number of data. Experimental evidence is provided through a series of examples using which we quantify the performance of the forecasting model and provide with some comparative analysis. {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
author = {Dong, Ruijun and Pedrycz, Witold},
doi = {10.1016/j.physa.2008.01.095},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dong, Pedrycz - 2008 - A granular time series approach to long-term forecasting and trend forecasting.pdf:pdf},
isbn = {0378-4371},
issn = {03784371},
journal = {Physica A: Statistical Mechanics and its Applications},
keywords = {Forecasting,Granular time series,Information granules,Long-term forecasting,Time series,Trend forecasting},
number = {13},
pages = {3253--3270},
title = {{A granular time series approach to long-term forecasting and trend forecasting}},
volume = {387},
year = {2008}
}
@article{Salehpour2017a,
abstract = {In this paper, a new version of differential evolution (DE) with adaptive mutation factor has been proposed for solving complex optimization problems. The proposed algorithm uses fuzzy logic inference system to dynamically tune the mutation factor of DE and improve its exploration and exploitation. In this way, two factors, named, the number of generation and population diversity are considered as inputs and, one factor, named, the mutation factor as output of the fuzzy logic inference system. The performance of the suggested approach has been tested firstly by using some popular single objective test functions. It has been shown that the proposed method finds better solutions than the classical differential evolution and also the convergence rate of that is really fast. Secondly, a five degree of freedom vehicle vibration model is chosen to be optimally designed by the aforesaid proposed approach. Comparison of the obtained results with those in the literature demonstrates the superiority of the results of this work.},
author = {Salehpour, M. and Jamali, A. and Bagheri, A. and Nariman-zadeh, N.},
doi = {10.1016/j.jestch.2017.01.004},
issn = {22150986},
journal = {Engineering Science and Technology, an International Journal},
keywords = {Differential evolution,Fuzzy logic,Mutation factor,Optimization,Population diversity,Vehicle vibration model},
number = {2},
pages = {587--597},
publisher = {Karabuk University},
title = {{A new adaptive differential evolution optimization algorithm based on fuzzy inference system}},
url = {http://dx.doi.org/10.1016/j.jestch.2017.01.004},
volume = {20},
year = {2017}
}
@article{Bhargava2018,
abstract = {Person Re-Identification is still a challenging task in Computer Vision due to a variety of reasons. On the other side, Incremental Learning is still an issue since deep learning models tend to face the problem of overcatastrophic forgetting when trained on subsequent tasks. In this paper, we propose a model which can be used for multiple tasks in Person Re-Identification, provide state-of-the-art results on a variety of tasks and still achieve considerable accuracy subsequently. We evaluated our model on two datasets Market 1501 and Duke MTMC. Extensive experiments show that this method can achieve Incremental Learning in Person ReID efficiently as well as for other tasks in computer vision as well. The code for this work can be found here},
archivePrefix = {arXiv},
arxivId = {1808.06281},
author = {Bhargava, Prajjwal},
eprint = {1808.06281},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bhargava - 2018 - Incremental learning in person re-identification.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {continual learning,incremental learning,person,person re-identification,re-identificiation},
mendeley-tags = {continual learning,incremental learning,person,person re-identification,re-identificiation},
title = {{Incremental learning in person re-identification}},
year = {2018}
}
@article{Paoli2010,
abstract = {This paper presents an application of Artificial Neural Networks (ANNs) in the renewable energy domain and, more particularly, to predict solar energy. We look at the Multi-Layer Perceptron (MLP) network which has been the most used of ANNs architectures both in the renewable energy domain and in the time series forecasting. In previous studies, we have demonstrated that an optimized ANN with endogenous inputs can forecast the solar radiation on a horizontal surface with acceptable errors. Thus we propose to study the contribution of exogenous meteorological data to our optimized PMC and compare with different forecasting methods used previously: a na{\"{i}}ve forecaster like persistence and an ANN with preprocessing using only endogenous inputs. Although intuitively the use of meteorological data may increase the quality of prediction, the obtained results are relatively mixed. The use of exogenous data generates a decrease of nRMSE between 0.5% and 1% for the two studied locations. The absolute error (RMSE) is decreased by 52 Wh/m2/day in the simple endogenous case and 335 Wh/m2/day for the persistence forecast.},
author = {Paoli, Christophe and Voyant, Cyril and Muselli, Marc and Nivet, Marie Laure},
doi = {10.1109/EEEIC.2010.5490018},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paoli et al. - 2010 - Use of exogenous data to improve an artificial neural networks dedicated to daily global radiation forecasting.pdf:pdf},
isbn = {9781424453719},
journal = {2010 9th Conference on Environment and Electrical Engineering, EEEIC 2010},
keywords = {Artificial neural networks,Multi-layer perceptron,Pre-processing,Prediction,Renewable energy,Solar energy,Time series forecasting},
pages = {49--52},
title = {{Use of exogenous data to improve an artificial neural networks dedicated to daily global radiation forecasting}},
year = {2010}
}
@article{VikasDesai2020,
abstract = {We study the problem of using active learning to reduce annotation effort in training object detectors. Existing efforts in this space ignore the fact that image annotation costs are variable, depending on the number of objects present in a single image. In this regard, we examine a fine-grained sampling based approach for active learning in object detection. Over an unlabeled pool of images, our method aims to selectively pick the most informative subset of bounding boxes (as opposed to full images) to query an annotator. We measure annotation efforts in terms of the number of ground truth bounding boxes obtained. We study the effects of our method on the Feature Pyramid Network and RetinaNet models, and show promising savings in labeling effort to obtain good detection performance.},
author = {{Vikas Desai}, Sai and Balasubramanian, Vineeth N.},
doi = {10.1109/CVPRW50498.2020.00470},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vikas Desai, Balasubramanian - 2020 - Towards fine-grained sampling for active learning in object detection.pdf:pdf},
isbn = {9781728193601},
issn = {21607516},
journal = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
keywords = {active learning,object detection},
mendeley-tags = {active learning,object detection},
number = {ii},
pages = {4010--4014},
title = {{Towards fine-grained sampling for active learning in object detection}},
volume = {2020-June},
year = {2020}
}
@article{Coppa2014,
abstract = {Near (NIR) and medium (MIR) infrared reflectance spectroscopy (IR) predictions of fatty acid (FA) composition, expressed as g/kg of milk or g/100 g of FA, on fresh and thawed milk were compared. Two-hundred-and-fifty bulk cow milks, collected from 70 farms in northwest Italy, were scanned by MIR in liquid form and by NIR in liquid and oven-dried forms. MIR and NIR FA (g/100 g FA) predictions on oven-dried milk were similar for the sum of even chain-saturated FA (ECSFA), odd chain-FA (OCFA), unsaturated FA (UFA), conjugated linoleic acid (CLA), n-3 FA, and C18:1cis9 to C16 ratio. The monounsaturated FA (MUFA), n-6 to n-3 ratio, polyunsaturated FA (PUFA), and n-6 FA were predicted better by NIR on oven-dried milk. The NIR showed worse predictions than MIR for almost all FA, when expressed as g/kg of milk. The NIR predictions on fresh liquid and oven-dried milk were similar, but the reliability decreased for thawed liquid milk. The high performance shown by NIR and MIR allows their use for routine milk FA composition recording. {\textcopyright} 2013 Elsevier Ltd. All rights reserved.},
author = {Coppa, Mauro and Revello-Chion, Andrea and Giaccone, Daniele and Ferlay, Anne and Tabacco, Ernesto and Borreani, Giorgio},
doi = {10.1016/j.foodchem.2013.10.087},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Coppa et al. - 2014 - Comparison of near and medium infrared spectroscopy to predict fatty acid composition on fresh and thawed milk.pdf:pdf},
isbn = {0308-8146 (Print)\r0308-8146 (Linking)},
issn = {18737072},
journal = {Food Chemistry},
keywords = {Medium infrared reflectance spectroscopy (MIR),Milk fatty acids,Near infrared reflectance spectroscopy (NIR)},
pages = {49--57},
pmid = {24360418},
publisher = {Elsevier Ltd},
title = {{Comparison of near and medium infrared spectroscopy to predict fatty acid composition on fresh and thawed milk}},
url = {http://dx.doi.org/10.1016/j.foodchem.2013.10.087},
volume = {150},
year = {2014}
}
@article{Koizumi2013,
abstract = {—To remedy the paucity of studies on the relationship between vocabulary knowledge and speaking proficiency, we examine the degree to which second language (L2) speaking proficiency can be predicted by the size, depth, and speed of L2 vocabulary among novice to intermediate Japanese learners of English. Studies 1 and 2 administered vocabulary tests and a speaking test to 224 and 87 L2 learners, respectively. Analyses using structural equation modeling demonstrated that a substantial proportion of variance in speaking proficiency can be explained by vocabulary knowledge, size, depth, and speed. These results suggest the centrality of vocabulary knowledge to speaking proficiency.},
author = {Koizumi, Rie and In'nami, Yo},
doi = {10.4304/jltr.4.5.900-913},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Koizumi, In'nami - 2013 - Vocabulary Knowledge and Speaking Proficiency among Second Language Learners from Novice to Intermediate Lev.pdf:pdf},
isbn = {1798-4769},
issn = {1798-4769},
journal = {Journal of Language Teaching and Research},
number = {5},
pages = {900--913},
title = {{Vocabulary Knowledge and Speaking Proficiency among Second Language Learners from Novice to Intermediate Levels}},
url = {http://www.academypublication.com/issues/past/jltr/vol04/05/02.pdf},
volume = {4},
year = {2013}
}
@article{Diesmann1999,
abstract = {The classical view of neural coding has emphasized the importance of information carried by the rate at which neurons discharge action potentials. More recent proposals that information may be carried by precise spike timing have been challenged by the assumption that these neurons operate in a noisy fashion - presumably reflecting fluctuations in synaptic input and, thus, incapable of transmitting signals with millisecond fidelity. Here we show that precisely synchronized action potentials can propagate within a model of cortical network activity that recapitulates many of the features of biological systems. An attractor, yielding a stable spiking precision in the (sub)millisecond range, governs the dynamics of synchronization. Our results indicate that a combinatorial neural code, based on rapid associations of groups of neurons co-ordinating their activity at the single spike level, is possible within a cortical-like network.},
author = {Diesmann, Markus and Gewaltig, Marc-Oliver and Aertsen, Ad},
doi = {10.1038/990101},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Diesmann, Gewaltig, Aertsen - 1999 - Stable propagation of synchronous spiking in cortical neural networks.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
month = {dec},
number = {6761},
pages = {529--533},
pmid = {10591212},
title = {{Stable propagation of synchronous spiking in cortical neural networks}},
url = {http://www.nature.com/articles/990101},
volume = {402},
year = {1999}
}
@inproceedings{Raghu2020,
abstract = {Effective training of deep neural networks can be challenging, and there remain many open questions on how to best learn these models. Recently developed methods to improve neural network training examine teaching: providing learned information during the training process to improve downstream model performance. In this paper, we take steps towards extending the scope of teaching. We propose a flexible teaching framework using commentaries, meta-learned information helpful for training on a particular task or dataset. We present an efficient and scalable gradient-based method to learn commentaries, leveraging recent work on implicit differentiation. We explore diverse applications of commentaries, from learning weights for individual training examples, to parameterizing label-dependent data augmentation policies, to representing attention masks that highlight salient image regions. In these settings, we find that commentaries can improve training speed and/or performance and also provide fundamental insights about the dataset and training process.},
archivePrefix = {arXiv},
arxivId = {2011.03037},
author = {Raghu, Aniruddh and Raghu, Maithra and Kornblith, Simon and Duvenaud, David and Hinton, Geoffrey},
booktitle = {Iclr 2021},
eprint = {2011.03037},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Raghu et al. - 2020 - Teaching with Commentaries.pdf:pdf},
keywords = {knowledge distillation},
mendeley-tags = {knowledge distillation},
pages = {1--20},
title = {{Teaching with Commentaries}},
url = {http://arxiv.org/abs/2011.03037},
year = {2020}
}
@article{Pelikan2010,
author = {Pelikan, M.},
doi = {10.1016/B978-0-12-409545-8.00005-4},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pelikan - 2010 - Genetic Algorithms in.pdf:pdf},
isbn = {9780471488897},
journal = {Wiley Encyclopedia of Operations Research and Management Science},
pages = {1--9},
title = {{Genetic Algorithms in}},
year = {2010}
}
@article{Roweis1996,
abstract = {Levenberg-Marquardt Optimization is a virtual standard in nonlinear optimization which signi cantly outperforms gradient descent and conjugate gradient methods for medium sized problems. It is a pseudo-second order method which means that it works with only function evaluations and gradient information but it estimates the Hessian matrix using the sum of outer products of the gradients. This note reviews the mathematical motivations for Levenberg-Marquardt and also details the algorithm.},
author = {Roweis, Sam},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roweis - 1996 - Levenberg-Marquardt Optimization.pdf:pdf},
isbn = {1420050435},
journal = {Notes, University Of Toronto},
title = {{Levenberg-Marquardt Optimization}},
year = {1996}
}
@article{Dongyu2015,
abstract = {Abstract Here the 1-3 connectivity cement/polymer based piezoelectric composites with varied piezoelectric phase distribution were designed. The dielectric, piezoelectric and electromechanical properties of the composites were studied. The results indicate that the composite with varied distribution of piezoelectric ceramic has large relative permittivity, piezoelectric strain constant and electromechanical coupling coefficient at the thickness vibration mode. The composites with varied distribution of matrix phase have larger piezoelectric voltage constant, smaller mechanical quality factor and acoustic impedance value than those with varied distribution of piezoelectric ceramic phase. The electromechanical coupling property of the composites at the planar vibration mode shows obvious dependence on matrix phase distribution. The novel piezoelectric composites show potential applications in fabricating ultrasonic transducers with specific surface vibration amplitude.},
author = {Dongyu, Xu and Xin, Cheng and Hongda, Geng and Fan, Lu and Shifeng, Huang},
doi = {10.1016/j.ceramint.2015.03.324},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dongyu et al. - 2015 - Design, fabrication and properties of 1-3 piezoelectric ceramic composites with varied piezoelectric phase distri.pdf:pdf},
isbn = {0021-8979 (Print)\r0021-8979 (Linking)},
issn = {02728842},
journal = {Ceramics International},
keywords = {Cement based material,Piezoelectricity,Smart composite},
number = {8},
pages = {9433--9442},
pmid = {25565725},
publisher = {Elsevier},
title = {{Design, fabrication and properties of 1-3 piezoelectric ceramic composites with varied piezoelectric phase distribution}},
url = {http://dx.doi.org/10.1016/j.ceramint.2015.03.324},
volume = {41},
year = {2015}
}
@article{Thresholds2020,
abstract = {Self-supervised representation learning approaches have recently surpassed their supervised learning counterparts on downstream tasks like object detection and image classification. Somewhat mysteriously the recent gains in performance come from training instance classification models, treating each image and it's augmented versions as samples of a single class. In this work, we first present quantitative experiments to demystify these gains. We demonstrate that approaches like MOCO[1] and PIRL[2] learn occlusion-invariant representations. However, they fail to capture viewpoint and category instance invariance which are crucial components for object recognition. Second, we demonstrate that these approaches obtain further gains from access to a clean object-centric training dataset like Imagenet. Finally, we propose an approach to leverage unstructured videos to learn representations that possess higher viewpoint invariance. Our results show that the learned representations outperform MOCOv2 trained on the same data in terms of invariances encoded and the performance on downstream image classification and semantic segmentation tasks.},
archivePrefix = {arXiv},
arxivId = {2007.13916},
author = {Thresholds, Chosen and Firing, Local and Since, Rate and Since, Invariance Scores and Top-k, The and For, Dataset Creation and Purushwalkam, Senthil and Gupta, Abhinav},
eprint = {2007.13916},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thresholds et al. - 2020 - Demystifying contrastive self-supervised learning Invariances, augmentations and dataset biases.pdf:pdf;:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thresholds et al. - 2020 - Demystifying contrastive self-supervised learning Invariances, augmentations and dataset biases(2).pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
pages = {1--12},
title = {{Demystifying contrastive self-supervised learning: Invariances, augmentations and dataset biases}},
year = {2020}
}
@article{Ansotegui2013,
abstract = {Many industrial optimization problems can be translated to MaxSAT. Although the general problem is NP hard, like SAT, many practical problems may be solved using modern MaxSAT solvers. In this paper we present several algorithms specially designed to deal with industrial or real problems. All of them are based on the idea of solving MaxSAT through successive calls to a SAT solver. We show that this SAT-based technique is efficient in solving industrial problems. In fact, all state-of-the-art MaxSAT solvers that perform well in industrial instances are based on this technique. In particular, our solvers won the 2009 partial MaxSAT and the 2011 weighted partial MaxSAT industrial categories of the MaxSAT evaluation. We prove the correctness of all our algorithms. We also present a complete experimental study comparing the performance of our algorithms with latest MaxSAT solvers. {\textcopyright} 2013 Elsevier B.V.},
author = {Ans{\'{o}}tegui, Carlos and Bonet, Maria Luisa and Levy, Jordi},
doi = {10.1016/j.artint.2013.01.002},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ans{\'{o}}tegui, Bonet, Levy - 2013 - SAT-based MaxSAT algorithms.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {Boolean optimization,MaxSAT,SAT},
pages = {77--105},
publisher = {Elsevier B.V.},
title = {{SAT-based MaxSAT algorithms}},
url = {http://dx.doi.org/10.1016/j.artint.2013.01.002},
volume = {196},
year = {2013}
}
@article{Chitra2015,
abstract = {This paper was an attempt to apply Auto-Regressive Integrated Moving Average (ARIMA) model in Supply Chain management (SCM) of fresh vegetables analysis using SPSS Software.The ARIMA methodology developed by Box and Jenkins was used in this paper. Time Series refers an ordered sequence of values of a variable at equally spaced time intervals. Time series occur frequently when looking at agricultural data applications. The analysis was carried out using time series data on the supply of fresh vegetables during the period from 2002 to 2011 which was collected from the office of the Deputy Directorate of Agri-business situated at Madurai, India. The analysis of monthly supply and price of vegetables data was used to find out seasonal pattern. The seasonal index for vegetable supply was highest in March and April and was lower in the November and December. The seasonal variation in vegetables price was high in the period of November to January and price low in March. It was further inferred that forecast value for the supply of fresh brinjal , Bhendi and Green Chilly was low in January'13 and it was high in December for these vegetables whereas in the forecasted value for the supply of fresh tomato and green chilly variations were found. The study suggested that cold storage capacities may be developed in the needy places to increase the benefits of consumers and farmers to increase the efficiency of Supply Chain Management.},
author = {Chitra, N and Shanmathi, Ra and Rajesh, R},
journal = {International Journal of Science Technology & Management},
keywords = {auto-regressive integrated moving average,model,seasonal index,spss software,supply chain management,time series analysis},
number = {01},
pages = {206--215},
title = {{Application of ARIMA Model Using SPSS Software - A Case Study in Supply Chain Management}},
url = {www.ijstm.com},
year = {2015}
}
@article{Berger1988a,
abstract = {The influence of exercise mode and practice qualities on the stress reduction benefits of exercise was examined. College students in swimming, body conditioning, hatha yoga, fencing, exercise, and lecture-control classes completed the Profile of Mood States and the State Anxiety Inventory before and after class on three occasions. Swimmers had unusually positive initial moods and reported less tension and confusion after swimming only on the first day of testing. Participants in yoga, an anaerobic activity that satisfied three of the four mode requirements, were significantly less anxious, tense, depressed, angry, fatigued, and confused after class than before on all three occasions. Supporting the importance of the four mode characteristics, participants in the exercise control activity of fencing reported improvements only in vigor. A possible influence of practice conditions was observed when members of the body conditioning class reported significant increases in fatigue, but no other mood changes. Results of this study supported the possibility that exercise mode and practice requirements in the proposed taxonomy moderate the stress reduction benefits.},
author = {Berger, Bonnie G. and Owen, David R.},
doi = {10.1080/02701367.1988.10605493},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Berger, Owen - 1988 - Stress reduction and mood enhancement in four exercise modes Swimming, body conditioning, hatha yoga, and fencing.pdf:pdf},
isbn = {0270-1367},
issn = {21683824},
journal = {Research Quarterly for Exercise and Sport},
number = {2},
pages = {148--159},
title = {{Stress reduction and mood enhancement in four exercise modes: Swimming, body conditioning, hatha yoga, and fencing}},
volume = {59},
year = {1988}
}
@article{Kuzniar2011,
abstract = {Two techniques of neural network input data pre-processing are discussed in the paper: (i) data compression with the application of the principal component analysis method, (ii) various forms of data scaling. Neural networks are applied for the prediction of the first natural frequencies of horizontal vibrations of modified medium height load-bearing walls. The small and the large changes of the wall stiffness and mass resulted from the new door openings size and position are taken into account. The influence of the type of data pre-processing technique on the accuracy of the frequencies neural prediction is discussed.},
author = {Ku{\'{z}}niar, Krystyna and Zaj{\c{a}}c, Maciej},
journal = {[Online] CMM-2011 - Computer Methods in Mechanics http://www.cmm.il.pw.edu.pl/cd/pdf/120.pdf},
keywords = {0,11,14m,5 storeys x 2,7m width and 14m,8m,dynamics,height,neural networks,vibrations},
number = {May},
title = {{Data pre-processing in the neural network identification of the modified walls natural frequencies}},
url = {http://www.cmm.il.pw.edu.pl/cd/pdf/120.pdf},
year = {2011}
}
@article{Guo2017a,
abstract = {Wind energy is one of the most promising renewable energy and wind farm is globally constructed for sustainable development. However, wind could produce adverse effects on some wind-sensitive tasks of wind turbine construction projects. Due to limited understanding of how wind may influence productivity in wind turbine construction project, this research presents a fuzzy duration forecast model for wind turbine construction project subject to the impact of wind uncertainty. Through the use of Beaufort scale, professional expertise, and fuzzy membership functions, the productivity loss (PL) subject to various Beaufort scale of wind can be analyzed. With historical wind speed data incorporated, the duration can be simulated and forecasted by the model. Besides, the practicality of the model is demonstrated by an actual wind turbine construction project. The findings from this research are very useful in allocating schedule risk for wind turbine construction projects where wind uncertainty arises.},
author = {Guo, Sy Jye and Chen, Jung Hsing and Chiu, Chia Hsin},
doi = {10.1016/j.autcon.2017.03.009},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guo, Chen, Chiu - 2017 - Fuzzy duration forecast model for wind turbine construction project subject to the impact of wind uncertainty.pdf:pdf},
isbn = {0926-5805},
issn = {09265805},
journal = {Automation in Construction},
keywords = {Duration forecast,Fuzzy modeling,Impact of wind uncertainty,Wind turbine construction},
pages = {401--410},
publisher = {Elsevier B.V.},
title = {{Fuzzy duration forecast model for wind turbine construction project subject to the impact of wind uncertainty}},
url = {http://dx.doi.org/10.1016/j.autcon.2017.03.009},
volume = {81},
year = {2017}
}
@article{Martens2015,
abstract = {We propose an efficient method for approximating natural gradient descent in neural networks which we call Kronecker-factored Approximate Curvature (K-FAC). K-FAC is based on an efficiently invertible approximation of a neural network's Fisher information matrix which is neither diagonal nor low-rank, and in some cases is completely non-sparse. It is derived by approximating various large blocks of the Fisher (corresponding to entire layers) as being the Kronecker product of two much smaller matrices. While only several times more expensive to compute than the plain stochastic gradient, the updates produced by K-FAC make much more progress optimizing the objective, which results in an algorithm that can be much faster than stochastic gradient descent with momentum in practice. And unlike some previously proposed approximate natural-gradient/Newton methods which use high-quality non-diagonal curvature matrices (such as Hessian-free optimization), K-FAC works very well in highly stochastic optimization regimes. This is because the cost of storing and inverting K-FAC's approximation to the curvature matrix does not depend on the amount of data used to estimate it, which is a feature typically associated only with diagonal or low-rank approximations to the curvature matrix.},
archivePrefix = {arXiv},
arxivId = {1503.05671},
author = {Martens, James and Grosse, Roger},
eprint = {1503.05671},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Martens, Grosse - 2015 - Optimizing neural networks with Kronecker-factored approximate curvature.pdf:pdf},
isbn = {9781510810587},
journal = {32nd International Conference on Machine Learning, ICML 2015},
pages = {2398--2407},
title = {{Optimizing neural networks with Kronecker-factored approximate curvature}},
volume = {3},
year = {2015}
}
@article{Allegretti2008,
abstract = {The demand for efficient optical active devices operating in the near and medium infrared wavelength ranges is originated from different needs. This wavelength band is of strong interest in a number of applications as remote sensing, sensors, optical communication, medical and military technology. The paper is a review on the NIR and MID-IR fiber optic lasers, also with reference to the host materials and the dopants employed for their construction, and the corresponding applications. An example of MID-IR fiber optic laser design is mentioned. {\textcopyright} 2008 IEEE.},
author = {Allegretti, L. and Cal{\`{o}}, G. and D'Orazio, A. and Sario, M. De and Mescia, L. and Palmisano, T. and Petruzzelli, V. and Prudenzano, F.},
doi = {10.1109/ICTON.2008.4598409},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Allegretti et al. - 2008 - Near and medium infrared fiber optic lasers and applications.pdf:pdf},
isbn = {9781424426256},
journal = {Proceedings of 2008 10th Anniversary International Conference on Transparent Optical Networks, ICTON},
keywords = {Chalcogenide glasses,Fiber optic lasers,Infrared lasers,Optical properties,Rare earth dopants},
pages = {210--213},
title = {{Near and medium infrared fiber optic lasers and applications}},
volume = {1},
year = {2008}
}
@article{Padhi,
author = {Padhi, Radhakant},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Padhi - Unknown - Pole Placement Control Design.pdf:pdf},
journal = {Design},
title = {{Pole Placement Control Design}}
}
@article{Zeng2017,
abstract = {Reliable energy consumption forecasting can provide effective decision-making support for planning development strategies to energy enterprises and for establishing national energy policies. Accordingly, the present study aims to apply a hybrid intelligent approach named ADE–BPNN, the back-propagation neural network (BPNN) model supported by an adaptive differential evolution algorithm, to estimate energy consumption. Most often, energy consumption is influenced by socioeconomic factors. The proposed hybrid model incorporates gross domestic product, population, import, and export data as inputs. An improved differential evolution with adaptive mutation and crossover is utilized to find appropriate global initial connection weights and thresholds to enhance the forecasting performance of the BPNN. A comparative example and two extended examples are utilized to validate the applicability and accuracy of the proposed ADE–BPNN model. Errors of the test data sets indicate that the ADE–BPNN model can effectively predict energy consumption compared with the traditional back-propagation neural network model and other popular existing models. Moreover, mean impact value based analysis is conducted for electrical energy consumption in U.S. and total energy consumption forecasting in China to quantitatively explore the relative importance of each input variable for the improvement of effective energy consumption prediction.},
author = {Zeng, Yu Rong and Zeng, Yi and Choi, Beomjin and Wang, Lin},
doi = {10.1016/j.energy.2017.03.094},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zeng et al. - 2017 - Multifactor-influenced energy consumption forecasting using enhanced back-propagation neural network.pdf:pdf},
issn = {03605442},
journal = {Energy},
keywords = {Adaptive differential evolution,Back-propagation neural network,Energy consumption,Mean impact value,Multifactor-influenced forecasting},
pages = {381--396},
publisher = {Elsevier Ltd},
title = {{Multifactor-influenced energy consumption forecasting using enhanced back-propagation neural network}},
url = {http://dx.doi.org/10.1016/j.energy.2017.03.094},
volume = {127},
year = {2017}
}
@article{Vihinen2012,
abstract = {BACKGROUND: Prediction methods are increasingly used in biosciences to forecast diverse features and characteristics. Binary two-state classifiers are the most common applications. They are usually based on machine learning approaches. For the end user it is often problematic to evaluate the true performance and applicability of computational tools as some knowledge about computer science and statistics would be needed.\n\nRESULTS: Instructions are given on how to interpret and compare method evaluation results. For systematic method performance analysis is needed established benchmark datasets which contain cases with known outcome, and suitable evaluation measures. The criteria for benchmark datasets are discussed along with their implementation in VariBench, benchmark database for variations. There is no single measure that alone could describe all the aspects of method performance. Predictions of genetic variation effects on DNA, RNA and protein level are important as information about variants can be produced much faster than their disease relevance can be experimentally verified. Therefore numerous prediction tools have been developed, however, systematic analyses of their performance and comparison have just started to emerge.\n\nCONCLUSIONS: The end users of prediction tools should be able to understand how evaluation is done and how to interpret the results. Six main performance evaluation measures are introduced. These include sensitivity, specificity, positive predictive value, negative predictive value, accuracy and Matthews correlation coefficient. Together with receiver operating characteristics (ROC) analysis they provide a good picture about the performance of methods and allow their objective and quantitative comparison. A checklist of items to look at is provided. Comparisons of methods for missense variant tolerance, protein stability changes due to amino acid substitutions, and effects of variations on mRNA splicing are presented.},
author = {Vihinen, Mauno},
doi = {10.1186/1471-2164-13-S4-S2},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vihinen - 2012 - How to evaluate performance of prediction methods Measures and their interpretation in variation effect analysis.pdf:pdf},
isbn = {1471-2164 (Electronic)\r1471-2164 (Linking)},
issn = {14712164},
journal = {BMC genomics},
number = {Suppl 4},
pages = {S2},
pmid = {22759650},
publisher = {BioMed Central Ltd},
title = {{How to evaluate performance of prediction methods? Measures and their interpretation in variation effect analysis.}},
url = {http://www.biomedcentral.com/1471-2164/13/S4/S2},
volume = {13 Suppl 4},
year = {2012}
}
@article{Thong2016,
abstract = {{\textcopyright} 2016 IEEE. Weather nowcasting is a short-range forecasting that maps current weather, then uses an estimation of its speed and direction of movement to forecast weather in a short period ahead -Assuming the weather will move without significant changes. It operates through latest radar, satellite or observational data. However, flawed characterization of transitions between different meteorological structures is its main challenges. In this paper, an innovative method for weather nowcasting from satellite image sequences using the combination of picture fuzzy clustering and interpolative fuzzy rules is proposed. Firstly, picture fuzzy clustering algorithm, a fuzzy clustering method based on the theory of picture fuzzy set, is used to partition the satellite image pixels into clusters. Secondly, the interpolative trapezoidal picture fuzzy rules are created from the clusters. Finally, particle swarm optimization is employed to train the defuzzified parameter from the rules to enhance the accuracy of the predicted satellite images in sequence. The experimental results indicate that the proposed method is better than the relevant ones for weather nowcasting.},
author = {Thong, Pham Huy and Son, Le Hoang and Fujita, Hamido},
doi = {10.1109/FUZZ-IEEE.2016.7737672},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thong, Son, Fujita - 2016 - Interpolative picture fuzzy rules A novel forecast method for weather nowcasting.pdf:pdf},
isbn = {9781509006250},
journal = {2016 IEEE International Conference on Fuzzy Systems, FUZZ-IEEE 2016},
keywords = {Interpolative picture fuzzy rules,Picture fuzzy clustering,Picture fuzzy sets,Satellite images,Weather nowcasting},
pages = {86--93},
title = {{Interpolative picture fuzzy rules: A novel forecast method for weather nowcasting}},
year = {2016}
}
@article{Zhao2020a,
abstract = {With the memory-resource-limited constraints, class-incremental learning (CIL) usually suffers from the “catastrophic forgetting” problem when updating the joint classification model on the arrival of newly added classes. To cope with the forgetting problem, many CIL methods transfer the knowledge of old classes by preserving some exemplar samples into the size-constrained memory buffer. To utilize the memory buffer more efficiently, we propose to keep more auxiliary low-fidelity exemplar samples rather than the original real high-fidelity exemplar samples. Such memory-efficient exemplar preserving scheme make the old-class knowledge transfer more effective. However, the low-fidelity exemplar samples are often distributed in a different domain away from that of the original exemplar samples, that is, a domain shift. To alleviate this problem, we propose a duplet learning scheme that seeks to construct domain-compatible feature extractors and classifiers, which greatly narrows down the above domain gap. As a result, these low-fidelity auxiliary exemplar samples have the ability to moderately replace the original exemplar samples with a lower memory cost. In addition, we present a robust classifier adaptation scheme, which further refines the biased classifier (learned with the samples containing distillation label knowledge about old classes) with the help of the samples of pure true class labels. Experimental results demonstrate the effectiveness of this work against the state-of-the-art approaches. We will release the code, baselines, and training statistics for all models to facilitate future research.},
archivePrefix = {arXiv},
arxivId = {2008.01411},
author = {Zhao, Hanbin and Wang, Hui and Fu, Yongjian and Wu, Fei and Li, Xi},
eprint = {2008.01411},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao et al. - 2020 - Memory efficient class-incremental learning for image classification.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {Catastrophic Forgetting,Class-incremental Learning,Classification,Exemplar,Memory Efficient,continual learning,incremental learning,memory-efficient},
mendeley-tags = {continual learning,incremental learning,memory-efficient},
number = {X},
pages = {1--10},
title = {{Memory efficient class-incremental learning for image classification}},
volume = {XX},
year = {2020}
}
@article{Sutskever2009,
abstract = {The Temporal Restricted Boltzmann Machine (TRBM) is a probabilistic model for sequences that is able to successfully model (i.e., generate nice-looking samples of) several very high dimensional sequences, such as motion capture data and the pixels of low resolution videos of balls bouncing in a box. The major disadvantage of the TRBM is that exact inference is extremely hard, since even computing a Gibbs update for a single variable of the posterior is exponentially expensive. This difficulty has necessitated the use of a heuristic inference procedure, that nonetheless was accurate enough for successful learning. In this paper we introduce the Recurrent TRBM, which is a very slight modification of the TRBM for which exact inference is very easy and exact gradient learning is almost tractable. We demonstrate that the RTRBM is better than an analogous TRBM at generating motion capture and videos of bouncing balls.},
author = {Sutskever, Ilya and Hinton, Geoffrey and Taylor, Graham},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sutskever, Hinton, Taylor - 2009 - The recurrent temporal restricted boltzmann machine.pdf:pdf},
isbn = {9781605609492},
journal = {Advances in Neural Information Processing Systems 21 - Proceedings of the 2008 Conference},
pages = {1601--1608},
title = {{The recurrent temporal restricted boltzmann machine}},
year = {2009}
}
@inproceedings{Koh2022,
archivePrefix = {arXiv},
arxivId = {arXiv:2110.10031v1},
author = {Koh, Hyunseo and Kim, Dahyun and Ha, Jung-woo and Choi, Jonghyun and Korea, South},
booktitle = {International Conference on Learning Representations},
eprint = {arXiv:2110.10031v1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Koh et al. - 2022 - Online Continual Learning On Class Incremental Blurry Task Configuration With Anytime Inference.pdf:pdf},
keywords = {continual learning},
mendeley-tags = {continual learning},
pages = {1--17},
title = {{Online Continual Learning On Class Incremental Blurry Task Configuration With Anytime Inference}},
year = {2022}
}
@article{Ekpenyong2013,
abstract = {Photovoltaic (PV) power systems have been widely applied in commercial and domestic facilities. Electrical Energy Storage (EES) systems are mandatory in standalone PV systems for continuous power supply. In this paper the efficiency and robustness enhancement methods for PV systems under partial shading have been investigated. Partial shading due to moving clouds and shadows of nearby obstacles on the PV module array causes significant efficiency degradation, since shaded and non-shaded PV modules have large discrepancy in their maximum power points. Use of by-pass diodes for each PV module may mitigate the negative effect from partial shading. However, this method alone may still face severe energy efficiency degradation caused by the energy loss due to parasitic effects in the EES elements under variable incoming power from the PV modules. Hence, this paper investigates the effect of shading on photovoltaic cells.},
author = {Ekpenyong, E E and Anyasi, F},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ekpenyong, Anyasi - 2013 - Effect of Shading on Photovoltaic Cell.pdf:pdf},
journal = {IOSR Journal of Electrical and Electronics Engineering},
number = {2},
pages = {2278--1676},
title = {{Effect of Shading on Photovoltaic Cell}},
url = {www.iosrjournals.org},
volume = {8},
year = {2013}
}
@article{Yang2017a,
abstract = {lp−lq problems with 0 < p, q ≤ 2 have received significant attentions in image restoration and compressive sensing. Half-quadratic regularization method is usually a technique to solve this problem. To improve the performance of this technique, instead of conjugate gradient(CG) method, we propose an alternating direction method of multipliers (ADMM) as the inner iterations to solve the corresponding linear equations. The convergence of the resulting algorithm is discussed. Numerical results related to some image restoration and reconstruction problems are presented to demonstrate the effectiveness of our method.},
author = {Yang, Xiaojuan and Wang, Li},
doi = {10.1016/j.apm.2017.05.031},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang, Wang - 2017 - Fast half-quadratic algorithm for image restoration and reconstruction.pdf:pdf},
issn = {0307904X},
journal = {Applied Mathematical Modelling},
keywords = {Alternating direction method,Half-quadratic,Impulse noise,Magnetic resonance imaging,Regularization},
pages = {92--104},
publisher = {Elsevier Inc.},
title = {{Fast half-quadratic algorithm for image restoration and reconstruction}},
url = {http://dx.doi.org/10.1016/j.apm.2017.05.031},
volume = {50},
year = {2017}
}
@article{WadeJr.2003,
abstract = {Theory and Interpretation of IR spectra ASSIGNED READINGS • Introduction to technique 25 (p. 833-834 in lab textbook) • Uses of the Infrared Spectrum (p. 847-853) • Look over pages 853-866 after viewing this presentation for additional examples of various functional groups. • Emphasis is on data interpretation, not on data memorization.},
author = {Wade,Jr., L.G.},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wade,Jr. - 2003 - ( IR ) Theory and Interpretation of IR spectra presentation for additional examples of How do we know.pdf:pdf},
journal = {Organic Chemistry},
pages = {853--866},
title = {{( IR ) Theory and Interpretation of IR spectra presentation for additional examples of How do we know}},
volume = {5th},
year = {2003}
}
@article{Gordon2018,
abstract = {We present MorphNet, an approach to automate the design of neural network structures. MorphNet iteratively shrinks and expands a network, shrinking via a resource-weighted sparsifying regularizer on activations and expanding via a uniform multiplicative factor on all layers. In contrast to previous approaches, our method is scalable to large networks, adaptable to specific resource constraints (e.g. the number of floating-point operations per inference), and capable of increasing the network's performance. When applied to standard network architectures on a wide variety of datasets, our approach discovers novel structures in each domain, obtaining higher performance while respecting the resource constraint.},
archivePrefix = {arXiv},
arxivId = {1711.06798},
author = {Gordon, Ariel and Eban, Elad and Nachum, Ofir and Chen, Bo and Wu, Hao and Yang, Tien Ju and Choi, Edward},
doi = {10.1109/CVPR.2018.00171},
eprint = {1711.06798},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gordon et al. - 2018 - MorphNet Fast & Simple Resource-Constrained Structure Learning of Deep Networks.pdf:pdf},
isbn = {9781538664209},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
number = {1},
pages = {1586--1595},
title = {{MorphNet: Fast & Simple Resource-Constrained Structure Learning of Deep Networks}},
year = {2018}
}
@article{Robbins1951,
abstract = {Let M(x) denote the expected value at level x of the response to a certain experiment. M(x) is assumed to be a monotone function of x but is unknown to the experimenter, and it is desired to find the solution x = $\theta$ of the equation M(x) = $\alpha$, where $\alpha$ is a given constant. We give a method for making successive experiments at levels x1,x2,⋯ in such a way that xn will tend to $\theta$ in probability.},
author = {Robbins, Herbert and Monro, Sutton},
doi = {10.1214/aoms/1177729586},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Robbins, Monro - 1951 - A Stochastic Approximation Method.pdf:pdf},
issn = {0003-4851},
journal = {The Annals of Mathematical Statistics},
number = {3},
pages = {400--407},
title = {{A Stochastic Approximation Method}},
volume = {22},
year = {1951}
}
@inproceedings{Caron2018,
abstract = {Clustering is a class of unsupervised learning methods that has been extensively applied and studied in computer vision. Little work has been done to adapt it to the end-to-end training of visual features on large-scale datasets. In this work, we present DeepCluster, a clustering method that jointly learns the parameters of a neural network and the cluster assignments of the resulting features. DeepCluster iteratively groups the features with a standard clustering algorithm, k-means, and uses the subsequent assignments as supervision to update the weights of the network. We apply DeepCluster to the unsupervised training of convolutional neural networks on large datasets like ImageNet and YFCC100M. The resulting model outperforms the current state of the art by a significant margin on all the standard benchmarks.},
archivePrefix = {arXiv},
arxivId = {1807.05520},
author = {Caron, Mathilde and Bojanowski, Piotr and Joulin, Armand and Douze, Matthijs},
booktitle = {European Conference on Computer Vision},
doi = {10.1007/978-3-030-01264-9_9},
eprint = {1807.05520},
file = {:home/user/Downloads/Mathilde_Caron_Deep_Clustering_for_ECCV_2018_paper.pdf:pdf},
isbn = {9783030012632},
issn = {16113349},
keywords = {Clustering,Unsupervised learning,representation learning,self-supervised learning},
mendeley-tags = {representation learning,self-supervised learning},
title = {{Deep clustering for unsupervised learning of visual features}},
year = {2018}
}
@article{Su2012,
abstract = {This study adopts intraday return instead of daily return used by previous researches to examine the effect of order imbalance not only on the individual stock return but also volatility among jump losers. We also build up order imbalance-based trading strategies to earn abnormal return.  A contemporaneous order imbalance-return relation is examined by GARCH (1,1) model and time-series regression model. The data presents significantly positive relation in both models as previous studies on daily reurn. We focus on the lagged effect of imbalance on return and find that such relation is negatively significant, while contemporaneous imbalance has positive significant impact on return. We examine the volatility-order imbalance relationship by a time-varying GARCH (1,1) model. The positive relation of volatility and order imbalance is consistent with our ex ante expectatio n that larger imbalance make s return more volatile. Then, the small firm effect shows the weakly negative relation between order imbalance coefficient and market capitalization.  We develop two order imbalance-based trading strategies based on different definitions of price: trading price and bid-ask. Due to the characteristics of our jump losers, we use short selling strategy. Our results show the huge profitability of order imbalance strategies when we trade on extreme volume.  In order to explore the reason of profitable order imbalance based strategy, we investigate the causal relationship between return and order imbalance. We find that order imbalance is a good indicator of price discovery. Moreover, order imbalance apparently is an excellent indicator for return prediction in small firm size quartile.},
author = {Su, Yong Chern and Huang, Han Ching and Lina, Shiue Fang},
doi = {10.1080/00036846.2010.543080},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Su, Huang, Lina - 2012 - Dynamic relations between order imbalance, volatility and return of top gainers.pdf:pdf},
isbn = {0003-6846},
issn = {00036846},
journal = {Applied Economics},
keywords = {anfis,forecasting model,klang gate},
number = {12},
pages = {1509--1519},
title = {{Dynamic relations between order imbalance, volatility and return of top gainers}},
volume = {44},
year = {2012}
}
@article{Saini2016,
abstract = {The recent exponential growth in the use of image processing software applications has been accompanied by a parallel increase in their use in criminal activities. Image processing tools have been associated with a variety of crimes, including counterfeiting of currency notes, cheques, as well as manipulation of important government documents, wills, financial deeds or educational certificates. Thus, it is important for the Document Examiner to keep up to date with latest technological and scientific advances in the field. The present research focuses on the use of image processing tools for the examination of computer-manipulated documents. The altered documents were examined using a suite of currently available image processing tools. The results demonstrate that a number of tools are capable of detecting computer-based manipulations of written documents.},
author = {Saini, Komal and Kaur, Shabnampreet},
doi = {10.1016/j.ejfs.2015.03.001},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saini, Kaur - 2016 - Forensic examination of computer-manipulated documents using image processing techniques.pdf:pdf},
issn = {20905939},
journal = {Egyptian Journal of Forensic Sciences},
keywords = {Alterations of documents,Computer manipulated documents,Forensic document examination,Image processing},
number = {3},
pages = {317--322},
publisher = {The International Association of Law and Forensic Sciences (IALFS)},
title = {{Forensic examination of computer-manipulated documents using image processing techniques}},
url = {http://dx.doi.org/10.1016/j.ejfs.2015.03.001},
volume = {6},
year = {2016}
}
@article{Wen2016,
abstract = {High demand for computation resources severely hinders deployment of large-scale Deep Neural Networks (DNN) in resource constrained devices. In this work, we propose a Structured Sparsity Learning (SSL) method to regularize the structures (i.e., filters, channels, filter shapes, and layer depth) of DNNs. SSL can: (1) learn a compact structure from a bigger DNN to reduce computation cost; (2) obtain a hardware-friendly structured sparsity of DNN to efficiently accelerate the DNN's evaluation. Experimental results show that SSL achieves on average 5.1× and 3.1× speedups of convolutional layer computation of AlexNet against CPU and GPU, respectively, with off-the-shelf libraries. These speedups are about twice speedups of non-structured sparsity; (3) regularize the DNN structure to improve classification accuracy. The results show that for CIFAR-10, regularization on layer depth reduces a 20-layer Deep Residual Network (ResNet) to 18 layers while improves the accuracy from 91.25% to 92.60%, which is still higher than that of original ResNet with 32 layers. For AlexNet, SSL reduces the error by ∼ 1%.},
archivePrefix = {arXiv},
arxivId = {1608.03665},
author = {Wen, Wei and Wu, Chunpeng and Wang, Yandan and Chen, Yiran and Li, Hai},
eprint = {1608.03665},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wen et al. - 2016 - Learning structured sparsity in deep neural networks.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {2082--2090},
title = {{Learning structured sparsity in deep neural networks}},
year = {2016}
}
@inproceedings{Cvpr2021,
author = {Cvpr, Anonymous and Id, Paper},
booktitle = {International Conference on Computer Vision},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cvpr, Id - 2021 - Vi2CLR Video and Image for Visual Contrastive Learning of Representation.pdf:pdf},
keywords = {contrastive learning,self-supervised learning,video understanding},
mendeley-tags = {contrastive learning,self-supervised learning,video understanding},
pages = {1502--1512},
title = {{Vi2CLR : Video and Image for Visual Contrastive Learning of Representation}},
year = {2021}
}
@article{Hong2012,
abstract = {This paper proposes a novel blind image restoration method based on estimating the point-spread functions by using two real turbulence-degraded images as input. The non-negative constraint and the spatial correlation are transformed mathematically into the penalty terms and added to the objective function. An anisotropic and nonlinear regularization function is proposed to adequately punish the differences of the point spread functions (PSFs) in the process of optimization estimation. Some definitions of weighted second-order differences are given and a fast method to construct the matrix of second-order weighted gradient operator is derived. The PSF values can be quickly estimated. With the estimated PSFs, the true images can be recovered by non-blind restoration methods. Experiment results for the restoration of real turbulence-degraded images with complicated backgrounds support the effectiveness of this proposed method. {\textcopyright} 2012 Elsevier B.V. All rights reserved.},
author = {Hong, Hanyu and Li, Liangcheng and Zhang, Tianxu},
doi = {10.1016/j.optcom.2012.07.080},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hong, Li, Zhang - 2012 - Blind restoration of real turbulence-degraded image with complicated backgrounds using anisotropic regularizati.pdf:pdf},
issn = {00304018},
journal = {Optics Communications},
keywords = {Anisotropic regularization,Image restoration,Optimization estimation},
number = {24},
pages = {4977--4986},
publisher = {Elsevier},
title = {{Blind restoration of real turbulence-degraded image with complicated backgrounds using anisotropic regularization}},
url = {http://dx.doi.org/10.1016/j.optcom.2012.07.080},
volume = {285},
year = {2012}
}
@article{Aisjah2011,
abstract = {Fuzzy logic has mostly been used in different kind of field either in taking decision, or control system and forecasting. Fuzzy logic is one that can represent a complex situation into a simple form in a language that is easily caught by humans. Similarly, to represent the nature of weather easily understood by ordinary people, this is the result of weather forecasting based on meteorological data. Some of the statistical methods used for weather forecasting are Auto Regressive (AR), Integrated Moving Average (ARIMA) and found some shortcomings of these traditional method. That is the need for historical data is not small, low-prediction accuracy results in a complex condition. This paper describes the strategy in weather forecasting based on fuzzy logic for maritime weather. Case studies conducted in the Java Sea, cruise lines Surabaya- Banjarmasin. The results showed that the level of accuracy prediction for 86.64% of the Java Sea, and prediction accuracy decreased for the next 24 hours ahead. Predictors of ability to demonstrate the ability to detect anomalous high sea waves in the waters of the Java Sea},
author = {Aisjah, Aulia Siti and Arifin, Syamsul},
doi = {10.1109/ICA.2011.6130157},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aisjah, Arifin - 2011 - Maritime Weather Prediction using Fuzzy Logic in Java Sea.pdf:pdf},
isbn = {9781457714603},
journal = {International Conference on Instrumentation Control and Automation},
keywords = {forecast,fuzzy,high wave,java sea,wheather},
number = {November},
pages = {205--208},
title = {{Maritime Weather Prediction using Fuzzy Logic in Java Sea}},
year = {2011}
}
@article{Saruhan2014,
abstract = {In this study, nature inspired algorithms – the Differential Evolution (DE) and the Simulated Annealing (SA) – are utilized to seek a global optimum solution for ball bearings link system assembly weight with constraints and mixed design variables. The Genetic Algorithm (GA) and the Evolution Strategy (ES) will be a reference for the examination and validation of the DE and the SA. The main purpose is to minimize the weight of an assembly system composed of a shaft and two ball bearings. Ball bearings link system is used extensively in many machinery applications. Among mechanical systems, designers pay great attention to the ball bearings link system because of its significant industrial importance. The problem is complex and a time consuming process due to mixed design variables and inequality constraints imposed on the objective function. The results showed that the DE and the SA performed and obtained convergence reliability on the global optimum solution. So the contribution of the DE and the SA application to the mechanical system design can be very useful in many real-world mechanical system design problems. Beside, the comparison confirms the effectiveness and the superiority of the DE over the others algorithms – the SA, the GA, and the ES – in terms of solution quality. The ball bearings link system assembly weight of 634,099 gr was obtained using the DE while 671,616 gr, 728213.8 gr, and 729445.5 gr were obtained using the SA, the ES, and the GA respectively.},
author = {Saruhan, H.},
doi = {10.1016/j.jestch.2014.04.006},
issn = {22150986},
journal = {Engineering Science and Technology, an International Journal},
keywords = {Design optimization,Differential evolution,Genetic algorithm,Simulated annealing},
number = {3},
pages = {131--136},
publisher = {Elsevier Ltd},
title = {{Differential evolution and simulated annealing algorithms for mechanical systems design}},
url = {http://dx.doi.org/10.1016/j.jestch.2014.04.006},
volume = {17},
year = {2014}
}
@article{Rosasco2021b,
abstract = {Replay strategies are Continual Learning techniques which mitigate catastrophic forgetting by keeping a buffer of patterns from previous experience, which are interleaved with new data during training. The amount of patterns stored in the buffer is a critical parameter which largely influences the final performance and the memory footprint of the approach. This work introduces Distilled Replay, a novel replay strategy for Continual Learning which is able to mitigate forgetting by keeping a very small buffer (up to $1$ pattern per class) of highly informative samples. Distilled Replay builds the buffer through a distillation process which compresses a large dataset into a tiny set of informative examples. We show the effectiveness of our Distilled Replay against naive replay, which randomly samples patterns from the dataset, on four popular Continual Learning benchmarks.},
archivePrefix = {arXiv},
arxivId = {2103.15851},
author = {Rosasco, Andrea and Carta, Antonio and Cossu, Andrea and Lomonaco, Vincenzo and Bacciu, Davide},
eprint = {2103.15851},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rosasco et al. - 2021 - Distilled Replay Overcoming Forgetting through Synthetic Samples(2).pdf:pdf},
keywords = {continual learning},
mendeley-tags = {continual learning},
title = {{Distilled Replay: Overcoming Forgetting through Synthetic Samples}},
year = {2021}
}
@article{Fritschel1992,
author = {Fritschel, Peter and Weiss, Rainer},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fritschel, Weiss - 1992 - This Coupling Eliminates Any Change in the Beam Direction.pdf:pdf},
pages = {2--4},
title = {{This Coupling Eliminates Any Change in the Beam Direction}},
year = {1992}
}
@article{Hinton2015,
abstract = {A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.},
archivePrefix = {arXiv},
arxivId = {1503.02531},
author = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
eprint = {1503.02531},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hinton, Vinyals, Dean - 2015 - Distilling the Knowledge in a Neural Network.pdf:pdf},
pages = {1--9},
title = {{Distilling the Knowledge in a Neural Network}},
url = {http://arxiv.org/abs/1503.02531},
volume = {abs/1503.0},
year = {2015}
}
@article{Loia2017,
abstract = {{\textcopyright} 2017 IEEE. In this paper, we propose a computational scheme for the problem of wind power forecasting. Such scheme combines a local weighted regression model with fuzzy transform. The latter provides a way to reduce the cardinality of the learning problem, resulting in a more efficient algorithm. Numerical examples show the effectiveness of the proposed approach.},
author = {Loia, Vincenzo and Tomasiello, Stefania and Vaccaro, Alfredo},
doi = {10.1109/IFSA-SCIS.2017.8023237},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Loia, Tomasiello, Vaccaro - 2017 - Joining fuzzy transform and local learning for wind power forecasting.pdf:pdf},
isbn = {9781509049172},
journal = {IFSA-SCIS 2017 - Joint 17th World Congress of International Fuzzy Systems Association and 9th International Conference on Soft Computing and Intelligent Systems},
keywords = {forecasting,fuzzy sets,lazy learning,local regression},
number = {1},
title = {{Joining fuzzy transform and local learning for wind power forecasting}},
volume = {2},
year = {2017}
}
@article{Haffner2016,
abstract = {Complementing plasmonic slot waveguides with highly nonlinear organic materials has rendered a new generation of ultracompact active nanophotonic components that are redefining the state of the art. In this paper, we review the fundamentals of this so-called plasmonicorganic-hybrid (POH) platform. Starting from simple phase shifters to the most compact IQ modulators, we introduce key devices of high-speed data communications. For instance, all-plasmonic Mach-Zehnder modulators (MZMs) are reviewed and long-term prospects are discussed. This kind of modulator already features unique properties such as a small footprint (<20 mu m(2)), a large electro-optic bandwidth (>110 GHz), a small energy consumption (similar to 25 fJ/b), a large extinction ratio (9 25 dB) in combination with a record small voltage-length product of 40 V mu m. Finally, as an example for seamless integration we introduce novel plasmonic IQ modulators. With such modulators we show the generation of advanced modulation formats (QPSK, 16-QAM) on footprints as small as 10 mu m x 75 mu m. This demonstration ultimately shows how plasmonics can be used to control both phase and amplitude of an optical carrier on the microscale with reasonably low losses.},
author = {Haffner, Christian and Heni, Wolfgang and Fedoryshyn, Yuriy and Josten, Arne and Baeuerle, Benedikt and Hoessbacher, Claudia and Salamin, Yannick and Koch, Ueli and Dordevi{\'{c}}, Nikola and Mousel, Pol and Bonjour, Romain and Emboras, Alexandros and Hillerkuss, David and Leuchtmann, Pascal and Elder, Delwin L. and Dalton, Larry R. and Hafner, Christian and Leuthold, Juerg},
doi = {10.1109/JPROC.2016.2547990},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Haffner et al. - 2016 - Plasmonic Organic Hybrid Modulators - Scaling Highest Speed Photonics to the Microscale.pdf:pdf},
issn = {00189219},
journal = {Proceedings of the IEEE},
keywords = {IQ modulators,Mach-Zehnder modulators (MZMs),linear electro-optic effect,plasmonic modulators,plasmonic-organic-hybrid (POH),plasmonics},
number = {12},
pages = {2362--2379},
title = {{Plasmonic Organic Hybrid Modulators - Scaling Highest Speed Photonics to the Microscale}},
volume = {104},
year = {2016}
}
@article{Orseau2020,
abstract = {The Lottery Ticket Hypothesis is a conjecture that every large neural network contains a subnetwork that, when trained in isolation, achieves comparable performance to the large network. An even stronger conjecture has been proven recently: Every sufficiently overparameterized network contains a subnetwork that, even without training, achieves comparable accuracy to the trained large network. This theorem, however, relies on a number of strong assumptions and guarantees a polynomial factor on the size of the large network compared to the target function. In this work, we remove the most limiting assumptions of this previous work while providing significantly tighter bounds: the overparameterized network only needs a logarithmic factor (in all variables but depth) number of neurons per weight of the target subnetwork.},
archivePrefix = {arXiv},
arxivId = {2006.12156},
author = {Orseau, Laurent and Hutter, Marcus and Rivasplata, Omar},
eprint = {2006.12156},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Orseau, Hutter, Rivasplata - 2020 - Logarithmic Pruning is All You Need.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {neural networks,overparameterized,pruning},
mendeley-tags = {neural networks,overparameterized,pruning},
number = {NeurIPS},
title = {{Logarithmic Pruning is All You Need}},
year = {2020}
}
@article{Mei2017,
abstract = {A polarization Scheimpflug lidar system based on the Scheimpflug principle has been developed by employing two linearly polarized 808 nm laser diodes and a complementary metal-oxide-semiconductor (CMOS) image sensor. The polarization of one laser diode is rotated 90 degrees by a half-wave plate. The two laser beams with orthogonal polarizations are combined by a polarization beam splitter and transmitted into the atmosphere. The corresponding parallel- and perpendicular-polarized backscattering echoes are detected by the 45 degrees tilted CMOS sensor using a time-division multiplexing scheme. A 24 h continuous atmospheric vertical profiling of the depolarization ratio has been performed by using the polarization Scheimpflug lidar system. The promising results successfully demonstrated that the present lidar system has potential for the polarization studies of atmospheric aerosols.},
author = {Mei, Liang and Guan, Peng},
doi = {10.1364/OL.42.003562},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mei, Guan - 2017 - Development of an atmospheric polarization Scheimpflug lidar system based on a time-division multiplexing scheme.pdf:pdf},
issn = {1539-4794 (Electronic)},
journal = {Optics letters},
number = {18},
pages = {3562--3565},
pmid = {28914902},
title = {{Development of an atmospheric polarization Scheimpflug lidar system based on a time-division multiplexing scheme.}},
volume = {42},
year = {2017}
}
@article{Sinha2017,
abstract = {Bilevel optimization problems are a class of challenging optimization problems, which contain two levels of optimization tasks. In these problems, the optimal solutions to the lower level problem become possible feasible candidates to the upper level problem. Such a requirement makes the optimization problem difficult to solve, and has kept the researchers busy towards devising methodologies, which can efficiently handle the problem. Despite the efforts, there hardly exists any effective methodology, which is capable of handling a complex bilevel problem. In this paper, we introduce bilevel evolutionary algorithm based on quadratic approximations (BLEAQ) of optimal lower level variables with respect to the upper level variables. The approach is capable of handling bilevel problems with different kinds of complexities in relatively smaller number of function evaluations. Ideas from classical optimization have been hybridized with evolutionary methods to generate an efficient optimization algorithm for a wide class of bilevel problems. The performance of the algorithm has been evaluated on two sets of test problems. The first set is a recently proposed SMD test set, which contains problems with controllable complexities, and the second set contains standard test problems collected from the literature. The proposed method has been compared against three benchmarks, and the performance gain is observed to be significant. The codes related to the paper may be accessed from the website http://bilevel.org.},
author = {Sinha, Ankur and Malo, Pekka and Deb, Kalyanmoy},
doi = {10.1016/j.ejor.2016.08.027},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sinha, Malo, Deb - 2017 - Evolutionary algorithm for bilevel optimization using approximations of the lower level optimal solution mappi.pdf:pdf},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Bilevel optimization,Evolutionary algorithms,Quadratic approximations},
number = {2},
pages = {395--411},
publisher = {Elsevier B.V.},
title = {{Evolutionary algorithm for bilevel optimization using approximations of the lower level optimal solution mapping}},
url = {http://dx.doi.org/10.1016/j.ejor.2016.08.027},
volume = {257},
year = {2017}
}
@article{Min2013,
author = {Min, Zhang Jian},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Min - 2013 - Analysis and Comparison on Image Restoration Algorithms Using MATLAB.pdf:pdf},
journal = {International Journal of Engineering Research & Technology (IJERT)},
keywords = {"ijert"},
number = {12},
pages = {1350--1360},
title = {{Analysis and Comparison on Image Restoration Algorithms Using MATLAB}},
volume = {2},
year = {2013}
}
@article{Chen2020h,
abstract = {How to represent an image? While the visual world is presented in a continuous manner, machines store and see the images in a discrete way with 2D arrays of pixels. In this paper, we seek to learn a continuous representation for images. Inspired by the recent progress in 3D reconstruction with implicit function, we propose Local Implicit Image Function (LIIF), which takes an image coordinate and the 2D deep features around the coordinate as inputs, predicts the RGB value at a given coordinate as an output. Since the coordinates are continuous, LIIF can be presented in an arbitrary resolution. To generate the continuous representation for pixel-based images, we train an encoder and LIIF representation via a self-supervised task with super-resolution. The learned continuous representation can be presented in arbitrary resolution even extrapolate to $\times 30$ higher resolution, where the training tasks are not provided. We further show that LIIF representation builds a bridge between discrete and continuous representation in 2D, it naturally supports the learning tasks with size-varied image ground-truths and significantly outperforms the method with resizing the ground-truths. Our project page with code is at https://yinboc.github.io/liif/ .},
archivePrefix = {arXiv},
arxivId = {2012.09161},
author = {Chen, Yinbo and Liu, Sifei and Wang, Xiaolong},
eprint = {2012.09161},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Liu, Wang - 2020 - Learning Continuous Image Representation with Local Implicit Image Function.pdf:pdf},
keywords = {visual representation},
mendeley-tags = {visual representation},
title = {{Learning Continuous Image Representation with Local Implicit Image Function}},
url = {http://arxiv.org/abs/2012.09161 https://yinboc.github.io/liif/},
year = {2020}
}
@article{Sculley2015,
abstract = {Machine learning offers a fantastically powerful toolkit for building useful complex prediction systems quickly. This paper argues it is dangerous to think of these quick wins as coming for free. Using the software engineering framework of technical debt, we find it is common to incur massive ongoing maintenance costs in real-world ML systems. We explore several ML-specific risk factors to account for in system design. These include boundary erosion, entanglement, hidden feedback loops, undeclared consumers, data dependencies, configuration issues, changes in the external world, and a variety of system-level anti-patterns.},
author = {Sculley, D. and Holt, Gary and Golovin, Daniel and Davydov, Eugene and Phillips, Todd and Ebner, Dietmar and Chaudhary, Vinay and Young, Michael and Crespo, Jean Fran{\c{c}}ois and Dennison, Dan},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sculley et al. - 2015 - Hidden technical debt in machine learning systems.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {2503--2511},
title = {{Hidden technical debt in machine learning systems}},
volume = {2015-Janua},
year = {2015}
}
@article{Salehpour2017,
abstract = {In this paper, a new version of differential evolution (DE) with adaptive mutation factor has been proposed for solving complex optimization problems. The proposed algorithm uses fuzzy logic inference system to dynamically tune the mutation factor of DE and improve its exploration and exploitation. In this way, two factors, named, the number of generation and population diversity are considered as inputs and, one factor, named, the mutation factor as output of the fuzzy logic inference system. The performance of the suggested approach has been tested firstly by using some popular single objective test functions. It has been shown that the proposed method finds better solutions than the classical differential evolution and also the convergence rate of that is really fast. Secondly, a five degree of freedom vehicle vibration model is chosen to be optimally designed by the aforesaid proposed approach. Comparison of the obtained results with those in the literature demonstrates the superiority of the results of this work.},
author = {Salehpour, M. and Jamali, A. and Bagheri, A. and Nariman-zadeh, N.},
doi = {10.1016/j.jestch.2017.01.004},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Salehpour et al. - 2017 - A new adaptive differential evolution optimization algorithm based on fuzzy inference system.pdf:pdf},
issn = {22150986},
journal = {Engineering Science and Technology, an International Journal},
keywords = {Differential evolution,Fuzzy logic,Mutation factor,Optimization,Population diversity,Vehicle vibration model},
number = {2},
pages = {587--597},
publisher = {Karabuk University},
title = {{A new adaptive differential evolution optimization algorithm based on fuzzy inference system}},
url = {http://dx.doi.org/10.1016/j.jestch.2017.01.004},
volume = {20},
year = {2017}
}
@article{Hill2019,
abstract = {The question of whether deep neural networks are good at generalising beyond their immediate training experience is of critical importance for learning-based approaches to AI. Here, we consider tests of out-of-sample generalisation that require an agent to respond to never-seen-before instructions by manipulating and positioning objects in a 3D Unity simulated room. We first describe a comparatively generic agent architecture that exhibits strong performance on these tests. We then identify three aspects of the training regime and environment that make a significant difference to its performance: (a) the number of object/word experiences in the training set; (b) the visual invariances afforded by the agent's perspective, or frame of reference; and (c) the variety of visual input inherent in the perceptual aspect of the agent's perception. Our findings indicate that the degree of generalisation that networks exhibit can depend critically on particulars of the environment in which a given task is instantiated. They further suggest that the propensity for neural networks to generalise in systematic ways may increase if, like human children, those networks have access to many frames of richly varying, multi-modal observations as they learn.},
archivePrefix = {arXiv},
arxivId = {1910.00571},
author = {Hill, Felix and Lampinen, Andrew and Schneider, Rosalia and Clark, Stephen and Botvinick, Matthew and McClelland, James L. and Santoro, Adam},
eprint = {1910.00571},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hill et al. - 2019 - Environmental drivers of systematicity and generalization in a situated agent.pdf:pdf},
pages = {1--15},
title = {{Environmental drivers of systematicity and generalization in a situated agent}},
url = {http://arxiv.org/abs/1910.00571 https://openreview.net/pdf?id=SklGryBtwr},
year = {2019}
}
@article{Khalid2016a,
abstract = {The integration and adoption of digital technologies have enabled improvements in the quality of and inclusion in higher education. However, a significant proportion of the population has either remained or become digitally excluded. This systematic literature review elucidates the factors underlying the concepts of “digital exclusion” and the “digital divide” in higher education. The identified factors are grouped into three categories: social exclusion (i.e., low income, ICT-avoidance as the norm, lack of motivation and commitment, and physical or mental disability), digital exclusion (i.e., lack of hardware devices and Internet services) and accessibility (which include the division between rural and urban areas, as well as disparities in ICT literacy and information literacy). These factors are multi-tiered and overlapping. Studies on the digital divide, digital exclusion, and barriers to ICT adoption in higher education deal with similar factors, but these are experienced differently in different contexts. While generalizing these factors into categories enables a better understanding of the nature of digital exclusion, solving and circumventing them remains complex due their dependency on the particular context of a higher education institution.},
author = {Khalid, Md. Saifuddin and Pedersen, Mette Jun Lykkegaard},
doi = {10.1016/j.sbspro.2016.07.094},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khalid, Pedersen - 2016 - Digital Exclusion in Higher Education Contexts A Systematic Literature Review.pdf:pdf},
isbn = {0000000000},
issn = {18770428},
journal = {Procedia - Social and Behavioral Sciences},
keywords = {digital divide,digital exclusion,higher education,ict,tertiary education,university education},
number = {June},
pages = {614--621},
publisher = {The Author(s)},
title = {{Digital Exclusion in Higher Education Contexts: A Systematic Literature Review}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877042816310205},
volume = {228},
year = {2016}
}
@article{Liu2017,
abstract = {{\textcopyright} The Institution of Engineering and Technology 2017. With the increasing contribution of the power production by the photovoltaic (PV) systems to the electricity supply, the PV power forecasting becomes increasingly important. There are many factors influencing the forecasting performance, such as the air temperature, humidity, insolation, wind speed, wind direction and so on. This study proposes a Takagi-Sugeno (T-S) fuzzy model-based PV power short-term forecasting approach. First, by means of the correlation analysis, the influential factors are selected as the model inputs. Then, the fuzzy c-mean clustering algorithm and the recursive least squares method are used to identify the antecedent and the consequent parameters. The performance of the proposed forecasting approach is tested by using a large database of measurement data from the 433 kW PV array at St Lucia campus of The Queensland University of Australia. The forecasting results are compared with the support vector machine (SVM), the hybrid of empirical mode decomposition and SVM, the back propagation neural network and the recurrent neural network. The results indicate that, compared with the existing approaches, the proposed T-S fuzzy model-based forecasting approach is simpler and can forecast more accurately.},
author = {Liu, Fang and Li, Ranran and Li, Yong and Yan, Ruifeng and Saha, Tapan},
doi = {10.1049/iet-rpg.2016.1036},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2017 - Takagi–Sugeno fuzzy model-based approach considering multiple weather factors for the photovoltaic power short-ter.pdf:pdf},
issn = {1752-1416},
journal = {IET Renewable Power Generation},
number = {10},
pages = {1281--1287},
title = {{Takagi–Sugeno fuzzy model-based approach considering multiple weather factors for the photovoltaic power short-term forecasting}},
url = {http://digital-library.theiet.org/content/journals/10.1049/iet-rpg.2016.1036},
volume = {11},
year = {2017}
}
@article{Ilievski2021,
abstract = {Commonsense knowledge is essential for many AI applications, including those in natural language processing, visual processing, and planning. Consequently, many sources that include commonsense knowledge have been designed and constructed over the past decades. Recently, the focus has been on large text-based sources, which facilitate easier integration with neural (language) models and application on textual tasks, typically at the expense of the semantics of the sources. Such practice prevents the harmonization of these sources, understanding their coverage and gaps, and may hinder the semantic alignment of their knowledge with downstream tasks. Efforts to consolidate commonsense knowledge have yielded partial success, but provide no clear path towards a comprehensive consolidation of existing commonsense knowledge. The ambition of this paper is to organize these sources around a common set of dimensions of commonsense knowledge. For this purpose, we survey a wide range of popular commonsense sources with a special focus on their relations. We consolidate these relations into 13 knowledge dimensions, each abstracting over more specific relations found in sources. This consolidation allows us to unify the separate sources and to compute indications of their coverage, overlap, and gaps with respect to the knowledge dimensions. Moreover, we analyze the impact of each dimension on downstream reasoning tasks that require commonsense knowledge, observing that the temporal and desire/goal dimensions are very beneficial for reasoning on current downstream tasks, while distinctness and lexical knowledge have little impact. These results reveal focus towards some dimensions in current evaluation, and potential neglect of others.},
archivePrefix = {arXiv},
arxivId = {2101.04640},
author = {Ilievski, Filip and Oltramari, Alessandro and Ma, Kaixin and Zhang, Bin and McGuinness, Deborah L. and Szekely, Pedro},
eprint = {2101.04640},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ilievski et al. - 2021 - Dimensions of Commonsense Knowledge.pdf:pdf},
keywords = {commonsense knowledge,knowledge graphs,reasoning},
mendeley-tags = {commonsense knowledge,knowledge graphs,reasoning},
title = {{Dimensions of Commonsense Knowledge}},
url = {http://arxiv.org/abs/2101.04640},
year = {2021}
}
@article{Chen2017b,
abstract = {In this paper, we propose a new fuzzy time series (FTS) forecasting method based on optimal partitions of intervals in the universe of discourse and optimal weighting vectors of two-factors second-order fuzzy-trend logical relationship groups (TSFTLRGs). The proposed method uses particle swarm optimization (PSO) techniques to obtain the optimal partitions of intervals and the optimal weighting vectors simultaneously. The proposed FTS forecasting method outperforms the existing methods for forecasting the TAIEX and the NTD/USD exchange rates in terms of forecasting accuracy rates. It provides us with a useful way to deal with forecasting problems to get higher forecasting accuracy rates.},
author = {Chen, Shyi Ming and Phuong, Bui Dang Ha},
doi = {10.1016/j.knosys.2016.11.019},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Phuong - 2017 - Fuzzy time series forecasting based on optimal partitions of intervals and optimal weighting vectors.pdf:pdf},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Fuzzy time series forecasting,Particle swarm optimization,Two-factors second-order fuzzy logical relationshi,Two-factors second-order fuzzy-trend logical relat},
pages = {204--216},
publisher = {Elsevier B.V.},
title = {{Fuzzy time series forecasting based on optimal partitions of intervals and optimal weighting vectors}},
volume = {118},
year = {2017}
}
@article{Kocurkova2000,
author = {Kocurkov{\'{a}}, Radmila},
doi = {975-8100-08-4},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kocurkov{\'{a}} - 2000 - Time Series Analysis and Trends by Using SPSS Programme.pdf:pdf},
journal = {Challenges for business administrators in the new millenium},
keywords = {process arima,programme spss,time series analysis,unemployment},
number = {January 1997},
pages = {836--841},
title = {{Time Series Analysis and Trends by Using SPSS Programme}},
year = {2000}
}
@article{Shi-YuanHan2016a,
author = {{Shi-Yuan Han} and {Xiao-Yu Wan} and {Lin Wang} and {Jin Zhou} and {Xiao-Fang Zhong}},
doi = {10.1109/ICCSS.2016.7586422},
isbn = {978-1-5090-3367-6},
journal = {2016 3rd International Conference on Informative and Cybernetics for Computational Social Systems (ICCSS)},
pages = {52--55},
title = {{Comparison between genetic algorithm and differential evolution algorithm applied to one dimensional bin-packing problem}},
url = {http://ieeexplore.ieee.org/document/7586422/},
year = {2016}
}
@article{Griffies2010,
abstract = {The ocean is a forced dissipative system with an enormous range of dynamical phenomena occurring over a huge range of space timescales. Simulating the World Ocean for purposes of climate is a massive problem involving fundamental areas of physics, mathematics, computer science, and all areas of ocean and climate science. This article presents a broad overview of key physical issues that arise when posing the problem of ocean climate modeling. {\textcopyright} 2008 Copyright {\textcopyright} unknown. Published by Elsevier Ltd.},
author = {Griffies, S.M.},
doi = {10.1016/B978-012374473-9.00714-1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Griffies - 2010 - Science of Ocean Climate Models.pdf:pdf},
isbn = {9780123744739},
journal = {Encyclopedia of Ocean Sciences},
keywords = {[Finite volume formulation, Geostrophic turbulence},
pages = {133--140},
title = {{Science of Ocean Climate Models}},
year = {2010}
}
@article{Sanchez2016,
abstract = {Ego-motion estimation and localization in large environments are key components in any assistive technology for real-time user orientation and navigation. We consider the case where a large known environment is explored without a priori assumptions on the initial location. In particular we propose a framework that uses a single portable 3D sensor to solve the place recognition problem and continuously tracks its position even when leaving the known area or when significant changes occur in the observed environment. We cast the place recognition step as a classification problem and propose an efficient search space reduction considering only navigable areas where the user can be localized. Classification hypotheses are then discarded exploiting temporal consistency w.r.t. a relative tracker that exploits only the sensor input data. The solution uses a compact classifier whose representation scales well with the map size. After being localized, the user is continuously tracked exploiting the known environment using an efficient data structure that provides constant access time for nearest neighbor searches and that can be streamed to keep only the local region close to the last known position in memory. Robust results are achieved by performing a geometrically stable selection of points, efficiently filtering outliers and integrating the relative tracker based on previous observations. We experimentally show that such a framework provides good localization results and that it scales well with the environment map size yielding real-time performance for both place recognition and tracking.},
author = {S{\'{a}}nchez, Carlos and Taddei, Pierluigi and Ceriani, Simone and Wolfart, Erik and Sequeira, V{\'{i}}tor},
doi = {10.1016/j.cviu.2015.11.012},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/S{\'{a}}nchez et al. - 2016 - Localization and tracking in known large environments using portable real-time 3D sensors.pdf:pdf},
issn = {1090235X},
journal = {Computer Vision and Image Understanding},
keywords = {3D sensors,Ego-motion,Place recognition},
pages = {197--208},
title = {{Localization and tracking in known large environments using portable real-time 3D sensors}},
volume = {149},
year = {2016}
}
@article{Liu2021b,
abstract = {This paper presents a simple unsupervised visual representation learning method with a pretext task of discriminating all images in a dataset using a parametric, instance-level classifier. The overall framework is a replica of a supervised classification model, where semantic classes (e.g., dog, bird, and ship) are replaced by instance IDs. However, scaling up the classification task from thousands of semantic labels to millions of instance labels brings specific challenges including 1) the large-scale softmax computation; 2) the slow convergence due to the infrequent visiting of instance samples; and 3) the massive number of negative classes that can be noisy. This work presents several novel techniques to handle these difficulties. First, we introduce a hybrid parallel training framework to make large-scale training feasible. Second, we present a raw-feature initialization mechanism for classification weights, which we assume offers a contrastive prior for instance discrimination and can clearly speed up converge in our experiments. Finally, we propose to smooth the labels of a few hardest classes to avoid optimizing over very similar negative pairs. While being conceptually simple, our framework achieves competitive or superior performance compared to state-of-the-art unsupervised approaches, i.e., SimCLR, MoCoV2, and PIC under ImageNet linear evaluation protocol and on several downstream visual tasks, verifying that full instance classification is a strong pretraining technique for many semantic visual tasks.},
archivePrefix = {arXiv},
arxivId = {2102.04848},
author = {Liu, Yu and Huang, Lianghua and Pan, Pan and Wang, Bin and Xu, Yinghui and Jin, Rong},
eprint = {2102.04848},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2021 - Train a One-Million-Way Instance Classifier for Unsupervised Visual Representation Learning.pdf:pdf},
keywords = {large-scale,representation learning,unsupervised learning},
mendeley-tags = {large-scale,representation learning,unsupervised learning},
title = {{Train a One-Million-Way Instance Classifier for Unsupervised Visual Representation Learning}},
url = {http://arxiv.org/abs/2102.04848},
year = {2021}
}
@article{Raid2014,
abstract = {Image processing including noise suppression, feature extraction, edge detection, image segmentation, shape recognition, texture analysis, image restoration and reconstruction, image compression etc uses mathematical morphology which is a method of nonlinear filters. It is modulated from traditional morphology to order morphology, soft mathematical morphology and fuzzy soft mathematical morphology. This paper is covers 6 morphological operations which are implemented in the matlab program, including erosion, dilation, opening, closing, boundary extraction and region filling. KEYWORDS Image Restoration, Structure Elements (SE), and Morphological operations.},
author = {Raid, A M and Khedr, W M and El-Dosuky, M A and Aoud, Mona},
doi = {10.5121/ijcseit.2014.4302},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Raid et al. - 2014 - Image Restoration Based on Morphological Operations.pdf:pdf},
issn = {22313605},
journal = {International Journal of Computer Science, Engineering and Information Technology (IJCSEIT)},
number = {3},
pages = {9--21},
title = {{Image Restoration Based on Morphological Operations}},
volume = {4},
year = {2014}
}
@article{Babu2021,
abstract = {Deep learning (DL) has gained much attention and become increasingly popular in modern data science. Computer scientists led the way in developing deep learning techniques, so the ideas and perspectives can seem alien to statisticians. Nonetheless, it is important that statisticians become involved -- many of our students need this expertise for their careers. In this paper, developed as part of a program on DL held at the Statistical and Applied Mathematical Sciences Institute, we address this culture gap and provide tips on how to teach deep learning to statistics graduate students. After some background, we list ways in which DL and statistical perspectives differ, provide a recommended syllabus that evolved from teaching two iterations of a DL graduate course, offer examples of suggested homework assignments, give an annotated list of teaching resources, and discuss DL in the context of two research areas.},
archivePrefix = {arXiv},
arxivId = {2102.01194},
author = {Babu, G. Jogesh and Banks, David and Cho, Hyunsoon and Han, David and Sang, Hailin and Wang, Shouyi},
eprint = {2102.01194},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Babu et al. - 2021 - A Statistician Teaches Deep Learning.pdf:pdf},
keywords = {curriculum,deep learning,neural networks,statistics,teaching},
mendeley-tags = {curriculum,deep learning,statistics},
pages = {1--19},
title = {{A Statistician Teaches Deep Learning}},
url = {http://arxiv.org/abs/2102.01194},
year = {2021}
}
@article{LotziBoloniUniversityofCentralFlorida2008,
author = {{Lotzi B{\"{o}}l{\"{o}}ni (University of Central Florida)}},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lotzi B{\"{o}}l{\"{o}}ni (University of Central Florida) - 2008 - Some thoughts about writing a survey paper.pdf:pdf},
pages = {1--3},
title = {{Some thoughts about writing a survey paper}},
year = {2008}
}
@article{Khanna2017,
abstract = {{\textcopyright} 2016 IEEE. The use of digital watermarking technique in multimedia applications is evolving day by day. In this digital world copyright protection and claiming ownership on digital data is a big challenge. Watermarking multimedia objects/files is one of the solutions to this problem. Digital watermarking has been fascinating many researchers since last few decades. There is no algorithm that has been accepted universally till date. Various computational intelligence methodologies are also being used in digital watermarking to get the desired requirements of watermarking i.e. invisibility and resistance to various attacks. This paper is an attempt to create an optimal image watermarking scheme for copyright protection that can also resist the common attacks on watermarked image. Genetic algorithm has been employed in the proposed algorithm to find the embedding strength of watermark. Genetic algorithm and specially the parameters associated with it have helped in achieving the desired goals of watermarking.},
author = {Khanna, A.K. and Roy, N.R. and Verma, B.},
doi = {10.1109/CCAA.2016.7813888},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khanna, Roy, Verma - 2017 - Digital image watermarking and its optimization using genetic algorithm.pdf:pdf},
isbn = {9781509016662},
journal = {Proceeding - IEEE International Conference on Computing, Communication and Automation, ICCCA 2016},
keywords = {Digital Watermarking,Discrete Wavelet Transform,Genetic Algorithm,Singular Value Decomposition},
pages = {1--5},
title = {{Digital image watermarking and its optimization using genetic algorithm}},
year = {2017}
}
@article{Yu2011,
abstract = {This paper reports the first development of the Levenberg-Marquardt algorithm for neural networks. It describes the theory and application of the algorithm, which trains neural networks at a rate 10 to 100 times faster than the usual gradient descent backpropagation method.},
author = {Yu, Hao and Wilamowski, Bogdan},
doi = {10.1201/b10604-15},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu, Wilamowski - 2011 - Levenberg–Marquardt Training.pdf:pdf},
isbn = {978-1-4398-0283-0},
pages = {1--16},
title = {{Levenberg–Marquardt Training}},
url = {http://www.crcnetbase.com/doi/abs/10.1201/b10604-15},
year = {2011}
}
@article{Tastemirov2017,
abstract = {In this paper we develop a complete dynamic model of the Twin Rotor MIMO System (TRMS) using the Euler–Lagrange method. Our model improves upon the model provided by the manufacturer in the user manual and upon previous models of the TRMS which can be found in the literature. The complete procedure for the model parameters' estimation and validation is illustrated.},
author = {Tastemirov, Azamat and Lecchini-Visintini, Andrea and Morales-Viviescas, Rafael M.},
doi = {10.1016/j.conengprac.2017.06.009},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tastemirov, Lecchini-Visintini, Morales-Viviescas - 2017 - Complete dynamic model of the Twin Rotor MIMO System (TRMS) with experimental.pdf:pdf},
issn = {09670661},
journal = {Control Engineering Practice},
keywords = {Dynamic models,Euler–Lagrange method,Twin rotor MIMO system (TRMS)},
number = {April},
pages = {89--98},
publisher = {Elsevier Ltd},
title = {{Complete dynamic model of the Twin Rotor MIMO System (TRMS) with experimental validation}},
url = {http://dx.doi.org/10.1016/j.conengprac.2017.06.009},
volume = {66},
year = {2017}
}
@article{Gibaldi2017,
abstract = {In stereoscopic vision, the ability of perceiving the three-dimensional structure of the surrounding environment is subordinated to a precise and effective motor control for the binocular coordination of the eyes/cameras. If, on the one side, the binocular coordination of camera movements is a complicating factor, on the other side, a proper vergence control, acting on the binocular disparity, facilitates the binocular fusion and the subsequent stereoscopic perception process. In real-world situations, an effective vergence control requires further features other than real time capabilities: real robot systems are indeed characterized by mechanical and geometrical imprecision that affect the binocular vision, and the illumination conditions are changeable and unpredictable. Moreover, in order to allow an effective visual exploration of the peripersonal space, it is necessary to cope with different gaze directions and provide a large working space. The proposed control strategy resorts to a neuromimetic approach that provides a distributed representation of disparity information. The vergence posture is obtained by an open-loop and a closed-loop control, which directly interacts with saccadic control. Before saccade, the open-loop component is computed in correspondence of the saccade target region, to obtain a vergence correction to be applied simultaneously with the saccade. At fixation, the closed-loop component drives the binocular disparity to zero in a foveal region. The obtained vergence servos are able to actively drive both the horizontal and the vertical alignment of the optical axes on the object of interest, thus ensuring a correct vergence posture. Experimental tests were purposely designed to measure the performance of the control in the peripersonal space, and were performed on three different robot platforms. The results demonstrated that the proposed approach yields real-time and effective vergence camera movements on a visual stimulus in a wide working range, regardless of the illumination in the environment and the geometry of the system.},
author = {Gibaldi, Agostino and Vanegas, Mauricio and Canessa, Andrea and Sabatini, Silvio P.},
doi = {10.1007/s11263-016-0936-z},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gibaldi et al. - 2017 - A Portable Bio-Inspired Architecture for Efficient Robotic Vergence Control.pdf:pdf},
issn = {15731405},
journal = {International Journal of Computer Vision},
keywords = {Active vision,Binocular energy models,Neuromorphic architectures,Stereo vision,Vergence control},
number = {2},
pages = {281--302},
publisher = {Springer US},
title = {{A Portable Bio-Inspired Architecture for Efficient Robotic Vergence Control}},
volume = {121},
year = {2017}
}
@article{Chaudhry2019,
abstract = {In continual learning (CL), an agent learns from a stream of tasks leveraging prior experience to transfer knowledge to future tasks. It is an ideal framework to decrease the amount of supervision in the existing learning algorithms. But for a successful knowledge transfer, the learner needs to remember how to perform previous tasks. One way to endow the learner the ability to perform tasks seen in the past is to store a small memory, dubbed episodic memory, that stores few examples from previous tasks and then to replay these examples when training for future tasks. In this work, we empirically analyze the effectiveness of a very small episodic memory in a CL setup where each training example is only seen once. Surprisingly, across four rather different supervised learning benchmarks adapted to CL, a very simple baseline, that jointly trains on both examples from the current task as well as examples stored in the episodic memory, significantly outperforms specifically designed CL approaches with and without episodic memory. Interestingly, we find that repetitive training on even tiny memories of past tasks does not harm generalization, on the contrary, it improves it, with gains between 7% and 17% when the memory is populated with a single example per class.},
archivePrefix = {arXiv},
arxivId = {1902.10486},
author = {Chaudhry, Arslan and Rohrbach, Marcus and Elhoseiny, Mohamed and Dokania, Puneet K. and Torr, Philip H.S. and Ajanthan, Thalaiyasingam and Ranzato, Marc'Aurelio},
eprint = {1902.10486},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chaudhry et al. - 2019 - On tiny episodic memories in continual learning.pdf:pdf},
journal = {arXiv},
keywords = {continual learning,replay},
mendeley-tags = {continual learning,replay},
pages = {1--15},
title = {{On tiny episodic memories in continual learning}},
url = {https://github.com/facebookresearch/agem https://arxiv.org/abs/1902.10486},
year = {2019}
}
@article{Zhang2016b,
abstract = {Given a grayscale photograph as input, this paper attacks the problem of hallucinating a plausible color version of the photograph. This problem is clearly underconstrained, so previous approaches have either relied on significant user interaction or resulted in desaturated colorizations. We propose a fully automatic approach that produces vibrant and realistic colorizations. We embrace the underlying uncertainty of the problem by posing it as a classification task and use class-rebalancing at training time to increase the diversity of colors in the result. The system is implemented as a feed-forward pass in a CNN at test time and is trained on over a million color images. We evaluate our algorithm using a “colorization Turing test,” asking human participants to choose between a generated and ground truth color image. Our method successfully fools humans on 32% of the trials, significantly higher than previous methods. Moreover, we show that colorization can be a powerful pretext task for self-supervised feature learning, acting as a cross-channel encoder. This approach results in state-of-the-art performance on several feature learning benchmarks.},
archivePrefix = {arXiv},
arxivId = {1603.08511},
author = {Zhang, Richard and Isola, Phillip and Efros, Alexei A.},
doi = {10.1007/978-3-319-46487-9_40},
eprint = {1603.08511},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Isola, Efros - 2016 - Colorful image colorization.pdf:pdf},
isbn = {9783319464862},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {CNNs,Colorization,Self-supervised learning,Vision for graphics},
pages = {649--666},
title = {{Colorful image colorization}},
volume = {9907 LNCS},
year = {2016}
}
@article{Leproult2001a,
abstract = {The only well documented effect of light exposure on endocrine function is the suppression of nocturnal melatonin. Bright light exposure has behavioral effects, including the alleviation of sleepiness during nocturnal sleep deprivation. The present study examines the effects of bright light on the profiles of hormones known to be affected by sleep deprivation (TSH) or involved in behavioral activation (cortisol). Eight healthy men participated each in three studies involving 36 h of continuous wakefulness. In one study, the subjects were exposed to constant dim light (baseline). In the two other studies, dim light exposure was interrupted by a 3-h period of bright light exposure either from 0500-0800 h (early morning study) or from 1300-1600 h (afternoon study). Blood samples were obtained every 15 min for 24 h to determine melatonin, cortisol, and TSH concentrations. Alertness was estimated by the number of lapses on two computerized vigilance-sensitive performance tasks. The early morning transition from dim to bright light suppressed melatonin secretion, induced an immediate, greater than 50% elevation of cortisol levels, and limited the deterioration of alertness normally associated with overnight sleep deprivation. No effect was detected on TSH profiles. Afternoon exposure to bright light did not have any effect on either hormonal or behavioral parameters. The data unambiguously demonstrate an effect of light on the corticotropic axis that is dependent on time of day.},
author = {Leproult, Rachel and Colecchia, Egidio F. and L'Hermite-Bal{\'{e}}riaux, Mireille and {Van Cauter}, Eve},
doi = {10.1210/jc.86.1.151},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leproult et al. - 2001 - Transition from dim to bright light in the morning induces an immediate elevation of cortisol levels.pdf:pdf},
isbn = {0021-972X (Print)},
issn = {0021972X},
journal = {Journal of Clinical Endocrinology and Metabolism},
number = {1},
pages = {151--157},
pmid = {11231993},
title = {{Transition from dim to bright light in the morning induces an immediate elevation of cortisol levels}},
volume = {86},
year = {2001}
}
@article{Yang2020a,
abstract = {Current methods for training robust networks lead to a drop in test accuracy, which has led prior works to posit that a robustness-accuracy tradeoff may be inevitable in deep learning. We take a closer look at this phenomenon and first show that real image datasets are actually separated. With this property in mind, we then prove that robustness and accuracy should both be achievable for benchmark datasets through locally Lipschitz functions, and hence, there should be no inherent tradeoff between robustness and accuracy. Through extensive experiments with robustness methods, we argue that the gap between theory and practice arises from two limitations of current methods: either they fail to impose local Lipschitzness or they are insufficiently generalized. We explore combining dropout with robust training methods and obtain better generalization. We conclude that achieving robustness and accuracy in practice may require using methods that impose local Lipschitzness and augmenting them with deep learning generalization techniques. Code available at https://github.com/yangarbiter/robust-local-lipschitz},
archivePrefix = {arXiv},
arxivId = {2003.02460},
author = {Yang, Yao-Yuan and Rashtchian, Cyrus and Zhang, Hongyang and Salakhutdinov, Ruslan and Chaudhuri, Kamalika},
eprint = {2003.02460},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2020 - A Closer Look at Accuracy vs. Robustness.pdf:pdf},
keywords = {robustness},
mendeley-tags = {robustness},
number = {NeurIPS},
pages = {1--14},
title = {{A Closer Look at Accuracy vs. Robustness}},
url = {http://arxiv.org/abs/2003.02460},
year = {2020}
}
@article{JosePalacios2017,
abstract = {In this paper we tackle a variant of the job shop scheduling problem with uncertain task durations modelled as fuzzy numbers. Our goal is to simultaneously minimise the schedule's fuzzy makespan and maximise its robustness. To this end, we consider two measures of solution robustness: a predictive one, prior to the schedule execution, and an empirical one, measured at execution. To optimise both the expected makespan and the predictive robustness of the fuzzy schedule we propose a multiobjective evolutionary algorithm combined with a novel dominance-based tabu search method. The resulting hybrid algorithm is then evaluated on existing benchmark instances, showing its good behaviour and the synergy between its components. The experimental results also serve to analyse the goodness of the predictive robustness measure, in terms of its correlation with simulations of the empirical measure.},
author = {{Jos{\'{e}} Palacios}, Juan and Gonz{\'{a}}lez-Rodr{\'{i}}guez, In{\'{e}}s and Vela, Camino R. and Puente, Jorge},
doi = {10.1016/j.asoc.2016.07.004},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jos{\'{e}} Palacios et al. - 2017 - Robust multiobjective optimisation for fuzzy job shop problems.pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {Fuzzy sets,Metaheuristics,Multiobjective optimisation,Robustness,Scheduling},
pages = {604--616},
publisher = {Elsevier B.V.},
title = {{Robust multiobjective optimisation for fuzzy job shop problems}},
url = {http://dx.doi.org/10.1016/j.asoc.2016.07.004},
volume = {56},
year = {2017}
}
@article{Dong2014,
abstract = {In this paper, a study is presented on the microstructure of a cement-based PZT (Lead Zirconate Titanate) piezoelectric ceramic composite. A mechanism is proposed for chemical bonding between piezoelectric ceramic particles and cement material in the composite. The microstructure of the composite, as well as chemical bonding at the ceramic-cement interface is investigated using XRD, IR and XPS. Experimental results indicate that Ti-O in the ceramic particles links to Si-O in the cement paste via bridging oxygen, forming a Ti-O...Si-O bonding. And the change of chemical environment takes place for all of Ti, Si, Ca and Zr for cement-based piezoelectric ceramic composites. One prominent result pertaining to chemical reactions at the interface between ceramic particles and cement paste shows that Ti diffuses into the cement paste via Ti-O...Si-O bonding.},
author = {Dong, Biqin and Liu, Yuqing and Han, Ningxu and Sun, Hongfang and Xing, Feng and Qin, Daoding},
doi = {10.1016/j.conbuildmat.2014.08.058},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dong et al. - 2014 - Study on the microstructure of cement-based piezoelectric ceramic composites.pdf:pdf},
isbn = {09500618},
issn = {09500618},
journal = {Construction and Building Materials},
keywords = {Cement,Composite,Microstructure,Piezoelectric ceramic},
pages = {133--138},
publisher = {Elsevier Ltd},
title = {{Study on the microstructure of cement-based piezoelectric ceramic composites}},
url = {http://dx.doi.org/10.1016/j.conbuildmat.2014.08.058},
volume = {72},
year = {2014}
}
@inproceedings{Zhong2017a,
abstract = {Incremental learning is one of the research hotspots in machine learning. In this paper, we view the complex changes of data as three changes that are the change of sample, the change of class and the change of feature, and analyze the popular machine learning classification algorithms which support incremental learning. And then we focus on reviewing the research of three types of incremental learning: Sample Incremental Learning, Class Incremental Learning and Feature Incremental Learning. Finally, we make a prospect on the focus and difficulty of future research of incremental learning.},
author = {Yang, Qing and Gu, Yudi and Wu, Dongsheng},
booktitle = {2019 Chinese Control And Decision Conference (CCDC)},
doi = {10.1109/CCDC.2019.8832774},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhong et al. - 2017 - A Survey on Incremental Learning.pdf:pdf},
isbn = {978-1-7281-0106-4},
keywords = {abstract,changes of data as,class incremental learning,classification,continual learning,feature,in machine learning,in this paper,incremental learning,incremental learning is one,of the research hotspots,review,sample incremental learning,survey,the change of,the change of sample,three changes that are,we view the complex},
mendeley-tags = {continual learning,incremental learning,review,survey},
month = {jun},
number = {Cape},
pages = {399--404},
publisher = {IEEE},
title = {{Survey of incremental learning}},
url = {https://ieeexplore.ieee.org/document/8832774/},
year = {2019}
}
@article{Panchal2014,
abstract = {-Artificial Neural Networks are most effective and appropriate for pattern recognition and many other real world problems like signal processing, Classification problems. Superior results in pattern recognition can be directly provided in the forecasting, classification and data analysis. To bring proper results, ANN requires correct data pre-processing, architecture selection and network training but still the performance of a neural network depends on the size of network. Selection of hidden neurons in neural network is one of the major problems in the field of Artificial Neural Network. The random selections of hidden neurons may cause the problem of either Underfitting or Overfitting. Overfitting arises because the network matches the data so closely as to lose its generalization ability over the test data. The proposed method finds the near to optimal number of hidden nodes after training the ANN from real world data. The advantage of proposed method is that it is not approximately calculating number of hidden nodes but based on similarity between input data, they are calculated.},
author = {Panchal, Foram S and Panchal, Mahesh},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Panchal, Panchal - 2014 - Review on Methods of Selecting Number of Hidden Nodes in Artificial Neural Network.pdf:pdf},
journal = {International Journal of Computer Science and Mobile Computing},
keywords = {Hidden nodes,Learning rate,Supervised learning,– Artificial Neural Network},
number = {11},
pages = {455--464},
title = {{Review on Methods of Selecting Number of Hidden Nodes in Artificial Neural Network}},
url = {http://www.ijcsmc.com/docs/papers/November2014/V3I11201499a19.pdf},
volume = {311},
year = {2014}
}
@article{Fini2020,
abstract = {Continual Learning (CL) aims to develop agents emulating the human ability to sequentially learn new tasks while being able to retain knowledge obtained from past experiences. In this paper, we introduce the novel problem of Memory-Constrained Online Continual Learning (MC-OCL) which imposes strict constraints on the memory overhead that a possible algorithm can use to avoid catastrophic forgetting. As most, if not all, previous CL methods violate these constraints, we propose an algorithmic solution to MC-OCL: Batch-level Distillation (BLD), a regularization-based CL approach, which effectively balances stability and plasticity in order to learn from data streams, while preserving the ability to solve old tasks through distillation. Our extensive experimental evaluation, conducted on three publicly available benchmarks, empirically demonstrates that our approach successfully addresses the MC-OCL problem and achieves comparable accuracy to prior distillation methods requiring higher memory overhead (Code available at https://github.com/DonkeyShot21/batch-level-distillation).},
archivePrefix = {arXiv},
arxivId = {2008.01510},
author = {Fini, Enrico and Lathuili{\`{e}}re, St{\'{e}}phane and Sangineto, Enver and Nabi, Moin and Ricci, Elisa},
doi = {10.1007/978-3-030-58604-1_43},
eprint = {2008.01510},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fini et al. - 2020 - Online Continual Learning Under Extreme Memory Constraints.pdf:pdf},
isbn = {9783030586034},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Continual Learning,Memory efficient,Online learning,continual learning,memory-efficient,online learning},
mendeley-tags = {continual learning,memory-efficient,online learning},
pages = {720--735},
title = {{Online Continual Learning Under Extreme Memory Constraints}},
url = {https://github.com/DonkeyShot21/batch-level-distillation},
volume = {12373 LNCS},
year = {2020}
}
@article{Hanitsch2001,
abstract = {the quality of power supply from photovoltaic generators is very sensitive to shading effects of single or multiple cells. The energy yield of a partly shaded photovoltaic system is much lower than we could assume from the mean solar irradiance. Therefore we have to optimise the module structure and to select the right type of maximum power point tracking system in combination with the solar inverter},
author = {Hanitsch, R E and Schulz, Detlef and Siegfried, Udo},
doi = {10.1016/j.solener.2015.02.005},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hanitsch, Schulz, Siegfried - 2001 - Shading Effects on Output Power of Grid Connected Photovoltaic Generator Systems.pdf:pdf},
isbn = {0038-092X},
issn = {0038092X},
journal = {Renewable Energy},
keywords = {photovoltaic generators,power supply,shading effects,solar irradiance},
pages = {93--99},
title = {{Shading Effects on Output Power of Grid Connected Photovoltaic Generator Systems}},
year = {2001}
}
@article{Dai2007,
abstract = {Traditional machine learning makes a ba- sic assumption: the training and test data should be under the same distribution. However, in many cases, this identical- distribution assumption does not hold. The assumption might be violated when a task from one new domain comes, while there are only labeled data from a similar old domain. Labeling the new data can be costly and it would also be a waste to throw away all the old data. In this pa- per, we present a novel transfer learning framework called TrAdaBoost, which extends boosting-based learning algorithms (Freund & Schapire, 1997). TrAdaBoost allows users to utilize a small amount of newly labeled data to leverage the old data to construct a high-quality classification model for the new data. We show that this method can allow us to learn an accurate model using only a tiny amount of new data and a large amount of old data, even when the new data are not sufficient to train a model alone. We show that TrAdaBoost allows knowledge to be ef- fectively transferred from the old data to the new. The effectiveness of our algorithm is an- alyzed theoretically and empirically to show that our iterative algorithm can converge well to an accurate model. Appearing},
author = {Dai, W. and Yang, Q. and Gui-Rong, X. and Yong, Y.},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dai et al. - 2007 - Boosting for Transfer Learning.pdf:pdf},
journal = {Proceedings of the 24th International Confer- ence on Machine Learning},
keywords = {transfer learning},
mendeley-tags = {transfer learning},
pages = {193--200},
title = {{Boosting for Transfer Learning}},
year = {2007}
}
@article{Haussmann2020,
abstract = {Deep Neural Networks trained in a fully supervised fashion are the dominant technology in perception-based autonomous driving systems. While collecting large amounts of unlabeled data is already a major undertaking, only a subset of it can be labeled by humans due to the effort needed for high-quality annotation. Therefore, finding the right data to label has become a key challenge. Active learning is a powerful technique to improve data efficiency for supervised learning methods, as it aims at selecting the smallest possible training set to reach a required performance. We have built a scalable production system for active learning in the domain of autonomous driving. In this paper, we describe the resulting high-level design, sketch some of the challenges and their solutions, present our current results at scale, and briefly describe the open problems and future directions.},
archivePrefix = {arXiv},
arxivId = {2004.04699},
author = {Haussmann, Elmar and Fenzi, Michele and Chitta, Kashyap and Ivanecky, Jan and Xu, Hanson and Roy, Donna and Mittel, Akshita and Koumchatzky, Nicolas and Farabet, Clement and Alvarez, Jose M.},
doi = {10.1109/IV47402.2020.9304793},
eprint = {2004.04699},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Haussmann et al. - 2020 - Scalable Active Learning for Object Detection.pdf:pdf},
journal = {IEEE Intelligent Vehicles Symposium, Proceedings},
keywords = {active learning,object detection},
mendeley-tags = {active learning,object detection},
pages = {1430--1435},
title = {{Scalable Active Learning for Object Detection}},
year = {2020}
}
@article{Mobius2014,
abstract = {Stylized evidence suggests that people process information about their own ability in a biased manner. We provide a precise characterization of the nature and extent of these biases. We directly elicit experimental subjects' beliefs about their relative performance on an IQ quiz and track the evolution of these beliefs in response to noisy feedback. Our main result is that subjects update as if they misinterpret the information content of signals, but then process these misinterpreted signals like Bayesians. Specifically, they are asymmetric, over-weighting positive feedback relative to negative, and conservative, updating too little in response to both positive and negative feedback. These biases are substantially less pronounced in a placebo experiment where ego is not at stake, suggesting they are motivated rather than cognitive. Consistent with Bayes' rule, on the other hand, updating is invariant to priors (and over time) and priors are sufficient statistics for past information. Based on these findings, we build a model that theoretically derives the optimal bias of a decision-maker with ego utility and show that it naturally gives rise to both asymmetry and conservatism as complementary strategies in self-confidence management.},
author = {M{\"{o}}bius, Markus M and Niederle, Muriel and Niehaus, Paul and Rosenblat, Tanja S},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/M{\"{o}}bius et al. - 2014 - Managing Self-Confidence.pdf:pdf},
journal = {Working Paper},
keywords = {Bayes' rule,C91,C93,D83 Keywords,JEL Classification,asymmetric belief updating,conservatism * We are grateful to,economic experiments},
title = {{Managing Self-Confidence}},
year = {2014}
}
@article{Naranjo2018,
abstract = {This paper proposes a methodology to detect candlestick patterns in a stock trading system using fuzzy logic. The fuzzy approach make possible to account for the vagueness and uncertainty of the pattern features. Even more, the use of fuzzy rules allows it to include that uncertainty into a trading decision system that not only advises the investor on when but also on how much capital to invest. In this way, the intelligent system helps the experts to use their knowledge, i.e. the candlestick-based rules, in a more natural and realistic way than the standard one based on crisp rules. In the paper we have illustrated this methodology with the generation of a fuzzy trading system that uses three well-known candlestick patterns that have been fuzzified. The performance of this intelligent stock trading system is tested in two portfolios of different stock markets, Nasdaq-100 and Eurostoxx, and it is compared against its crisp counterpart and the classical Buy-and-Hold trading strategy. Our fuzzy candlestick-based trading system not only improves the pattern recognition with respect to its crisp version, but it also provides promising results since it exhibits a more stable behavior in the markets analyzed, and obtains more profits in a less risky way than the other trading systems considered.},
author = {Naranjo, Rodrigo and Arroyo, Javier and Santos, Matilde},
doi = {10.1016/j.eswa.2017.10.002},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Naranjo, Arroyo, Santos - 2018 - Fuzzy modeling of stock trading with fuzzy candlesticks.pdf:pdf},
isbn = {0957-4174},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Candlesticks,Forecasting,Fuzzy logic,Pattern recognition,Stock market,Trading},
pages = {15--27},
publisher = {Elsevier Ltd},
title = {{Fuzzy modeling of stock trading with fuzzy candlesticks}},
url = {https://doi.org/10.1016/j.eswa.2017.10.002},
volume = {93},
year = {2018}
}
@article{Pan2010,
abstract = {A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data-labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classification, regression, and clustering problems. In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as covariate shift. We also explore some potential future issues in transfer learning research. {\textcopyright} 2006 IEEE.},
author = {Pan, Sinno Jialin and Yang, Qiang},
doi = {10.1109/TKDE.2009.191},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pan, Yang - 2010 - A survey on transfer learning.pdf:pdf},
issn = {10414347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Transfer learning,data mining.,machine learning,survey},
number = {10},
pages = {1345--1359},
publisher = {IEEE},
title = {{A survey on transfer learning}},
volume = {22},
year = {2010}
}
@article{Nguyen2020,
abstract = {Explaining the behaviors of deep neural networks, usually considered as black boxes, is critical especially when they are now being adopted over diverse aspects of human life. Taking the advantages of interpretable machine learning (interpretable ML), this paper proposes a novel tool called Catastrophic Forgetting Dissector (or CFD) to explain catastrophic forgetting in continual learning settings. We also introduce a new method called Critical Freezing based on the observations of our tool. Experiments on ResNet articulate how catastrophic forgetting happens, particularly showing which components of this famous network are forgetting. Our new continual learning algorithm defeats various recent techniques by a significant margin, proving the capability of the investigation. Critical freezing not only attacks catastrophic forgetting but also exposes explainability.},
archivePrefix = {arXiv},
arxivId = {2005.01004},
author = {Nguyen, Giang and Chen, Shuan and Jun, Tae Joon and Kim, Daeyoung},
eprint = {2005.01004},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen et al. - 2020 - Explaining how deep neural networks forget by deep visualization.pdf:pdf},
journal = {arXiv},
keywords = {catastrophic,continual learning,explainable ai,explainable deep learning,forgetting},
pages = {1--12},
title = {{Explaining how deep neural networks forget by deep visualization}},
year = {2020}
}
@article{Khaliq2017,
abstract = {Piezoelectric composites made from soft and hard lead zirconium titanate (PZT) particles as filler and an epoxy as the matrix were prepared by dielectrophoresis and studied for their piezoelectric properties. It was found that the dielectric constant of the piezoelectric filler plays a significant role in determining the final piezoelectric properties of the composites. Composites with lower dielectric constant for the PZT filler material showed better piezoelectric properties compared to the composites with high dielectric constant filler. This can be ascribed to a more efficient poling of the piezoelectric filler particles. The aging behaviour of these composites was compared to that reported for monolithic ceramics.},
author = {Khaliq, Jibran and Deutz, Daniella Bayle and Frescas, Jesus Alfonso Caraveo and Vollenberg, Peter and Hoeks, Theo and van der Zwaag, Sybrand and Groen, Pim},
doi = {10.1016/j.ceramint.2016.11.108},
issn = {02728842},
journal = {Ceramics International},
keywords = {Aging rate,Hard/Soft PZT,Piezoelectrics,Structured composites},
number = {2},
pages = {2774--2779},
title = {{Effect of the piezoelectric ceramic filler dielectric constant on the piezoelectric properties of PZT-epoxy composites}},
volume = {43},
year = {2017}
}
@book{Hoanca2002,
abstract = {Unlike the many “comprehensive” books on optical communications,  DWDM  focuses strictly on the technology, its enablers, and its system implications. There are no general chapters on optical data formats, on receiver types, or on legacy telecommunications networks. Instead, the book covers only DWDM-related topics, and it covers them very well.},
author = {Hoanca, Bogdan},
booktitle = {J. Opt. Netw.},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hoanca - 2002 - DWDM Fundamentals, Components, and Applications.pdf:pdf},
isbn = {1580531776},
issn = {15365379},
keywords = {components,m fundamentals},
number = {5},
pages = {184--185},
title = {{DWDM Fundamentals, Components, and Applications}},
url = {http://www.opticsinfobase.org/abstract.cfm?id=68848},
volume = {1},
year = {2002}
}
@article{Sarkar2017,
abstract = {Pure and fresh water is being scarce day by day. Although Bangladesh is a riverine country, pure drinking potable water is not a cheap commodity. Most of the people in the cities boil water to drink, and people of the villages take tube-well's water directly, which might have high amount of heavy metal like arsenic. Solar still is a cheap and very useful renewable technology, which can be used in Bangladesh extensively everywhere at the rooftop as a pure water source. Objective of this paper was to find a low cost portable and easily maintainable passive solar still for southern part of Bangladesh. All the parameters of passive solar still are studied, and it is found that an inclined stepped solar still with passive condenser, internal and external reflectors, black cotton wick, and with optimum design values can be the desired still, which would give maximum yield. Finally, the optimum values of the parameters are used to propose a cheap design.},
author = {Sarkar, Md. Nazmul Islam and Sifat, Anwarul Islam and Reza, S. M. Shamim and Sadique, Md. Shibli},
doi = {10.1186/s40807-017-0038-8},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sarkar et al. - 2017 - A review of optimum parameter values of a passive solar still and a design for southern Bangladesh.pdf:pdf},
issn = {2198-994X},
journal = {Renewables: Wind, Water, and Solar},
keywords = {Solar distillation,Desalination,Passive solar stil,desalination,parameters affecting still yield,passive solar still,solar distillation,stepped still},
number = {1},
pages = {1},
publisher = {Springer Singapore},
title = {{A review of optimum parameter values of a passive solar still and a design for southern Bangladesh}},
url = {http://jrenewables.springeropen.com/articles/10.1186/s40807-017-0038-8},
volume = {4},
year = {2017}
}
@article{IBM2014,
abstract = {About IBM Business Analytics IBM Business Analytics software delivers complete, consistent and accurate information that decision-makers trust to improve business performance. A comprehensive portfolio of business intelligence, predictive analytics, financial performance and strategy management, and analytic applications provides clear, immediate and actionable insights into current performance and the ability to predict future outcomes. Combined with rich industry solutions, proven practices and professional services, organizations of every size can drive the highest productivity, confidently automate decisions and deliver better results. As part of this portfolio, IBM SPSS Predictive Analytics software helps organizations predict future events and proactively act upon that insight to drive better business outcomes. Commercial, government and academic customers worldwide rely on IBM SPSS technology as a competitive advantage in attracting, retaining and growing customers, while reducing fraud and mitigating risk. By incorporating IBM SPSS software into their daily operations, organizations become predictive enterprises – able to direct and automate decisions to meet business goals and achieve measurable competitive advantage. For further information or to reach a representative visit},
author = {IBM},
pages = {99},
title = {{IBM SPSS Missing Values 22}},
year = {2014}
}
@article{Robles2012,
abstract = {Hard skills are the technical expertise and knowledge needed for a job. Soft skills are interpersonal qualities, also known as people skills, and personal attributes that one possesses. Business executives consider soft skills a very important attribute in job applicants. Employers want new employees to have strong soft skills, as well as hard skills. This study identified the top 10 soft skills as perceived the most important by business executives: integrity, communication, courtesy, responsibility, social skills, positive attitude, professionalism, flexibility, teamwork, and work ethic.},
author = {Robles, Marcel M.},
doi = {10.1177/1080569912460400},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Robles - 2012 - Executive Perceptions of the Top 10 Soft Skills Needed in Today's Workplace.pdf:pdf},
isbn = {10805699},
issn = {10805699},
journal = {Business Communication Quarterly},
keywords = {interpersonal skills,people skills,soft skills},
number = {4},
pages = {453--465},
pmid = {83329495},
title = {{Executive Perceptions of the Top 10 Soft Skills Needed in Today's Workplace}},
volume = {75},
year = {2012}
}
@article{Lange2020,
abstract = {Attaining prototypical features to represent class distributions is well established in representation learning. However, learning prototypes online from streams of data proves a challenging endeavor as they rapidly become outdated, caused by an ever-changing parameter space in the learning process. Additionally, continual learning does not assume the data stream to be stationary, typically resulting in catastrophic forgetting of previous knowledge. As a first, we introduce a system addressing both problems, where prototypes evolve continually in a shared latent space, enabling learning and prediction at any point in time. In contrast to the major body of work in continual learning, data streams are processed in an online fashion, without additional task-information, and an efficient memory scheme provides robustness to imbalanced data streams. Besides nearest neighbor based prediction, learning is facilitated by a novel objective function, encouraging cluster density about the class prototype and increased inter-class variance. Furthermore, the latent space quality is elevated by pseudo-prototypes in each batch, constituted by replay of exemplars from memory. We generalize the existing paradigms in continual learning to incorporate data incremental learning from data streams by formalizing a two-agent learner-evaluator framework, and obtain state-of-the-art performance by a significant margin on eight benchmarks, including three highly imbalanced data streams.},
archivePrefix = {arXiv},
arxivId = {2009.00919},
author = {Lange, Matthias De and Tuytelaars, Tinne},
eprint = {2009.00919},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lange, Tuytelaars - 2020 - Continual Prototype Evolution Learning Online from Non-Stationary Data Streams.pdf:pdf},
keywords = {continual learning,data stream,non-stationary},
mendeley-tags = {continual learning,data stream,non-stationary},
title = {{Continual Prototype Evolution: Learning Online from Non-Stationary Data Streams}},
year = {2020}
}
@article{Yin2020a,
abstract = {Neural networks have achieved remarkable success in many cognitive tasks. However, when they are trained sequentially on multiple tasks without access to old data, their performance on early tasks tend to drop significantly. This problem is often referred to as catastrophic forgetting, a key challenge in continual learning of neural networks. The regularization-based approach is one of the primary classes of methods to alleviate catastrophic forgetting. In this paper, we provide a novel viewpoint of regularization-based continual learning by formulating it as a second-order Taylor approximation of the loss function of each task. This viewpoint leads to a unified framework that can be instantiated to derive many existing algorithms such as Elastic Weight Consolidation and Kronecker factored Laplace approximation. Based on this viewpoint, we study the optimization aspects (i.e., convergence) as well as generalization properties (i.e., finite-sample guarantees) of regularization-based continual learning. Our theoretical results indicate the importance of accurate approximation of the Hessian matrix. The experimental results on several benchmarks provide empirical validation of our theoretical findings.},
archivePrefix = {arXiv},
arxivId = {2006.10974},
author = {Yin, Dong and Farajtabar, Mehrdad and Li, Ang and Levine, Nir and Mott, Alex},
eprint = {2006.10974},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yin et al. - 2020 - Optimization and Generalization of Regularization-Based Continual Learning a Loss Approximation Viewpoint.pdf:pdf},
keywords = {continual learning,regularization,review,survey},
mendeley-tags = {continual learning,regularization,review,survey},
month = {jun},
pages = {1--17},
title = {{Optimization and Generalization of Regularization-Based Continual Learning: a Loss Approximation Viewpoint}},
url = {http://arxiv.org/abs/2006.10974},
year = {2020}
}
@article{Tuggener2021,
abstract = {An implicit but pervasive hypothesis of modern computer vision research is that convolutional neural network (CNN) architectures that perform better on ImageNet will also perform better on other vision datasets. We challenge this hypothesis through an extensive empirical study for which we train 500 sampled CNN architectures on ImageNet as well as 8 other image classification datasets from a wide array of application domains. The relationship between architecture and performance varies wildly, depending on the datasets. For some of them, the performance correlation with ImageNet is even negative. Clearly, it is not enough to optimize architectures solely for ImageNet when aiming for progress that is relevant for all applications. Therefore, we identify two dataset-specific performance indicators: the cumulative width across layers as well as the total depth of the network. Lastly, we show that the range of dataset variability covered by ImageNet can be significantly extended by adding ImageNet subsets restricted to few classes.},
archivePrefix = {arXiv},
arxivId = {2103.09108},
author = {Tuggener, Lukas and Schmidhuber, J{\"{u}}rgen and Stadelmann, Thilo},
eprint = {2103.09108},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tuggener, Schmidhuber, Stadelmann - 2021 - Is it Enough to Optimize CNN Architectures on ImageNet.pdf:pdf},
keywords = {imagenet,transfer learning},
mendeley-tags = {imagenet,transfer learning},
title = {{Is it Enough to Optimize CNN Architectures on ImageNet?}},
url = {http://arxiv.org/abs/2103.09108},
year = {2021}
}
@article{Zhang2017b,
abstract = {{\textcopyright} 2017 Technical Committee on Control Theory, CAA. Short-term prediction of water demand provides basic guarantee of water supply system operation and management. In this study, an effective model for daily water demand forecasting is proposed. Firstly, principle component analysis (PCA) is utilized to simplify the complexity and reduce the correlation between influence variables, and the score values of selected principle components (PCs) turn into the irrelevant input data of fuzzy neural network (FNN), which models the prediction of water demand. Moreover, an improved Levenberg-Marquardt (ILM) algorithm is employed to optimize the parameters of FNN simultaneously. Quassi-Hessian and gradient matrices could be calculated directly without the storage and multiplication of whole Jaccobian matrix, therefore the problems of heavy computing burden and limited memory space could be solved. At last, contrast experiments are implemented to demonstrate the fuzzy neural network with Levenberg-Marquardt algorithm (ILM-FNN) has better prediction performance and capability to handle practical issues.},
author = {Zhang, Li and Li, Wen Jing and Qiao, Jun Fei},
doi = {10.23919/ChiCC.2017.8027971},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Li, Qiao - 2017 - The prediction of daily water demand based on fuzzy neural network with an improved Levenberg-Marquardt algorit.pdf:pdf},
isbn = {9789881563934},
issn = {21612927},
journal = {Chinese Control Conference, CCC},
keywords = {PCA,fuzzy neural network,improved LM algorithm,water demand forecasting},
number = {Lm},
pages = {3925--3930},
title = {{The prediction of daily water demand based on fuzzy neural network with an improved Levenberg-Marquardt algorithm}},
year = {2017}
}
@article{McCarthy1955,
author = {McCarthy and Minsky and Rochester and Shannon},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/McCarthy et al. - 1955 - A Proposal For The Dartmouth Summer Research Project on Artificial Intelligence.pdf:pdf},
pages = {1--13},
title = {{A Proposal For The Dartmouth Summer Research Project on Artificial Intelligence}},
year = {1955}
}
@article{Du2019a,
abstract = {There is an increasing need of continual learning in dynamic systems, such as the self-driving vehicle, the surveillance drone, and the robotic system. Such a system requires learning from the data stream, training the model to preserve previous information and adapt to a new task, and generating a single-headed vector for future inference. Different from previous approaches with dynamic structures, this work focuses on a single network and model segmentation to prevent catastrophic forgetting. Leveraging the redundant capacity of a single network, model parameters for each task are separated into two groups: one important group which is frozen to preserve current knowledge, and secondary group to be saved (not pruned) for a future learning. A fixed-size memory containing a small amount of previously seen data is further adopted to assist the training. Without additional regularization, the simple yet effective approach of PST successfully incorporates multiple tasks and achieves the state-of-the-art accuracy in the single-head evaluation on CIFAR-10 and CIFAR-100 datasets. Moreover, the segmented training significantly improves computation efficiency in continual learning.},
archivePrefix = {arXiv},
arxivId = {1905.11550},
author = {Du, Xiaocong and Charan, Gouranga and Liu, Frank and Cao, Yu},
doi = {10.1109/ICMLA.2019.00267},
eprint = {1905.11550},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Du et al. - 2019 - Single-Net Continual Learning with Progressive Segmented Training (PST).pdf:pdf},
isbn = {9781728145501},
journal = {arXiv},
keywords = {architectural,continual learning},
mendeley-tags = {architectural,continual learning},
month = {may},
number = {2},
pages = {1629--1636},
title = {{Single-Net Continual Learning with Progressive Segmented Training (PST)}},
url = {http://arxiv.org/abs/1905.11550 https://github.com/alessiabertugli/FUSION},
year = {2019}
}
@book{Uchino2010,
abstract = {Piezo-composites composed of a piezoelectric ceramic and a polymer are promising materials because of their excellent tailorable properties. The geometry for two-phase composites can be classified according to the connectivity of each phase (1, 2 or 3 dimensionally) into 10 structures; 0-0, 0-1, 0-2, 0-3, 1-1, 1-2, 1-3, 2-2, 2-3 and 3-3. In particular, a 1-3 piezo-composite, or PZT-rod/polymer-matrix composite is considered most useful. The advantages of this composite are high coupling factors, low acoustic impedance, good matching to water or human tissue, mechanical flexibility, broad bandwidth in combination with a low mechanical quality factor and the possibility of making undiced arrays by simply patterning the electrodes. The acoustic match to tissue or water of the typical piezoceramics is significantly improved when it is incorporated into such a composite structure, that is, by replacing some of the dense and stiff ceramic with a less dense, more pliant polymer. Piezoelectric composite materials are especially useful for underwater sonar and medical diagnostic ultrasonic transducer applications. Other types of composites based on piezoelectric ceramics are also introduced in this chapter. Piezo-passive-dampers comprise a piezoelectric ceramic particle, polymer, and a carbon black, which suppress the noise vibration more effectively than traditional rubbers. A composite with a magnetostrictive ceramic and a piezoelectric ceramic produces an intriguing product effect, the magnetoelectric effect in which an electric field is produced in the material in response to an applied magnetic field. {\textcopyright} 2010 Woodhead Publishing Limited All rights reserved.},
author = {Uchino, Kenji},
booktitle = {Advanced Piezoelectric Materials: Science and Technology},
doi = {10.1533/9781845699758.1.318},
edition = {2},
isbn = {9781845695347},
keywords = {Combination effect,Magnetoelectric effect,PZT-polymer composite,Phase connectivity,Piezoelectric composite,Piezoelectric damping,Piezoelectric energy harvesting,Product effect,Sum effect},
pages = {318--346},
publisher = {Elsevier Ltd.},
title = {{Piezoelectric composite materials}},
url = {http://dx.doi.org/10.1016/B978-0-08-102135-4.00009-6},
year = {2010}
}
@article{Tvrd,
author = {Tvrd, J},
number = {1},
title = {{COMPETITIVE DIFFERENTIAL EVOLUTION AND GENETIC ALGORITHM IN GA-DS TOOLBOX}}
}
@article{Wang2020e,
abstract = {We investigate the relationship between the frequency spectrum of image data and the generalization behavior of convolutional neural networks (CNN). We first notice CNN's ability in capturing the high-frequency components of images. These high-frequency components are almost imperceptible to a human. Thus the observation leads to multiple hypotheses that are related to the generalization behaviors of CNN, including a potential explanation for adversarial examples, a discussion of CNN's trade-off between robustness and accuracy, and some evidence in understanding training heuristics.},
archivePrefix = {arXiv},
arxivId = {1905.13545},
author = {Wang, Haohan and Wu, Xindi and Huang, Zeyi and Xing, Eric P.},
doi = {10.1109/CVPR42600.2020.00871},
eprint = {1905.13545},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2020 - High-Frequency Component Helps Explain the Generalization of Convolutional Neural Networks.pdf:pdf;:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2020 - High-Frequency Component Helps Explain the Generalization of Convolutional Neural Networks(2).pdf:pdf},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
keywords = {generalization},
mendeley-tags = {generalization},
number = {Remark 1},
pages = {8681--8691},
title = {{High-Frequency Component Helps Explain the Generalization of Convolutional Neural Networks}},
year = {2020}
}
@inproceedings{Kukleva2021,
abstract = {Both generalized and incremental few-shot learning have to deal with three major challenges: learning novel classes from only few samples per class, preventing catastrophic forgetting of base classes, and classifier calibration across novel and base classes. In this work we propose a three-stage framework that allows to explicitly and effectively address these challenges. While the first phase learns base classes with many samples, the second phase learns a calibrated classifier for novel classes from few samples while also preventing catastrophic forgetting. In the final phase, calibration is achieved across all classes. We evaluate the proposed framework on four challenging benchmark datasets for image and video few-shot classification and obtain state-of-the-art results for both generalized and incremental few shot learning.},
archivePrefix = {arXiv},
arxivId = {2108.08165},
author = {Kukleva, Anna and Kuehne, Hilde and Schiele, Bernt},
booktitle = {International Conference on Computer Vision},
eprint = {2108.08165},
file = {:home/user/Downloads/2108.08165.pdf:pdf},
keywords = {continual learning},
mendeley-tags = {continual learning},
title = {{Generalized and Incremental Few-Shot Learning by Explicit Learning and Calibration without Forgetting}},
url = {http://arxiv.org/abs/2108.08165},
year = {2021}
}
@inproceedings{Arifin2019,
address = {Surabaya},
author = {Arifin, Syamsul and Mahistha, Dvitiya Srestha Prajna and Ukhti, Magfiroh Fatwaning and Kurniawan, Muhammad Rifki and Aisjah, Aulia Siti},
booktitle = {AIP Conference Proceedings 2088},
doi = {10.1063/1.5095287},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arifin et al. - 2019 - Optimization of neural network based on hybrid method of genetic algorithm and particle swarm optimization for ma.pdf:pdf},
isbn = {9780735418189},
publisher = {American Institute of Physics},
title = {{Optimization of neural network based on hybrid method of genetic algorithm and particle swarm optimization for maritime weather forecasting in buoyweather station type II Optimization of Neural Network Based on Hybrid Method of Genetic Algorithm and Parti}},
volume = {020042},
year = {2019}
}
@book{Filippini2006,
abstract = {Chemical sensors and biosensors are becoming more and more indispensable tools in life science, medicine, chemistry and biotechnology. The series covers exciting sensor-related aspects of chemistry, biochemistry, thin film and interface techniques, physics, including opto-electronics, measurement sciences and signal processing. The single volumes of the series focus on selected topics and will be edited by selected volume editors. The Springer Series on Chemical Sensors and Biosensors aims to publish state-of-the-art articles that canserve as invaluable tools for both practitioners and researchers active in this highly interdisciplinary field. The carefully edited collection of papers in each volume will give continuous inspiration for new research and will point to existing new trends and brand new applications.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Filippini, D.},
booktitle = {Springer Series on Chemical Sensors and Biosensors},
doi = {10.1007/b100321},
eprint = {arXiv:1011.1669v3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Filippini - 2006 - Springer Series on Chemical Sensors and Biosensors.pdf:pdf},
isbn = {9783540365679},
issn = {16182642},
number = {5},
pages = {251},
pmid = {25246403},
title = {{Springer Series on Chemical Sensors and Biosensors}},
url = {http://books.google.com/books?hl=en&lr=&id=Lhd_JVZW7D0C&oi=fnd&pg=PA4&dq=Surface+Plasmon+Resonance+Based+Sensors&ots=N3X8Wmu8iV&sig=dR8HSAv-9M9mcdjSNwj-AKwD-aQ},
volume = {4},
year = {2006}
}
@article{Thai2021,
abstract = {Continual learning is known for suffering from catastrophic forgetting, a phenomenon where earlier learned concepts are forgotten at the expense of more recent samples. In this work, we challenge the assumption that continual learning is inevitably associated with catastrophic forgetting by presenting a set of tasks that surprisingly do not suffer from catastrophic forgetting when learned continually. We attempt to provide an insight into the property of these tasks that make them robust to catastrophic forgetting and the potential of having a proxy representation learning task for continual classification. We further introduce a novel yet simple algorithm, YASS that outperforms state-of-the-art methods in the class-incremental categorization learning task. Finally, we present DyRT, a novel tool for tracking the dynamics of representation learning in continual models. The codebase, dataset and pre-trained models released with this article can be found at https://github.com/ngailapdi/CLRec.},
archivePrefix = {arXiv},
arxivId = {2101.07295},
author = {Thai, Anh and Stojanov, Stefan and Rehg, Isaac and Rehg, James M.},
eprint = {2101.07295},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thai et al. - 2021 - Does Continual Learning = Catastrophic Forgetting.pdf:pdf},
keywords = {catastrophic forgetting,continual learning},
mendeley-tags = {catastrophic forgetting,continual learning},
title = {{Does Continual Learning = Catastrophic Forgetting?}},
url = {http://arxiv.org/abs/2101.07295 https://github.com/ngailapdi/CLRec},
year = {2021}
}
@article{Jiaran2015,
abstract = {Wind power prediction accuracy has important implications for the scheduling and stable operation of the power system. An Intelligent Combined Prediction algorithm of Wind Power Based on Numerical Weather Prediction and Fuzzy Clustering is proposed in the paper. Based on numerical weather prediction (NWP) data and using the method of fuzzy clustering subtraction, the original NWP data is divided into several typical weather patterns; T-S fuzzy model, time-series model, multiple linear regression model and gray model are established respectively according to different whether types; the combination of multi-model is optimized using intelligent optimization algorithms and the optimal combination prediction model is obtained. Prediction results of a domestic wind farm indicate that the proposed combination prediction method is valid and effective in short-term wind power prediction, with better prediction accuracy.},
author = {Jiaran, Yang and Xingcheng, Wang and Xiaofen, Luo and Cheng, Jiang},
doi = {10.1016/j.ifacol.2015.12.184},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jiaran et al. - 2015 - Intelligent Combined Prediction of Wind Power Based on Numerical Weather Prediction and Fuzzy Clustering.pdf:pdf},
issn = {24058963},
journal = {IFAC-PapersOnLine},
keywords = {Combined Prediction,Fuzzy Clustering,Intelligent Optimization,Numerical Weather Prediction,Wind Power},
number = {28},
pages = {538--543},
publisher = {Elsevier B.V.},
title = {{Intelligent Combined Prediction of Wind Power Based on Numerical Weather Prediction and Fuzzy Clustering}},
url = {http://dx.doi.org/10.1016/j.ifacol.2015.12.184},
volume = {48},
year = {2015}
}
@article{Satyavani2016,
abstract = {Lithium ion battery technology has the potential to meet the requirements of high energy density and high power density applications. A continuous search for novel materials is pursued continually to exploit the latent potential of this technology. In this review paper, methods for preparation of Lithium Iron Phosphate are discussed which include solid state and solution based synthesis routes. The methods to improve the electrochemical performance of lithium iron phosphate are presented in detail.},
author = {Satyavani, T. V.S.L. and {Srinivas Kumar}, A. and {Subba Rao}, P. S.V.},
doi = {10.1016/j.jestch.2015.06.002},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Satyavani, Srinivas Kumar, Subba Rao - 2016 - Methods of synthesis and performance improvement of lithium iron phosphate for high rate L.pdf:pdf},
isbn = {2215-0986},
issn = {22150986},
journal = {Engineering Science and Technology, an International Journal},
keywords = {Electrochemical performance,Li-ion battery,Lithium iron phosphate,Solid state synthesis,Solution based synthesis},
number = {1},
pages = {178--188},
publisher = {Elsevier B.V.},
title = {{Methods of synthesis and performance improvement of lithium iron phosphate for high rate Li-ion batteries: A review}},
url = {http://dx.doi.org/10.1016/j.jestch.2015.06.002},
volume = {19},
year = {2016}
}
@article{R1990,
author = {R, Ratcliff},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/R - 1990 - Catastrophic models of recognition memory Constraints imposed by learning and forgetting functions.pdf:pdf},
journal = {Psychological review},
number = {2},
pages = {285--308},
title = {{Catastrophic models of recognition memory: Constraints imposed by learning and forgetting functions}},
volume = {97},
year = {1990}
}
@article{August2006,
author = {August, Version and White, Steve P and Thornes, John E and Chapman, Lee},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/August et al. - 2006 - A Guide to Road Weather Information Systems.pdf:pdf},
title = {{A Guide to Road Weather Information Systems}},
volume = {2},
year = {2006}
}
@article{Hanidah2017,
author = {Hanidah, In-in and Safitri, Ratu and Subroto, Toto},
doi = {10.24198/jp2.2016.vol1.1.},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hanidah, Safitri, Subroto - 2017 - Alternatif Fermentasi Bio-Etanol dari Bagas Tebu oleh Zymomonas mobilis Bio-Ethanol Fermentation Alte.pdf:pdf},
title = {{Alternatif Fermentasi Bio-Etanol dari Bagas Tebu oleh Zymomonas mobilis Bio-Ethanol Fermentation Alternative of Sugarcane Bagasse by Zymomonas mobilis}},
volume = {1},
year = {2017}
}
@article{Prieto2009,
abstract = {Road sign recognition is a part of driver support systems. Its main aim is the increase of traffic safety by calling the driver's attention to the presence of key traffic signs. Additionally, a vision-based system able to detect and classify traffic signs from road images in real-time would also be useful as a support tool for guidance and navigation of intelligent vehicles. This paper proposes a new method for the detection and recognition of traffic signs using self-organising maps (SOM). This method first detects potential road signs by analysing the distribution of red pixels within the image, and then identifies these road signs from the distribution of dark pixels in their pictograms. Additionally, a novel hybrid system combining programmable hardware and artificial neural networks for embedded machine vision is introduced, and a prototype of this system is used in the implementation of the application. The experiments indicate a good performance of the new approach using SOM in both speed and classification accuracy. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
author = {Prieto, Miguel S. and Allen, Alastair R.},
doi = {10.1016/j.imavis.2008.07.006},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Prieto, Allen - 2009 - Using self-organising maps in the detection and recognition of road signs.pdf:pdf},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {Road sign detection,Road sign recognition,Self-organising map},
month = {may},
number = {6},
pages = {673--683},
publisher = {Elsevier B.V.},
title = {{Using self-organising maps in the detection and recognition of road signs}},
url = {http://dx.doi.org/10.1016/j.imavis.2008.07.006 https://linkinghub.elsevier.com/retrieve/pii/S0262885608001613},
volume = {27},
year = {2009}
}
@article{He2016,
abstract = {This paper solves the controller tuning problem of machine-directional predictive control for multiple-input–multiple-output (MIMO) paper-making processes represented as superposition of first-order-plus-dead-time (FOPDT) components with uncertain model parameters. A user-friendly multi-variable tuning problem is formulated based on user-specified time domain specifications and then simplified based on the structure of the closed-loop system. Based on the simplified tuning problem and a proposed performance evaluation technique, a fast multi-variable tuning technique is developed by ignoring the constraints of the MPC. In addition, a technique to predict the computation time of the tuning algorithm is proposed. The efficiency of the proposed method is verified through Honeywell real time simulator platform with a MIMO paper-making process obtained from real data from an industrial site.},
author = {He, Ning and Shi, Dawei and Forbes, Michael and Backstr{\"{o}}m, Johan and Chen, Tongwen},
doi = {10.1016/j.conengprac.2016.06.008},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/He et al. - 2016 - Robust tuning for machine-directional predictive control of MIMO paper-making processes.pdf:pdf},
issn = {09670661},
journal = {Control Engineering Practice},
keywords = {Controller tuning,MIMO systems,Model predictive control,Paper machines,Parametric uncertainty,Time-domain specifications},
pages = {1--12},
publisher = {Elsevier},
title = {{Robust tuning for machine-directional predictive control of MIMO paper-making processes}},
url = {http://dx.doi.org/10.1016/j.conengprac.2016.06.008},
volume = {55},
year = {2016}
}
@article{Bailie2015,
abstract = {A promising approach for upgrading the performance of an established low-bandgap solar technology without adding much cost is to deposit a high bandgap polycrystalline semiconductor on top to make a tandem solar cell. We use a transparent silver nanowire electrode on perovskite solar cells to achieve a semi-transparent device. We place the semi-transparent cell in a mechanically-stacked tandem configuration onto copper indium gallium diselenide (CIGS) and low-quality multicrystalline silicon (Si) to achieve solid-state polycrystalline tandem solar cells with a net improvement in efficiency over the bottom cell alone. This work paves the way for integrating perovskites into a low-cost and high-efficiency (>25%) tandem cell.},
archivePrefix = {arXiv},
arxivId = {_barata Materials and Techniques of polychrome wooden sculpture},
author = {Bailie, Colin D. and Christoforo, M. Greyson and Mailoa, Jonathan P. and Bowring, Andrea R. and Unger, Eva L. and Nguyen, William H. and Burschka, Julian and Pellet, Norman and Lee, Jungwoo Z. and Gr{\"{a}}tzel, Michael and Noufi, Rommel and Buonassisi, Tonio and Salleo, Alberto and McGehee, Michael D.},
doi = {10.1039/c4ee03322a},
eprint = {_barata Materials and Techniques of polychrome wooden sculpture},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bailie et al. - 2015 - Semi-transparent perovskite solar cells for tandems with silicon and CIGS.pdf:pdf},
isbn = {1754-5692 1754-5706},
issn = {17545706},
journal = {Energy and Environmental Science},
number = {3},
pages = {956--963},
pmid = {24173598},
title = {{Semi-transparent perovskite solar cells for tandems with silicon and CIGS}},
volume = {8},
year = {2015}
}
@article{Putra2015,
author = {Putra, Rolan Ardeka},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Putra - 2015 - Studi Optimalisasi Fasilitas Parkir di Fakultas Kedokteran ( FK ) serta Fakultas matematika dan Ilmu Pengetahuan Alam ( F.pdf:pdf},
keywords = {fk,fmipa,parking capacity,parking duration,parking index,pto},
number = {3},
pages = {411--426},
title = {{Studi Optimalisasi Fasilitas Parkir di Fakultas Kedokteran ( FK ) serta Fakultas matematika dan Ilmu Pengetahuan Alam ( FMIPA ) Universitas Lampung}},
volume = {3},
year = {2015}
}
@article{Klimberg2010,
author = {Klimberg, Ronald K. and Sillup, George P. and Boyle, Kevin J. and Tavva, Vinay},
doi = {10.1108/S1477-4070(2010)0000007012},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Klimberg et al. - 2010 - Forecasting performance measures - What are their practical meaning.pdf:pdf},
isbn = {9780857242013},
issn = {14774070},
journal = {Advances in Business and Management Forecasting},
number = {November},
pages = {137--147},
title = {{Forecasting performance measures - What are their practical meaning?}},
volume = {7},
year = {2010}
}
@article{Perez-Rua2020,
abstract = {Existing object detection methods typically rely on the availability of abundant labelled training samples per class and offline model training in a batch mode. These requirements substantially limit their scalability to open-ended accommodation of novel classes with limited labelled training data, both in terms of model accuracy and training efficiency during deployment. We present the first study aiming to go beyond these limitations by considering the Incremental Few-Shot Detection (iFSD) problem setting, where new classes must be registered incrementally (without revisiting base classes) and with few examples. To this end we propose OpeN-ended Centre nEt (ONCE), a detector designed for incrementally learning to detect novel class objects with few examples. This is achieved by an elegant adaptation of the efficient CentreNet detector to the few-shot learning scenario, and meta-learning a class-wise code generator model for registering novel classes. ONCE fully respects the incremental learning paradigm, with novel class registration requiring only a single forward pass of few-shot training samples, and no access to base classes-thus making it suitable for deployment on embedded devices, etc. Extensive experiments conducted on both the standard object detection (COCO, PASCAL VOC) and fashion landmark detection (DeepFashion2) tasks show the feasibility of iFSD for the first time, opening an interesting and very important line of research.},
archivePrefix = {arXiv},
arxivId = {2003.04668},
author = {Perez-Rua, Juan Manuel and Zhu, Xiatian and Hospedales, Timothy M. and Xiang, Tao},
doi = {10.1109/CVPR42600.2020.01386},
eprint = {2003.04668},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Perez-Rua et al. - 2020 - Incremental Few-Shot Object Detection.pdf:pdf},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
keywords = {continual learning,few-shot learning,object detection},
mendeley-tags = {continual learning,few-shot learning,object detection},
number = {1},
pages = {13843--13852},
title = {{Incremental Few-Shot Object Detection}},
year = {2020}
}
@article{Leproult2001,
abstract = {The only well documented effect of light exposure on endocrine function is the suppression of nocturnal melatonin. Bright light exposure has behavioral effects, including the alleviation of sleepiness during nocturnal sleep deprivation. The present study examines the effects of bright light on the profiles of hormones known to be affected by sleep deprivation (TSH) or involved in behavioral activation (cortisol). Eight healthy men participated each in three studies involving 36 h of continuous wakefulness. In one study, the subjects were exposed to constant dim light (baseline). In the two other studies, dim light exposure was interrupted by a 3-h period of bright light exposure either from 0500-0800 h (early morning study) or from 1300-1600 h (afternoon study). Blood samples were obtained every 15 min for 24 h to determine melatonin, cortisol, and TSH concentrations. Alertness was estimated by the number of lapses on two computerized vigilance-sensitive performance tasks. The early morning transition from dim to bright light suppressed melatonin secretion, induced an immediate, greater than 50% elevation of cortisol levels, and limited the deterioration of alertness normally associated with overnight sleep deprivation. No effect was detected on TSH profiles. Afternoon exposure to bright light did not have any effect on either hormonal or behavioral parameters. The data unambiguously demonstrate an effect of light on the corticotropic axis that is dependent on time of day.},
author = {Leproult, Rachel and Colecchia, Egidio F. and L'Hermite-Bal{\'{e}}riaux, Mireille and {Van Cauter}, Eve},
doi = {10.1210/jc.86.1.151},
isbn = {0021-972X (Print)},
issn = {0021972X},
journal = {Journal of Clinical Endocrinology and Metabolism},
number = {1},
pages = {151--157},
pmid = {11231993},
title = {{Transition from dim to bright light in the morning induces an immediate elevation of cortisol levels}},
volume = {86},
year = {2001}
}
@article{MakarfiIsa2018,
abstract = {Some efforts made to date in curbing greenhouse gases from the transportation sector have focused on the production of biofuels. Biomass derived oils have advantages that outweigh their flaws as fuels. Petroleum range hydrocarbons can be produced via secondary processing of bio-oils. Feedstock type and availability, catalyst choice and operating conditions have a significant influence on the potentials of biomass as a feedstock for petroleum Range hydrocarbons. Despite numerous works done, it is noted that more research is needed towards commercialising biomass conversion techniques with the view to producing petroleum range hydrocarbon and biomass like algae and palm oil have been seen to be very promising sources of biofuels.},
author = {{Makarfi Isa}, Yusuf and Ganda, Elvis Tinashe},
doi = {10.1016/j.rser.2017.07.036},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Makarfi Isa, Ganda - 2018 - Bio-oil as a potential source of petroleum range fuels.pdf:pdf},
issn = {18790690},
journal = {Renewable and Sustainable Energy Reviews},
keywords = {Biofuel,Biomass derived oils,Cracking,Low carbon society},
number = {November 2016},
pages = {69--75},
title = {{Bio-oil as a potential source of petroleum range fuels}},
volume = {81},
year = {2018}
}
@article{Zhao2020c,
abstract = {Recent developments in few-shot learning have shown that during fast adaption, gradient-based meta-learners mostly rely on embedding features of powerful pre-trained networks. This leads us to research ways to effectively adapt features and utilize the meta-learner's full potential. Here, we demonstrate the effectiveness of hypernetworks in this context. We propose a soft weight-sharing hypernetwork architecture and show that training the hypernetwork with a variant of MAML is tightly linked to meta-learning a curvature matrix used to condition gradients during fast adaptation. We achieve similar results as state-of-art model-agnostic methods in the overparametrized case, while outperforming many MAML variants without using different optimization schemes in the compressive regime. Furthermore, we empirically show that hypernetworks do leverage the inner loop optimization for better adaptation, and analyse how they naturally try to learn the shared curvature of constructed tasks on a toy problem when using our proposed training algorithm.},
author = {Zhao, Dominic and {Von Oswald}, Johannes and Kobayashi, Seijin and Sacramento, Jo{\~{a}}o and Grewe, Benjamin F},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao et al. - 2020 - Meta-Learning via Hypernetworks.pdf:pdf},
keywords = {few-shot learning,hypernetworks,meta-learning,model-agnostic},
mendeley-tags = {few-shot learning,hypernetworks,meta-learning,model-agnostic},
title = {{Meta-Learning via Hypernetworks}},
year = {2020}
}
@article{Cheung2019,
abstract = {We present a method for storing multiple models within a single set of parameters. Models can coexist in superposition and still be retrieved individually. In experiments with neural networks, we show that a surprisingly large number of models can be effectively stored within a single parameter instance. Furthermore, each of these models can undergo thousands of training steps without significantly interfering with other models within the superposition. This approach may be viewed as the online complement of compression: rather than reducing the size of a network after training, we make use of the unrealized capacity of a network during training.},
archivePrefix = {arXiv},
arxivId = {1902.05522},
author = {Cheung, Brian and Terekhov, Alex and Chen, Yubei and Agrawal, Pulkit and Olshausen, Bruno},
eprint = {1902.05522},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cheung et al. - 2019 - Superposition of many models into one.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {architecture,neural networks,superposition},
mendeley-tags = {architecture,neural networks,superposition},
title = {{Superposition of many models into one}},
url = {https://github.com/briancheung/superposition},
year = {2019}
}
@article{Lei2017,
abstract = {Despite rapid advances of information technologies for intelligent parking systems, it remains a challenge to optimally manage limited parking resources in busy urban neighborhoods. In this paper, we use dynamic location-dependent parking pricing and reservation to improve system-wide performance of an intelligent parking system. With this system, the parking agency is able to decide the spatial and temporal distribution of parking prices to achieve a variety of objectives, while drivers with different origins and destinations compete for limited parking spaces via online reservation. We develop a multi-period non-cooperative bi-level model to capture the complex interactions among the parking agency and multiple drivers, as well as a non-myopic approximate dynamic programming (ADP) approach to solve the model. It is shown with numerical examples that the ADP-based pricing policy consistently outperforms alternative policies in achieving greater performance of the parking system, and shows reliability in handling the spatial and temporal variations in parking demand.},
author = {Lei, Chao and Ouyang, Yanfeng},
doi = {10.1016/j.trc.2017.01.016},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lei, Ouyang - 2017 - Dynamic pricing and reservation for intelligent urban parking management.pdf:pdf},
issn = {0968090X},
journal = {Transportation Research Part C: Emerging Technologies},
keywords = {Approximate dynamic programming,Dynamic pricing,Equilibrium,MPEC,Parking management},
pages = {226--244},
title = {{Dynamic pricing and reservation for intelligent urban parking management}},
url = {http://dx.doi.org/10.1016/j.trc.2017.01.016},
volume = {77},
year = {2017}
}
@article{Gandluru2000,
author = {Gandluru, Muralikrishna},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gandluru - 2000 - Optical Networking And Dense Wavelength Division Multiplexing ( DWDM ) Abstract Table of Contents.pdf:pdf},
keywords = {Optical Networking,DWDM,dense wavelength division},
pages = {1--20},
title = {{Optical Networking And Dense Wavelength Division Multiplexing ( DWDM ) Abstract : Table of Contents :}},
year = {2000}
}
@article{OConnor2016,
abstract = {We introduce an algorithm to do backpropagation on a spiking network. Our network is "spiking" in the sense that our neurons accumulate their activation into a potential over time, and only send out a signal (a "spike") when this potential crosses a threshold and the neuron is reset. Neurons only update their states when receiving signals from other neurons. Total computation of the network thus scales with the number of spikes caused by an input rather than network size. We show that the spiking Multi-Layer Perceptron behaves identically, during both prediction and training, to a conventional deep network of rectified-linear units, in the limiting case where we run the spiking network for a long time. We apply this architecture to a conventional classification problem (MNIST) and achieve performance very close to that of a conventional Multi-Layer Perceptron with the same architecture. Our network is a natural architecture for learning based on streaming event-based data, and is a stepping stone towards using spiking neural networks to learn efficiently on streaming data.},
archivePrefix = {arXiv},
arxivId = {1602.08323},
author = {O'Connor, Peter and Welling, Max},
eprint = {1602.08323},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/O'Connor, Welling - 2016 - Deep Spiking Networks.pdf:pdf},
month = {feb},
number = {Nips},
pages = {1--16},
title = {{Deep Spiking Networks}},
url = {http://arxiv.org/abs/1602.08323},
year = {2016}
}
@article{Veneti2017,
abstract = {The paper presents an improved solution to the ship weather routing problem based on an exact time-dependent bi-objective shortest path algorithm. The two objectives of the problem are the minimization of the fuel consumption and the total risk of the ship route while taking into account the time-varying sea and weather conditions and an upper bound on the total passage time of the route. Safety is also considered by applying the guidelines of the International Maritime Organization (IMO). As a case study, the proposed algorithm is applied for finding ship routes in the area of the Aegean Sea, Greece. Enhancements of the proposed algorithm are also presented which improve the efficiency of our approach.},
author = {Veneti, Aphrodite and Makrygiorgos, Angelos and Konstantopoulos, Charalampos and Pantziou, Grammati and Vetsikas, Ioannis A.},
doi = {10.1016/j.cor.2017.07.010},
issn = {03050548},
journal = {Computers and Operations Research},
keywords = {Multi-criteria optimization,Resource-constrained shortest path,Ship weather routing,Time dependent networks},
pages = {220--236},
publisher = {Elsevier Ltd},
title = {{Minimizing the fuel consumption and the risk in maritime transportation: A bi-objective weather routing approach}},
url = {http://dx.doi.org/10.1016/j.cor.2017.07.010},
volume = {88},
year = {2017}
}
@article{Jaderberg2015,
abstract = {Convolutional Neural Networks define an exceptionally powerful class of models, but are still limited by the lack of ability to be spatially invariant to the input data in a computationally and parameter efficient manner. In this work we introduce a new learnable module, the Spatial Transformer, which explicitly allows the spatial manipulation of data within the network. This differentiable module can be inserted into existing convolutional architectures, giving neural networks the ability to actively spatially transform feature maps, conditional on the feature map itself, without any extra training supervision or modification to the optimisation process. We show that the use of spatial transformers results in models which learn invariance to translation, scale, rotation and more generic warping, resulting in state-of-the-art performance on several benchmarks, and for a number of classes of transformations.},
archivePrefix = {arXiv},
arxivId = {1506.02025},
author = {Jaderberg, Max and Simonyan, Karen and Zisserman, Andrew and Kavukcuoglu, Koray},
doi = {10.1145/2948076.2948084},
eprint = {1506.02025},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jaderberg et al. - 2015 - Spatial Transformer Networks.pdf:pdf},
isbn = {9781450341363},
journal = {ACM International Conference Proceeding Series},
keywords = {Academic-personal competence,Authentic and focused presence,Body-related awareness,Contact quality in communicative interactions,Emotional reality,Participation,Sensations},
month = {jun},
pages = {45--48},
title = {{Spatial Transformer Networks}},
url = {http://arxiv.org/abs/1506.02025},
volume = {2},
year = {2015}
}
@article{Kisi2004a,
abstract = {Abstract Abstract The prediction and estimation of suspended sediment concentration are investigated by using multi-layer perceptrons (MLP). The fastest MLP training algorithm, that is the Levenberg-Marquardt algorithm, is used for optimization of the network weights for data from two stations on the Tongue River in Montana, USA. The first part of the study deals with prediction and estimation of upstream and down-stream station sediment data, separately, and the second part focuses on the estimation of downstream suspended sediment data by using data from both stations. In each case, the MLP test results are compared to those of generalized regression neural networks (GRNN), radial basis function (RBF) and multi-linear regression (MLR) for the best-input combinations. Based on the comparisons, it was found that the MLP generally gives better suspended sediment concentration estimates than the other neural network techniques and the conventional statistical method (MLR). However, for the estimation of max...},
author = {Kişi, {\"{O}}zg{\"{u}}r},
doi = {10.1623/hysj.49.6.1025.55720},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kişi - 2004 - Multi-layer perceptrons with Levenberg-Marquardt training algorithm for suspended sediment concentration prediction and e.pdf:pdf},
isbn = {0262-6667},
issn = {02626667},
journal = {Hydrological Sciences Journal},
keywords = {Estimation,Generalized regression neural networks,Multi-layer perceptrons,Multi-linear regression,Prediction,Radial basis function,Suspended sediment concentration},
number = {6},
pages = {1025--1040},
title = {{Multi-layer perceptrons with Levenberg-Marquardt training algorithm for suspended sediment concentration prediction and estimation}},
volume = {49},
year = {2004}
}
@inproceedings{Zhang2021,
abstract = {Knowledge distillation, in which a student model is trained to mimic a teacher model, has been proved as an effective technique for model compression and model accuracy boosting. However, most knowledge distillation methods, de- signed for image classification, have failed on more challenging tasks, such as ob- ject detection. In this paper, we suggest that the failure of knowledge distillation on object detection is mainly caused by two reasons: (1) the imbalance between pixels of foreground and background and (2) lack of distillation on the relation be- tween different pixels. Observing the above reasons, we propose attention-guided distillation and non-local distillation to address the two problems, respectively. Attention-guided distillation is proposed to find the crucial pixels of foreground objects with attention mechanism and then make the students take more effort to learn their features. Non-local distillation is proposed to enable students to learn not only the feature of an individual pixel but also the relation between dif- ferent pixels captured by non-local modules. Experiments show that our meth- ods achieve excellent AP improvements on both one-stage and two-stage, both anchor-based and anchor-free detectors. For example, Faster RCNN (ResNet101 backbone) with our distillation achieves 43.9 AP on COCO2017, which is 4.1 higher than the baseline. Codes are will be released on Github},
author = {Zhang, Linfeng and Ma, Kaisheng},
booktitle = {Iclr 2021},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Ma - 2021 - Improve Object Detection With Feature-based Knowledge Distillation Towards Accurate And Efficient Detectors.pdf:pdf},
keywords = {feature-based,knowledge distillation,object detection},
mendeley-tags = {feature-based,knowledge distillation,object detection},
number = {2021},
pages = {1--12},
title = {{Improve Object Detection With Feature-based Knowledge Distillation: Towards Accurate And Efficient Detectors}},
year = {2021}
}
@article{Rubin2015,
abstract = {A fake news detection system aims to assist users in detecting and filtering out varieties of potentially deceptive news. The prediction of the chances that a particular news item is intentionally deceptive is based on the analysis of previously seen truthful and deceptive news. A scarcity of deceptive news, available as corpora for predictive modeling, is a major stumbling block in this field of natural language processing (NLP) and deception detection. This paper discusses three types of fake news, each in contrast to genuine serious reporting, and weighs their pros and cons as a corpus for text analytics and predictive modeling. Filtering, vetting, and verifying online information continues to be essential in library and information science (LIS), as the lines between traditional news and online information are blurring.},
author = {Rubin, Victoria L. and Chen, Yimin and Conroy, Niall J.},
doi = {10.1002/pra2.2015.145052010083},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rubin, Chen, Conroy - 2015 - Deception detection for news Three types of fakes.pdf:pdf},
isbn = {0-87715-547-X},
issn = {23739231},
journal = {Proceedings of the Association for Information Science and Technology},
keywords = {corpus construction,credibility assessment,deception detection,fabrication,fake news detection,hoax,natural language processing,news verification,predictive modeling,reputable sources,satire,text analytics},
number = {1},
pages = {1--4},
title = {{Deception detection for news: Three types of fakes}},
volume = {52},
year = {2015}
}
@article{Ali2016,
abstract = {The importance of long-term load forecasting in the power industries cannot be over-emphasised, as it provides the industries with future power demand that may be useful in generating, transmitting and distributing power reliably and economically. In recent times, many techniques have been used in load forecasting, but artificial intelligence techniques (fuzzy logic and ANN) provide greater efficiency compared to conventional techniques (e.g., regression and time series). In this paper, a fuzzy logic model for long-term load forecasting is presented. A fuzzy logic model is developed based on the weather parameters (temperature and humidity) and historical load data for the town of Mubi in Adamawa state to forecast a year-ahead load. The fuzzy logic model forecast a year-ahead load with a MAPE of 6.9% and efficiency of 93.1%. The result obtained reveal that the proposed model is capable of predicting future load.},
author = {Ali, Danladi and Yohanna, Michael and Puwu, M.I. and Garkida, B.M.},
doi = {10.1016/j.psra.2016.09.011},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ali et al. - 2016 - Long-term load forecast modelling using a fuzzy logic approach.pdf:pdf},
issn = {24058823},
journal = {Pacific Science Review A: Natural Science and Engineering},
number = {2},
pages = {123--127},
publisher = {Elsevier Ltd},
title = {{Long-term load forecast modelling using a fuzzy logic approach}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2405882316300217},
volume = {18},
year = {2016}
}
@article{Du2020,
abstract = {We propose several different techniques to improve contrastive divergence training of energy-based models (EBMs). We first show that a gradient term neglected in the popular contrastive divergence formulation is both tractable to estimate and is important to avoid training instabilities in previous models. We further highlight how data augmentation, multi-scale processing, and reservoir sampling can be used to improve model robustness and generation quality. Thirdly, we empirically evaluate stability of model architectures and show improved performance on a host of benchmarks and use cases, such as image generation, OOD detection, and compositional generation.},
archivePrefix = {arXiv},
arxivId = {2012.01316},
author = {Du, Yilun and Li, Shuang and Tenenbaum, Joshua and Mordatch, Igor},
eprint = {2012.01316},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Du et al. - 2020 - Improved Contrastive Divergence Training of Energy Based Models.pdf:pdf},
title = {{Improved Contrastive Divergence Training of Energy Based Models}},
url = {http://arxiv.org/abs/2012.01316},
year = {2020}
}
@misc{Shirane1952c,
abstract = {The phase diagram of the whole range of the PbZrO 3 -PbTiO 3 system was determined by the dielectric and dilatometric measurements. According to the reason shown in part I, this phase diagram can be divided into three regiors; paraelectric, ferroelectric and antiferroelectric phases. The crystal structure of this system was determined by the Debye photographs. In the antiferroelectric region solid solutions have a tetragonal modification of perovskite structure with c / a <1 and have some superstructure which seems to have intimate relation to the antiferroelectricity. In the ferroelectric region, except a region near antiferroelectric phase in which pseudocubic structure is observed, they have ordinary tetragonal structure of c / a >1 without any superstructure.},
author = {Shirane, Gen and Suzuki, Kazuo and Takeda, Akitsu},
booktitle = {Journal of the Physical Society of Japan},
doi = {10.1143/JPSJ.7.12},
isbn = {0031-9015},
issn = {0031-9015},
number = {1},
pages = {12--18},
title = {{Phase Transitions in Solid Solutions of PbZrO 3 and PbTiO 3 (II) X-ray Study}},
url = {http://journals.jps.jp/doi/abs/10.1143/JPSJ.7.12},
volume = {7},
year = {1952}
}
@article{Rifkin,
author = {Rifkin, Jeremy},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rifkin - Unknown - Third Industrial Revolution.pdf:pdf},
pages = {1--3},
title = {{Third Industrial Revolution}}
}
@article{Pereira2016,
abstract = {Social power is a pervasive feature with acknowledged impact in a multitude of social processes. However, despite its importance, common approaches to social power interactions in multi-agent systems are rather simplistic and lack a full comprehensive view of the processes involved. In this work, we integrated a comprehensive model of social power dynamics into a cognitive agent architecture based on an operationalization of different bases of social power inspired by theoretical background research in social psychology. The model was implemented in an agent framework that was subsequently used to generate the behavior of virtual characters in an interactive virtual environment. We performed a user study to assess users' perceptions of the agents and found evidence supporting both the social power capabilities provided by the model and their value for the creation of believable and interesting scenarios. We expect that these advances and the collected evidence can be used to support the development of agent systems with an enriched capacity for social agent simulation.},
author = {Pereira, Gon{\c{c}}alo and Prada, Rui and Santos, Pedro A.},
doi = {10.1016/j.artint.2016.08.003},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pereira, Prada, Santos - 2016 - Integrating social power into the decision-making of cognitive agents.pdf:pdf},
isbn = {0004-3702},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {Autonomous agents,Behavior expressiveness,Cognitive architecture,Social intelligence,Social power},
pages = {1--44},
publisher = {Elsevier B.V.},
title = {{Integrating social power into the decision-making of cognitive agents}},
url = {http://dx.doi.org/10.1016/j.artint.2016.08.003},
volume = {241},
year = {2016}
}
@article{Wirsam1997,
abstract = {OBJECTIVE: This paper demonstrates that a nutrient intake can be described in a differentiated way and can be evaluated by employing fuzzy decision making. It also examines whether fuzzy decision making can simplify nutrition education by small individual improvements in food selection behaviour. RESULTS: The recommendations for nutrient intakes are presented as fuzzy sets, so that the intake of each nutrient can be evaluated by an objective fuzzy value. The evaluation of the harmonic minimum allows, for the first time, that the fuzzy value of an individual nutrient can be stated as a total value. On the basis of individual nutrition assessment, fuzzy logic in connection with fuzzy decision making, allows optimization of meals considering individual food preferences. This makes it possible in nutrition counselling to improve the nutrient intake markedly with relative small changes in food choice. CONCLUSION: Fuzzy decision making can simplify and optimize nutrition education.},
author = {Wirsam, B. and Hahn, A. and Uthus, E. O. and Leitzmann, C.},
doi = {10.1038/sj.ejcn.1600378},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wirsam et al. - 1997 - Fuzzy sets and fuzzy decision making in nutrition.pdf:pdf},
issn = {09543007},
journal = {European Journal of Clinical Nutrition},
keywords = {Fuzzy decision making,Fuzzy logic,Fuzzy sets,Nutrition education,Optimization,Recommended dietary allowances},
number = {5},
pages = {286--296},
pmid = {9152678},
title = {{Fuzzy sets and fuzzy decision making in nutrition}},
volume = {51},
year = {1997}
}
@article{Tan2017,
abstract = {Forecasting stock volatility is crucial to many fundamental problems of financial field, such as risk management, asset pricing and asset allocation etc. This paper proposes a new Adaptive Network-Based Fuzzy Inference System (ANFIS) which adaptively adjusts fuzzy inference rules by using Fruit Fly Optimization Algorithm (FOA). Empirical analysis is made on the Shanghai A-share sample stocks. Compared with ANFIS, the experimental results reveal that this new model can accurately and successfully forecast the sample stocks' volatility.},
author = {Tan, Lijun and Wang, Shiheng and Wang, Ke},
doi = {10.1016/j.ipl.2017.06.012},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tan, Wang, Wang - 2017 - A new adaptive network-based fuzzy inference system with adaptive adjustment rules for stock market volatility.pdf:pdf},
issn = {00200190},
journal = {Information Processing Letters},
keywords = {Adaptive Network-Based Fuzzy Inference System (ANF,Algorithms,Fruit Fly Optimization Algorithm (FOA),Shanghai A-share stocks,Stock volatility},
pages = {32--36},
publisher = {Elsevier B.V.},
title = {{A new adaptive network-based fuzzy inference system with adaptive adjustment rules for stock market volatility forecasting}},
url = {http://dx.doi.org/10.1016/j.ipl.2017.06.012},
volume = {127},
year = {2017}
}
@article{Dewabharata2017,
abstract = {The electricity consumption is highly related to the consumption's pattern. Thus, analyzing the electricity consumption's pattern becomes an important issue in order to reduce the total electricity consumption. This paper aims to analyze the electricity consumption in Taipei Bus Station located in Taipei City, Taiwan. This building is one of the busiest bus station in Taiwan. The analysis of the electricity consumption in this building is conducted based on the historical data of total electricity consumed by some cooling equipment installed in the building and the total electricity consumptions. In addition, the building temperatures, humidity and CO2 are also considered. In order to obtain an accurate forecasting, some data preprocessing approaches are conducted. They include the missing value prediction, data normalization, feature selection and discretization. Furthermore, a fuzzy neural network is applied to obtain the forecasting model. The experiments results show that the proposed research framework can obtain an accurate forecasting model with very small error. The result also reveals that the total electricity consumption is only highly related to some of the features studied in this paper while other factors do not significantly influence the total electricity consumption.},
author = {Dewabharata, Anindhita and Chou, Shuo-Yan},
doi = {10.1109/IEA.2017.7939235},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dewabharata, Chou - 2017 - Application of fuzzy neural network on the electricity consumption forecasting.pdf:pdf},
isbn = {978-1-5090-6774-9},
journal = {2017 4th International Conference on Industrial Engineering and Applications (ICIEA)},
keywords = {electricity,forecasting,fuzzy neural network},
pages = {345--349},
title = {{Application of fuzzy neural network on the electricity consumption forecasting}},
url = {http://ieeexplore.ieee.org/document/7939235/},
year = {2017}
}
@article{Green2006a,
abstract = {Objective: Patients with suspicion of acute coronary syndrome (ACS) are difficult to diagnose and they represent a very heterogeneous group. Some require immediate treatment while others, with only minor disorders, may be sent home. Detecting ACS patients using a machine learning approach would be advantageous in many situations. Methods and materials: Artificial neural network (ANN) ensembles and logistic regression models were trained on data from 634 patients presenting an emergency department with chest pain. Only data immediately available at patient presentation were used, including electrocardiogram (ECG) data. The models were analyzed using receiver operating characteristics (ROC) curve analysis, calibration assessments, inter- and intra-method variations. Effective odds ratios for the ANN ensembles were compared with the odds ratios obtained from the logistic model. Results: The ANN ensemble approach together with ECG data preprocessed using principal component analysis resulted in an area under the ROC curve of 80%. At the sensitivity of 95% the specificity was 41%, corresponding to a negative predictive value of 97%, given the ACS prevalence of 21%. Adding clinical data available at presentation did not improve the ANN ensemble performance. Using the area under the ROC curve and model calibration as measures of performance we found an advantage using the ANN ensemble models compared to the logistic regression models. Conclusion: Clinically, a prediction model of the present type, combined with the judgment of trained emergency department personnel, could be useful for the early discharge of chest pain patients in populations with a low prevalence of ACS. {\textcopyright} 2006 Elsevier B.V. All rights reserved.},
author = {Green, Michael and Bj{\"{o}}rk, Jonas and Forberg, Jakob and Ekelund, Ulf and Edenbrandt, Lars and Ohlsson, Mattias},
doi = {10.1016/j.artmed.2006.07.006},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Green et al. - 2006 - Comparison between neural networks and multiple logistic regression to predict acute coronary syndrome in the emer.pdf:pdf},
isbn = {0933-3657 (Print)\r0933-3657 (Linking)},
issn = {09333657},
journal = {Artificial Intelligence in Medicine},
keywords = {Acute coronary syndrome,Acute myocardial infarction,Artificial neural networks,Clinical decision support,Ensemble methods,Logistic regression},
number = {3},
pages = {305--318},
pmid = {16962295},
title = {{Comparison between neural networks and multiple logistic regression to predict acute coronary syndrome in the emergency room}},
volume = {38},
year = {2006}
}
@article{Wang2021,
abstract = {Continual learning usually assumes the incoming data are fully labeled, which might not be applicable in real applications. In this work, we consider semi-supervised continual learning (SSCL) that incrementally learns from partially labeled data. Observing that existing continual learning methods lack the ability to continually exploit the unlabeled data, we propose deep Online Replay with Discriminator Consistency (ORDisCo) to interdependently learn a classifier with a conditional generative adversarial network (GAN), which continually passes the learned data distribution to the classifier. In particular, ORDisCo replays data sampled from the conditional generator to the classifier in an online manner, exploiting unlabeled data in a time- and storage-efficient way. Further, to explicitly overcome the catastrophic forgetting of unlabeled data, we selectively stabilize parameters of the discriminator that are important for discriminating the pairs of old unlabeled data and their pseudo-labels predicted by the classifier. We extensively evaluate ORDisCo on various semi-supervised learning benchmark datasets for SSCL, and show that ORDisCo achieves significant performance improvement on SVHN, CIFAR10 and Tiny-ImageNet, compared to strong baselines.},
archivePrefix = {arXiv},
arxivId = {2101.00407},
author = {Wang, Liyuan and Yang, Kuo and Li, Chongxuan and Hong, Lanqing and Li, Zhenguo and Zhu, Jun},
eprint = {2101.00407},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2021 - ORDisCo Effective and Efficient Usage of Incremental Unlabeled Data for Semi-supervised Continual Learning.pdf:pdf},
keywords = {continual learning,semi-supervised learning},
mendeley-tags = {continual learning,semi-supervised learning},
title = {{ORDisCo: Effective and Efficient Usage of Incremental Unlabeled Data for Semi-supervised Continual Learning}},
url = {http://arxiv.org/abs/2101.00407},
year = {2021}
}
@article{Singh2020,
abstract = {We present an approach for lifelong/continual learning of convolutional neural networks (CNN) that does not suffer from the problem of catastrophic forgetting when moving from one task to the other. We show that the activation maps generated by the CNN trained on the old task can be calibrated using very few calibration parameters, to become relevant to the new task. Based on this, we calibrate the activation maps produced by each network layer using spatial and channel-wise calibration modules and train only these calibration parameters for each new task in order to perform lifelong learning. Our calibration modules introduce significantly less computation and parameters as compared to the approaches that dynamically expand the network. Our approach is immune to catastrophic forgetting since we store the task-adaptive calibration parameters, which contain all the task-specific knowledge and is exclusive to each task. Further, our approach does not require storing data samples from the old tasks, which is done by many replay based methods. We perform extensive experiments on multiple benchmark datasets (SVHN, CIFAR, ImageNet, and MS-Celeb), all of which show substantial improvements over state-of-the-art methods (e.g., a 29% absolute increase in accuracy on CIFAR-100 with 10 classes at a time). On large-scale datasets, our approach yields 23.8% and 9.7% absolute increase in accuracy on ImageNet-100 and MS-Celeb-10K datasets, respectively, by employing very few (0.51% and 0.35% of model parameters) task-adaptive calibration parameters.},
author = {Singh, Pravendra and Verma, Vinay Kumar and Mazumder, Pratik},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Singh, Verma, Mazumder - 2020 - Calibrating CNNs for Lifelong Learning.pdf:pdf},
journal = {NeurIPS},
keywords = {calibration,continual learning,convolutional neural networks,regularization},
mendeley-tags = {calibration,continual learning,convolutional neural networks,regularization},
number = {NeurIPS},
pages = {1--12},
title = {{Calibrating CNNs for Lifelong Learning}},
year = {2020}
}
@article{Misra2019,
abstract = {The goal of self-supervised learning from images is to construct image representations that are semantically meaningful via pretext tasks that do not require semantic annotations for a large training set of images. Many pretext tasks lead to representations that are covariant with image transformations. We argue that, instead, semantic representations ought to be invariant under such transformations. Specifically, we develop Pretext-Invariant Representation Learning (PIRL, pronounced as “pearl”) that learns invariant representations based on pretext tasks. We use PIRL with a commonly used pretext task that involves solving jigsaw puzzles. We find that PIRL substantially improves the semantic quality of the learned image representations. Our approach sets a new state-of-the-art in self-supervised learning from images on several popular benchmarks for self-supervised learning. Despite being unsupervised, PIRL outperforms supervised pre-training in learning image representations for object detection. Altogether, our results demonstrate the potential of self-supervised learning of image representations with good invariance properties.},
author = {Misra, Ishan and van der Maaten, Laurens},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Misra, Maaten - 2019 - Self-Supervised Learning of Pretext-Invariant Representations.pdf:pdf},
journal = {arXiv},
number = {Figure 2},
title = {{Self-Supervised Learning of Pretext-Invariant Representations}},
year = {2019}
}
@article{Yoon2019,
abstract = {While recent continual learning methods largely alleviate the catastrophic problem on toy-sized datasets, some issues remain to be tackled to apply them to real-world problem domains. First, a continual learning model should effectively handle catastrophic forgetting and be efficient to train even with a large number of tasks. Secondly, it needs to tackle the problem of order-sensitivity, where the performance of the tasks largely varies based on the order of the task arrival sequence, as it may cause serious problems where fairness plays a critical role (e.g. medical diagnosis). To tackle these practical challenges, we propose a novel continual learning method that is scalable as well as order-robust, which instead of learning a completely shared set of weights, represents the parameters for each task as a sum of task-shared and sparse task-adaptive parameters. With our Additive Parameter Decomposition (APD), the task-adaptive parameters for earlier tasks remain mostly unaffected, where we update them only to reflect the changes made to the task-shared parameters. This decomposition of parameters effectively prevents catastrophic forgetting and order-sensitivity, while being computation- and memory-efficient. Further, we can achieve even better scalability with APD using hierarchical knowledge consolidation, which clusters the task-adaptive parameters to obtain hierarchically shared parameters. We validate our network with APD, APD-Net, on multiple benchmark datasets against state-of-the-art continual learning methods, which it largely outperforms in accuracy, scalability, and order-robustness.},
archivePrefix = {arXiv},
arxivId = {1902.09432},
author = {Yoon, Jaehong and Kim, Saehoon and Yang, Eunho and Hwang, Sung Ju},
eprint = {1902.09432},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yoon et al. - 2019 - Scalable and Order-robust Continual Learning with Additive Parameter Decomposition.pdf:pdf},
pages = {1--15},
title = {{Scalable and Order-robust Continual Learning with Additive Parameter Decomposition}},
url = {http://arxiv.org/abs/1902.09432},
year = {2019}
}
@article{Zamir2019a,
abstract = {Do visual tasks have relationships, or are they unrelated? For instance, could having surface normals simplify estimating the depth of an image? Intuition answers these questions positively, implying existence of a certain structure among visual tasks. Understanding this structure has notable values: it provides a principled way for identifying relationships across tasks, for instance, in order to reuse supervision among redundant tasks or solve many tasks in one system without piling up the complexity. We propose a fully computational approach for identifying the transfer learning structure of the space of visual tasks. This is done via computing the transfer learning dependencies across tasks in a dictionary of twenty-six 2D, 2.5D, 3D, and semantic tasks. The product is a computational taxonomic map among tasks for transfer learning, and we exploit it to reduce the demand for labeled data. For example, we show that the total number of labeled datapoints needed for solving a set of 10 tasks can be reduced by roughly 32 (compared to training independently) while keeping the performance nearly the same. We provide a set of tools for computing and visualizing this taxonomical structure at http://taskonomy.vision.},
archivePrefix = {arXiv},
arxivId = {1804.08328},
author = {Zamir, Amir and Sax, Alexander and Shen, William and Guibas, Leonidas and Malik, Jitendra and Savarese, Silvio},
doi = {10.24963/ijcai.2019/871},
eprint = {1804.08328},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zamir et al. - 2019 - Taskonomy Disentangling task transfer learning(2).pdf:pdf},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
pages = {6241--6245},
title = {{Taskonomy: Disentangling task transfer learning}},
volume = {2019-Augus},
year = {2019}
}
@article{Cyphers2018,
abstract = {The Deep Learning (DL) community sees many novel topologies published each year. Achieving high performance on each new topology remains challenging, as each requires some level of manual effort. This issue is compounded by the proliferation of frameworks and hardware platforms. The current approach, which we call "direct optimization", requires deep changes within each framework to improve the training performance for each hardware backend (CPUs, GPUs, FPGAs, ASICs) and requires $\mathcal{O}(fp)$ effort; where $f$ is the number of frameworks and $p$ is the number of platforms. While optimized kernels for deep-learning primitives are provided via libraries like Intel Math Kernel Library for Deep Neural Networks (MKL-DNN), there are several compiler-inspired ways in which performance can be further optimized. Building on our experience creating neon (a fast deep learning library on GPUs), we developed Intel nGraph, a soon to be open-sourced C++ library to simplify the realization of optimized deep learning performance across frameworks and hardware platforms. Initially-supported frameworks include TensorFlow, MXNet, and Intel neon framework. Initial backends are Intel Architecture CPUs (CPU), the Intel(R) Nervana Neural Network Processor(R) (NNP), and NVIDIA GPUs. Currently supported compiler optimizations include efficient memory management and data layout abstraction. In this paper, we describe our overall architecture and its core components. In the future, we envision extending nGraph API support to a wider range of frameworks, hardware (including FPGAs and ASICs), and compiler optimizations (training versus inference optimizations, multi-node and multi-device scaling via efficient sub-graph partitioning, and HW-specific compounding of operations).},
archivePrefix = {arXiv},
arxivId = {1801.08058},
author = {Cyphers, Scott and Bansal, Arjun K. and Bhiwandiwalla, Anahita and Bobba, Jayaram and Brookhart, Matthew and Chakraborty, Avijit and Constable, Will and Convey, Christian and Cook, Leona and Kanawi, Omar and Kimball, Robert and Knight, Jason and Korovaiko, Nikolay and Kumar, Varun and Lao, Yixing and Lishka, Christopher R. and Menon, Jaikrishnan and Myers, Jennifer and Narayana, Sandeep Aswath and Procter, Adam and Webb, Tristan J.},
eprint = {1801.08058},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cyphers et al. - 2018 - Intel nGraph An Intermediate Representation, Compiler, and Executor for Deep Learning.pdf:pdf},
pages = {6--8},
title = {{Intel nGraph: An Intermediate Representation, Compiler, and Executor for Deep Learning}},
url = {http://arxiv.org/abs/1801.08058},
year = {2018}
}
@article{Benzing2020,
abstract = {The problem of Catastrophic Forgetting has received a lot of attention in the past years. An important class of proposed solutions are so-called regularisation approaches, which protect weights from large changes according to their importances. Various ways to measure this importance have been put forward, all stemming from different theoretical or intuitive motivations. We present mathematical and empirical evidence that two of these methods – Synaptic Intelligence and Memory Aware Synapses – approximate a rescaled version of the Fisher Information, a theoretically justified importance measure also used in the literature. As part of our methods, we show that the importance approximation of Synaptic Intelligence is biased and that, in fact, this bias explains its performance best. Altogether, our results offer a theoretical account for the effectiveness of different regularisation approaches and uncover similarities between the methods proposed so far.},
archivePrefix = {arXiv},
arxivId = {2006.06357},
author = {Benzing, Frederik},
eprint = {2006.06357},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Benzing - 2020 - Understanding Regularisation Methods for Continual Learning.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {continual learning,regularization},
mendeley-tags = {continual learning,regularization},
number = {2017},
pages = {1--27},
title = {{Understanding Regularisation Methods for Continual Learning}},
url = {https://github.com/freedbee/continual_regularisation},
year = {2020}
}
@article{Sokar2021,
abstract = {Continual learning aims to provide intelligent agents capable of learning multiple tasks sequentially with neural networks. One of its main challenging, catastrophic forgetting, is caused by the neural networks non-optimal ability to learn in non-stationary distributions. In most settings of the current approaches, the agent starts from randomly initialized parameters and is optimized to master the current task regardless of the usefulness of the learned representation for future tasks. Moreover, each of the future tasks uses all the previously learned knowledge although parts of this knowledge might not be helpful for its learning. These cause interference among tasks, especially when the data of previous tasks is not accessible. In this paper, we propose a new method, named Self-Attention Meta-Learner (SAM), which learns a prior knowledge for continual learning that permits learning a sequence of tasks, while avoiding catastrophic forgetting. SAM incorporates an attention mechanism that learns to select the particular relevant representation for each future task. Each task builds a specific representation branch on top of the selected knowledge, avoiding the interference between tasks. We evaluate the proposed method on the Split CIFAR-10/100 and Split MNIST benchmarks in the task agnostic inference. We empirically show that we can achieve a better performance than several state-of-the-art methods for continual learning by building on the top of selected representation learned by SAM. We also show the role of the meta-attention mechanism in boosting informative features corresponding to the input data and identifying the correct target in the task agnostic inference. Finally, we demonstrate that popular existing continual learning methods gain a performance boost when they adopt SAM as a starting point.},
archivePrefix = {arXiv},
arxivId = {2101.12136},
author = {Sokar, Ghada and Mocanu, Decebal Constantin and Pechenizkiy, Mykola},
eprint = {2101.12136},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sokar, Mocanu, Pechenizkiy - 2021 - Self-Attention Meta-Learner for Continual Learning.pdf:pdf},
keywords = {continual learning,meta learning,prior knowledge,self-attention,task agnos-},
mendeley-tags = {continual learning,meta learning,self-attention},
title = {{Self-Attention Meta-Learner for Continual Learning}},
url = {http://arxiv.org/abs/2101.12136},
year = {2021}
}
@article{Oh2017,
abstract = {Recently, smart fluids have drawn significant attention and growing a great interest in a broad range of engineering applications such as automotive and medical areas. In this article, two smart fluids called electro-rheological (ER) fluid and magneto-rheological (MR) fluid are reviewed in terms of medical applications. Especially, this article describes the attributes and inherent properties of individual medical and rehabilitation devices. The devices surveyed in this article include multi-degree-of-freedom haptic masters for robot surgery, thin membrane touch panels for braille readers, sponge-like tactile sensors to feel human tissues such as liver, rehabilitation systems such as prosthetic leg, and haptic interfaces for dental implant surgery. The operating principle, inherent characteristics and practical feasibility of each medical device or system are fully discussed in details.},
author = {Oh, Jong Seok and Choi, Seung Bok},
doi = {10.1016/j.jksus.2017.05.012},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oh, Choi - 2017 - State of the art of medical devices featuring smart electro-rheological and magneto-rheological fluids.pdf:pdf},
issn = {10183647},
journal = {Journal of King Saud University - Science},
keywords = {ER and MR brake,ER and MR clutch,Electro-rheological (ER) fluid,MR sponge,Magneto-rheological (MR) fluid,Medical application,Smart fluid},
number = {4},
pages = {390--400},
publisher = {King Saud University},
title = {{State of the art of medical devices featuring smart electro-rheological and magneto-rheological fluids}},
url = {http://dx.doi.org/10.1016/j.jksus.2017.05.012},
volume = {29},
year = {2017}
}
@article{Redmon2018,
abstract = {We present some updates to YOLO! We made a bunch of little design changes to make it better. We also trained this new network that's pretty swell. It's a little bigger than last time but more accurate. It's still fast though, don't worry. At 320x320 YOLOv3 runs in 22 ms at 28.2 mAP, as accurate as SSD but three times faster. When we look at the old .5 IOU mAP detection metric YOLOv3 is quite good. It achieves 57.9 mAP@50 in 51 ms on a Titan X, compared to 57.5 mAP@50 in 198 ms by RetinaNet, similar performance but 3.8x faster. As always, all the code is online at https://pjreddie.com/yolo/},
archivePrefix = {arXiv},
arxivId = {1804.02767},
author = {Redmon, Joseph and Farhadi, Ali},
eprint = {1804.02767},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Redmon - Unknown - YOLOv3 An Incremental Improvement.pdf:pdf},
title = {{YOLOv3: An Incremental Improvement}},
url = {http://arxiv.org/abs/1804.02767},
year = {2018}
}
@article{Liu2020f,
abstract = {We propose a method to train a model so it can learn new classification tasks while improving with each task solved. This amounts to combining meta-learning with incremental learning. Different tasks can have disjoint classes, so one cannot directly align different classifiers as done in model distillation. On the other hand, simply aligning features shared by all classes does not allow the base model sufficient flexibility to evolve to solve new tasks. We therefore indirectly align features relative to a minimal set of "anchor classes." Such indirect discriminant alignment (IDA) adapts a new model to old classes without the need to reprocess old data, while leaving maximum flexibility for the model to adapt to new tasks. This process enables incrementally improving the model by processing multiple learning episodes, each representing a different learning task, even with few training examples. Experiments on few-shot learning benchmarks show that this incremental approach performs favorably even compared to training the model with the entire dataset at once.},
archivePrefix = {arXiv},
arxivId = {2002.04162v2},
author = {Liu, Qing and {Achille AWS}, Alessandro and {Ravichandran AWS}, Avinash and {Bhotika AWS}, Rahul and Soatto, Stefano},
eprint = {2002.04162v2},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2020 - Incremental Meta-Learning via Indirect Discriminant Alignment Orchid Majumder AWS.pdf:pdf},
journal = {Eccv},
keywords = {continual learning,discriminant alginment,meta-learning},
mendeley-tags = {continual learning,discriminant alginment,meta-learning},
title = {{Incremental Meta-Learning via Indirect Discriminant Alignment Orchid Majumder AWS}},
year = {2020}
}
@article{Masanes2017,
abstract = {The third law of thermodynamics has a controversial past and a number of formulations due to Planck, Einstein, and Nernst. It's most accepted version, the unattainability principle, states that "any thermodynamic process cannot reach the temperature of absolute zero by a finite number of steps and within a finite time." Although formulated in 1912, there has been no general proof of the principle, and the only evidence we have for it is that particular cooling methods become less efficient as the temperature decreases. Here we provide the first derivation of a general unattainability principle, which applies to arbitrary cooling processes, even those exploiting the laws of quantum mechanics or involving an infinite-dimensional reservoir. We quantify the resources needed to cool a system to any particular temperature, and translate these resources into a minimal time or number of steps by considering the notion of a Thermal Machine which obeys similar restrictions to universal computers. We generally find that the obtainable temperature can scale as an inverse power of the cooling time. Our argument relies on the heat capacity of the bath being positive, and we show that if this is not the case then perfect cooling in finite time is in principle possible. Our results also clarify the connection between two versions of the third law (the Unattainability Principle and the Heat Theorem), and place ultimate bounds on the speed at which information can be erased.},
archivePrefix = {arXiv},
arxivId = {1412.3828},
author = {Masanes, Llu{\'{i}}s and Oppenheim, Jonathan},
doi = {10.1038/ncomms14538},
eprint = {1412.3828},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Masanes, Oppenheim - 2017 - A general derivation and quantification of the third law of thermodynamics.pdf:pdf},
issn = {20411723},
journal = {Nature Communications},
pages = {1--7},
pmid = {28290452},
title = {{A general derivation and quantification of the third law of thermodynamics}},
volume = {8},
year = {2017}
}
@article{Gibbs2012,
abstract = {Near infrared (NIR) image-guided surgery holds great promise for improved surgical outcomes. A number of NIR image-guided surgical systems are currently in preclinical and clinical development with a few approved for limited clinical use. In order to wield the full power of NIR image-guided surgery, clinically available tissue and disease specific NIR fluorophores with high signal to background ratio are necessary. In the current review, the status of NIR image-guided surgery is discussed along with the desired chemical and biological properties of NIR fluorophores. Lastly, tissue and disease targeting strategies for NIR fluorophores are reviewed.},
author = {Gibbs, Summer L},
doi = {10.3978/j.issn.2223-4292.2012.09.04},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gibbs - 2012 - Near infrared fluorescence for image-guided surgery.pdf:pdf},
isbn = {2223-4292 (Print)\r2223-4306 (Linking)},
issn = {2223-4292},
journal = {Quantitative imaging in medicine and surgery},
keywords = {04,09,10,1078,1373,2012,2223-4292,24,3978,accepted for publication sep,amepc,article,article at,device or view this,doi,http,image-guided surgery,issn,j,near infrared,nir,org,qims,scan to your mobile,submitted aug 22,view,www},
number = {3},
pages = {177--87},
pmid = {23256079},
title = {{Near infrared fluorescence for image-guided surgery.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3496513&tool=pmcentrez&rendertype=abstract},
volume = {2},
year = {2012}
}
@article{Bengtsson2005a,
abstract = {PURPOSE: To compare the performance of neural networks for perimetric glaucoma diagnosis when using different types of data inputs: numerical threshold sensitivities, Statpac Total Deviation and Pattern Deviation, and probability scores based on Total and Pattern Deviation probability maps (Carl Zeiss Meditec, Inc., Dublin, CA). METHODS: The results of SITA Standard visual field tests in 213 healthy subjects, 127 patients with glaucoma, 68 patients with concomitant glaucoma and cataract, and 41 patients with cataract only were included. The five different types of input data were entered into five identically designed artificial neural networks. Network thresholds were adjusted for each network. Receiver operating characteristic (ROC) curves were constructed to display the combinations of sensitivity and specificity. RESULTS: Input data in the form of Pattern Deviation probability scores gave the best results, with an area of 0.988 under the ROC curve, and were significantly better (P < 0.001) than threshold sensitivities and numerical Total Deviations and Total Deviation probability scores. The second best result was obtained with numerical Pattern Deviations with an area of 0.980. CONCLUSIONS: The choice of type of data input had important effects on the performance of the neural networks in glaucoma diagnosis. Refined input data, based on Pattern Deviations, resulted in higher sensitivity and specificity than did raw threshold values. Neural networks may have high potential in the production of useful clinical tools for the classification of visual field tests.},
author = {Bengtsson, Boel and Bizios, Dimitrios and Heijl, Anders},
doi = {10.1167/iovs.05-0175},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bengtsson, Bizios, Heijl - 2005 - Effects of input data on the performance of a neural network in distinguishing normal and glaucomatous.pdf:pdf},
isbn = {0146-0404 (Print)},
issn = {01460404},
journal = {Investigative Ophthalmology and Visual Science},
number = {10},
pages = {3730--3736},
pmid = {16186356},
title = {{Effects of input data on the performance of a neural network in distinguishing normal and glaucomatous visual fields}},
volume = {46},
year = {2005}
}
@article{Crowley2018,
abstract = {Many engineers wish to deploy modern neural networks in memory-limited settings; but the development of flexible methods for reducing memory use is in its infancy, and there is little knowledge of the resulting cost-benefit. We propose structural model distillation for memory reduction using a strategy that produces a student architecture that is a simple transformation of the teacher architecture: no redesign is needed, and the same hyperparameters can be used. Using attention transfer, we provide Pareto curves/tables for distillation of residual networks with four benchmark datasets, indicating the memory versus accuracy payoff. We show that substantial memory savings are possible with very little loss of accuracy, and confirm that distillation provides student network performance that is better than training that student architecture directly on data.},
archivePrefix = {arXiv},
arxivId = {1711.02613},
author = {Crowley, Elliot J. and Gray, Gavin and Storkey, Amos},
eprint = {1711.02613},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Crowley, Gray, Storkey - 2018 - Moonshine Distilling with cheap convolutions.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {NeurIPS},
pages = {2888--2898},
title = {{Moonshine: Distilling with cheap convolutions}},
volume = {2018-Decem},
year = {2018}
}
@article{Shoemaker1991,
abstract = {We describe a rigid, internally modulated Michelson interferometer with Fabry-Perot cavities in the interferometer arms. The high contrast (0.986) and the small cavity losses (2.7%) permit efficient use of the light power available. The measured shot-noise-limited displacement sensitivity for 35mW of light power is 2.5 x 10(-17) m radicalHz, in good agreement with the calculated signal-to-noise ratio.},
author = {Shoemaker, D and Fritschel, P and Giaime, J and Christensen, N and Weiss, R},
doi = {10.1364/AO.30.003133},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shoemaker et al. - 1991 - Prototype Michelson interferometer with Fabry-Perot cavities.pdf:pdf},
isbn = {0003-6935},
issn = {0003-6935},
journal = {Applied optics},
number = {June 1990},
pages = {3133--3138},
pmid = {20706365},
title = {{Prototype Michelson interferometer with Fabry-Perot cavities.}},
volume = {30},
year = {1991}
}
@inproceedings{Li2019LearnTG,
abstract = {Addressing catastrophic forgetting is one of the key challenges in continual learning where machine learning systems are trained with sequential or streaming tasks. Despite recent remarkable progress in state-of-the-art deep learning, deep neural networks (DNNs) are still plagued with the catastrophic forgetting problem. This paper presents a conceptually simple yet general and effective framework for handling catastrophic forgetting in continual learning with DNNs. The proposed method consists of two components: a neural structure optimization component and a parameter learning and/or fine-tuning component. By separating the explicit neural structure learning and the parameter estimation, not only is the proposed method capable of evolving neural structures in an intuitively meaningful way, but also shows strong capabilities of alleviating catastrophic forgetting in experiments. Furthermore, the proposed method outperforms all other baselines on the permuted MNIST dataset, the split CIFAR100 dataset and the Visual Domain Decathlon dataset in continual learning setting},
archivePrefix = {arXiv},
arxivId = {1904.00310},
author = {Li, Xilai and Zhou, Yingbo and Wu, Tianfu and Socher, Richard and Xiong, Caiming},
booktitle = {ICML},
eprint = {1904.00310},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2019 - Learn to grow A continual structure learning framework for overcoming catastrophic forgetting.pdf:pdf},
keywords = {architectural,continual learning},
mendeley-tags = {architectural,continual learning},
title = {{Learn to grow: A continual structure learning framework for overcoming catastrophic forgetting}},
url = {https://arxiv.org/pdf/1904.00310.pdf},
year = {2019}
}
@article{Yoon2021,
abstract = {A dataset is a shred of crucial evidence to describe a task. However, each data point in the dataset does not have the same potential, as some of the data points can be more representative or informative than others. This unequal importance among the data points may have a large impact in rehearsal-based continual learning, where we store a subset of the training examples (coreset) to be replayed later to alleviate catastrophic forgetting. In continual learning, the quality of the samples stored in the coreset directly affects the model's effectiveness and efficiency. The coreset selection problem becomes even more important under realistic settings, such as imbalanced continual learning or noisy data scenarios. To tackle this problem, we propose Online Coreset Selection (OCS), a simple yet effective method that selects the most representative and informative coreset at each iteration and trains them in an online manner. Our proposed method maximizes the model's adaptation to a target dataset while selecting high-affinity samples to past tasks, which directly inhibits catastrophic forgetting. We validate the effectiveness of our coreset selection mechanism over various standard, imbalanced, and noisy datasets against strong continual learning baselines, demonstrating that it improves task adaptation and prevents catastrophic forgetting in a sample-efficient manner.},
archivePrefix = {arXiv},
arxivId = {2106.01085},
author = {Yoon, Jaehong and Madaan, Divyam and Yang, Eunho and Hwang, Sung Ju},
eprint = {2106.01085},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yoon et al. - 2021 - Online Coreset Selection for Rehearsal-based Continual Learning.pdf:pdf},
keywords = {continual learning,rehearsal},
mendeley-tags = {continual learning,rehearsal},
pages = {1--15},
title = {{Online Coreset Selection for Rehearsal-based Continual Learning}},
url = {http://arxiv.org/abs/2106.01085},
year = {2021}
}
@inproceedings{Liu2020b,
abstract = {Few-shot classification aims to recognize unseen classes when presented with only a small number of samples. We consider the problem of multi-domain few-shot image classification, where unseen classes and examples come from diverse data sources. This problem has seen growing interest and has inspired the development of benchmarks such as Meta-Dataset. A key challenge in this multi-domain setting is to effectively integrate the feature representations from the diverse set of training domains. Here, we propose a Universal Representation Transformer (URT) layer, that meta-learns to leverage universal features for few-shot classification by dynamically re-weighting and composing the most appropriate domain-specific representations. In experiments, we show that URT sets a new state-of-the-art result on Meta-Dataset. Specifically, it outperforms the best previous model on three data sources or performs the same in others. We analyze variants of URT and present a visualization of the attention score heatmaps that sheds light on how the model performs cross-domain generalization. Our code is available at https://github.com/liulu112601/URT},
archivePrefix = {arXiv},
arxivId = {2006.11702},
author = {Liu, Lu and Hamilton, William and Long, Guodong and Jiang, Jing and Larochelle, Hugo},
booktitle = {Iclr 2021},
eprint = {2006.11702},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2020 - A Universal Representation Transformer Layer for Few-Shot Image Classification.pdf:pdf},
issn = {23318422},
keywords = {few-shot learning,meta-learning,representation learning,transformer},
mendeley-tags = {few-shot learning,meta-learning,representation learning,transformer},
title = {{A Universal Representation Transformer Layer for Few-Shot Image Classification}},
year = {2020}
}
@article{Yang2019a,
abstract = {Automatic news comment generation is beneficial for real applications but has not attracted enough attention from the research community. In this paper, we propose a "read-attend-comment" procedure for news comment generation and formalize the procedure with a reading network and a generation network. The reading network comprehends a news article and distills some important points from it, then the generation network creates a comment by attending to the extracted discrete points and the news title. We optimize the model in an end-to-end manner by maximizing a variational lower bound of the true objective using the back-propagation algorithm. Experimental results on two public datasets indicate that our model can significantly outperform existing methods in terms of both automatic evaluation and human judgment.},
archivePrefix = {arXiv},
arxivId = {1909.11974},
author = {Yang, Ze and Xu, Can and Wu, Wei and Li, Zhoujun},
eprint = {1909.11974},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2019 - Read, Attend and Comment A Deep Architecture for Automatic News Comment Generation.pdf:pdf},
title = {{Read, Attend and Comment: A Deep Architecture for Automatic News Comment Generation}},
url = {http://arxiv.org/abs/1909.11974},
year = {2019}
}
@article{Losing2018,
abstract = {Recently, incremental and on-line learning gained more attention especially in the context of big data and learning from data streams, conflicting with the traditional assumption of complete data availability. Even though a variety of different methods are available, it often remains unclear which of them is suitable for a specific task and how they perform in comparison to each other. We analyze the key properties of eight popular incremental methods representing different algorithm classes. Thereby, we evaluate them with regards to their on-line classification error as well as to their behavior in the limit. Further, we discuss the often neglected issue of hyperparameter optimization specifically for each method and test how robustly it can be done based on a small set of examples. Our extensive evaluation on data sets with different characteristics gives an overview of the performance with respect to accuracy, convergence speed as well as model complexity, facilitating the choice of the best method for a given application.},
author = {Losing, Viktor and Hammer, Barbara and Wersing, Heiko},
doi = {10.1016/j.neucom.2017.06.084},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Losing, Hammer, Wersing - 2018 - Incremental on-line learning A review and comparison of state of the art algorithms.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Data streams,Hyperparameter optimization,Incremental learning,Model selection,On-line learning,continual learning,incremental learning,online learning,review,survey},
mendeley-tags = {continual learning,incremental learning,online learning,review,survey},
pages = {1261--1274},
title = {{Incremental on-line learning: A review and comparison of state of the art algorithms}},
url = {https://github.com/vlosing/Online-learning},
volume = {275},
year = {2018}
}
@article{Tramer2020,
abstract = {Adaptive attacks have (rightfully) become the de facto standard for evaluating defenses to adversarial examples. We find, however, that typical adaptive evaluations are incomplete. We demonstrate that thirteen defenses recently published at ICLR, ICML and NeurIPS—and chosen for illustrative and pedagogical purposes—can be circumvented despite attempting to perform evaluations using adaptive attacks. While prior evaluation papers focused mainly on the end result—showing that a defense was ineffective—this paper focuses on laying out the methodology and the approach necessary to perform an adaptive attack. We hope that these analyses will serve as guidance on how to properly perform adaptive attacks against defenses to adversarial examples, and thus will allow the community to make further progress in building more robust models.},
archivePrefix = {arXiv},
arxivId = {2002.08347},
author = {Tram{\`{e}}r, Florian and Carlini, Nicholas and Brendel, Wieland},
eprint = {2002.08347},
journal = {arXiv},
number = {NeurIPS},
pages = {1--13},
title = {{On adaptive attacks to adversarial example defenses}},
year = {2020}
}
@article{Yeh2015,
abstract = {Ultrasound molecular imaging using targeting microbubbles is predominantly a semi-quantitative tool, thus limiting its potential diagnostic power and clinical applications. In the work described here, we developed a novel method for acoustic quantification of molecular expression. E-Selectin expression in the mouse heart was induced by lipopolysaccharide. Real-time ultrasound imaging of E-selectin expression in the heart was performed using E-selectin-targeting microbubbles and a clinical ultrasound scanner in contrast pulse sequencing mode at 14 MHz, with a mechanical index of 0.22-0.26. The level of E-selectin expression was quantified using a novel time-signal intensity curve analytical method based on bubble elimination, which consisted of curve-fitting the bi-exponential equation Itissue(t)=Afe-$\lambda$ft+Are-$\lambda$rtto the elimination phase of the myocardial time-signal intensity curve. Arand Afrepresent the maximum signal intensities of the retained and freely circulating bubbles in the myocardium, respectively; $\lambda$rand $\lambda$frepresent the elimination rate constants of the retained and freely circulating bubbles in the myocardium, respectively. Arcorrelated strongly with the level of E-selectin expression (|r|>0.8), determined using reverse transcriptase real-time quantitative polymerase chain reaction, and the duration of post-lipopolysaccharide treatment-both linearly related to cell surface E-selectin protein (actual bubble target) concentration in the expression range imaged. Compared with a conventional acoustic quantification method (which used retained bubble signal intensity at 20 min post-bubble injection), this new approach exhibited greater dynamic range and sensitivity and was able to simultaneously quantify other useful characteristics (e.g., the microbubble half-life). In conclusion, quantitative determination of the level of molecular expression is feasible acoustically using a time-signal intensity curve analytical method based on bubble elimination.},
author = {Yeh, James Shue Min and Sennoga, Charles A. and McConnell, Ellen and Eckersley, Robert and Tang, Meng Xing and Nourshargh, Sussan and Seddon, John M. and Haskard, Dorian O. and Nihoyannopoulos, Petros},
doi = {10.1016/j.ultrasmedbio.2015.04.011},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yeh et al. - 2015 - Quantitative Ultrasound Molecular Imaging.pdf:pdf},
issn = {1879291X},
journal = {Ultrasound in Medicine and Biology},
keywords = {Contrast agent,Contrast echocardiography,E-Selectin,Echocardiography,Microbubble elimination,Molecular imaging,Quantification,Targeted microbubbles,Time-signal intensity curve,Ultrasound imaging},
number = {9},
pages = {2478--2496},
title = {{Quantitative Ultrasound Molecular Imaging}},
volume = {41},
year = {2015}
}
@article{Rollins2004,
abstract = {A high-power, low-noise photodetector, in conjunction with a current shunt actuator, is used in an ac-coupled servo to stabilize the intensity of a 10-W cw Nd:YAG laser. A relative intensity noise of 1 x 10(-8) Hz(-1/2) at 10 Hz is achieved.},
author = {Rollins, Jameson and Ottaway, David and Zucker, Michael and Weiss, Rainer and Abbott, Richard},
doi = {10.1364/OL.29.001876},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rollins et al. - 2004 - Solid-state laser intensity stabilization at the 10-8 level.pdf:pdf},
issn = {0146-9592},
journal = {Optics Letters},
number = {16},
pages = {1876},
pmid = {15357345},
title = {{Solid-state laser intensity stabilization at the 10^-8 level}},
url = {https://www.osapublishing.org/abstract.cfm?URI=ol-29-16-1876},
volume = {29},
year = {2004}
}
@article{Yuan2021,
abstract = {Transformers, which are popular for language modeling, have been explored for solving vision tasks recently, e.g., the Vision Transformers (ViT) for image classification. The ViT model splits each image into a sequence of tokens with fixed length and then applies multiple Transformer layers to model their global relation for classification. However, ViT achieves inferior performance compared with CNNs when trained from scratch on a midsize dataset (e.g., ImageNet). We find it is because: 1) the simple tokenization of input images fails to model the important local structure (e.g., edges, lines) among neighboring pixels, leading to its low training sample efficiency; 2) the redundant attention backbone design of ViT leads to limited feature richness in fixed computation budgets and limited training samples. To overcome such limitations, we propose a new Tokens-To-Token Vision Transformers (T2T-ViT), which introduces 1) a layer-wise Tokens-to-Token (T2T) transformation to progressively structurize the image to tokens by recursively aggregating neighboring Tokens into one Token (Tokens-to-Token), such that local structure presented by surrounding tokens can be modeled and tokens length can be reduced; 2) an efficient backbone with a deep-narrow structure for vision transformers motivated by CNN architecture design after extensive study. Notably, T2T-ViT reduces the parameter counts and MACs of vanilla ViT by 200\%, while achieving more than 2.5\% improvement when trained from scratch on ImageNet. It also outperforms ResNets and achieves comparable performance with MobileNets when directly training on ImageNet. For example, T2T-ViT with ResNet50 comparable size can achieve 80.7\% top-1 accuracy on ImageNet. (Code: https://github.com/yitu-opensource/T2T-ViT)},
archivePrefix = {arXiv},
arxivId = {2101.11986},
author = {Yuan, Li and Chen, Yunpeng and Wang, Tao and Yu, Weihao and Shi, Yujun and Tay, Francis EH and Feng, Jiashi and Yan, Shuicheng},
eprint = {2101.11986},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yuan et al. - 2021 - Tokens-to-Token ViT Training Vision Transformers from Scratch on ImageNet.pdf:pdf},
keywords = {architecture,representation learning,transformer},
mendeley-tags = {architecture,representation learning,transformer},
title = {{Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet}},
url = {http://arxiv.org/abs/2101.11986},
year = {2021}
}
@book{Hristev1998,
author = {Hristev, R.M.},
pages = {392},
publisher = {GNU Public},
title = {{The ANN Book}},
year = {1998}
}
@article{Ibrahim2020a,
abstract = {The ability to perform accurate prognosis of patients is crucial for proactive clinical decision making, informed resource management and personalised care. Existing outcome prediction models suffer from a low recall of infrequent positive outcomes. We present a highly-scalable and robust machine learning framework to automatically predict adversity represented by mortality and ICU admission from time-series vital signs and laboratory results obtained within the first 24 hours of hospital admission. The stacked platform comprises two components: a) an unsupervised LSTM Autoencoder that learns an optimal representation of the time-series, using it to differentiate the less frequent patterns which conclude with an adverse event from the majority patterns that do not, and b) a gradient boosting model, which relies on the constructed representation to refine prediction, incorporating static features of demographics, admission details and clinical summaries. The model is used to assess a patient's risk of adversity over time and provides visual justifications of its prediction based on the patient's static features and dynamic signals. Results of three case studies for predicting mortality and ICU admission show that the model outperforms all existing outcome prediction models, achieving PR-AUC of 0.93 (95$%$ CI: 0.878 - 0.969) in predicting mortality in ICU and general ward settings and 0.987 (95$%$ CI: 0.985-0.995) in predicting ICU admission.},
archivePrefix = {arXiv},
arxivId = {2011.09361},
author = {Ibrahim, Zina M and Bean, Daniel and Searle, Thomas and Wu, Honghan and Shek, Anthony and Kraljevic, Zeljko and Galloway, James and Norton, Sam and Teo, James T and Dobson, Richard JB},
eprint = {2011.09361},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ibrahim et al. - 2020 - A Knowledge Distillation Ensemble Framework for Predicting Short and Long-term Hospitalisation Outcomes from Ele.pdf:pdf},
issn = {23318422},
keywords = {time series},
mendeley-tags = {time series},
number = {Xx},
pages = {1--13},
title = {{A Knowledge Distillation Ensemble Framework for Predicting Short and Long-term Hospitalisation Outcomes from Electronic Health Records Data}},
url = {http://arxiv.org/abs/2011.09361 https://github.com/zibrahim/KD-OP},
volume = {XX},
year = {2020}
}
@article{Phaengkieo2016,
author = {Phaengkieo, D and Ruangsinchaiwanich, S},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Phaengkieo, Ruangsinchaiwanich - 2016 - Optimization of three-phase transformer design using adaptive genetic algorithm.pdf:pdf},
journal = {2016 19th International Conference on Electrical Machines and Systems (ICEMS)},
keywords = {electric machines;finite element analysis;genetic},
pages = {1--5},
title = {{Optimization of three-phase transformer design using adaptive genetic algorithm}},
year = {2016}
}
@article{Bohn2020,
author = {Bohn, Tanner and Ling, Charles X},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bohn, Ling - 2020 - Towards a Unified Lifelong Learning Framework.pdf:pdf},
pages = {1--8},
title = {{Towards a Unified Lifelong Learning Framework}},
year = {2020}
}
@article{Lim2019,
abstract = {Multi-horizon forecasting problems often contain a complex mix of inputs - including static (i.e. time-invariant) covariates, known future inputs, and other exogenous time series that are only observed historically - without any prior information on how they interact with the target. While several deep learning models have been proposed for multi-step prediction, they typically comprise black-box models which do not account for the full range of inputs present in common scenarios. In this paper, we introduce the Temporal Fusion Transformer (TFT) - a novel attention-based architecture which combines high-performance multi-horizon forecasting with interpretable insights into temporal dynamics. To learn temporal relationships at different scales, the TFT utilizes recurrent layers for local processing and interpretable self-attention layers for learning long-term dependencies. The TFT also uses specialized components for the judicious selection of relevant features and a series of gating layers to suppress unnecessary components, enabling high performance in a wide range of regimes. On a variety of real-world datasets, we demonstrate significant performance improvements over existing benchmarks, and showcase three practical interpretability use-cases of TFT.},
archivePrefix = {arXiv},
arxivId = {1912.09363},
author = {Lim, Bryan and Arık, Sercan and Loeff, Nicolas and Pfister, Tomas},
eprint = {1912.09363},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lim et al. - 2019 - Temporal fusion transformers for interpretable multi-horizon time series forecasting.pdf:pdf},
journal = {arXiv},
keywords = {Attention mechanisms,Interpretable deep learning,Time series forecasting,time series},
mendeley-tags = {time series},
number = {Bryan Lim},
pages = {1--27},
title = {{Temporal fusion transformers for interpretable multi-horizon time series forecasting}},
url = {https://github.com/google-research/google-research/tree/master/tft https://github.com/mattsherar/Temporal_Fusion_Transform https://arxiv.org/pdf/1912.09363v3.pdf},
year = {2019}
}
@article{Cosgun2014a,
abstract = {In this study, the pricing problem of a transportation service provider company is considered. Our goal is to find optimal prices by using probabilistic dynamic programming. A fuzzy IF-THEN-rule based system is used to identify the demand levels under different prices and other characteristics of the journey. The results obtained by optimal price policies show that the revenue increases by applying dynamic pricing policy instead of fixed pricing. Thus, the diversification of pricing policies under different conditions is beneficial for the company.},
author = {Coşgun, {\"{O}}zlem and Ekinci, Yeliz and Yanik, Seda},
doi = {10.1016/j.knosys.2014.04.015},
isbn = {9789814417730},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Demand forecasting,Dynamic pricing,Dynamic programming,Fuzzy IF-THEN rules,Transportation},
number = {May},
pages = {88--96},
title = {{Fuzzy rule-based demand forecasting for dynamic pricing of a maritime company}},
volume = {70},
year = {2014}
}
@article{Liu2019a,
author = {Liu, Vincent},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu - 2019 - Sparse Representation Neural Networks for Online Reinforcement Learning.pdf:pdf},
keywords = {continual learning,reinforcement learning},
mendeley-tags = {continual learning,reinforcement learning},
title = {{Sparse Representation Neural Networks for Online Reinforcement Learning}},
year = {2019}
}
@article{Arif2016,
abstract = {This paper revisits the existing literature on the concept of citizenship in digital age. It provides a detailed discussion on the proponents and opponents of technological determinism. The paper should be read as an effort to reinitiate an important debate in the scholarship, which has been largely undermined while studying the Internet phenomenon in the information age. Thus, instead of offering a solution-oriented conclusion, the paper sets the stage to invite mass media and communication scholars' attention back to revisit the important ideological concepts, so as to evolve and improve our existing theories on communication and change in the society.},
author = {Arif, Rauf},
doi = {10.1016/j.sbspro.2016.12.002},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arif - 2016 - Internet as a Hope or a Hoax for Emerging Democracies Revisiting the Concept of Citizenship in the Digital Age.pdf:pdf},
isbn = {0019035667287},
issn = {18770428},
journal = {Procedia - Social and Behavioral Sciences},
keywords = {citizen,digital age,internet,netizen,public sphere},
number = {December 2015},
pages = {4--8},
publisher = {The Author(s)},
title = {{Internet as a Hope or a Hoax for Emerging Democracies: Revisiting the Concept of Citizenship in the Digital Age}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877042816316354},
volume = {236},
year = {2016}
}
@article{Ma2021a,
abstract = {Lottery ticket hypothesis suggests that a dense neural network contains a sparse sub-network that can match the test accuracy of the original dense net when trained in isolation from (the same) random initialization. However, the hypothesis failed to generalize to larger dense networks such as ResNet-50. As a remedy, recent studies demonstrate that a sparse sub-network can still be obtained by using a rewinding technique, which is to re-train it from early-phase training weights or learning rates of the dense model, rather than from random initialization. Is rewinding the only or the best way to scale up lottery tickets? This paper proposes a new, simpler and yet powerful technique for re-training the sub-network, called "Knowledge Distillation ticket" (KD ticket). Rewinding exploits the value of inheriting knowledge from the early training phase to improve lottery tickets in large networks. In comparison, KD ticket addresses a complementary possibility - inheriting useful knowledge from the late training phase of the dense model. It is achieved by leveraging the soft labels generated by the trained dense model to re-train the sub-network, instead of the hard labels. Extensive experiments are conducted using several large deep networks (e.g ResNet-50 and ResNet-110) on CIFAR-10 and ImageNet datasets. Without bells and whistles, when applied by itself, KD ticket performs on par or better than rewinding, while being nearly free of hyperparameters or ad-hoc selection. KD ticket can be further applied together with rewinding, yielding state-of-the-art results for large-scale lottery tickets.},
archivePrefix = {arXiv},
arxivId = {2101.03255},
author = {Ma, Haoyu and Chen, Tianlong and Hu, Ting-Kuei and You, Chenyu and Xie, Xiaohui and Wang, Zhangyang},
eprint = {2101.03255},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ma et al. - 2021 - Good Students Play Big Lottery Better(3).pdf:pdf},
journal = {NeurIPS_submitted},
keywords = {knowledge distillation,lottery ticket,transfer learning},
mendeley-tags = {knowledge distillation,lottery ticket,transfer learning},
number = {NeurIPS},
pages = {1--10},
title = {{Good Students Play Big Lottery Better}},
year = {2021}
}
@inproceedings{Goodfellow2015,
abstract = {Several machine learning models, including neural networks, consistently misclassify adversarial examples—inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that the perturbed input results in the model outputting an incorrect answer with high confidence. Early attempts at explaining this phenomenon focused on nonlinearity and overfitting. We argue instead that the primary cause of neural networks' vulnerability to adversarial perturbation is their linear nature. This explanation is supported by new quantitative results while giving the first explanation of the most intriguing fact about them: their generalization across architectures and training sets. Moreover, this view yields a simple and fast method of generating adversarial examples. Using this approach to provide examples for adversarial training, we reduce the test set error of a maxout network on the MNIST dataset.},
archivePrefix = {arXiv},
arxivId = {1412.6572},
author = {Goodfellow, Ian J. and Shlens, Jonathon and Szegedy, Christian},
booktitle = {3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings},
eprint = {1412.6572},
title = {{Explaining and harnessing adversarial examples}},
year = {2015}
}
@article{Alhassan2006,
author = {Alhassan, Mohammed and Garba, Mohammed Umar},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alhassan, Garba - 2006 - Design of an Alkaline Fuel Cell.pdf:pdf},
journal = {Leonardo Electronic Journal of Practises and Technologies},
keywords = {alkaline,enthalpy,fuel cell},
number = {9},
pages = {99--106},
title = {{Design of an Alkaline Fuel Cell}},
volume = {July-Decem},
year = {2006}
}
@article{Alexandrov2019,
abstract = {We introduce Gluon Time Series (GluonTS)1, a library for deep-learning-based time series modeling. GluonTS simplifies the development of and experimentation with time series models for common tasks such as forecasting or anomaly detection. It provides all necessary components and tools that scientists need for quickly building new models, for efficiently running and analyzing experiments and for evaluating model accuracy.},
archivePrefix = {arXiv},
arxivId = {1906.05264},
author = {Alexandrov, Alexander and Benidis, Konstantinos and Bohlke-Schneider, Michael and Flunkert, Valentin and Gasthaus, Jan and Januschowski, Tim and Maddix, Danielle C. and Rangapuram, Syama and Salinas, David and Schulz, Jasper and Stella, Lorenzo and T{\"{u}}rkmen, Ali Caner and Wang, Yuyang},
eprint = {1906.05264},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alexandrov et al. - 2019 - GluonTS Probabilistic time series models in python.pdf:pdf},
journal = {arXiv},
keywords = {time series},
mendeley-tags = {time series},
pages = {1--24},
title = {{GluonTS: Probabilistic time series models in python}},
url = {https://arxiv.org/pdf/1906.05264v2.pdf https://github.com/awslabs/gluon-ts},
year = {2019}
}
@article{Li2020d,
abstract = {Contrastive learning is very effective at learning useful representations without supervision. Yet contrastive learning has its limitations. It can learn a shortcut that is irrelevant to the downstream task, and discard relevant information. Past work has addressed this limitation via custom data augmentations that eliminate the shortcut. This solution however does not work for data modalities that are not interpretable by humans, e.g., radio signals. For such modalities, it is hard for a human to guess which shortcuts may exist in the signal, or how to alter the radio signals to eliminate the shortcuts. Even for visual data, sometimes eliminating the shortcut may be undesirable. The shortcut may be irrelevant to one downstream task but important to another. In this case, it is desirable to learn a representation that captures both the shortcut information and the information relevant to the other downstream task. This paper presents information-preserving contrastive learning (IPCL), a new framework for unsupervised representation learning that preserves relevant information even in the presence of shortcuts. We empirically show that IPCL addresses the above problems and outperforms contrastive learning on radio signals and learning RGB data representation with different features that support different downstream tasks.},
archivePrefix = {arXiv},
arxivId = {2012.09962},
author = {Li, Tianhong and Fan, Lijie and Yuan, Yuan and He, Hao and Tian, Yonglong and Katabi, Dina},
eprint = {2012.09962},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2020 - Information-Preserving Contrastive Learning for Self-Supervised Representations.pdf:pdf},
keywords = {contrastive learning,self-supervised learning},
mendeley-tags = {contrastive learning,self-supervised learning},
title = {{Information-Preserving Contrastive Learning for Self-Supervised Representations}},
url = {http://arxiv.org/abs/2012.09962},
year = {2020}
}
@article{Gamella2018,
abstract = {The article represents a short conceptual overview of biofuel cell applications, rather than their design and operation. Special attention is given to interfacing enzyme-based biofuel cells with power consuming microelectronic devices. Importance of electronic management of the power extracted from biological sources is emphasized. In addition to several briefly explained examples collected from recent publications, one system demonstrating powering of a standard glucometer with an implantable or wearable biofuel cell is described in details. The opinion on the biofuel cell applications and limitations represents the personal vision of the authors and might be not fully in accordance with the opinions of other experts.},
author = {Gamella, Maria and Koushanpour, Ashkan and Katz, Evgeny},
doi = {10.1016/j.bioelechem.2017.09.002},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gamella, Koushanpour, Katz - 2018 - Biofuel cells – Activation of micro- and macro-electronic devices.pdf:pdf},
issn = {1878562X},
journal = {Bioelectrochemistry},
keywords = {Biofuel cell,Biomedical application,Enzymes,Glucometer,Microbial fuel cell,Microelectronics,Power management},
pages = {33--42},
publisher = {Elsevier B.V},
title = {{Biofuel cells – Activation of micro- and macro-electronic devices}},
url = {http://dx.doi.org/10.1016/j.bioelechem.2017.09.002},
volume = {119},
year = {2018}
}
@article{Brito2007,
abstract = {Complete recycling of waste edible oil has recently attracted considerable attention as a worldwide social problem. Production of a biodiesel fuel from used vegetable oil is considered an important step in reducing and recycling waste oil. This technology employs used vegetable oil as a potential renewable alternative resource to fossil diesel fuel, and the transesterification reaction is the usual process to obtain biodiesel. The objective of this work is to study the transesterification of waste oil with methanol in the presence of several Y-type zeolites with different Al2O3 content. In this study, the reaction is carried out in a continuous tubular steel reactor using zeolite Y as catalyst, being tested at atmospheric pressure within a reactor temperature range of 200–476 °C and methanol/oil molar ratio of 6. The results show an important decrease of viscosity of the product obtained until values close to biodiesel specifications.},
author = {Brito, A. and Borges, M. E. and Otero, N.},
doi = {10.1021/ef700455r},
isbn = {0887-0624},
issn = {0887-0624},
journal = {Energy & Fuels},
number = {6},
pages = {3280--3283},
title = {{Zeolite Y as a Heterogeneous Catalyst in Biodiesel Fuel Production from Used Vegetable Oil}},
url = {http://pubs.acs.org/doi/abs/10.1021/ef700455r},
volume = {21},
year = {2007}
}
@article{Adel2020,
abstract = {Approaches to continual learning aim to successfully learn a set of related tasks that arrive in an online manner. Recently, several frameworks have been developed which enable deep learning to be deployed in this learning scenario. A key mod- elling decision is to what extent the architecture should be shared across tasks. On the one hand, separately modelling each task avoids catastrophic forgetting but it does not support transfer learning and leads to large models. On the other hand, rigidly specifying a shared component and a task-specific part enables task transfer and limits the model size, but it is vulnerable to catastrophic forgetting and restricts the form of task-transfer that can occur. Ideally, the network should adaptively identify which parts of the network to share in a data driven way. Here we intro- duce such an approach called Continual Learning with Adaptive Weights (CLAW), which is based on probabilistic modelling and variational inference. Experiments show that CLAW achieves state-of-the-art performance on six benchmarks in terms of overall continual learning performance, as measured by classification accuracy, and in terms of addressing catastrophic forgetting.},
archivePrefix = {arXiv},
arxivId = {1911.09514v2},
author = {Adel, Tameem and Zhao, Han and Turner, Richard E.},
eprint = {1911.09514v2},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Adel, Zhao, Turner - 2020 - Continual Learning with Adaptive Weights (CLAW).pdf:pdf},
keywords = {continual learning,regularization},
mendeley-tags = {continual learning,regularization},
pages = {2748--},
title = {{Continual Learning with Adaptive Weights (CLAW)}},
url = {https://arxiv.org/abs/1911.09514},
year = {2020}
}
@article{Wandinger,
abstract = {1.1 Lidar and the Atmosphere Atmospheric research nowadays is hard to conceive without the use of remote-sensing techniques. Light detection and ranging (lidar) is, along with radiowave detection and ranging (radar), one of the backbones of the research field that deals with the profiling of the atmosphere. High spatial and temporal resolution of the measurements, the possibility of observing the atmosphere at ambient conditions, and the potential of covering the height range from the ground to more than 100 km altitude make up the attractiveness of lidar instruments. The variety of interaction processes of the emitted radiation with the atmospheric constituents that can be used in lidar allow the determination of the basic atmospheric variables of state, i.e., temperature, pressure, humidity, and wind, as well as the measurement of trace gases, aerosols, and clouds. Lidar has largely contributed to our knowledge of the Earth's atmosphere during the past decades. It is particularly useful for the investigation of highly variable atmospheric parameters. Lidar has the potential for the observation of processes on scales that extend from a few cubic meters and a few seconds to global, multi-year coverage. Lidar has been used to investigate turbulent processes and the diur-nal cycle of the planetary boundary layer, including the measurement of water-vapor and ozone fluxes. Meteorological phenomena such as frontal passages, hurricanes, and mountain lee waves were studied. Lidar helps monitor emission rates and concentration levels of trace gases. The stratospheric ozone depletion is documented globally with lidar. The role of polar stratospheric clouds is investigated and the classification of 2 Ulla Wandinger polar stratospheric clouds is based on their scattering properties as seen with lidar. Lidar is used to distinguish water droplets from ice crystals in clouds. Lidar contributes to our knowledge of the climatic effects of aerosols. The stratospheric perturbation after major volcanic eruptions has been studied and the intercontinental transport of air pollution, desert dust, and forest-fire smoke has been detected. In the mesosphere, lidar has proven the existence of layers of metallic atoms and ions and of gravity waves therein. Lidar instruments can operate from the ground or from aircraft, one system has been flown on the Space Shuttle, and in the near future satellite-based lidar instruments will carry out global observations of atmospheric constituents from space. These and many more aspects of lidar are presented in this book giving an overview on the state of the art of the basic lidar techniques used in the investigation of the Earth's atmosphere.},
author = {Wandinger, Ulla},
doi = {10.1007/0-387-25101-4_1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wandinger - Unknown - Introduction to Lidar.pdf:pdf},
isbn = {0-387-40075-3},
journal = {Lidar},
pages = {1--18},
pmid = {13639825},
title = {{Introduction to Lidar}},
url = {http://link.springer.com/10.1007/0-387-25101-4_1}
}
@article{Klein2020,
abstract = {We introduce a model-based asynchronous multi-fidelity method for hyperparameter and neural architecture search that combines the strengths of asynchronous Hyperband and Gaussian process-based Bayesian optimization. At the heart of our method is a probabilistic model that can simultaneously reason across hyperparameters and resource levels, and supports decision-making in the presence of pending evaluations. We demonstrate the effectiveness of our method on a wide range of challenging benchmarks, for tabular data, image classification and language modelling, and report substantial speed-ups over current state-of-the-art methods. Our new methods, along with asynchronous baselines, are implemented in a distributed framework which will be open sourced along with this publication.},
archivePrefix = {arXiv},
arxivId = {2003.10865},
author = {Klein, Aaron and Tiao, Louis C. and Lienart, Thibaut and Archambeau, Cedric and Seeger, Matthias},
eprint = {2003.10865},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Klein et al. - 2020 - Model-based Asynchronous Hyperparameter and Neural Architecture Search.pdf:pdf},
keywords = {neural architecture search,tabular data},
mendeley-tags = {neural architecture search,tabular data},
month = {mar},
pages = {1--17},
title = {{Model-based Asynchronous Hyperparameter and Neural Architecture Search}},
url = {http://arxiv.org/abs/2003.10865 https://github.com/jim-schwoebel/allie https://github.com/awslabs/autogluon},
year = {2020}
}
@article{Hadfield2017,
abstract = {{\textcopyright} 2016 The Author(s)Action recognition “in the wild” is extremely challenging, particularly when complex 3D actions are projected down to the image plane, losing a great deal of information. The recent growth of 3D data in broadcast content and commercial depth sensors, makes it possible to overcome this. However, there is little work examining the best way to exploit this new modality. In this paper we introduce the Hollywood 3D benchmark, which is the first dataset containing “in the wild” action footage including 3D data. This dataset consists of 650 stereo video clips across 14 action classes, taken from Hollywood movies. We provide stereo calibrations and depth reconstructions for each clip. We also provide an action recognition pipeline, and propose a number of specialised depth-aware techniques including five interest point detectors and three feature descriptors. Extensive tests allow evaluation of different appearance and depth encoding schemes. Our novel techniques exploiting this depth allow us to reach performance levels more than triple those of the best baseline algorithm using only appearance information. The benchmark data, code and calibrations are all made available to the community.},
archivePrefix = {arXiv},
arxivId = {1311.2901},
author = {Hadfield, Simon and Lebeda, Karel and Bowden, Richard},
doi = {10.1007/s11263-016-0917-2},
eprint = {1311.2901},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hadfield, Lebeda, Bowden - 2017 - Hollywood 3D What are the Best 3D Features for Action Recognition.pdf:pdf},
isbn = {978-3-319-46447-3},
issn = {15731405},
journal = {International Journal of Computer Vision},
keywords = {3D,3D motion,Action recognition,Benchmark,Depth,Hollywood 3D,In the wild,Structure},
number = {1},
pages = {95--110},
pmid = {10463930},
publisher = {Springer US},
title = {{Hollywood 3D: What are the Best 3D Features for Action Recognition?}},
volume = {121},
year = {2017}
}
@article{Howard2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1704.04861v1},
author = {Howard, Andrew G and Wang, Weijun},
eprint = {arXiv:1704.04861v1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Howard, Wang - 2012 - MobileNets Efficient Convolutional Neural Networks for Mobile Vision Applications.pdf:pdf},
title = {{MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications}},
year = {2012}
}
@article{Lynch1996a,
author = {Lynch, C S},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lynch - 1996 - The effect of uniaxial stress on the electro-mechanical response of 86535 textsc{PLZT}.pdf:pdf},
journal = {Acta Mater.},
number = {10},
pages = {4137--4148},
title = {{The effect of uniaxial stress on the electro-mechanical response of 8/65/35 \textsc{PLZT}}},
volume = {44},
year = {1996}
}
@article{Todorov2012,
abstract = {Faces are one of the most significant social stimuli and the processes underlying face perception are at the intersection of cognition, affect, and motivation. Vision scientists have had a tremendous success of mapping the regions for perceptual analysis of faces in posterior cortex. Based on evidence from (a) single unit recording studies in monkeys and humans; (b) human functional localizer studies; and (c) meta-analyses of neuroimaging studies, I argue that faces automatically evoke responses not only in these regions but also in the amygdala. I also argue that (a) a key property of faces represented in the amygdala is their typicality; and (b) one of the functions of the amygdala is to bias attention to atypical faces, which are associated with higher uncertainty. This framework is consistent with a number of other amygdala findings not involving faces, suggesting a general account for the role of the amygdala in perception.},
author = {Todorov, Alexander},
doi = {10.1007/s11031-011-9238-5},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Todorov - 2012 - The role of the amygdala in face perception and evaluation.pdf:pdf},
isbn = {0146-7239},
issn = {01467239},
journal = {Motivation and Emotion},
keywords = {Amygdala,Face evaluation,Face perception,Social cognition},
number = {1},
pages = {16--26},
pmid = {22448077},
title = {{The role of the amygdala in face perception and evaluation}},
volume = {36},
year = {2012}
}
@article{Lamara2012,
abstract = {The targeted purpose here is the control of a nonlinear and non-square system with three inputs and two outputs in order to reduce soot and greenhouse gas pollutants. In this paper, a non-square multivariable controller for the air-path system of a turbocharged Diesel engine is proposed. The controller is designed using the CRONE (Commande Robuste d'Ordre Non Entier) Control-System-Design approach to maintain performance and robust stability for a wide set of operating points. In this research, we focused on the multi-input multi-output system identification problem, and test-bench data were processed to find a nominal linear model. The controller was then designed via an open-loop transfer function optimization. Finally, simulation results from a simulation model show the performance of the proposed control-system. {\textcopyright} 2012 IFAC.},
author = {Lamara, Abderrahim and Colin, Guillaume and Lanusse, Patrick and Chamaillard, Yann and Charlet, Alain},
doi = {10.3182/20121023-3-FR-4025.00002},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lamara et al. - 2012 - Decentralized robust control-system for a non-square MIMO system, the air-path of a turbocharged Diesel engine.pdf:pdf},
isbn = {9783902823168},
issn = {14746670},
journal = {IFAC Proceedings Volumes (IFAC-PapersOnline)},
keywords = {CRONE,Diesel engine air path,Multivariable control,Non-square system,Robust control},
number = {30},
pages = {130--137},
title = {{Decentralized robust control-system for a non-square MIMO system, the air-path of a turbocharged Diesel engine}},
volume = {45},
year = {2012}
}
@article{Bau2020,
abstract = {Deep neural networks excel at finding hierarchical representations that solve complex tasks over large datasets. How can we humans understand these learned representations? In this work, we present network dissection, an analytic framework to systematically identify the semantics of individual hidden units within image classification and image generation networks. First, we analyze a convolutional neural network (CNN) trained on scene classification and discover units that match a diverse set of object concepts. We find evidence that the network has learned many object classes that play crucial roles in classifying scene classes. Second, we use a similar analytic method to analyze a generative adversarial network (GAN) model trained to generate scenes. By analyzing changes made when small sets of units are activated or deactivated, we find that objects can be added and removed from the output scenes while adapting to the context. Finally, we apply our analytic framework to understanding adversarial attacks and to semantic image editing.},
archivePrefix = {arXiv},
arxivId = {2009.05041},
author = {Bau, David and Zhu, Jun-Yan and Strobelt, Hendrik and Lapedriza, Agata and Zhou, Bolei and Torralba, Antonio},
doi = {10.1073/pnas.1907375117},
eprint = {2009.05041},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bau et al. - 2020 - Understanding the role of individual units in a deep neural network.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
month = {sep},
pages = {201907375},
title = {{Understanding the role of individual units in a deep neural network}},
url = {http://arxiv.org/abs/2009.05041 http://dx.doi.org/10.1073/pnas.1907375117 http://www.pnas.org/lookup/doi/10.1073/pnas.1907375117},
year = {2020}
}
@article{Finn2017a,
abstract = {We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.},
archivePrefix = {arXiv},
arxivId = {1703.03400},
author = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
eprint = {1703.03400},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Finn, Abbeel, Levine - 2017 - Model-agnostic meta-learning for fast adaptation of deep networks.pdf:pdf;:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/N-way - 2017 - A . Additional Experiment Details B . Additional Sinusoid Results C . Additional Comparisons.pdf:pdf},
journal = {arXiv},
keywords = {few-shot learning,meta-learning,model-agnostic},
mendeley-tags = {few-shot learning,meta-learning,model-agnostic},
number = {2015},
pages = {5--7},
title = {{Model-agnostic meta-learning for fast adaptation of deep networks}},
url = {https://github.com/cbfinn/maml http://proceedings.mlr.press/v70/finn17a.html},
year = {2017}
}
@article{Titsias2020,
author = {Titsias, Michalis K and Schwarz, Jonathan and Pascanu, Razvan and Teh, Yee Whye},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Titsias et al. - 2020 - Functional Regularisation for Continual Learning with Gaussian Process.pdf:pdf},
pages = {1--17},
title = {{Functional Regularisation for Continual Learning with Gaussian Process}},
year = {2020}
}
@article{Schafle2016,
author = {Sch{\"{a}}fle, T R and Mohamed, S and Uchiyama, N and Sawodny, O},
doi = {10.1109/ELECSYM.2016.7860983},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sch{\"{a}}fle et al. - 2016 - Coverage path planning for mobile robots using genetic algorithm with energy optimization.pdf:pdf},
isbn = {9781509016402},
journal = {2016 International Electronics Symposium (IES)},
keywords = {approximation theory;genetic algorithms;mobile rob},
pages = {99--104},
title = {{Coverage path planning for mobile robots using genetic algorithm with energy optimization}},
year = {2016}
}
@article{Kumar2017,
author = {Kumar, Satish and Kumar, Ashwani and Sharma, Nikhlesh Kumar},
doi = {10.1186/s40807-017-0039-7},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kumar, Kumar, Sharma - 2017 - Sensitivity analysis-based performance and economic operation of wind-integrated system with FACTS devices.pdf:pdf},
issn = {2198-994X},
journal = {Renewables: Wind, Water, and Solar},
keywords = {Wind integration,FACTS,Cost function,Voltage stabi,cost function,cpf,facts,opf,pf,pso,senstivity,voltage collapse,voltage stability,wind integration},
number = {1},
pages = {2},
publisher = {Springer Singapore},
title = {{Sensitivity analysis-based performance and economic operation of wind-integrated system with FACTS devices for optimum load dispatch}},
url = {http://jrenewables.springeropen.com/articles/10.1186/s40807-017-0039-7},
volume = {4},
year = {2017}
}
@inproceedings{Acharya2020,
abstract = {Humans can incrementally learn to do new visual detection tasks, which is a huge challenge for today's computer vision systems. Incrementally trained deep learning models lack backwards transfer to previously seen classes and suffer from a phenomenon known as “catastrophic forgetting.” In this paper, we pioneer online streaming learning for object detection, where an agent must learn examples one at a time with severe memory and computational constraints. In object detection, a system must output all bounding boxes for an image with the correct label. Unlike earlier work, the system described in this paper can learn this task in an online manner with new classes being introduced over time. We achieve this capability by using a novel memory replay mechanism that efficiently replays entire scenes. We achieve state-of-the-art results on both the PASCAL VOC 2007 and MS COCO datasets.},
archivePrefix = {arXiv},
arxivId = {2008.06439},
author = {Acharya, Manoj and Hayes, Tyler L. and Kanan, Christopher},
booktitle = {The British Machine Vision Conference},
eprint = {2008.06439},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Acharya, Hayes, Kanan - 2020 - RODEO Replay for online object detection.pdf:pdf},
issn = {23318422},
keywords = {continual learning,incremental learning,object detection},
mendeley-tags = {continual learning,incremental learning,object detection},
title = {{RODEO: Replay for online object detection}},
year = {2020}
}
@article{Sharma2016b,
author = {Sharma, Neel and Takeshita, Nobuyoshi and Ho, Khek Yu},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sharma, Takeshita, Ho - 2016 - Raman Spectroscopy for the Endoscopic Diagnosis of Esophageal , Gastric , and Colonic Diseases.pdf:pdf},
keywords = {confocal endomicroscopy,narrow band imaging,raman,real-time decision making,real-time diagnosis,spectrum analysis},
pages = {404--407},
title = {{Raman Spectroscopy for the Endoscopic Diagnosis of Esophageal , Gastric , and Colonic Diseases}},
year = {2016}
}
@article{Smith2021,
abstract = {Rehearsal is a critical component for class-incremental continual learning, yet it requires a substantial memory budget. Our work investigates whether we can significantly reduce this memory budget by leveraging unlabeled data from an agent's environment in a realistic and challenging continual learning paradigm. Specifically, we explore and formalize a novel semi-supervised continual learning (SSCL) setting, where labeled data is scarce yet non-i.i.d. unlabeled data from the agent's environment is plentiful. Importantly, data distributions in the SSCL setting are realistic and therefore reflect object class correlations between, and among, the labeled and unlabeled data distributions. We show that a strategy built on pseudo-labeling, consistency regularization, Out-of-Distribution (OoD) detection, and knowledge distillation reduces forgetting in this setting. Our approach, DistillMatch, increases performance over the state-of-the-art by no less than 8.7% average task accuracy and up to a 54.5% increase in average task accuracy in SSCL CIFAR-100 experiments. Moreover, we demonstrate that DistillMatch can save up to 0.23 stored images per processed unlabeled image compared to the next best method which only saves 0.08. Our results suggest that focusing on realistic correlated distributions is a significantly new perspective, which accentuates the importance of leveraging the world's structure as a continual learning strategy.},
archivePrefix = {arXiv},
arxivId = {2101.09536},
author = {Smith, James and Balloch, Jonathan and Hsu, Yen-Chang and Kira, Zsolt},
eprint = {2101.09536},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Smith et al. - 2021 - Memory-Efficient Semi-Supervised Continual Learning The World is its Own Replay Buffer.pdf:pdf},
keywords = {continual learning,incremental learning,rehearsal,replay,semi-supervised learning},
mendeley-tags = {continual learning,incremental learning,rehearsal,replay,semi-supervised learning},
pages = {1--25},
title = {{Memory-Efficient Semi-Supervised Continual Learning: The World is its Own Replay Buffer}},
url = {http://arxiv.org/abs/2101.09536},
year = {2021}
}
@article{Frankland2020,
abstract = {Imagine Genghis Khan, Aretha Franklin, and the Cleveland Cavaliers performing an opera on Maui. This silly sentence makes a serious point: As humans, we can flexibly generate and comprehend an unbounded number of complex ideas. Little is known, however, about how our brains accomplish this. Here we assemble clues from disparate areas of cognitive neuroscience, integrating recent research on language, memory, episodic simulation, and computational models of high-level cognition. Our review is framed by Fodor's classic language of thought hypothesis, according to which our minds employ an amodal, language-like system for combining and recombining simple concepts to form more complex thoughts. Here, we highlight emerging work on combinatorial processes in the brain and consider this work's relation to the language of thought. We review evidence for distinct, but complementary, contributions of map-like representations in subregions of the default mode network and sentence-like representations of conceptual relations in regions of the temporal and prefrontal cortex.Expected final online publication date for the Annual Review of Psychology, Volume 71 is January 4, 2020. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates.},
author = {Frankland, Steven M. and Greene, Joshua D.},
doi = {10.1146/annurev-psych-122216-011829},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Frankland, Greene - 2020 - Concepts and Compositionality In Search of the Brain's Language of Thought.pdf:pdf},
issn = {0066-4308},
journal = {Annual Review of Psychology},
keywords = {artificial intelligence,compositionality,conceptual combination,default,grid cells,language of thought,mode network},
number = {1},
title = {{Concepts and Compositionality: In Search of the Brain's Language of Thought}},
volume = {71},
year = {2020}
}
@article{Ronneberger2015,
abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
archivePrefix = {arXiv},
arxivId = {arXiv:1505.04597v1},
author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
doi = {10.1007/978-3-319-24574-4_28},
eprint = {arXiv:1505.04597v1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ronneberger, Fischer, Brox - 2015 - U-net Convolutional networks for biomedical image segmentation.pdf:pdf},
isbn = {9783319245737},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {234--241},
title = {{U-net: Convolutional networks for biomedical image segmentation}},
volume = {9351},
year = {2015}
}
@article{Lynch1996,
author = {Lynch, C S},
journal = {Acta Mater.},
number = {10},
pages = {4137--4148},
title = {{The effect of uniaxial stress on the electro-mechanical response of 8/65/35 \textsc{PLZT}}},
volume = {44},
year = {1996}
}
@article{Jiang2018a,
abstract = {An early warning system is important to guarantee human health and ecological safety. Microbial fuel cell (MFC) sensor can achieve a self-sustainable monitoring without additional transducer or power sources. It would not limited by the main bottleneck of other contemporary MFC technologies, i.e., the low current density output, and is believed one of the most promising applications in the niche market of MFC technologies. This review is limited to MFC sensors for water quality early warning systems only, with emphasis on biochemical oxygen demand (BOD) and toxicity sensors. A comprehensive summary and discussion on sensor fabrication, operation, data representation, and optimization are provided. The MFC sensor is particularly promising to serve as a self-powered sensing device for in-situ and on-line environmental monitoring, as proved both in laboratory and field test. In addition, the main hurdles and future perspectives are discussed, as well as potential future research, which includes the following: separately lowering the detection limit or improving the concentration range dependent on the application of MFC for organic matter monitoring; further improving the sensitivity as well as lowering the recovery time of biofilm after a certain shock; developing the kinetic and/or empirical model in combining with the detection algorithm to distinguish the signal interference of complex aquatic environment, especially when the shock of BOD and toxicity occur simultaneously.},
author = {Jiang, Yong and Yang, Xufei and Liang, Peng and Liu, Panpan and Huang, Xia},
doi = {10.1016/j.rser.2017.06.099},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jiang et al. - 2018 - Microbial fuel cell sensors for water quality early warning systems Fundamentals, signal resolution, optimization.pdf:pdf},
isbn = {1364-0321},
issn = {18790690},
journal = {Renewable and Sustainable Energy Reviews},
keywords = {BOD,Early warning system,Microbial fuel cell,Performance indicators,Sensor,Toxicity},
number = {April 2017},
pages = {292--305},
publisher = {Elsevier Ltd},
title = {{Microbial fuel cell sensors for water quality early warning systems: Fundamentals, signal resolution, optimization and future challenges}},
url = {http://dx.doi.org/10.1016/j.rser.2017.06.099},
volume = {81},
year = {2018}
}
@article{Bojarski2016,
abstract = {We trained a convolutional neural network (CNN) to map raw pixels from a single front-facing camera directly to steering commands. This end-to-end approach proved surprisingly powerful. With minimum training data from humans the system learns to drive in traffic on local roads with or without lane markings and on highways. It also operates in areas with unclear visual guidance such as in parking lots and on unpaved roads. The system automatically learns internal representations of the necessary processing steps such as detecting useful road features with only the human steering angle as the training signal. We never explicitly trained it to detect, for example, the outline of roads. Compared to explicit decomposition of the problem, such as lane marking detection, path planning, and control, our end-to-end system optimizes all processing steps simultaneously. We argue that this will eventually lead to better performance and smaller systems. Better performance will result because the internal components self-optimize to maximize overall system performance, instead of optimizing human-selected intermediate criteria, e.g., lane detection. Such criteria understandably are selected for ease of human interpretation which doesn't automatically guarantee maximum system performance. Smaller networks are possible because the system learns to solve the problem with the minimal number of processing steps. We used an NVIDIA DevBox and Torch 7 for training and an NVIDIA DRIVE(TM) PX self-driving car computer also running Torch 7 for determining where to drive. The system operates at 30 frames per second (FPS).},
archivePrefix = {arXiv},
arxivId = {1604.07316},
author = {Bojarski, Mariusz and {Del Testa}, Davide and Dworakowski, Daniel and Firner, Bernhard and Flepp, Beat and Goyal, Prasoon and Jackel, Lawrence D. and Monfort, Mathew and Muller, Urs and Zhang, Jiakai and Zhang, Xin and Zhao, Jake and Zieba, Karol},
eprint = {1604.07316},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bojarski et al. - 2016 - End to End Learning for Self-Driving Cars.pdf:pdf},
month = {apr},
pages = {1--9},
title = {{End to End Learning for Self-Driving Cars}},
url = {http://arxiv.org/abs/1604.07316},
year = {2016}
}
@article{Anzilli2018,
abstract = {We propose a model for the pricing of the minimum guarantee option embedded in equity-linked life insurance policies under uncertainty of randomness and fuzziness. The future lifetime of the insured is modelled as a random variable and the asset price evolution is described using a fuzzy binomial-tree model. In order to deal with both randomness and fuzziness, we model the present value of liabilities as a fuzzy random variable. Our results can be used by the actuary to understand the incidence of the minimum guarantee on the premium and to define the appropriate coverage strategies. A numerical example illustrates how our methodology works.},
author = {Anzilli, Luca and Facchinetti, Gisella and Pirotti, Tommaso},
doi = {10.1016/j.ins.2017.10.001},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Anzilli, Facchinetti, Pirotti - 2018 - Pricing of minimum guarantees in life insurance contracts with fuzzy volatility.pdf:pdf},
issn = {00200255},
journal = {Information Sciences},
keywords = {Equity-linked policies,Fuzzy random variables,Fuzzy volatility,Life insurance,Minimum guarantee},
pages = {578--593},
publisher = {Elsevier Inc.},
title = {{Pricing of minimum guarantees in life insurance contracts with fuzzy volatility}},
url = {https://doi.org/10.1016/j.ins.2017.10.001},
volume = {460-461},
year = {2018}
}
@article{Mani2016,
abstract = {The use and commercial applications of biosurfactants in the petroleum industries have been raised during the past decades. Marine bacteria and their efficiency in crude oil recovery has been less studied than terrestrial strain, hence this present study. A novel marine bacterium Bacillus simplex having promising biosurfactant production was isolated from a petroleum hydrocarbon-contaminated coastal sea sediment samples of Nagapattinam fishing harbor, Tamil Nadu, India. This strain showed most economical biosurfactant production with an agro-industrial waste substrate, sunflower oil cake at 54th h time incubation along with the cultural conditions of 20ppt salinity, 35°C temperature, and pH7. The produced biosurfactant was purified, which was accounted at 908±7mg/L on dry weight basis. The biosurfactant was identified as lipopeptide with a molecular mass of 1111.1Da which was deduced using TLC, biochemical estimation methods, FT-IR, NMR, and MALDI-TOF MS analysis. Furthermore, this purified lipopeptide surfactant showed consistent and enhanced crude oil recovering efficiency under different salinity conditions (0–30%). Based on the above facts, the isolated novel marine bacterium proved its cheaper production of novel biosurfactant and its promising oil recovering efficiency even at hypersaline conditions. Further, this is the first report of a biosurfactant from the bacterium Bacillus simplex.},
author = {Mani, Panagal and Sivakumar, Pethanen and Balan, Shanmugasundaram Senthil},
doi = {10.1016/j.als.2016.05.010},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mani, Sivakumar, Balan - 2016 - Economic Production and Oil Recovery Efficiency of a Lipopeptide Biosurfactant from a Novel Marine Bacte.pdf:pdf},
issn = {20781520},
journal = {Achievements in the Life Sciences},
keywords = {Bacillus simplex,Crude oil recovery,Lipopeptide surfactant,Marine bacterium,Sunflower oil cake},
number = {1},
pages = {102--110},
publisher = {Far Eastern Federal University},
title = {{Economic Production and Oil Recovery Efficiency of a Lipopeptide Biosurfactant from a Novel Marine Bacterium Bacillus simplex}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2078152016300049},
volume = {10},
year = {2016}
}
@article{Bennani2020,
abstract = {In continual learning settings, deep neural networks are prone to catastrophic forgetting. Orthogonal Gradient Descent (Farajtabar et al., 2019) achieves state-of-the-art results in practice for continual learning, although no theoretical guarantees have been proven yet. We derive the first generalisation guarantees for the algorithm OGD for continual learning, for overparameterized neural networks. We find that OGD is only provably robust to catastrophic forgetting across a single task. We propose OGD+, prove that it is robust to catastrophic forgetting across an arbitrary number of tasks, and that it verifies tighter generalisation bounds. Our experiments show that OGD+ achieves state-of-the-art results on settings with a large number of tasks, even though the models are not overparameterized. Also, we derive a closed form expression of the learned models through tasks, as a recursive kernel regression relation, which captures the transferability of knowledge through tasks. Finally, we quantify theoretically the impact of task ordering on the generalisation error, which highlights the importance of the curriculum for lifelong learning.},
archivePrefix = {arXiv},
arxivId = {2006.11942},
author = {Bennani, Mehdi Abbana and Sugiyama, Masashi},
eprint = {2006.11942},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bennani, Sugiyama - 2020 - Generalisation guarantees for continual learning with orthogonal gradient descent.pdf:pdf},
journal = {arXiv},
keywords = {continual learning,orthogonal gradient descent},
mendeley-tags = {continual learning,orthogonal gradient descent},
pages = {1--37},
title = {{Generalisation guarantees for continual learning with orthogonal gradient descent}},
url = {https://arxiv.org/pdf/2006.11942.pdf https://github.com/MehdiAbbanaBennani/continual-learning-ogdplus},
year = {2020}
}
@article{Shoshan2021,
abstract = {We present a framework for training GANs with explicit control over generated images. We are able to control the generated image by settings exact attributes such as age, pose, expression, etc. Most approaches for editing GAN-generated images achieve partial control by leveraging the latent space disentanglement properties, obtained implicitly after standard GAN training. Such methods are able to change the relative intensity of certain attributes, but not explicitly set their values. Recently proposed methods, designed for explicit control over human faces, harness morphable 3D face models to allow fine-grained control capabilities in GANs. Unlike these methods, our control is not constrained to morphable 3D face model parameters and is extendable beyond the domain of human faces. Using contrastive learning, we obtain GANs with an explicitly disentangled latent space. This disentanglement is utilized to train control-encoders mapping human-interpretable inputs to suitable latent vectors, thus allowing explicit control. In the domain of human faces we demonstrate control over identity, age, pose, expression, hair color and illumination. We also demonstrate control capabilities of our framework in the domains of painted portraits and dog image generation. We demonstrate that our approach achieves state-of-the-art performance both qualitatively and quantitatively.},
archivePrefix = {arXiv},
arxivId = {2101.02477},
author = {Shoshan, Alon and Bhonker, Nadav and Kviatkovsky, Igor and Medioni, Gerard},
eprint = {2101.02477},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shoshan et al. - 2021 - GAN-Control Explicitly Controllable GANs.pdf:pdf},
keywords = {disentangled representation,gan},
mendeley-tags = {disentangled representation,gan},
title = {{GAN-Control: Explicitly Controllable GANs}},
url = {http://arxiv.org/abs/2101.02477 https://alonshoshan10.github.io/gan_control/},
year = {2021}
}
@article{Xu2018,
abstract = {Generative adversarial networks (GANs) implicitly learn the probability distribution of a dataset and can draw samples from the distribution. This paper presents, Tabular GAN (TGAN), a generative adversarial network which can generate tabular data like medical or educational records. Using the power of deep neural networks, TGAN generates high-quality and fully synthetic tables while simultaneously generating discrete and continuous variables. When we evaluate our model on three datasets, we find that TGAN outperforms conventional statistical generative models in both capturing the correlation between columns and scaling up for large datasets.},
archivePrefix = {arXiv},
arxivId = {1811.11264},
author = {Xu, Lei and Veeramachaneni, Kalyan},
eprint = {1811.11264},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu, Veeramachaneni - 2018 - Synthesizing Tabular Data using Generative Adversarial Networks.pdf:pdf},
keywords = {gan,tabular data},
mendeley-tags = {gan,tabular data},
month = {nov},
title = {{Synthesizing Tabular Data using Generative Adversarial Networks}},
url = {http://arxiv.org/abs/1811.11264 https://github.com/sdv-dev/TGAN},
year = {2018}
}
@article{5288526,
abstract = {To facilitate learning in a target domain, transfer learning borrows knowledge from a source domain. What and how to transfer are two main issues that need to be addressed in transferring learning. Different transfer learning algorithms result in different knowledge transferred between them for a couple of domains. To find the optimal transfer learning algorithm that maximizes learning efficiency in the target domain, scientists need to investigate all current computationally intractable transfer learning algorithms exhaustively. A sub-optimal algorithm is selected as a trade-off, which in an ad hoc way requires considerable expertise. In instructional psychology, meanwhile, it is commonly recognized that people enhance the transfer of teaching abilities to decide what to transfer. This paper discusses what is transfer learning, the different transfer learning techniques, future scope, and applications of it.},
author = {Pan, Sinno Jialin and Yang, Qiang},
doi = {10.1109/TKDE.2009.191},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pan, Yang - 2010 - A Survey on Transfer Learning.pdf:pdf},
isbn = {9789811559709},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Computer vision,Deep learning,Domain adaptation,Machine learning,Transfer learning,review,survey,transfer learning},
mendeley-tags = {review,survey,transfer learning},
month = {oct},
number = {10},
pages = {1345--1359},
title = {{A Survey on Transfer Learning}},
url = {http://ieeexplore.ieee.org/document/5288526/},
volume = {22},
year = {2010}
}
@article{Zagoruyko2019,
abstract = {Attention plays a critical role in human visual experience. Furthermore, it has recently been demonstrated that attention can also play an important role in the context of applying artificial neural networks to a variety of tasks from fields such as computer vision and NLP. In this work we show that, by properly defining attention for convolutional neural networks, we can actually use this type of information in order to significantly improve the performance of a student CNN network by forcing it to mimic the attention maps of a powerful teacher network. To that end, we propose several novel methods of transferring attention, showing consistent improvement across a variety of datasets and convolutional neural network architectures. Code and models for our experiments are available at https://github.com/szagoruyko/attention-transfer.},
archivePrefix = {arXiv},
arxivId = {1612.03928},
author = {Zagoruyko, Sergey and Komodakis, Nikos},
eprint = {1612.03928},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zagoruyko, Komodakis - 2019 - Paying more attention to attention Improving the performance of convolutional neural networks via attentio.pdf:pdf},
journal = {5th International Conference on Learning Representations, ICLR 2017 - Conference Track Proceedings},
pages = {1--13},
title = {{Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer}},
year = {2019}
}
@book{Uchino2017a,
author = {Uchino, K.},
booktitle = {Advanced Piezoelectric Materials},
doi = {10.1016/B978-0-08-102135-4.00010-2},
edition = {2},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Uchino - 2017 - Manufacturing Methods for Piezoelectric Ceramic Materials.pdf:pdf},
isbn = {9780081021354},
keywords = {1,1 composition selection,1 material designing,10,Bimorph,Calcination,Composite,Dopant,Multilayer,Particle size.,Sintering,Solid solution,bimorph,calcination,composite,dopant,multilayer,particle size,sintering,solid solution},
number = {1},
pages = {385--421},
publisher = {Elsevier Ltd.},
title = {{Manufacturing Methods for Piezoelectric Ceramic Materials}},
url = {http://linkinghub.elsevier.com/retrieve/pii/B9780081021354000102},
year = {2017}
}
@inproceedings{Ramakrishnan2020,
abstract = {Standard deep learning based object detectors suffer from catastrophic forgetting, which results in performance degradation on old classes as new classes are incrementally added. There has been a few recent methods that attempt to address this problem by minimizing the discrepancy between individual object proposal responses for old classes from the original and the updated networks. Different from these methods, we introduce a novel approach that not only focuses on what knowledge to transfer but also how to effectively transfer for minimizing the effect of catastrophic forgetting in incremental learning of object detectors. Towards this, we first propose a proposal selection mechanism using ground truth objects from the new classes and then a relation guided transfer loss function that aims to preserve the relations of selected proposals between the base network and the new network trained on additional classes. Experiments on three standard datasets demonstrate the efficacy of our proposed approach over state-of-the-art methods.},
author = {Ramakrishnan, Kandan and Panda, Rameswar and Fan, Quanfu and Henning, John and Oliva, Aude and Feris, Rogerio},
booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
doi = {10.1109/CVPRW50498.2020.00133},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramakrishnan et al. - 2020 - Relationship Matters Relation Guided Knowledge Transfer for Incremental Learning of Object Detectors.pdf:pdf},
isbn = {978-1-7281-9360-1},
issn = {21607516},
keywords = {continual learning,incremental learning,object detection},
mendeley-tags = {continual learning,incremental learning,object detection},
month = {jun},
pages = {1009--1018},
publisher = {IEEE},
title = {{Relationship Matters: Relation Guided Knowledge Transfer for Incremental Learning of Object Detectors}},
url = {https://ieeexplore.ieee.org/document/9150833/},
volume = {2020-June},
year = {2020}
}
@book{Sundareswaran2014,
abstract = {This paper proposes an evolutionary process for the output voltage regulation of dual input buck type dc-dc converter. The output voltage regulation against a step change in reference signal is formulated as an optimization model and the optimum controller structure is identified using Genetic Algorithm (GA). The extensive simulation results obtained on a prototype dc-converter together with a few measured results demonstrate the validity of the new method. {\textcopyright} 2014 IFAC.},
author = {Sundareswaran, K. and Kuruvinashetti, Kiran and Hariprasad, B. and Sankar, P. and Nayak, P. S. and Vigneshkumar, V.},
booktitle = {IFAC Proceedings Volumes (IFAC-PapersOnline)},
doi = {10.3182/20140313-3-IN-3024.00012},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sundareswaran et al. - 2014 - Optimization of dual input buck converter control through genetic algorithm.pdf:pdf},
isbn = {9783902823601},
issn = {14746670},
number = {PART 1},
pages = {142--146},
publisher = {IFAC},
title = {{Optimization of dual input buck converter control through genetic algorithm}},
url = {http://dx.doi.org/10.3182/20140313-3-IN-3024.00012},
volume = {3},
year = {2014}
}
@article{Scholkopf2021,
abstract = {The two fields of machine learning and graphical causality arose and developed separately. However, there is now cross-pollination and increasing interest in both fields to benefit from the advances of the other. In the present paper, we review fundamental concepts of causal inference and relate them to crucial open problems of machine learning, including transfer and generalization, thereby assaying how causality can contribute to modern machine learning research. This also applies in the opposite direction: we note that most work in causality starts from the premise that the causal variables are given. A central problem for AI and causality is, thus, causal representation learning, the discovery of high-level causal variables from low-level observations. Finally, we delineate some implications of causality for machine learning and propose key research areas at the intersection of both communities.},
archivePrefix = {arXiv},
arxivId = {2102.11107},
author = {Sch{\"{o}}lkopf, Bernhard and Locatello, Francesco and Bauer, Stefan and Ke, Nan Rosemary and Kalchbrenner, Nal and Goyal, Anirudh and Bengio, Yoshua},
eprint = {2102.11107},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sch{\"{o}}lkopf et al. - 2021 - Towards Causal Representation Learning.pdf:pdf},
keywords = {causal learning,representation learning},
mendeley-tags = {causal learning,representation learning},
pages = {1--24},
title = {{Towards Causal Representation Learning}},
url = {http://arxiv.org/abs/2102.11107},
year = {2021}
}
@article{Khosravi2018,
abstract = {In this study, three models of machine learning algorithms are implemented to predict wind speed, wind direction and output power of a wind turbine. The first model is multilayer feed-forward neural network (MLFFNN) that is trained with different data training algorithms. The second model is support vector regression with a radial basis function (SVR-RBF). The third model is adaptive neuro-fuzzy inference system (ANFIS) that is optimized with a partial swarm optimization algorithm (ANFIS-PSO). Temperature, pressure, relative humidity and local time are considered as input variables of the models. A large set of wind speed and wind direction data measured at 5-min, 10-min, 30-min and 1-h intervals are utilized to accurately predict wind speed and its direction for Bushehr. Energy and exergy analysis of wind energy for a wind turbine (E-44, 900 kW) is done. Also, the developed models are used to predict the output power of the wind turbine. Comparison of the statistical indices for the predicted and actual data indicate that the SVR-RBF model outperforms the MLFFNN and ANFIS-PSO models. Also, the current energy and exergy analysis presents an average of 32% energy efficiency and approximately 25% exergy efficiency of the wind turbine in the study region.},
author = {Khosravi, A. and Koury, R. N.N. and Machado, L. and Pabon, J. J.G.},
doi = {10.1016/j.seta.2018.01.001},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khosravi et al. - 2018 - Prediction of wind speed and wind direction using artificial neural network, support vector regression and adap.pdf:pdf},
issn = {22131388},
journal = {Sustainable Energy Technologies and Assessments},
keywords = {ANFIS,Partial swarm optimization,Support vector regression,Wind direction,Wind energy},
number = {December 2017},
pages = {146--160},
publisher = {Elsevier},
title = {{Prediction of wind speed and wind direction using artificial neural network, support vector regression and adaptive neuro-fuzzy inference system}},
url = {https://doi.org/10.1016/j.seta.2018.01.001},
volume = {25},
year = {2018}
}
@article{Lirgg1992,
author = {Lirgg, Cathy D},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lirgg - 1992 - Girls and Women , Sport , and.pdf:pdf},
pages = {158--178},
title = {{Girls and Women , Sport , and}},
year = {1992}
}
@article{Piersanti2018,
abstract = {One of the state-of-the-art optimization strategies is the introduction of an artificial neural network in place of a more time-consuming numerical tool to compute the cost function. This work describes the development of a genetic algorithm optimization strategy for a meandered microstrip line by using an artificial neural network whose training set has been designed by a uniform sampling of the global design space. The results in terms of the total radiated electromagnetic power are discussed and compared with those obtained by the initial and not optimized configuration. {\textcopyright} 2017 IEEE.},
author = {Piersanti, S and Orlandi, A},
doi = {10.1109/TEMC.2017.2764623},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Piersanti, Orlandi - 2018 - Genetic Algorithm Optimization for the Total Radiated Power of a Meandered Line by Using an Artificial Neura.pdf:pdf},
issn = {00189375 (ISSN)},
journal = {IEEE Transactions on Electromagnetic Compatibility},
keywords = {Artificial neural network (ANN),Bioinformatics,Biological cells,Cost functions,Genetic algorithm (GAs),Genetic algorithms,Learning systems,Microstripes,Nature inspired algorithms,Neural networks,Optimization,Personnel training,Scattering parameters,Signal Integrity,Total radiated power,electromagnetic (EM) radiation,genetic algorithms (GAs),machine learning,meandered line,nature-inspired algorithms,signal integrity,total radiated power (TRP)},
number = {4},
pages = {1014--1017},
title = {{Genetic Algorithm Optimization for the Total Radiated Power of a Meandered Line by Using an Artificial Neural Network}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032733823&doi=10.1109%2FTEMC.2017.2764623&partnerID=40&md5=20e75a64ba7819212a8a610788def21d},
volume = {60},
year = {2018}
}
@article{Jaffres2018,
abstract = {The quality and quantity of observed and reanalysed data influence the direction and accuracy of scientific research. This paper reviews the data available for the study of climate and weather patterns in Australia. A list of global reanalysis and satellite data is provided, along with a more detailed review of available in situ (weather station) data in Australia. Regularly updated climate indices are identified that have previously been linked to Australian climate and weather events. Observation of Australian weather is severely hampered by the continents' vastness and remoteness, as evidenced by heavy bias of in situ measurements that are generally clustered in the coastal high-population centres (mainly southeast of Australia), with central and northern regions often having to rely on remote sensing and reanalysis data. Data sparsity can introduce significant uncertainty in terms of extreme weather and climate change management, as variables such as rainfall exhibit high spatial and temporal variability. Several areas for future research are identified, including investigation into the impact of Australian aerosol levels, the connection between soil moisture and flooding potential, and teleconnection between Atlantic sea surface temperature and Australian climate. While this study focusses on data availability to investigate Australian climate patterns, findings are applicable at a global scale.},
author = {Jaffr{\'{e}}s, Jasmine B.D. and Cuff, Chris and Rasmussen, Cecily and Hesson, Aimee S.},
doi = {10.1016/j.earscirev.2017.08.010},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jaffr{\'{e}}s et al. - 2018 - Teleconnection of atmospheric and oceanic climate anomalies with Australian weather patterns a review of data a.pdf:pdf},
isbn = {0012-8252},
issn = {00128252},
journal = {Earth-Science Reviews},
keywords = {Australia,Climate indices,Data availability,Extreme weather events,Reanalysis,Satellites,Weather stations},
pages = {117--146},
publisher = {Elsevier B.V},
title = {{Teleconnection of atmospheric and oceanic climate anomalies with Australian weather patterns: a review of data availability}},
url = {http://dx.doi.org/10.1016/j.earscirev.2017.08.010},
volume = {176},
year = {2018}
}
@inproceedings{Chaudhry2021,
abstract = {In continual learning, the learner faces a stream of data whose distribution changes over time. Modern neural networks are known to suffer under this setting, as they quickly forget previously acquired knowledge. To address such catastrophic forgetting, many continual learning methods implement different types of experience replay, re-learning on past data stored in a small buffer known as episodic memory. In this work, we complement experience replay with a new objective that we call “anchoring”, where the learner uses bilevel optimization to update its knowledge on the current task, while keeping intact the predictions on some anchor points of past tasks. These anchor points are learned using gradient-based optimization to maximize forgetting, which is approximated by fine-tuning the currently trained model on the episodic memory of past tasks. Experiments on several supervised learning benchmarks for continual learning demonstrate that our approach improves the standard experience replay in terms of both accuracy and forgetting metrics and for various sizes of episodic memories.},
archivePrefix = {arXiv},
arxivId = {2002.08165},
author = {Chaudhry, Arslan and Gordo, Albert and Dokania, Puneet K. and Torr, Philip and Lopez-Paz, David},
booktitle = {35th AAAI Conference on Artificial Intelligence, AAAI 2021},
eprint = {2002.08165},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chaudhry et al. - 2021 - Using hindsight to anchor past knowledge in continual learning.pdf:pdf},
issn = {23318422},
keywords = {continual learning,rehearsal,replay},
mendeley-tags = {continual learning,rehearsal,replay},
title = {{Using hindsight to anchor past knowledge in continual learning}},
year = {2021}
}
@article{Bui2021,
abstract = {Contrastive learning (CL) has recently emerged as an effective approach to learning representation in a range of downstream tasks. Central to this approach is the selection of positive (similar) and negative (dissimilar) sets to provide the model the opportunity to `contrast' between data and class representation in the latent space. In this paper, we investigate CL for improving model robustness using adversarial samples. We first designed and performed a comprehensive study to understand how adversarial vulnerability behaves in the latent space. Based on these empirical evidences, we propose an effective and efficient supervised contrastive learning to achieve model robustness against adversarial attacks. Moreover, we propose a new sample selection strategy that optimizes the positive/negative sets by removing redundancy and improving correlation with the anchor. Experiments conducted on benchmark datasets show that our Adversarial Supervised Contrastive Learning (ASCL) approach outperforms the state-of-the-art defenses by $2.6\%$ in terms of the robust accuracy, whilst our ASCL with the proposed selection strategy can further gain $1.4\%$ improvement with only $42.8\%$ positives and $6.3\%$ negatives compared with ASCL without a selection strategy.},
archivePrefix = {arXiv},
arxivId = {2101.10027},
author = {Bui, Anh and Le, Trung and Zhao, He and Montague, Paul and Camtepe, Seyit and Phung, Dinh},
eprint = {2101.10027},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bui et al. - 2021 - Understanding and Achieving Efficient Robustness with Adversarial Contrastive Learning.pdf:pdf},
keywords = {adversarial learning,contrastive learning,robustness,self-supervised learning},
mendeley-tags = {adversarial learning,contrastive learning,robustness,self-supervised learning},
title = {{Understanding and Achieving Efficient Robustness with Adversarial Contrastive Learning}},
url = {http://arxiv.org/abs/2101.10027},
year = {2021}
}
@article{Huynh2020,
abstract = {We address the problem of efficient end-to-end learning a multi-label Convolutional Neural Network (CNN) on training images with partial labels. Training a CNN with partial labels, hence a small number of images for every label, using the standard cross-entropy loss is prone to overfitting and performance drop. We introduce a new loss function that regularizes the cross-entropy loss with a cost function that measures the smoothness of labels and features of images on the data manifold. Given that optimizing the new loss function over the CNN parameters requires learning similarities among labels and images, which itself depends on knowing the parameters of the CNN, we develop an efficient interactive learning framework in which the two steps of similarity learning and CNN training interact and improve the performance of each another. Our method learns the CNN parameters without requiring keeping all training data in the memory, allows to learn few informative similarities only for images in each mini-batch and handles changing feature representations. By extensive experiments on Open Images, CUB and MS-COCO datasets, we demonstrate the effectiveness of our method. In particular, on the large-scale Open Images dataset, we improve the state of the art by 1.02% in mAP score over 5,000 classes.},
author = {Huynh, Dat and Elhamifar, Ehsan},
doi = {10.1109/CVPR42600.2020.00944},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huynh, Elhamifar - 2020 - Interactive multi-label CNN learning with partial labels.pdf:pdf},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {9420--9429},
title = {{Interactive multi-label CNN learning with partial labels}},
year = {2020}
}
@article{Ceramics2003,
author = {Ceramics, Piezoelectric},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ceramics - 2003 - 4.1 Piezoelectric Ceramics.pdf:pdf},
number = {1},
title = {{4.1 Piezoelectric Ceramics}},
year = {2003}
}
@article{Lerner2020,
abstract = {Recently, Semi-Supervised Learning (SSL) has shown much promise in leveraging unlabeled data while being provided with very few labels. In this paper, we show that ignoring the labels altogether for whole epochs intermittently during training can significantly improve performance in the small sample regime. More specifically, we propose to train a network on two tasks jointly. The primary classification task is exposed to both the unlabeled and the scarcely annotated data, whereas the secondary task seeks to cluster the data without any labels. As opposed to hand-crafted pretext tasks frequently used in self-supervision, our clustering phase utilizes the same classification network and head in an attempt to relax the primary task and propagate the information from the labels without overfitting them. On top of that, the self-supervised technique of classifying image rotations is incorporated during the unsupervised learning phase to stabilize training. We demonstrate our method's efficacy in boosting several state-of-the-art SSL algorithms, significantly improving their results and reducing running time in various standard semi-supervised benchmarks, including 92.6% accuracy on CIFAR-10 and 96.9% on SVHN, using only 4 labels per class in each task. We also notably improve the results in the extreme cases of 1,2 and 3 labels per class, and show that features learned by our model are more meaningful for separating the data.},
archivePrefix = {arXiv},
arxivId = {2012.00504},
author = {Lerner, Boaz and Shiran, Guy and Weinshall, Daphna},
eprint = {2012.00504},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lerner, Shiran, Weinshall - 2020 - Boosting the Performance of Semi-Supervised Learning with Unsupervised Clustering.pdf:pdf},
keywords = {semi-supervised learning,unsupervised clustering},
mendeley-tags = {semi-supervised learning,unsupervised clustering},
title = {{Boosting the Performance of Semi-Supervised Learning with Unsupervised Clustering}},
url = {http://arxiv.org/abs/2012.00504},
year = {2020}
}
@article{Chen2016a,
abstract = {The emerging of intelligent sensors results in the emergence and development of intelligent parking. Parking survey is one of the most important things for the parking managers and corresponding planners or researchers. We discuss the problem of making parking survey in intelligent parking systems where parking spaces, entrance and exit are detected to acquire the occupation of the parking. We present three possible sensor layouts and corresponding algorithms to obtain the characteristic index needed in parking survey. In intelligent parking systems, we can also do parking survey in different time and areas with the same detection data. Parking survey can focuses on parking section or a single parking space.},
author = {Chen, Na and Wang, Lu and Jia, Limin and Dong, Honghui and Li, Haijian},
doi = {10.1016/j.proeng.2016.01.284},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2016 - Parking Survey Made Efficient in Intelligent Parking Systems.pdf:pdf},
issn = {18777058},
journal = {Procedia Engineering},
keywords = {characteristic index,intelligent parking,parking survey,sensor,sensor layout},
pages = {487--495},
publisher = {Elsevier B.V.},
title = {{Parking Survey Made Efficient in Intelligent Parking Systems}},
volume = {137},
year = {2016}
}
@article{NASA,
author = {(NASA)},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/(NASA) - Unknown - How to Train Shape Memory Alloys.pdf:pdf},
title = {{How to Train Shape Memory Alloys}}
}
@article{Leskens2002,
abstract = {In this paper, the application of a specific system identification procedure to a municipal solid waste (MSW) incinerator is discussed. This procedure is a combination of, on the one hand, a particular closed-loop identification method called the two-stage method and, on the other hand, the approach of high-order multiple input multiple output (MIMO) ARX model estimation followed by model reduction. MIMO ARX model estimation is performed by means of a, so-called, multiple data set identification method, i.e. a method by means of which it is possible to estimate a model on the basis of several data sets instead of just one data set. Model reduction is applied to each transfer function of the resulting MIMO ARX model separately. It is shown that with the proposed identification procedure a model of the MSW incinerator is obtained which, according to system identification validation measures, is good. Using the estimated model, the influence of the disturbances on the identification and control of an MSW incinerator is discussed. Furthermore, the validation of a first-principles model of the MSW incineration process by means of the resulting low-order SISO models is discussed. The results show that the proposed way of validating a first-principles model is a powerful tool for determining its quality. {\textcopyright} 2002 Elsevier Science Ltd. All rights reserved.},
author = {Leskens, M. and {Van Kessel}, L. B M and {Van den Hof}, P. M J},
doi = {10.1016/S0967-0661(01)00139-3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leskens, Van Kessel, Van den Hof - 2002 - MIMO closed-loop identification of an MSW incinerator.pdf:pdf},
issn = {09670661},
journal = {Control Engineering Practice},
keywords = {Closed-loop identification,MIMO ARX model estimation,Model validation,Multiple data set identification,Municipal solid waste incineration,Two-stage method},
number = {3},
pages = {315--326},
title = {{MIMO closed-loop identification of an MSW incinerator}},
volume = {10},
year = {2002}
}
@article{Sapna2012,
abstract = {Data Mining aims at discovering knowledge out of data and presenting it in a form that is easily compressible to humans. Data Mining represents a process developed to examine large amounts of data routinely collected. The term also refers to a collection of tools used to perform the process. One of the useful applications in the field of medicine is the incurable chronic disease diabetes. Data Mining algorithm is used for testing the accuracy in predicting diabetic status. Fuzzy Systems are been used for solving a wide range of problems in different application domain and Genetic Algorithm for designing. Fuzzy systems allows in introducing the learning and adaptation capabilities. Neural Networks are efficiently used for learning membership functions. Diabetes occurs throughout the world, but Type 2 is more common in the most developed countries. The greater increase in prevalence is however expected in Asia and Africa where most patients will likely be found by 2030. This paper is proposed on the Levenberg – Marquardt algorithm which is specifically designed to minimize sum-of-square error functions. Levernberg-Marquardt algorithm gives the best performance in the prediction of diabetes compared to any other backpropogation algorithm.},
author = {Sapna, S},
doi = {10.5121/csit.2012.2438},
isbn = {9781921987052},
journal = {Computer Science & Information Technology ( CS & IT )},
pages = {393--398},
title = {{Backpropagation Learning Algorithm Based on Levenberg Marquardt Algorithm}},
url = {http://www.airccj.org/CSCP/vol2/csit2438.pdf},
year = {2012}
}
@book{Paulescu2013,
address = {New York},
author = {Paulescu, Marius and Paulescu, Eugenia and Gravila, Paul and Badescu, Viorel},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paulescu et al. - 2013 - Weather Modeling and Forecasting of PV Systems Operation.pdf:pdf},
isbn = {9781447146483},
publisher = {Springer London Heidelberg New York Dordrecht},
title = {{Weather Modeling and Forecasting of PV Systems Operation}},
year = {2013}
}
@article{Allen-Zhu2020a,
abstract = {How does a 110-layer ResNet learn a high-complexity classifier using relatively few training examples and short training time? We present a theory towards explaining this in terms of hierarchical learning. We refer hierarchical learning as the learner learns to represent a compli- cated target function by decomposing it into a sequence of simpler functions to reduce sample and time complexity. This paper formally analyzes how multi-layer neural networks can perform such hierarchical learning efficiently and automatically simply by applying stochastic gradient descent (SGD) to the training objective. On the conceptual side, we present, to the best of our knowledge, the first theory result indicating how very deep neural networks can still be sample and time efficient on certain hi- erarchical learning tasks, when no known non-hierarchical algorithms (such as kernel method, linear regression over feature mappings, tensor decomposition, sparse coding, and their simple combinations) are efficient. We establish a new principle called "backward feature correction", which we believe is the key to understand the hierarchical learning in multi-layer neural networks. On the technical side, we show for regression and even for binary classification, for every input dimension d > 0, there is a concept class consisting of degree $\omega$(1) multi-variate polyno- mials so that, using $\omega$(1)-layer neural networks as learners, SGD can learn any target function from this class in poly(d) time using poly(d) samples to any 1/poly(d) regression or classification error, through learning to represent it as a composition of $\omega$(1) layers of quadratic functions. In contrast, we present lower bounds stating that several non-hierarchical learners, including any kernel methods, neural tangent kernels, must suffer from super-polynomial d$\omega$(1)sample or time complexity to learn functions in this concept class even to any d-0.01error.},
archivePrefix = {arXiv},
arxivId = {2001.04413},
author = {Allen-Zhu, Zeyuan and Li, Yuanzhi},
eprint = {2001.04413},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Allen-Zhu, Li - 2020 - Backward feature correction How deep learning performs deep learning.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {deep learning,empirical study,theory},
mendeley-tags = {deep learning,empirical study,theory},
title = {{Backward feature correction: How deep learning performs deep learning}},
year = {2020}
}
@article{VanBavel2018,
abstract = {Democracies assume accurate knowledge by the populace, but the human attraction to fake and untrustworthy news poses a serious problem for healthy democratic functioning. We articulate why and how identification with political parties – known as partisanship – can bias information processing in the human brain. There is extensive evidence that people engage in motivated political reasoning, but recent research suggests that partisanship can alter memory, implicit evaluation, and even perceptual judgments. We propose an identity-based model of belief for understanding the influence of partisanship on these cognitive processes. This framework helps to explain why people place party loyalty over policy, and even over truth. Finally, we discuss strategies for de-biasing information processing to help to create a shared reality across partisan divides.},
author = {{Van Bavel}, Jay J and Pereira, Andrea},
doi = {10.1016/j.tics.2018.01.004},
issn = {1364-6613},
journal = {Trends in Cognitive Sciences},
keywords = {attention,group identity,memory,partisanship,perception,reasoning},
pages = {1--12},
pmid = {29475636},
publisher = {Elsevier Ltd},
title = {{The Partisan Brain: An Identity-Based Model of Political Belief The Role of Identity in Political Belief}},
url = {http://www.cell.com/trends/cognitive-sciences/pdf/S1364-6613(18)30017-2.pdf},
volume = {xx},
year = {2018}
}
@article{Jimoh2013a,
author = {Jimoh, R. G. and Olagunju, M. and Folorunso, I.O. and Asiribo, M.A.},
journal = {International Journal of Innovative Research in Computer and Communication Engineering},
keywords = {2005,background to the study,continue to be processes,despite the fact that,forecast,fuzzy logic,i,improve,jim,meteorological processes continue to,physical processes not yet,planning,rainfall,rigorous numerical modeling of,solutions,that elude explicit analytical,there will likely,understood or},
number = {4},
pages = {929--936},
title = {{Modeling Rainfall Prediction using Fuzzy Logic}},
volume = {1},
year = {2013}
}
@article{Reinhard2016,
abstract = {PwC's 2016 Global Industry 4.0 Survey is the biggest worldwide survey of its kind, with over 2,000 participants from nine major industrial sectors and 26 countries. The study explores the benefits of digitising your company's horizontal and vertical value chains, as well as building your digital product & service portfolio. Based on the findings and our experience working with first movers, we've also crafted a blueprint for success to help you secure your company's position as a leading digital enterprise in tomorrow's complex industrial ecosystems.},
author = {Reinhard, Griessbauer and Jesper, Vedso and Stefan, Schrauf},
doi = {10.1080/01969722.2015.1007734},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Reinhard, Jesper, Stefan - 2016 - Industry 4.0 Building the digital enterprise.pdf:pdf},
isbn = {9781467382465},
issn = {0196-9722},
journal = {2016 Global Industry 4.0 Survey},
keywords = {analytics,cap,data,digitalisation,digitization},
pages = {1--39},
title = {{Industry 4.0: Building the digital enterprise}},
url = {www.pwc.com/industry40},
year = {2016}
}
@article{Steyerberg2011,
abstract = {Prediction models are becoming more and more important in medicine and cardiology. Nowadays, specific interest focuses on ways in which models can be improved using new prognostic markers. We aim to describe the similarities and differences between performance measures for prediction models. We analyzed data from 3264 subjects to predict 10-year risk of coronary heart disease according to age, systolic blood pressure, diabetes, and smoking. We specifically study the incremental value of adding high-density lipoprotein cholesterol to this model. We emphasize that we need to separate the evaluation of predictions, where traditional performance measures such as the area under the receiver operating characteristic curve and calibration are useful, from the evaluation of classifications, where various other statistics are now available, including the net reclassification index and net benefit.},
author = {Steyerberg, Ewout W. and Calster, Ben Van and Pencina, Michael J.},
doi = {10.1016/j.rec.2011.05.004},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Steyerberg, Calster, Pencina - 2011 - Performance Measures for Prediction Models and Markers Evaluation of Predictions and Classificatio.pdf:pdf},
isbn = {1579-2242; 0300-8932},
issn = {18855857},
journal = {Revista Espa{\~{n}}ola de Cardiolog{\'{i}}a (English Edition)},
number = {9},
pages = {788--794},
pmid = {24775954},
title = {{Performance Measures for Prediction Models and Markers: Evaluation of Predictions and Classifications}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1885585711003604},
volume = {64},
year = {2011}
}
@article{Putri2015,
author = {Putri, Hana S},
title = {{Perancangan Prediktor Cuaca Mtaritim Berbasis Fuzzy Sebagai Decision Support Untuk Keselamatan Nelayan}},
year = {2015}
}
@article{Kertechian2016,
author = {Kertechian, Sevag},
doi = {10.5171/2016.598520},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kertechian - 2016 - The Impact of Beauty during Job Applications.pdf:pdf},
issn = {21660018},
journal = {Journal of Human Resources Management Research},
keywords = {attractiveness,cosmetics,job applications,makeup},
pages = {1--7},
title = {{The Impact of Beauty during Job Applications}},
url = {http://ibimapublishing.com/articles/JHRMR/2016/598520/},
volume = {2016},
year = {2016}
}
@article{Okamoto2016,
abstract = {In recent years, due to a rise in healthy thinking on eating, many people take care of their eating habits, and some people record daily diet regularly. To assist them, many mobile applications for recording everyday meals have been released so far. Some of them employ food image recognition which can estimate not only food names but also food calorie. However, most of such applications have some problems especially on their usability. Then, in this paper, we propose a novel single-image-based food calorie estimation system which runs on a smartphone as a standalone application without external recognition servers. The proposed system carries out food region segmentation, food region categorization, and calorie estimation automatically. By the experiments and the user study on the proposed system, the effectiveness of the proposed system was confirmed.},
author = {Okamoto, Koichi and Yanai, Keiji},
doi = {10.1145/2986035.2986040},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Okamoto, Yanai - 2016 - An automatic calorie estimation system of food images on a smartphone.pdf:pdf},
isbn = {9781450345200},
journal = {MADiMa 2016 - Proceedings of the 2nd International Workshop on Multimedia Assisted Dietary Management, co-located with ACM Multimedia 2016},
keywords = {Convolutional neural network,Food calorie estimation,Food image recognition},
pages = {63--70},
title = {{An automatic calorie estimation system of food images on a smartphone}},
year = {2016}
}
@article{Chang2020,
abstract = {Generative adversarial networks (GANs) suffer from catastrophic forgetting when learning multiple consecutive tasks. Parameter regularization methods that constrain the parameters of the new model in order to be close to the previous model through parameter importance are effective in overcoming forgetting. Many parameter regularization methods have been tried, but each of them is only suitable for limited types of neural networks. Aimed at GANs, this paper proposes a unified framework called Memory Protection GAN (MPGAN), in which many parametrization methods can be used to overcome forgetting. The proposed framework includes two modules: Protecting Weights in Generator and Controller. In order to incorporate parameter regularization methods into MPGAN, the Protecting Weights in Generator module encapsulates different parameter regularization methods into a 'container', and consolidates the most important parameters in the generator through a parameter regularization method selected from the container. In order to differentiate tasks, the Controller module creates unique tags for the tasks. Another problem with existing parameter regularization methods is their low accuracy in measuring parameter importance. These methods always rely on the first derivative of the output function, and ignore the second derivative. To assess parameter importance more accurately, a new parameter regularization method called Second Derivative Preserver (SDP), which takes advantage of the second derivative of the output function, is designed into MPGAN. Experiments demonstrate that MPGAN is applicable to multiple parameter regularization methods and that SDP achieves high accuracy in parameter importance.},
author = {Chang, Yifan and Li, Wenbo and Peng, Jian and Li, Haifeng and Kang, Yu and Huang, Yingliang},
doi = {10.1109/ACCESS.2020.3028067},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chang et al. - 2020 - Memory Protection Generative Adversarial Network (MPGAN) A Framework to Overcome the Forgetting of GANs Using Para.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Catastrophic forgetting,continual learning,gan,generative adversarial network,generative model,image generation,incremental learning,parameter regularization methods},
mendeley-tags = {continual learning,gan,generative model,image generation,incremental learning},
pages = {179942--179954},
title = {{Memory Protection Generative Adversarial Network (MPGAN): A Framework to Overcome the Forgetting of GANs Using Parameter Regularization Methods}},
volume = {8},
year = {2020}
}
@article{Makandar2015,
abstract = {Image restoration is to enhance the image quality which is blurred and noised from various defects which damage the quality of an image. The most degradation is done in motion blur and noise defects as shown in the results. This introduces and implements the computing methods used in the image processing world to restore images as well as improve the quality by threshold. In order to know the detailed information carried in the digital image for better visualization. The aim is to provide information of image degradation and restoration process by various filters such as wiener filter, blind convolution and wavelet techniques are used in experiments in this paper will be presented as followed by MATLAB simulation results. Weiner filter gives maximum PSNR value and minimum MSE value in dB comparable to other techniques for image restoration.},
author = {Makandar, Aziz and Patrot, Anita},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Makandar, Patrot - 2015 - Computation Pre-Processing Techniques for Image Restoration.pdf:pdf},
journal = {International Journal of Computer Applications},
keywords = {Blind Convolution,General Terms Image Processing,MSE,Noise,PSNR,Pre-processing Keywords Blurring,RMSE,Restoration,Wavelet,Weiner},
number = {4},
pages = {975--8887},
title = {{Computation Pre-Processing Techniques for Image Restoration}},
url = {https://pdfs.semanticscholar.org/df43/ab5675cdf418e1b41b044547f69da32312f1.pdf},
volume = {113},
year = {2015}
}
@article{Liu2021,
abstract = {In this paper, we introduce a new perspective on training deep neural networks capable of state-of-the-art performance without the need for the expensive over-parameterization by proposing the concept of In-Time Over-Parameterization (ITOP) in sparse training. By starting from a random sparse network and continuously exploring sparse connectivities during training, we can perform an Over-Parameterization in the space-time manifold, closing the gap in the expressibility between sparse training and dense training. We further use ITOP to understand the underlying mechanism of Dynamic Sparse Training (DST) and indicate that the benefits of DST come from its ability to consider across time all possible parameters when searching for the optimal sparse connectivity. As long as there are sufficient parameters that have been reliably explored during training, DST can outperform the dense neural network by a large margin. We present a series of experiments to support our conjecture and achieve the state-of-the-art sparse training performance with ResNet-50 on ImageNet. More impressively, our method achieves dominant performance over the overparameterization-based sparse methods at extreme sparsity levels. When trained on CIFAR-100, our method can match the performance of the dense model even at an extreme sparsity (98%).},
archivePrefix = {arXiv},
arxivId = {2102.02887},
author = {Liu, Shiwei and Yin, Lu and Mocanu, Decebal Constantin and Pechenizkiy, Mykola},
eprint = {2102.02887},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2021 - Do We Actually Need Dense Over-Parameterization In-Time Over-Parameterization in Sparse Training.pdf:pdf},
keywords = {overparameterized,sparse network,sparsity,theory},
mendeley-tags = {overparameterized,sparse network,sparsity,theory},
title = {{Do We Actually Need Dense Over-Parameterization? In-Time Over-Parameterization in Sparse Training}},
url = {http://arxiv.org/abs/2102.02887},
year = {2021}
}
@article{Hafiyusholeh2017,
author = {Hafiyusholeh, Moh},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hafiyusholeh - 2017 - Forecasts Marine Weather On Java Sea Using Hybrid Methods TS-ANFIS.pdf:pdf},
isbn = {9781538605493},
keywords = {anfis time series,marine weather prediction},
number = {September},
pages = {19--21},
title = {{Forecasts Marine Weather On Java Sea Using Hybrid Methods : TS-ANFIS}},
year = {2017}
}
@article{Khan2014,
author = {Khan, S U and Qureshi, I M and Zaman, F and Shoaib, B and Naveed, A and Basit, A},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khan et al. - 2014 - Correction of Faulty Sensors in Phased Array Radars Using Symmetrical Sensor Failure Technique and Cultural Algorit.pdf:pdf},
title = {{Correction of Faulty Sensors in Phased Array Radars Using Symmetrical Sensor Failure Technique and Cultural Algorithm with Differential Evolution}},
volume = {2014},
year = {2014}
}
@article{Molenaar2016,
abstract = {Professor Klaus Schwab, Founder and Executive Chairman of the World Economic Forum, has been at the center of global affairs for over four decades. He is convinced that the period of change we are living through is more significant, and the ramifications of the latest technological revolution more profound than any prior period of human history. He has dubbed this era the fourth industrial revolution. Crowdsourcing ideas, insights and wisdom from the World Economic Forum's global network of business, government, civil society and youth leaders, this book looks deeply at the future that is unfolding today and how we might take collective responsibility to ensure it is a positive one for all of us. The fourth industrial revolution. Historical context -- Profound and systematic change -- Drivers. Megatrends -- Tipping points -- Impact. Economy -- Business -- National and global -- Society -- The individual -- The way forward -- Appendix: Deep Shift. Implantable technologies -- Our digital presence -- Vision as the new interface -- Wearable Internet -- Ubiquitous computing -- A supercomputer in your pocket -- Storage for all -- The Internet of and for things -- The connected home -- Smart cities -- Big data for decisions -- Driverless cars -- Artificial intelligence and decision-making -- AI and white-collar jobs -- Robotics and services -- Bitcoin and the blockchain -- The sharing economy -- Governments and the blockchain -- 3D Printing and manufacturing -- 3D Printing and human health -- 3D Printing and consumer products -- Designer beings -- Neurotechnologies.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Molenaar, C.},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Molenaar - 2016 - The Fourth Industrial Revolution.pdf:pdf},
isbn = {9781944835002},
issn = {1098-6596},
journal = {World Economic Forum},
pages = {1--5},
pmid = {25246403},
title = {{The Fourth Industrial Revolution}},
url = {http://cormolenaar.nl/wp-content/uploads/2016/04/The-fourth-industrial-revolution.pdf},
year = {2016}
}
@article{Li2020c,
abstract = {Convolutional neural networks often dominate fully-connected counterparts in generalization performance, especially on image classification tasks. This is often explained in terms of 'better inductive bias'. However, this has not been made mathematically rigorous, and the hurdle is that the fully connected net can always simulate the convolutional net (for a fixed task). Thus the training algorithm plays a role. The current work describes a natural task on which a provable sample complexity gap can be shown, for standard training algorithms. We construct a single natural distribution on $\mathbb{R}^d\times\{\pm 1\}$ on which any orthogonal-invariant algorithm (i.e. fully-connected networks trained with most gradient-based methods from gaussian initialization) requires $\Omega(d^2)$ samples to generalize while $O(1)$ samples suffice for convolutional architectures. Furthermore, we demonstrate a single target function, learning which on all possible distributions leads to an $O(1)$ vs $\Omega(d^2/\varepsilon)$ gap. The proof relies on the fact that SGD on fully-connected network is orthogonal equivariant. Similar results are achieved for $\ell_2$ regression and adaptive training algorithms, e.g. Adam and AdaGrad, which are only permutation equivariant.},
archivePrefix = {arXiv},
arxivId = {2010.08515},
author = {Li, Zhiyuan and Zhang, Yi and Arora, Sanjeev},
eprint = {2010.08515},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Zhang, Arora - 2020 - Why Are Convolutional Nets More Sample-Efficient than Fully-Connected Nets.pdf:pdf},
keywords = {convolutional neural networks,neural networks},
mendeley-tags = {convolutional neural networks,neural networks},
pages = {1--24},
title = {{Why Are Convolutional Nets More Sample-Efficient than Fully-Connected Nets?}},
url = {http://arxiv.org/abs/2010.08515},
year = {2020}
}
@article{EngstromLoganandGilmerJustinandGohGabrielandHendrycksDanandIlyasAndrewandMadryAleksanderandNakanoReiichiroandNakkiranPreetumandSanturkarShibaniandTranBrandonandTsiprasDimitrisandWallace2019,
abstract = {Adversarial examples have attracted significant attention in machine learning, but the reasons for their existence and pervasiveness remain unclear. We demonstrate that adversarial examples can be directly attributed to the presence of non-robust features: features (derived from patterns in the data distribution) that are highly predictive, yet brittle and (thus) incomprehensible to humans. After capturing these features within a theoretical framework, we establish their widespread ex- istence in standard datasets. Finally, we present a simple setting where we can rigorously tie the phenomena we observe in practice to a misalignment between the (human-specified) notion of robustness and the inherent geometry of the data.},
author = {{Engstrom, Logan and Gilmer, Justin and Goh, Gabriel and Hendrycks, Dan and Ilyas, Andrew and Madry, Aleksander and Nakano, Reiichiro and Nakkiran, Preetum and Santurkar, Shibani and Tran, Brandon and Tsipras, Dimitris and Wallace}, Eric},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Engstrom, Logan and Gilmer, Justin and Goh, Gabriel and Hendrycks, Dan and Ilyas, Andrew and Madry, Aleksander and Nakano, Reiichiro and.pdf:pdf},
journal = {Distill},
number = {NeurIPS},
title = {{Adversarial Examples Are Not Bugs, They Are Features}},
url = {https://gradientscience.org/adv/},
year = {2019}
}
@article{Girshick2014,
abstract = {Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012 - achieving a mAP of 53.3%. Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. We also present experiments that provide insight into what the network learns, revealing a rich hierarchy of image features. Source code for the complete system is available at http://www.cs.berkeley.edu/$\sim$rbg/rcnn.},
archivePrefix = {arXiv},
arxivId = {1311.2524},
author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
doi = {10.1109/CVPR.2014.81},
eprint = {1311.2524},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Girshick et al. - 2014 - Rich feature hierarchies for accurate object detection and semantic segmentation.pdf:pdf},
isbn = {9781479951178},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {580--587},
title = {{Rich feature hierarchies for accurate object detection and semantic segmentation}},
year = {2014}
}
@article{Farooque2015,
abstract = {Together with 106 farmers who started growing Jatropha (Jatropha curcas\nL.) in 20042006, this research sought to increase the knowledge around\nthe real-life experience of Jatropha farming in the southern India\nstates of Tamil Nadu and Andhra Pradesh. Launched as an alternative for\ndiesel in India, Jatropha has been promoted as a non-edible plant that\ncould grow on poor soils, yield oil-rich seeds for production of\nbio-diesel, and not compete directly with food production. Through\ninterviews with the farmers, information was gathered regarding their\nsocio-economic situation, the implementation and performance of their\nJatropha plantations, and their reasons for continuing or discontinuing\nJatropha cultivation. Results reveal that 82% of the farmers had\nsubstituted former cropland for their Jatropha cultivation. By 2010,\n85% (n = 90) of the farmers who cultivated Jatropha in 2004 had\nstopped. Cultivating the crop did not give the economic returns the\nfarmers anticipated, mainly due to a lack of information about the crop\nand its maintenance during cultivation and due to water scarcity. A\nmajority of the farmers irrigated and applied fertilizer, and even\npesticides. Many problems experienced by the farmers were due to limited\nknowledge about cultivating Jatropha caused by poor planning and\nimplementation of the national Jatropha program. Extension services,\nsubsidies, and other support were not provided as promised. The farmers\nwho continued cultivation had means of income other than Jatropha and\nheld hopes of a future Jatropha market. The lack of market structures,\nsuch as purchase agreements and buyers, as well as a low retail price\nfor the seeds, were frequently stated as barriers to Jatropha\ncultivation. For Jatropha biodiesel to perform well, efforts are needed\nto improve yield levels and stability through genetic improvements and\ndrought tolerance, as well as agriculture extension services to support\nadoption of the crop. Government programs will -probably be more\neffective if implementing biodiesel production is conjoined with\nstimulating the demand for Jatropha biodiesel. To avoid food-biofuel\ncompetition, additional measures may be needed such as land-use\nrestrictions for Jatropha producers and taxes on biofuels or biofuel\nfeedstocks to improve the competitiveness of the food sector compared to\nthe bioenergy sector. (c) 2012 Society of Chemical Industry and John\nWiley & Sons, Ltd},
author = {Farooque, Mohammad and Leo, Anthony and Rauseo, Anthony and Wang, Jin Yun},
doi = {10.1186/s13705-015-0041-0},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Farooque et al. - 2015 - Efficient and ultra-clean use of biogas in the fuel cell - the DFC experience.pdf:pdf},
isbn = {1932-104X},
issn = {21920567},
journal = {Energy, Sustainability and Society},
keywords = {Biogas,Biogas contaminants,Carbonate fuel cell,Combined heat and power,Direct FuelCell{\textregistered},Fuel cell},
number = {1},
pages = {1--9},
publisher = {???},
title = {{Efficient and ultra-clean use of biogas in the fuel cell - the DFC experience}},
url = {???},
volume = {5},
year = {2015}
}
@article{Shanahan2019b,
abstract = {With a view to bridging the gap between deep learning and symbolic AI, we present a novel end-to-end neural network architecture that learns to form propositional representations with an explicitly relational structure from raw pixel data. In order to evaluate and analyse the architecture, we introduce a family of simple visual relational reasoning tasks of varying complexity. We show that the proposed architecture, when pre-trained on a curriculum of such tasks, learns to generate reusable representations that better facilitate subsequent learning on previously unseen tasks when compared to a number of baseline architectures. The workings of a successfully trained model are visualised to shed some light on how the architecture functions.},
archivePrefix = {arXiv},
arxivId = {1905.10307},
author = {Shanahan, Murray and Nikiforou, Kyriacos and Creswell, Antonia and Kaplanis, Christos and Barrett, David and Garnelo, Marta},
eprint = {1905.10307},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shanahan et al. - 2019 - An explicitly relational neural network architecture.pdf:pdf;:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shanahan et al. - 2019 - An explicitly relational neural network architecture(2).pdf:pdf},
journal = {arXiv},
keywords = {reasoning,relational structure},
mendeley-tags = {reasoning,relational structure},
title = {{An explicitly relational neural network architecture}},
year = {2019}
}
@article{Design2006,
author = {Design, Systems},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Design - 2006 - Survey Paper Guideline - Computer Science - Kent State University.pdf:pdf},
title = {{Survey Paper Guideline - Computer Science - Kent State University}},
year = {2006}
}
@article{Yun2021,
abstract = {ImageNet has been arguably the most popular image classification benchmark, but it is also the one with a significant level of label noise. Recent studies have shown that many samples contain multiple classes, despite being assumed to be a single-label benchmark. They have thus proposed to turn ImageNet evaluation into a multi-label task, with exhaustive multi-label annotations per image. However, they have not fixed the training set, presumably because of a formidable annotation cost. We argue that the mismatch between single-label annotations and effectively multi-label images is equally, if not more, problematic in the training setup, where random crops are applied. With the single-label annotations, a random crop of an image may contain an entirely different object from the ground truth, introducing noisy or even incorrect supervision during training. We thus re-label the ImageNet training set with multi-labels. We address the annotation cost barrier by letting a strong image classifier, trained on an extra source of data, generate the multi-labels. We utilize the pixel-wise multi-label predictions before the final pooling layer, in order to exploit the additional location-specific supervision signals. Training on the re-labeled samples results in improved model performances across the board. ResNet-50 attains the top-1 classification accuracy of 78.9% on ImageNet with our localized multi-labels, which can be further boosted to 80.2% with the CutMix regularization. We show that the models trained with localized multi-labels also outperforms the baselines on transfer learning to object detection and instance segmentation tasks, and various robustness benchmarks. The re-labeled ImageNet training set, pre-trained weights, and the source code are available at {https://github.com/naver-ai/relabel_imagenet}.},
archivePrefix = {arXiv},
arxivId = {2101.05022},
author = {Yun, Sangdoo and Oh, Seong Joon and Heo, Byeongho and Han, Dongyoon and Choe, Junsuk and Chun, Sanghyuk},
eprint = {2101.05022},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yun et al. - 2021 - Re-labeling ImageNet from Single to Multi-Labels, from Global to Localized Labels.pdf:pdf},
keywords = {multi-label},
mendeley-tags = {multi-label},
title = {{Re-labeling ImageNet: from Single to Multi-Labels, from Global to Localized Labels}},
url = {http://arxiv.org/abs/2101.05022},
year = {2021}
}
@article{Silver2017,
abstract = {A long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, superhuman proficiency in challenging domains. Recently, AlphaGo became the first program to defeat a world champion in the game of Go. The tree search in AlphaGo evaluated positions and selected moves using deep neural networks. These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play. Here we introduce an algorithm based solely on reinforcement learning, without human data, guidance or domain knowledge beyond game rules. AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo's own move selections and also the winner of AlphaGo's games. This neural network improves the strength of the tree search, resulting in higher quality move selection and stronger self-play in the next iteration. Starting tabula rasa, our new program AlphaGo Zero achieved superhuman performance, winning 100-0 against the previously published, champion-defeating AlphaGo.},
author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and {Van Den Driessche}, George and Graepel, Thore and Hassabis, Demis},
doi = {10.1038/nature24270},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Silver et al. - 2017 - Mastering the game of Go without human knowledge.pdf:pdf},
issn = {14764687},
journal = {Nature},
number = {7676},
pages = {354--359},
pmid = {29052630},
publisher = {Nature Publishing Group},
title = {{Mastering the game of Go without human knowledge}},
url = {http://dx.doi.org/10.1038/nature24270},
volume = {550},
year = {2017}
}
@article{Troisi2016,
abstract = {Accidental spillage of oil in to the sea from shipping transport and drilling rigs results in spills that cause significant unsustainable mortality of wildlife and destroys marine ecosystem services. External oiling of seabirds causes large scale mortality within days following a spill, while survivors suffercauses long term chronic effects from the exposure to toxic polycyclic aromatic hydrocarbons (PAHs) present in ingested oil. Survival rates for rehabilitated oiled birds are very low despite investment of significant resources. PAHs disturb thyroid homeostasis which plays a vital role in the control of energy metabolism. In this study, plasma PAH and thyroid-stimulating hormone (TSH) were quantified as biomarkers of exposure and endocrine disruption in oiled guillemots (Uria aalge). Mean plasma PAH and TSH concentrations, were 98.1 ± 8.3 ng/ml and 0.13 ± 0.02 ng/ml and these parameters were found to be negatively correlated (p < 0.01) indicative of PAH-associated thyroid hormone suppression in more heavily oiled birds. Body condition and weight were also lower in birds that died compared with birds that were released. The data also show the value of measuring plasma TSH and PAH to monitor metabolic status and progress of decontamination of oiled birds in a rehabilitation setting.},
author = {Troisi, G. and Barton, S. and Bexton, S.},
doi = {10.1016/j.ijhydene.2016.04.011},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Troisi, Barton, Bexton - 2016 - Impacts of oil spills on seabirds Unsustainable impacts of non-renewable energy.pdf:pdf},
isbn = {0000000296618},
issn = {03603199},
journal = {International Journal of Hydrogen Energy},
keywords = {Birds,Oil pollution,Polycyclic aromatic hydrocarbons (PAHs),Thyroid-stimulating hormone (TSH),Wildlife},
number = {37},
pages = {16549--16555},
publisher = {Elsevier Ltd},
title = {{Impacts of oil spills on seabirds: Unsustainable impacts of non-renewable energy}},
url = {http://dx.doi.org/10.1016/j.ijhydene.2016.04.011},
volume = {41},
year = {2016}
}
@article{Yin1996,
abstract = {Serious studies of the formation mechanisms of age-related pigments and their possible cellular influence have been hampered for a long time by discrepancies and controversies over the definition, fluorescence emission, origin, and composition of these pigments. This review discusses several critical controversies in this field and lay special emphasis on the cellular and biochemical reactions related to the formation mechanisms of lipofuscin, ceroid, advanced glycation end-products (AGEs), and age pigment-like fluorophores (APFs). Various amino compounds and their reaction with secondary aldehydic products of oxygen free radical-induced oxidation, particularly lipid peroxidation, are important sources of the fluorophores of ceroid/lipofuscin, which progressively accumulate as a result of phagocytosis and autophagocytosis of modified biomaterials within secondary lysosomes of postmitotic and other cells. Lipofuscin is the classical age pigment of postmitotic cells, while ceroid accumulates due to pathologic and experimental processes. There are good reasons to consider both ceroid and lipofuscin as materials of the same principal origin. The age-related intracellular fluorophores of retinal pigment epithelium (RPE) seems to represent a special class of lipofuscin, which partly contains derivatives of retinoids and carotenoids. Saccharide-originated fluorophores, principally AGEs formed during glycation/Maillard reactions, may be mainly responsible for the extracellular fluorescence of long-lived proteins, such as collagen, elastin, and lens crystalline. Although lipofuscin, ceroid, AGEs, and APFs can be produced from different types of biological materials due to different side reactions of essential biology, the crosslinking of carbonyl-amino compounds is recognized as a common process during their formation.},
author = {Yin, Dazhong},
doi = {10.1016/0891-5849(96)00175-X},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yin - 1996 - Biochemical basis of lipofuscin, ceroid, and age pigment-like fluorophores.pdf:pdf},
isbn = {0891-5849 (Print)},
issn = {08915849},
journal = {Free Radical Biology and Medicine},
keywords = {Age pigments,Carbonyls,Ceroid,Fluorophores,Free radicals,Glycation,Lipofuscin},
number = {6},
pages = {871--888},
pmid = {8902532},
title = {{Biochemical basis of lipofuscin, ceroid, and age pigment-like fluorophores}},
volume = {21},
year = {1996}
}
@inproceedings{Abuduweili2021,
abstract = {While recent studies on semi-supervised learning have shown remarkable progress in leveraging both labeled and unlabeled data, most of them presume a basic setting of the model is randomly initialized. In this work, we consider semi-supervised learning and transfer learning jointly, leading to a more practical and competitive paradigm that can utilize both powerful pre-trained models from source domain as well as labeled/unlabeled data in the target domain. To better exploit the value of both pre-trained weights and unlabeled target examples, we introduce adaptive consistency regularization that consists of two complementary components: Adaptive Knowledge Consistency (AKC) on the examples between the source and target model, and Adaptive Representation Consistency (ARC) on the target model between labeled and unlabeled examples. Examples involved in the consistency regularization are adaptively selected according to their potential contributions to the target task. We conduct extensive experiments on several popular benchmarks including CUB-200-2011, MIT Indoor-67, MURA, by fine-tuning the ImageNet pre-trained ResNet-50 model. Results show that our proposed adaptive consistency regularization outperforms state-of-the-art semi-supervised learning techniques such as Pseudo Label, Mean Teacher, and MixMatch. Moreover, our algorithm is orthogonal to existing methods and thus able to gain additional improvements on top of MixMatch and FixMatch. Our code is available at https://github.com/SHI-Labs/Semi-Supervised-Transfer-Learning.},
archivePrefix = {arXiv},
arxivId = {2103.02193},
author = {Abuduweili, Abulikemu and Li, Xingjian and Shi, Humphrey and Xu, Cheng-Zhong and Dou, Dejing},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
eprint = {2103.02193},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abuduweili et al. - 2021 - Adaptive Consistency Regularization for Semi-Supervised Transfer Learning.pdf:pdf},
keywords = {semi-supervised learning,transfer learning},
mendeley-tags = {semi-supervised learning,transfer learning},
title = {{Adaptive Consistency Regularization for Semi-Supervised Transfer Learning}},
url = {http://arxiv.org/abs/2103.02193},
year = {2021}
}
@article{Wortsman2021d,
abstract = {Recent observations have advanced our understanding of the neural network optimization landscape, revealing the existence of (1) paths of high accuracy containing diverse solutions and (2) wider minima offering improved performance. Previous methods observing diverse paths require multiple training runs. In contrast we aim to leverage both property (1) and (2) with a single method and in a single training run. With a similar computational cost as training one model, we learn lines, curves, and simplexes of high-accuracy neural networks. These neural network subspaces contain diverse solutions that can be ensembled, approaching the ensemble performance of independently trained networks without the training cost. Moreover, using the subspace midpoint boosts accuracy, calibration, and robustness to label noise, outperforming Stochastic Weight Averaging.},
annote = {
},
archivePrefix = {arXiv},
arxivId = {2102.10472},
author = {Wortsman, Mitchell and Horton, Maxwell and Guestrin, Carlos and Farhadi, Ali and Rastegari, Mohammad},
eprint = {2102.10472},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wortsman et al. - 2021 - Learning Neural Network Subspaces.pdf:pdf},
keywords = {neural networks,optimization,subspaces},
mendeley-tags = {neural networks,optimization,subspaces},
title = {{Learning Neural Network Subspaces}},
year = {2021}
}
@misc{Ly2007,
author = {Ly, David},
pages = {. kenyon.edu /index.php/Zymomonas_mobilis},
title = {{Zymomonas mobilis}},
urldate = {2019-07-01},
year = {2007}
}
@article{Alhassan2014,
abstract = {Solvent Technology, is gaining the interest of researchers in improving transesterification process recently. Transesterification of cotton seed oil into biodiesel using different mixtures of methanol with Diethyl Ether (DEE), Dichlorobenzene (CBN) or Acetone (ACT) co-solvent systems was conducted. Potassium hydroxide (KOH) was used as the catalyst all through. The reaction conditions optimized include; the molar ratio of co-solvent in methanol, reaction temperature and time. The catalyst concentration was also optimized. The optimization was based on the percentage yields of Fatty Acids Methyl Esters (FAMEs) produced. In addition, the effects of co-solvent systems on physico-chemical properties (Acid value and fatty acids composition) and fuel properties (viscosity, density and calorific value) were investigated as well. The result obtained, indicated 10% (v/v) addition of co-solvents CBN and ACT in methanol was the optimal volume. The optimal reaction temperature was 55 °0C for 10 min when the catalyst concentration of 0.75% (w/w) weight of oil was used. Fuel properties were within the acceptable limit of ASTM and not significantly affected by the co-solvent systems except for the calorific value. It was concluded that the addition of co-solvent reduced the reaction time and improved some fuel properties of the biodiesel produced. {\textcopyright} 2014 Elsevier Ltd. All rights reserved.},
author = {Alhassan, Y. and Kumar, N. and Bugaje, I. M. and Pali, H. S. and Kathkar, P.},
doi = {10.1016/j.enconman.2014.04.080},
isbn = {0196-8904},
issn = {01968904},
journal = {Energy Conversion and Management},
keywords = {Biodiesel,Co-solvent,FAMEs,Optimization and fuel properties},
pages = {640--648},
publisher = {Elsevier Ltd},
title = {{Co-solvents transesterification of cotton seed oil into biodiesel: Effects of reaction conditions on quality of fatty acids methyl esters}},
url = {http://dx.doi.org/10.1016/j.enconman.2014.04.080},
volume = {84},
year = {2014}
}
@article{Amin2011,
abstract = {A good lighting system has to meet three criteria; quality and quantity of light and efficient powerconsumption. A good lighting room will help effective activities inside the laboratorium. To achieve an optimum lighting, natural light has to be considered in the installation design. To optimise lighting installation of the building Elecronics and Microprosessor Laboratorium, clustering luminer with the switch has to proportionately adjust according tothe sun light incidence to the laboratorium. Keyword:},
author = {Amin, Nurhani},
isbn = {2579-7174},
keywords = {good lighting,natural light},
number = {1},
pages = {43--50},
title = {{Optimasi Sistem Pencahayaan Dengan Memanfaatkan Cahaya Alami (Studi Kasus Lab. Elektronika Dan Mikroprosessor Untad)}},
volume = {1},
year = {2011}
}
@article{Batty2010,
abstract = {In particular it is clear that living on low incomes did generate anxiety and low self-esteem for a significant number of research participants, with detrimental impacts on their psychological wellbeing (Wilkinson and Pickett, 2009; Frost and Hoggett, 2008; Ridge, 2009; Hopper et al, 2007; Orr et al, 2006; Ghate and Hazel, 2004; Reay, 2005; Wilkinson, 1996). Our study also found that part of the explanation for these detrimental impacts on self-esteem and emotional wellbeing arises from the internalisation of personal critique, self-blame and a sense of not being clever or resourceful enough to manage the consequences of living on a lower income (Bourdieu, 1984; Skeggs, 1994; Dolan, 2007; Orton, 2009; Blokland, 2007). This is an important contextual caveat to the sense of self worth and relative contentment found by Pahl et al, (2007). This focus of self-critique provides one possible explanation for the ‘quiescence' (Pahl et al, 2007: 1) within unequal societies. Our findings indicate that underclass concepts (of different cultural values, indolence and dependency alleged to pervade some communities in ‘Broken Britain') are inherently flawed, although they continue to be been espouse, most recently in Prime Minister David Cameron's rationales for the Big Society (Cameron, 2010) Indeed, the centrality of a proactive management of individuals' circumstances to their self-identity and their perceived duty to contribute to society was striking. However, our findings also suggest that the impact of stigmatisation upon the identities and behaviour of lower income households may be more limited than previous research suggests. This is not to say that mechanisms of distinction and denigration of particular groups were not present within the neighbourhoods- they were. But this denigration was driven as much by historical working class values as other sources, such as the media and policy discourses.},
author = {Batty, Elaine and Flint, John},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Batty, Flint - 2010 - Self-esteem, comparative poverty and neighbourhoods.pdf:pdf},
journal = {CRESR Working Paper},
number = {July},
title = {{Self-esteem, comparative poverty and neighbourhoods}},
year = {2010}
}
@article{Lewis2016,
abstract = {We introduce a hierarchical framework for conjunctive concept combination based on conceptual spaces and random set theory. The model has the flexibility to account for composition of concepts at various levels of complexity. We show that the conjunctive model includes linear combination as a special case, and that the more general model can account for non-compositional behaviours such as overextension, non-commutativity, preservation of necessity and impossibility of attributes and to some extent, attribute loss or emergence. We investigate two further aspects of human concept use, the conjunction fallacy and the 'guppy effect'.},
author = {Lewis, Martha and Lawry, Jonathan},
doi = {10.1016/j.artint.2016.04.008},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lewis, Lawry - 2016 - Hierarchical conceptual spaces for concept combination.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {Concept composition,Conceptual spaces,Random sets},
pages = {204--227},
publisher = {Elsevier B.V.},
title = {{Hierarchical conceptual spaces for concept combination}},
url = {http://dx.doi.org/10.1016/j.artint.2016.04.008},
volume = {237},
year = {2016}
}
@article{Silla2016,
abstract = {Previous artificial intelligence education research (DeNero and Klein, 2010) has used the classic video game Pacman to teach introductory artificial intelligence concepts. One of the advantages of the work proposed in (DeNero and Klein, 2010) is that the same framework, in this case using the video game Pacman, can be used for different student assignments covering different artificial intelligence algorithms and methods. The issue of how to use the same practical framework is an important one, because if students have to learn a different framework for every assignment they will often feel discouraged. For this reason, the main contribution of this paper is to present a practical assignment to teach students about genetic algorithm? based parameter optimization using the Pacman framework.},
author = {Silla, Carlos N.},
doi = {10.1109/FIE.2016.7757534},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Silla - 2016 - Teaching genetic algorithm-based parameter optimization using Pacman.pdf:pdf},
isbn = {9781509017904},
issn = {15394565},
journal = {Proceedings - Frontiers in Education Conference, FIE},
title = {{Teaching genetic algorithm-based parameter optimization using Pacman}},
volume = {2016-Novem},
year = {2016}
}
@article{Kouzu2008,
abstract = {In order to study solid base catalyst for biodiesel production with environmental benignity, transesterification of edible soybean oil with refluxing methanol was carried out in the presence of calcium oxide (CaO), -hydroxide (Ca(OH)2), or -carbonate (CaCO3). At 1 h of reaction time, yield of FAME was 93% for CaO, 12% for Ca(OH)2, and 0% for CaCO3. Under the same reacting condition, sodium hydroxide with the homogeneous catalysis brought about the complete conversion into FAME. Also, CaO was used for the further tests transesterifying waste cooking oil (WCO) with acid value of 5.1 mg-KOH/g. The yield of FAME was above 99% at 2 h of reaction time, but a portion of catalyst changed into calcium soap by reacting with free fatty acids included in WCO at initial stage of the transesterification. Owing to the neutralizing reaction of the catalyst, concentration of calcium in FAME increased from 187 ppm to 3065 ppm. By processing WCO at reflux of methanol in the presence of cation-exchange resin, only the free fatty acids could be converted into FAME. The transesterification of the processed WCO with acid value of 0.3 mg-KOH/g resulted in the production of FAME including calcium of 565 ppm. ?? 2007 Elsevier Ltd. All rights reserved.},
author = {Kouzu, Masato and Kasuno, Takekazu and Tajika, Masahiko and Sugimoto, Yoshikazu and Yamanaka, Shinya and Hidaka, Jusuke},
doi = {10.1016/j.fuel.2007.10.019},
isbn = {0016-2361},
issn = {00162361},
journal = {Fuel},
keywords = {Biodiesel,Calcium oxide,Cation-exchange resin,Free fatty acid,Solid base catalyst},
number = {12},
pages = {2798--2806},
title = {{Calcium oxide as a solid base catalyst for transesterification of soybean oil and its application to biodiesel production}},
volume = {87},
year = {2008}
}
@article{Chakraborty2011,
abstract = {This paper explores the feasibility of converting waste Rohu fish (Labeo rohita) scale into a high-performance, reusable, low-cost heterogeneous catalyst for synthesis of biodiesel from soybean oil. The thermo-gravimetric analysis (TGA) and X-ray diffraction (XRD) analysis revealed that a significant portion of the main component of fish scale i.e. HAP (hydroxyapatite) could be transformed into $\beta$-tri-calcium phosphate when calcined above 900°C for 2h. Scanning Electron Microscopy (SEM) morphology studies of the calcined scale depicted a fibrous layer of porous structure; while a BET surface area of 39m2/g was measured. Response surface methodology (RSM) was employed to determine the optimal parametric conditions viz. methanol/oil molar ratio, 6.27:1, calcination temperature, 997.42°C and catalyst concentration, 1.01wt.% of oil corresponding to a maximum FAME yield of 97.73%. Reusability results confirmed that the prepared catalyst could be reemployed up to six times, procreating a potentially applicable avenue in biodiesel synthesis. {\textcopyright} 2010 Elsevier Ltd.},
author = {Chakraborty, R. and Bepari, S. and Banerjee, A.},
doi = {10.1016/j.biortech.2010.10.123},
isbn = {1873-2976 (Electronic)\r0960-8524 (Linking)},
issn = {09608524},
journal = {Bioresource Technology},
keywords = {Biodiesel,Calcined fish scale,Heterogeneous catalyst,RSM optimization,Soybean oil},
number = {3},
pages = {3610--3618},
pmid = {21094040},
publisher = {Elsevier Ltd},
title = {{Application of calcined waste fish (Labeo rohita) scale as low-cost heterogeneous catalyst for biodiesel synthesis}},
url = {http://dx.doi.org/10.1016/j.biortech.2010.10.123},
volume = {102},
year = {2011}
}
@article{Goodfellow2014,
abstract = {Catastrophic forgetting is a problem faced by many machine learning models and algorithms. When trained on one task, then trained on a second task, many machine learning models “forget” how to perform the first task. This is widely believed to be a serious problem for neural networks. Here, we investigate the extent to which the catastrophic forgetting problem occurs for modern neural networks, comparing both established and recent gradient-based training algorithms and activation functions. We also examine the effect of the relationship between the first task and the second task on catastrophic forgetting. We find that it is always best to train using the dropout algorithm–the dropout algorithm is consistently best at adapting to the new task, remembering the old task, and has the best tradeoff curve between these two extremes. We find that different tasks and relationships between tasks result in very different rankings of activation function performance. This suggests that the choice of activation function should always be cross-validated.},
archivePrefix = {arXiv},
arxivId = {1312.6211},
author = {Goodfellow, Ian J. and Mirza, Mehdi and Xiao, Da and Courville, Aaron and Bengio, Yoshua},
eprint = {1312.6211},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goodfellow et al. - 2014 - An empirical investigation of catastrophic forgetting in gradient-based neural networks.pdf:pdf},
journal = {2nd International Conference on Learning Representations, ICLR 2014 - Conference Track Proceedings},
title = {{An empirical investigation of catastrophic forgetting in gradient-based neural networks}},
year = {2014}
}
@article{McCulloch1943,
abstract = {In this research, we tackle the problem of picking an object from randomly stacked pile. Since complex physical phenomena of contact among objects and fingers makes it difficult to perform the bin-picking with high success rate, we consider introducing a learning based approach. For the purpose of collecting enough number of training data within a reasonable period of time, we introduce a physics simulator where approximation is used for collision checking. In this paper, we first formulate the learning based robotic bin-picking by using CNN (Convolutional Neural Network). We also obtain the optimum grasping posture of parallel jaw gripper by using CNN. Finally, we show that the effect of approximation introduced in collision checking is relaxed if we use exact 3D model to generate the depth image of the pile as an input to CNN.},
archivePrefix = {arXiv},
arxivId = {1805.08936},
author = {McCulloch, Warren S. and Pitts, Walter},
doi = {10.1007/BF02478259},
eprint = {1805.08936},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/McCulloch, Pitts - 1943 - A logical calculus of the ideas immanent in nervous activity.pdf:pdf},
isbn = {9783030013691},
issn = {0007-4985},
journal = {The Bulletin of Mathematical Biophysics},
month = {dec},
number = {4},
pages = {115--133},
title = {{A logical calculus of the ideas immanent in nervous activity}},
url = {http://link.springer.com/10.1007/BF02478259},
volume = {5},
year = {1943}
}
@article{Das2020,
abstract = {Recent work has shown how predictive modeling can endow agents with rich knowledge of their surroundings, improving their ability to act in complex environments. We propose question-answering as a general paradigm to decode and understand the representations that such agents develop, applying our method to two recent approaches to predictive modeling – action-conditional CPC (Guo et al., 2018) and SimCore (Gregor et al., 2019). After training agents with these predictive objectives in a visually-rich, 3D environment with an assortment of objects, colors, shapes, and spatial configurations, we probe their internal state representations with synthetic (English) questions, without backpropagating gradients from the question-answering decoder into the agent. The performance of different agents when probed this way reveals that they learn to encode factual, and seemingly compositional, information about objects, properties and spatial relations from their physical environment. Our approach is intuitive, i.e. humans can easily interpret responses of the model as opposed to inspecting continuous vectors, and model-agnostic, i.e. applicable to any modeling approach. By revealing the implicit knowledge of objects, quantities, properties and relations acquired by agents as they learn, question-conditional agent probing can stimulate the design and development of stronger predictive learning objectives.},
archivePrefix = {arXiv},
arxivId = {2006.01016},
author = {Das, Abhishek and Carnevale, Federico and Merzic, Hamza and Rimell, Laura and Schneider, Rosalia and Abramson, Josh and Hung, Alden and Ahuja, Arun and Clark, Stephen and Wayne, Gregory and Hill, Felix},
eprint = {2006.01016},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Das et al. - 2020 - Probing emergent semantics in predictive agents via question answering.pdf:pdf},
journal = {arXiv},
title = {{Probing emergent semantics in predictive agents via question answering}},
url = {https://arxiv.org/pdf/2006.01016.pdf},
year = {2020}
}
@article{Jung2020,
abstract = {We propose a novel regularization-based continual learning method, dubbed as Adaptive Group Sparsity based Continual Learning (AGS-CL), using two group sparsity-based penalties. Our method selectively employs the two penalties when learning each node based its the importance, which is adaptively updated after learning each new task. By utilizing the proximal gradient descent method for learning, the exact sparsity and freezing of the model is guaranteed, and thus, the learner can explicitly control the model capacity as the learning continues. Furthermore, as a critical detail, we re-initialize the weights associated with unimportant nodes after learning each task in order to prevent the negative transfer that causes the catastrophic forgetting and facilitate efficient learning of new tasks. Throughout the extensive experimental results, we show that our AGS-CL uses much less additional memory space for storing the regularization parameters, and it significantly outperforms several state-of-the-art baselines on representative continual learning benchmarks for both supervised and reinforcement learning tasks.},
archivePrefix = {arXiv},
arxivId = {2003.13726},
author = {Jung, Sangwon and Ahn, Hongjoon and Cha, Sungmin and Moon, Taesup},
eprint = {2003.13726},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jung et al. - 2020 - Continual Learning with Node-Importance based Adaptive Group Sparse Regularization.pdf:pdf},
title = {{Continual Learning with Node-Importance based Adaptive Group Sparse Regularization}},
url = {http://arxiv.org/abs/2003.13726},
year = {2020}
}
@inproceedings{Puigcerver2020,
abstract = {Transfer of pre-trained representations can improve sample efficiency and reduce computational requirements for new tasks. However, representations used for transfer are usually generic, and are not tailored to a particular distribution of downstream tasks. We explore the use of expert representations for transfer with a simple, yet effective, strategy. We train a diverse set of experts by exploiting existing label structures, and use cheap-to-compute performance proxies to select the relevant expert for each target task. This strategy scales the process of transferring to new tasks, since it does not revisit the pre-training data during transfer. Accordingly, it requires little extra compute per target task, and results in a speed-up of 2–3 orders of magnitude compared to competing approaches. Further, we provide an adapter-based architecture able to compress many experts into a single model. We evaluate our approach on two different data sources and demonstrate that it outperforms baselines on over 20 diverse vision tasks in both cases.},
archivePrefix = {arXiv},
arxivId = {2009.13239},
author = {Puigcerver, Joan and Riquelme, Carlos and Mustafa, Basil and Renggli, Cedric and Pinto, Andr{\'{e}} Susano and Gelly, Sylvain and Keysers, Daniel and Houlsby, Neil},
booktitle = {Iclr 2021},
eprint = {2009.13239},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Puigcerver et al. - 2020 - Scalable transfer learning with expert models.pdf:pdf},
issn = {23318422},
keywords = {expert models,large-scale,transfer learning},
mendeley-tags = {expert models,large-scale,transfer learning},
title = {{Scalable transfer learning with expert models}},
year = {2020}
}
@article{Krishna2017,
abstract = {Despite progress in perceptual tasks such as image classification, computers still perform poorly on cognitive tasks such as image description and question answering. Cognition is core to tasks that involve not just recognizing, but reasoning about our visual world. However, models used to tackle the rich content in images for cognitive tasks are still being trained using the same datasets designed for perceptual tasks. To achieve success at cognitive tasks, models need to understand the interactions and relationships between objects in an image. When asked "What vehicle is the person riding?", computers will need to identify the objects in an image as well as the relationships riding(man, carriage) and pulling(horse, carriage) in order to answer correctly that "the person is riding a horse-drawn carriage". In this paper, we present the Visual Genome dataset to enable the modeling of such relationships. We collect dense annotations of objects, attributes, and relationships within each image to learn these models. Specifically, our dataset contains over 100K images where each image has an average of 21 objects, 18 attributes, and 18 pairwise relationships between objects. We canonicalize the objects, attributes, relationships, and noun phrases in region descriptions and questions answer pairs to WordNet synsets. Together, these annotations represent the densest and largest dataset of image descriptions, objects, attributes, relationships, and question answers.},
archivePrefix = {arXiv},
arxivId = {1602.07332},
author = {Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li Jia and Shamma, David A. and Bernstein, Michael S. and Fei-Fei, Li},
doi = {10.1007/s11263-016-0981-7},
eprint = {1602.07332},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krishna et al. - 2017 - Visual Genome Connecting Language and Vision Using Crowdsourced Dense Image Annotations.pdf:pdf},
issn = {15731405},
journal = {International Journal of Computer Vision},
keywords = {Attributes,Computer vision,Crowdsourcing,Dataset,Image,Knowledge,Language,Objects,Question answering,Relationships,Scene graph},
number = {1},
pages = {32--73},
publisher = {Springer US},
title = {{Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations}},
volume = {123},
year = {2017}
}
@article{Nandy2020,
abstract = {Among the existing uncertainty estimations approaches , only Dirichlet Prior Network (DPN) distinctly models different uncertainty types. However , in this paper, we show that for in-domain examples with high data uncertainties among multiple classes, a DPN also produces almost indistinguishable representations from the out-of-distribution (OOD) examples, compromising their OOD detection performance. We address this shortcoming by proposing a new loss function for DPN models that maximizes the representation gaps between the in-domain and OOD examples. Experimental results suggest that our proposed technique consistently improves OOD detection performance by solving this issue.},
author = {Nandy, Jay and Hsu, Wynne and Lee, Mong Li},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nandy, Hsu, Lee - 2020 - Maximizing the Representation Gap between In-domain & OOD examples.pdf:pdf},
journal = {ICML 2020 Workshop on Uncertainty & Robustness in Deep Learning},
title = {{Maximizing the Representation Gap between In-domain & OOD examples}},
url = {https://www.researchgate.net/publication/344387147},
year = {2020}
}
@article{Zhang2017,
abstract = {We propose a deep learning approach for user-guided image colorization. The system directly maps a grayscale image, along with sparse, local user "hints" to an output colorization with a Convolutional Neural Network (CNN). Rather than using hand-defined rules, the network propagates user edits by fusing low-level cues along with high-level semantic information, learned from large-scale data. We train on a million images, with simulated user inputs. To guide the user towards efficient input selection, the system recommends likely colors based on the input image and current user inputs. The colorization is performed in a single feed-forward pass, enabling real-time use. Even with randomly simulated user inputs, we show that the proposed system helps novice users quickly create realistic colorizations, and offers large improvements in colorization quality with just a minute of use. In addition, we demonstrate that the framework can incorporate other user "hints" to the desired colorization, showing an application to color histogram transfer. Our code and models are available at https://richzhang.github.io/ideepcolor.},
archivePrefix = {arXiv},
arxivId = {1705.02999},
author = {Zhang, Richard and Zhu, Jun-Yan and Isola, Phillip and Geng, Xinyang and Lin, Angela S. and Yu, Tianhe and Efros, Alexei A.},
doi = {10.1145/3072959.3073703},
eprint = {1705.02999},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2017 - Real-time user-guided image colorization with learned deep priors.pdf:pdf},
issn = {0730-0301},
journal = {ACM Transactions on Graphics},
keywords = {Colorization,Deep learning,Edit propagation,Interactivecolorization,Vision for graphics},
month = {jul},
number = {4},
pages = {1--11},
title = {{Real-time user-guided image colorization with learned deep priors}},
url = {http://arxiv.org/abs/1705.02999 https://dl.acm.org/doi/10.1145/3072959.3073703},
volume = {36},
year = {2017}
}
@article{Sakr2017,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Sakr, Dalia},
doi = {10.1016/j.jclepro.2016.10.135},
eprint = {arXiv:1011.1669v3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sakr - 2017 - Sustainability and Innovation The Next Global Industrial Revolution.pdf:pdf},
isbn = {9781783202188},
issn = {09596526},
journal = {Journal of Cleaner Production},
pages = {3355--3356},
pmid = {22251136},
title = {{Sustainability and Innovation: The Next Global Industrial Revolution}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0959652616317668},
volume = {142},
year = {2017}
}
@article{Zellers2019,
abstract = {Visual understanding goes well beyond object recognition. With one glance at an image, we can effortlessly imagine the world beyond the pixels: For instance, we can infer people's actions, goals, and mental states. While this task is easy for humans, it is tremendously difficult for today's vision systems, requiring higher-order cognition and commonsense reasoning about the world. We formalize this task as Visual Commonsense Reasoning. Given a challenging question about an image, a machine must answer correctly and then provide a rationale justifying its answer. Next, we introduce a new dataset, VCR, consisting of 290k multiple choice QA problems derived from 110k movie scenes. The key recipe for generating non-trivial and high-quality problems at scale is Adversarial Matching, a new approach to transform rich annotations into multiple choice questions with minimal bias. Experimental results show that while humans find VCR easy (over 90% accuracy), state-of-the-art vision models struggle ($\sim$45%). To move towards cognition-level understanding, we present a new reasoning engine, Recognition to Cognition Networks (R2C), that models the necessary layered inferences for grounding, contextualization, and reasoning. R2C helps narrow the gap between humans and machines ($\sim$65%); still, the challenge is far from solved, and we provide analysis that suggests avenues for future work.},
archivePrefix = {arXiv},
arxivId = {1811.10830},
author = {Zellers, Rowan and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
doi = {10.1109/CVPR.2019.00688},
eprint = {1811.10830},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zellers et al. - 2019 - From recognition to cognition Visual commonsense reasoning.pdf:pdf},
isbn = {9781728132938},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
keywords = {Categorization,Recognition: Detection,Retrieval,Scene Analysis and Understanding,Vision + Language,Visual Reasonin},
pages = {6713--6724},
title = {{From recognition to cognition: Visual commonsense reasoning}},
volume = {2019-June},
year = {2019}
}
@article{M2014,
author = {M, Author Felipe Albornoz},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/M - 2014 - LIDAR, a laser alternative for remote sensing.pdf:pdf},
title = {{LIDAR, a laser alternative for remote sensing}},
year = {2014}
}
@article{Fernando2017,
abstract = {For artificial general intelligence (AGI) it would be efficient if multiple users trained the same giant neural network, permitting parameter reuse, without catastrophic forgetting. PathNet is a first step in this direction. It is a neural network algorithm that uses agents embedded in the neural network whose task is to discover which parts of the network to re-use for new tasks. Agents are pathways (views) through the network which determine the subset of parameters that are used and updated by the forwards and backwards passes of the backpropogation algorithm. During learning, a tournament selection genetic algorithm is used to select pathways through the neural network for replication and mutation. Pathway fitness is the performance of that pathway measured according to a cost function. We demonstrate successful transfer learning; fixing the parameters along a path learned on task A and re-evolving a new population of paths for task B, allows task B to be learned faster than it could be learned from scratch or after fine-tuning. Paths evolved on task B re-use parts of the optimal path evolved on task A. Positive transfer was demonstrated for binary MNIST, CIFAR, and SVHN supervised learning classification tasks, and a set of Atari and Labyrinth reinforcement learning tasks, suggesting PathNets have general applicability for neural network training. Finally, PathNet also significantly improves the robustness to hyperparameter choices of a parallel asynchronous reinforcement learning algorithm (A3C).},
archivePrefix = {arXiv},
arxivId = {1701.08734},
author = {Fernando, Chrisantha and Banarse, Dylan and Blundell, Charles and Zwols, Yori and Ha, David and Rusu, Andrei A. and Pritzel, Alexander and Wierstra, Daan},
eprint = {1701.08734},
file = {:home/user/Downloads/1701.08734.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {Basal Ganglia,Continual Learning,Evolution and Learning,Giant networks,MultiTask Learning,Path evolution algorithm,Transfer Learning,architectural,continual learning,incremental learning},
mendeley-tags = {architectural,continual learning,incremental learning},
title = {{PathNet: Evolution channels gradient descent in super neural networks}},
year = {2017}
}
@article{Heintzman2014a,
abstract = {This article synthesizes empirical studies that explain the relation-ship between nature-based recreation and spirituality for persons with disabilities. In order to describe this relationship, a theoret-ical model, which includes the components of antecedent condi-tions, setting, and recreation, is developed. Antecedent conditions include history and current circumstances, motivation, sociodemo-graphic characteristics, and spiritual tradition. Setting components include being in nature, being away to a different environment, and place processes. Recreation components include activity, free time, solitude, and group experiences. The article further explains how these conditions and components may lead to outcomes of spir-itual experiences, spiritual well-being, and leisure-spiritual coping. Leisure-spiritual coping, which is particularly relevant for persons who are experiencing stress, refers to spiritual coping that takes place within the context of a person's leisure. This model illustrates the complexity of the nature-based recreation and spirituality re-lationship. Recommendations for future research and implications for practitioners who work with people who have disabilities are outlined.},
author = {Heintzman, Paul},
doi = {10.1080/15228967.2014.868983},
isbn = {01490400},
issn = {2331253X},
journal = {Journal of Disability and Religion},
keywords = {Disabilities,Leisure,Nature,Recreation,Spirituality},
number = {1},
pages = {97--116},
pmid = {49151820},
title = {{Nature-based recreation, spirituality, and persons with disabilities}},
volume = {18},
year = {2014}
}
@article{Sharma2017,
abstract = {Due to advancement of auto regulated powered wireless sensors systems; piezoelectric pulsation energy harvesters (PVEHs) have received a significant attention. Though, a popular of these devices has very low input frequencies. This paper seeks to analyze the current method to harness energy from vibration using piezoelectric setup in the low range of frequency zone and demonstrate an experiment model to validate the results from the setup. Many reviewers have given different modelling approach to optimize the performance parameter such as mass ratio, damping constant, frequency, load resistance, electromechanical coupling constant and capacitance etc. Finally, it has been found from experimentally and simulation that the maximum power harvested from the piezoelectric vibration setup depends upon the maximum deflection of the beam subjected to many dynamic constraint parameters such as inertia of the beam, maximum lift force due to wind, and lift drag characteristics curve etc.},
author = {Sharma, Pramod Kumar and Baredar, Prashant V.},
doi = {10.1016/j.jksus.2017.11.002},
issn = {10183647},
journal = {Journal of King Saud University - Science},
keywords = {Aeroleastic vibration,IDTE,MEMS,PZT,Reduced velocity},
publisher = {King Saud University},
title = {{Analysis on piezoelectric energy harvesting small scale device - a review}},
url = {https://doi.org/10.1016/j.jksus.2017.11.002},
year = {2017}
}
@article{Giunchiglia2020,
abstract = {Hierarchical multi-label classification (HMC) is a challenging classification task extending standard multi-label classification problems by imposing a hierarchy constraint on the classes. In this paper, we propose C-HMCNN(h), a novel approach for HMC problems, which, given a network h for the underlying multi-label classification problem, exploits the hierarchy information in order to produce predictions coherent with the constraint and improve performance. We conduct an extensive experimental analysis showing the superior performance of C-HMCNN(h) when compared to state-of-the-art models.},
archivePrefix = {arXiv},
arxivId = {2010.10151},
author = {Giunchiglia, Eleonora and Lukasiewicz, Thomas},
eprint = {2010.10151},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Giunchiglia, Lukasiewicz - 2020 - Coherent Hierarchical Multi-Label Classification Networks.pdf:pdf},
month = {oct},
number = {i},
title = {{Coherent Hierarchical Multi-Label Classification Networks}},
url = {http://arxiv.org/abs/2010.10151},
year = {2020}
}
@article{Masana2020,
archivePrefix = {arXiv},
arxivId = {arXiv:2010.15277v1},
author = {Masana, Marc and Liu, Xialei and Twardowski, Bart{\l}omiej and Menta, Mikel and Bagdanov, Andrew D and Weijer, Joost Van De},
eprint = {arXiv:2010.15277v1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Masana et al. - 2020 - Class-incremental learning survey and performance evaluation.pdf:pdf},
journal = {arXiv Preprint},
keywords = {continual learning,incremental learning,review,survey},
mendeley-tags = {continual learning,incremental learning,review,survey},
pages = {1--24},
title = {{Class-incremental learning : survey and performance evaluation}},
year = {2020}
}
@article{Carion2020c,
abstract = {We present a new method that views object detection as a direct set prediction problem. Our approach streamlines the detection pipeline, effectively removing the need for many hand-designed components like a non-maximum suppression procedure or anchor generation that explicitly encode our prior knowledge about the task. The main ingredients of the new framework, called DEtection TRansformer or DETR, are a set-based global loss that forces unique predictions via bipartite matching, and a transformer encoder-decoder architecture. Given a fixed small set of learned object queries, DETR reasons about the relations of the objects and the global image context to directly output the final set of predictions in parallel. The new model is conceptually simple and does not require a specialized library, unlike many other modern detectors. DETR demonstrates accuracy and run-time performance on par with the well-established and highly-optimized Faster RCNN baseline on the challenging COCO object detection dataset. Moreover, DETR can be easily generalized to produce panoptic segmentation in a unified manner. We show that it significantly outperforms competitive baselines. Training code and pretrained models are available at https://github.com/facebookresearch/detr.},
archivePrefix = {arXiv},
arxivId = {2005.12872},
author = {Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
eprint = {2005.12872},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Carion et al. - 2020 - End-to-End Object Detection with Transformers(4).pdf:pdf},
title = {{End-to-End Object Detection with Transformers}},
year = {2020}
}
@article{Veneti2017a,
abstract = {The paper presents an improved solution to the ship weather routing problem based on an exact time-dependent bi-objective shortest path algorithm. The two objectives of the problem are the minimization of the fuel consumption and the total risk of the ship route while taking into account the time-varying sea and weather conditions and an upper bound on the total passage time of the route. Safety is also considered by applying the guidelines of the International Maritime Organization (IMO). As a case study, the proposed algorithm is applied for finding ship routes in the area of the Aegean Sea, Greece. Enhancements of the proposed algorithm are also presented which improve the efficiency of our approach.},
author = {Veneti, Aphrodite and Makrygiorgos, Angelos and Konstantopoulos, Charalampos and Pantziou, Grammati and Vetsikas, Ioannis A.},
doi = {10.1016/j.cor.2017.07.010},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Veneti et al. - 2017 - Minimizing the fuel consumption and the risk in maritime transportation A bi-objective weather routing approach.pdf:pdf},
issn = {03050548},
journal = {Computers and Operations Research},
keywords = {Multi-criteria optimization,Resource-constrained shortest path,Ship weather routing,Time dependent networks},
pages = {220--236},
publisher = {Elsevier Ltd},
title = {{Minimizing the fuel consumption and the risk in maritime transportation: A bi-objective weather routing approach}},
url = {http://dx.doi.org/10.1016/j.cor.2017.07.010},
volume = {88},
year = {2017}
}
@article{Singpurwalla2004,
abstract = { The notion of fuzzy sets has proven useful in the context of control theory, pattern recognition, and medical diagnosis. However, it has also spawned the view that classical probability theory is unable to deal with uncertainties in natural language and machine learning, so that alternatives to probability are needed. One such alternative is what is known as ``possibility theory.'' Such alternatives have come into being because past attempts at making fuzzy set theory and probability theory work in concert have been unsuccessful. The purpose of this article is to develop a line of argument that demonstrates that probability theory has a sufficiently rich structure for incorporating fuzzy sets within its framework. Thus probabilities of fuzzy events can be logically induced. The philosophical underpinnings that make this happen are a subjectivistic interpretation of probability, an introduction of Laplace's famous genie, and the mathematics of encoding expert testimony. The benefit of making probability theory work in concert with fuzzy set theory is an ability to deal with different kinds of uncertainties that may arise within the same problem. },
author = {Singpurwalla, Nozer D. and Booker, Jane M.},
doi = {10.1198/016214504000001196},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Singpurwalla, Booker - 2004 - Membership functions and probability measures of fuzzy sets.pdf:pdf},
isbn = {0162-1459},
issn = {01621459},
journal = {Journal of the American Statistical Association},
keywords = {Decision making,Expert testimony,Fuzzy control,Laplace's genie,Likelihood,Machine learning,Membership functions,Subjective probability},
number = {467},
pages = {867--877},
title = {{Membership functions and probability measures of fuzzy sets}},
volume = {99},
year = {2004}
}
@article{Sun2018a,
abstract = {Aerosol deposition is highly concerned recently due to its significant impact on surface glass cleaning, glass transmittance and energy conversion of building-integrated photovoltaics (BIPV). Thus, this paper reviewed direct transmittance degradation works of PV module surface glasses, and employed several integrated and improved experiment and model methods to investigate the correlation effects of PM2.5 deposition dynamics, tilt angles, surface conditions and self-cleaning TiO2nanocoating on glasses. Series of physical models from ambient aerosol concentration to deposition density and transmittance reduction were extended or newly developed. Measured and modeled data could inter-validate with each other and literature results. The usage condition of Al-Hasan model was discovered as 0<ap<0.10 for particle projected-area fraction under clustering particle projected-area fraction apcp≤5%. Ranging from 0 to 18.7 $\mu$g/cm2, deposition densities with the most reductions (50–91%) were found under the combination of wet and nanocoating conditions due to effects of water film and low adhesive force. Generally, the average deposition densities decreased 19–47% with the increase of each 30° tilt angle for different surface properties. Finally, six linear empirical models were obtained with decreasing slopes of 0.001544–0.001841 between fine aerosol deposition density and transmittance ratio. These observed phenomena and derived models would be useful for solar energy, building illumination or heat-transfer, and BIPV industries.},
author = {Sun, Ke and Lu, Lin and Jiang, Yu and Wang, Yuanhao and Zhou, Kun and He, Zhu},
doi = {10.1016/j.rser.2017.10.062},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sun et al. - 2018 - Integrated effects of PM2.5 deposition, module surface conditions and nanocoatings on solar PV surface glass transmi.pdf:pdf},
issn = {18790690},
journal = {Renewable and Sustainable Energy Reviews},
keywords = {Aerosol dynamics,Deposition density,Mathematic modeling,TiO2nanocoating,Transmittance reduction},
number = {April 2016},
pages = {4107--4120},
publisher = {Elsevier Ltd},
title = {{Integrated effects of PM2.5 deposition, module surface conditions and nanocoatings on solar PV surface glass transmittance}},
url = {http://dx.doi.org/10.1016/j.rser.2017.10.062},
volume = {82},
year = {2018}
}
@book{Safranski2017a,
abstract = {Shape-memory polymers (SMPs) have had a long and successful history in commercial use. From SMP aircraft rivets to heat-shrink tubing to medical implants, the applications for SMPs have been highly varied and across numerous industries. In this chapter we attempt to provide examples of SMPs that have seen some form of commercial success or have high potential for commercialization. It does not intend to be an exhaustive summary, but is instead a means of sparking the creative process for those designers looking to apply these uniquely functional materials for their own application. This chapter covers applications in aerospace, automotive, biomedical, commercial, and industrial fields.},
author = {Safranski, David L. and Griffis, Jack C.},
booktitle = {Shape-Memory Polymer Device Design},
doi = {10.1016/B978-0-323-37797-3.00006-3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Safranski, Griffis - 2017 - Applications of Shape-Memory Polymers.pdf:pdf},
isbn = {9780323377973},
keywords = {Shape-memory polymers,aerospace application,biomedical application,cardiovascular,commercial application,composites,orthopedic,tissue engineering},
pages = {189--222},
publisher = {Elsevier Inc.},
title = {{Applications of Shape-Memory Polymers}},
url = {http://linkinghub.elsevier.com/retrieve/pii/B9780323377973000063},
year = {2017}
}
@article{Springer1991,
abstract = {We present here an isothermal, one-dimensional, steady-state model for a complete polymer electrolyte fuel cell (PEFC) with a 117 Nafion(R) membrane. In this model we employ water diffusion coefficients electro-osmotic drag coefficients, water sorption isotherms, and membrane conductivities, all measured in our laboratory as functions of membrane water content. The model predicts a net-water-per-proton flux ratio of 0.2 H2O/H+ under typical operating conditions, which is much less than the measured electro-osmotic drag coefficient for a fully hydrated membrane. It also predicts an increase in membrane resistance with increased current density and demonstrates the great advantage of a thinner membrane in alleviating this resistance problem. Both of these predictions were verified experimentally under certain conditions.},
author = {Springer, T. E.},
doi = {10.1149/1.2085971},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Springer - 1991 - Polymer Electrolyte Fuel Cell Model.pdf:pdf},
isbn = {10.1149/1.2085971},
issn = {00134651},
journal = {Journal of The Electrochemical Society},
number = {8},
pages = {2334},
title = {{Polymer Electrolyte Fuel Cell Model}},
url = {http://jes.ecsdl.org/cgi/doi/10.1149/1.2085971},
volume = {138},
year = {1991}
}
@article{Ha2016,
abstract = {Conjugation between various small fluorophores and specific ligands has become one of the main strategies for bioimaging in disease diagnosis, medicinal chemistry, immunology, and fluorescence-guided surgery, etc. Herein, we present our review of recent studies relating to molecular fluorescent imaging techniques for various cancers in cell-based and animal-based models. Various organic fluorophores, especially near-infrared (NIR) probes, have been employed with specific ligands. Types of ligands used were small molecules, peptides, antibodies, and aptamers; each has specific affinities for cellular receptor proteins, cancer-specific antigens, enzymes, and nucleic acids. This review can aid in the selection of cancer-specific ligands and fluorophores, and may inspire the further development of new conjugation strategies in various cellular and animal models.},
author = {Ha, Yonghwang and Choi, Hyun Kyung},
doi = {10.1016/j.cbi.2016.02.006},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ha, Choi - 2016 - Recent conjugation strategies of small organic fluorophores and ligands for cancer-specific bioimaging.pdf:pdf},
issn = {18727786},
journal = {Chemico-Biological Interactions},
keywords = {Cancer-specific biomarkers,Cancer-specific ligands,Cancer-specific receptors,Fluorescent diagnosis,Near-infrared},
pages = {36--51},
pmid = {26892219},
publisher = {Elsevier Ltd},
title = {{Recent conjugation strategies of small organic fluorophores and ligands for cancer-specific bioimaging}},
url = {http://dx.doi.org/10.1016/j.cbi.2016.02.006},
volume = {248},
year = {2016}
}
@article{Kocak2017,
abstract = {Within classic time series approaches, a time series model can be studied under 3 groups, namely AR (autoregressive model), MA (moving averages model) and ARMA (autoregressive moving averages model). On the other hand, solutions are based mostly on fuzzy AR time series models in the fuzzy time series literature. However, just a few fuzzy ARMA time series models have proposed until now. Fuzzy AR time series models have been divided into two groups named first order and high order models in the literature, highlighting the impact of model degree on forecast performance. However, model structure has been disregarded in these fuzzy AR models. Therefore, it is necessary to eliminate the model specification error arising from not utilizing of MA variables in the fuzzy time series approaches. For this reason, a new high order fuzzy ARMA(p,q) time series solution algorithm based on fuzzy logic group relations including fuzzy MA variables along with fuzzy AR variables has been proposed in this study. The main purpose of this article is to show that the forecast performance can be significantly improved when the deficiency of not utilizing MA variables. The other aim is also to show that the proposed method is better than the other fuzzy ARMA time series models in the literature from the point of forecast performance. Therefore, the new proposed method has been compared regarding forecast performance against some methods commonly used in literature by applying them on gold prices in Turkey, Istanbul Stock Exchange (IMKB) and the Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX).},
author = {Kocak, Cem},
doi = {10.1016/j.asoc.2017.04.021},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kocak - 2017 - ARMA(p,q) type high order fuzzy time series forecast method based on fuzzy logic relations(2).pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {Fuzzy ARMA models,Fuzzy autoregressive – moving avarage model,Fuzzy time series,Group relation table,High order fuzzy time series},
pages = {92--103},
publisher = {Elsevier B.V.},
title = {{ARMA(p,q) type high order fuzzy time series forecast method based on fuzzy logic relations}},
url = {http://dx.doi.org/10.1016/j.asoc.2017.04.021},
volume = {58},
year = {2017}
}
@article{Sharifian2018,
abstract = {Nowadays, due to some environmental restrictions and decrease of fossil fuel sources, renewable energy sources and specifically wind power plants have a major part of energy generation in the industrial countries. To this end, the accurate forecasting of wind power is considered as an important and influential factor for the management and planning of power systems. In this paper, a novel intelligent method is proposed to provide an accurate forecast of the medium-term and long-term wind power by using the uncertain data from an online supervisory control and data acquisition (SCADA) system and the numerical weather prediction (NWP). This new method is based on the particle swarm optimization (PSO) algorithm and applied to train the Type-2 fuzzy neural network (T2FNN) which is called T2FNN-PSO. The presented method combines both of fuzzy system's expert knowledge and the neural network's learning capability for accurate forecasting of the wind power. In addition, the T2FNN-PSO can appropriately handle the uncertainties associated with the measured parameters from SCADA system, the numerical weather prediction and measuring tools. The proposed method is applied on a case study of a real wind farm. The obtained simulation results validate effectiveness and applicability of the proposed method for a practical solution to an accurate wind power forecasting in a power system control center.},
author = {Sharifian, Amir and Ghadi, M. Jabbari and Ghavidel, Sahand and Li, Li and Zhang, Jiangfeng},
doi = {10.1016/j.renene.2017.12.023},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sharifian et al. - 2018 - A new method based on Type-2 fuzzy neural network for accurate wind power forecasting under uncertain data.pdf:pdf},
issn = {18790682},
journal = {Renewable Energy},
keywords = {Medium-term and long-term wind power forecasting,PSO algorithm,Type-2 fuzzy neural network,Uncertain information},
pages = {220--230},
title = {{A new method based on Type-2 fuzzy neural network for accurate wind power forecasting under uncertain data}},
volume = {120},
year = {2018}
}
@article{Chen2021,
abstract = {Meta-learning aims at learning quickly on novel tasks with limited data by transferring generic experience learned from previous tasks. Naturally, few-shot learning has been one of the most popular applications for meta-learning. However, existing meta-learning algorithms rarely consider the time and resource efficiency or the generalization capacity for unknown datasets, which limits their applicability in real-world scenarios. In this paper, we propose MetaDelta, a novel practical meta-learning system for the few-shot image classification. MetaDelta consists of two core components: i) multiple meta-learners supervised by a central controller to ensure efficiency, and ii) a meta-ensemble module in charge of integrated inference and better generalization. In particular, each meta-learner in MetaDelta is composed of a unique pretrained encoder fine-tuned by batch training and parameter-free decoder used for prediction. MetaDelta ranks first in the final phase in the AAAI 2021 MetaDL Challenge\footnote{https://competitions.codalab.org/competitions/26638}, demonstrating the advantages of our proposed system. The codes are publicly available at https://github.com/Frozenmad/MetaDelta.},
archivePrefix = {arXiv},
arxivId = {2102.10744},
author = {Chen, Yudong and Guan, Chaoyu and Wei, Zhikun and Wang, Xin and Zhu, Wenwu},
eprint = {2102.10744},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2021 - MetaDelta A Meta-Learning System for Few-shot Image Classification.pdf:pdf},
keywords = {few-shot learning,meta-learning},
mendeley-tags = {few-shot learning,meta-learning},
title = {{MetaDelta: A Meta-Learning System for Few-shot Image Classification}},
url = {http://arxiv.org/abs/2102.10744},
year = {2021}
}
@article{Zhai2020,
abstract = {Humans accumulate knowledge in a lifelong fashion. Modern deep neural networks, on the other hand, are susceptible to catastrophic forgetting: when adapted to perform new tasks, they often fail to preserve their performance on previously learned tasks. Given a sequence of tasks, a naive approach addressing catastrophic forgetting is to train a separate standalone model for each task, which scales the total number of parameters drastically without efficiently utilizing previous models. In contrast, we propose a parameter efficient framework, Piggyback GAN, which learns the current task by building a set of convolutional and deconvolutional filters that are factorized into filters of the models trained on previous tasks. For the current task, our model achieves high generation quality on par with a standalone model at a lower number of parameters. For previous tasks, our model can also preserve generation quality since the filters for previous tasks are not altered. We validate Piggyback GAN on various image-conditioned generation tasks across different domains, and provide qualitative and quantitative results to show that the proposed approach can address catastrophic forgetting effectively and efficiently.},
archivePrefix = {arXiv},
arxivId = {2104.11939},
author = {Zhai, Mengyao and Chen, Lei and He, Jiawei and Nawhal, Megha and Tung, Frederick and Mori, Greg},
doi = {10.1007/978-3-030-58589-1_24},
eprint = {2104.11939},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhai et al. - 2020 - Piggyback GAN Efficient Lifelong Learning for Image Conditioned Generation.pdf:pdf},
isbn = {9783030585884},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Generative adversarial networks,Lifelong learning,continual learning,gan,generative model,image generation,incremental learning},
mendeley-tags = {continual learning,gan,generative model,image generation,incremental learning},
pages = {397--413},
title = {{Piggyback GAN: Efficient Lifelong Learning for Image Conditioned Generation}},
volume = {12366 LNCS},
year = {2020}
}
@misc{Such2017a,
abstract = {Deep artificial neural networks (DNNs) are typically trained via gradient-based learning algorithms, namely backpropagation. Evolution strategies (ES) can rival backprop-based algorithms such as Q-learning and policy gradients on challenging deep reinforcement learning (RL) problems. However, ES can be considered a gradient-based algorithm because it performs stochastic gradient descent via an operation similar to a finite-difference approximation of the gradient. That raises the question of whether non-gradient-based evolutionary algorithms can work at DNN scales. Here we demonstrate they can: we evolve the weights of a DNN with a simple, gradient-free, populationbased genetic algorithm (GA) and it performs well on hard deep RL problems, including Atari and humanoid locomotion. The Deep GA successfully evolves networks with over four million free parameters, the largest neural networks ever evolved with a traditional evolutionary algorithm. These results (1) expand our sense of the scale at which GAs can operate, (2) suggest intriguingly that in some cases following the gradient is not the best choice for optimizing performance, and (3) make immediately available the multitude of neuroevolution techniques that improve performance. We demonstrate the latter by showing that combining DNNs with novelty search, which encourages exploration on tasks with deceptive or sparse reward functions, can solve a high-dimensional problem on which reward-maximizing algorithms (e.g. DQN, A3C, ES, and the GA) fail. Additionally, the Deep GA is faster than ES, A3C, and DQN (it can train Atari in ∼4 hours on one desktop or ∼1 hour distributed on 720 cores), and enables a stateof-the-art, up to 10,000-fold compact encoding technique.},
archivePrefix = {arXiv},
arxivId = {1712.06567},
author = {Such, Felipe Petroski and Madhavan, Vashisht and Conti, Edoardo and Lehman, Joel and Stanley, Kenneth O. and Clune, Jeff},
booktitle = {arXiv},
eprint = {1712.06567},
title = {{Deep neuroevolution: Genetic algorithms are a competitive alternative for training deep neural networks for reinforcement learning}},
year = {2017}
}
@article{Thakur2014,
author = {Thakur, Madri and Datar, Shilpa},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thakur, Datar - 2014 - Image Restoration Based On Deconvolution by Richardson-Lucy Algorithm.pdf:pdf},
journal = {International Journal of Engineering Trends and Technology},
keywords = {inverse filter,lucy- richardson,mean square error,mse,peak signal to noise,psnr,ratio,wiener filter},
number = {4},
pages = {161--165},
title = {{Image Restoration Based On Deconvolution by Richardson-Lucy Algorithm}},
volume = {14},
year = {2014}
}
@article{Suter2011,
abstract = {Do moral judgments hinge on the time available to render them? According to a recent dual-process model of moral judgment, moral dilemmas that engage emotional processes are likely to result in fast deontological gut reactions. In contrast, consequentialist responses that tot up lives saved and lost in response to such dilemmas would require cognitive control to override the initial response. Cognitive control, however, takes time. In two experiments, we manipulated the time available to arrive at moral judgments in two ways: by allotting a fixed short or large amount of time, and by nudging people to answer swiftly or to deliberate thoroughly. We found that faster responses indeed lead to more deontological responses among those moral dilemmas in which the killing of one to save many necessitates manhandling an innocent person and in which this action is depicted as a means to an end. Thus, our results are the first demonstration that inhibiting cognitive control through manipulations of time alters moral judgments. {\textcopyright} 2011 Elsevier B.V.},
author = {Suter, Renata S. and Hertwig, Ralph},
doi = {10.1016/j.cognition.2011.01.018},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Suter, Hertwig - 2011 - Time and moral judgment.pdf:pdf},
isbn = {0010-0277},
issn = {00100277},
journal = {Cognition},
keywords = {Intuition,Judgment,Moral dilemmas,Morality,Reasoning,Time pressure},
number = {3},
pages = {454--458},
pmid = {21354557},
publisher = {Elsevier B.V.},
title = {{Time and moral judgment}},
url = {http://dx.doi.org/10.1016/j.cognition.2011.01.018},
volume = {119},
year = {2011}
}
@article{LopezRodriguez2017,
abstract = {Mobile Model Predictive control is a novel control technique for irrigation canals that optimizes the actions carried out by human operators. In this paper it is assessed preliminary by means of the numerical model of a reduced scale laboratory irrigation canal located in the facilities of the University of {\'{E}}vora (Portugal). Other control algorithms have also been tested by using a numerical model of the canal and compared with the novel control method: proportional integral control, linear quadratic regulator and centralized model predictive control. The results show that mobile model predictive control offers a performance comparable to that of fully automatic control despite being based exclusively on human operation.},
author = {{L{\'{o}}pez Rodr{\'{i}}guez}, F. and Horv{\'{a}}th, K. and {Garc{\'{i}}a Mart{\'{i}}n}, J. and Maestre, J. M.},
doi = {10.1016/j.ifacol.2017.08.614},
issn = {24058963},
journal = {IFAC-PapersOnLine},
keywords = {Predictive control,automatic control,control applications},
number = {1},
pages = {6570--6575},
title = {{Mobile Model Predictive Control for the {\'{E}}vora irrigation test canal}},
volume = {50},
year = {2017}
}
@article{Puvanathasan2009,
abstract = {A novel, speckle noise reduction algorithm based on the combination of Anisotropic Diffusion (AD) filtering and Interval Type-II fuzzy sets was developed for reducing speckle noise in Optical Coherence Tomography (OCT) images. Unlike regular AD, the new Type-II fuzzy AD algorithm considers the uncertainty in the calculated diffusion coefficient and appropriate adjustments to the coefficient are made. The new algorithm offers flexibility in optimizing the trade-off between two of the image metrics: signal-to-noise (SNR) and Edginess, which are directly related to the structure of the imaged object. Application of the Type-II fuzzy AD algorithm to OCT tomograms acquired in-vivo from a human finger tip and human retina show reduction in the speckle noise with very little edge blurring and about 13 dB and 7 dB image SNR improvement respectively. Comparison with Wiener, Adaptive Lee and regular AD filters, applied to the same images, demonstrates the superior performance of the Type-II fuzzy AD algorithm in terms image SNR and edge preservation metrics improvement.},
author = {Puvanathasan, Prabakar and Bizheva, Kostadinka},
doi = {10.1364/OE.17.000733},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Puvanathasan, Bizheva - 2009 - Interval type-II fuzzy anisotropic diffusion algorithm for speckle noise reduction in optical coherence t.pdf:pdf},
issn = {1094-4087},
journal = {Optics Express},
number = {2},
pages = {733},
pmid = {19158887},
title = {{Interval type-II fuzzy anisotropic diffusion algorithm for speckle noise reduction in optical coherence tomography images}},
url = {https://www.osapublishing.org/oe/abstract.cfm?uri=oe-17-2-733},
volume = {17},
year = {2009}
}
@article{Brock2021,
abstract = {Batch normalization is a key component of most image classification models, but it has many undesirable properties stemming from its dependence on the batch size and interactions between examples. Although recent work has succeeded in training deep ResNets without normalization layers, these models do not match the test accuracies of the best batch-normalized networks, and are often unstable for large learning rates or strong data augmentations. In this work, we develop an adaptive gradient clipping technique which overcomes these instabilities, and design a significantly improved class of Normalizer-Free ResNets. Our smaller models match the test accuracy of an EfficientNet-B7 on ImageNet while being up to 8.7x faster to train, and our largest models attain a new state-of-the-art top-1 accuracy of 86.5%. In addition, Normalizer-Free models attain significantly better performance than their batch-normalized counterparts when finetuning on ImageNet after large-scale pre-training on a dataset of 300 million labeled images, with our best models obtaining an accuracy of 89.2%. Our code is available at https://github.com/deepmind/ deepmind-research/tree/master/nfnets},
archivePrefix = {arXiv},
arxivId = {2102.06171},
author = {Brock, Andrew and De, Soham and Smith, Samuel L. and Simonyan, Karen},
eprint = {2102.06171},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brock et al. - 2021 - High-Performance Large-Scale Image Recognition Without Normalization.pdf:pdf},
keywords = {architecture,backbone,deep learning,neural networks},
mendeley-tags = {architecture,backbone,deep learning,neural networks},
title = {{High-Performance Large-Scale Image Recognition Without Normalization}},
url = {http://arxiv.org/abs/2102.06171 https://github.com/vballoli/nfnets-pytorch},
year = {2021}
}
@article{Meng2016,
author = {Meng, Haijun and Long, Fei and Guo, Lu and Xiao, Yingqun},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Meng et al. - 2016 - Cooperating Base Station Location Optimization Using Genetic Algorithm.pdf:pdf},
isbn = {9781467397148},
keywords = {coordinated transmission,genetic algorithm,lte-a,radio network planning},
pages = {4820--4824},
title = {{Cooperating Base Station Location Optimization Using Genetic Algorithm}},
year = {2016}
}
@article{Lee1995,
abstract = {This paper presents an improved simple genetic algorithm developed for reactive power system planning. Successive linear programming is used to solve operational optimization sub-problems. A new population selection and generation method which makes the use of Benders' cut is presented in this paper. It is desirable to find the optimal solution in few iterations, especially in some test cases where the optimal results are expected to be obtained easily. However, the simple genetic algorithm has failed in finding the solution except through an extensive number of iterations. Different population generation and crossover methods are also tested and discussed. The method has been tested for 6 bus and 30 bus power systems to show its effectiveness. Further improvement for the method is also discussed.},
author = {Lee, K Y and Bai, Xiaomin and Park, Young-Moon},
doi = {10.1109/59.476049},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee, Bai, Park - 1995 - Optimization method for reactive power planning by using a modified simple genetic algorithm.pdf:pdf},
isbn = {0885-8950 VO - 10},
issn = {0885-8950},
journal = {IEEE Transactions on Power Systems},
keywords = {Benders' cut,computer simulation,crossover methods,genetic algorithms,iterations,iterative methods,linear programming,modified simple genetic algorithm,operational optimization sub-problems,optimization method,population generation,population selection,power system analysis computing,power system planning,reactive power,successive linear programming},
number = {4},
pages = {1843--1850},
title = {{Optimization method for reactive power planning by using a modified simple genetic algorithm}},
volume = {10},
year = {1995}
}
@book{Filippi2017,
abstract = {The application of structural and functional magnetic resonance imaging (MRI) techniques in patients with multiple sclerosis (MS) has certainly helped to improve our understanding of the mechanisms responsible for clinical disability and cognitive impairment in this condition.The numerous studies performed in MS patients have also provided many lessons on the structure-function relationships in the human brain, which could be applied to healthy subjects and to patients affected by other neurological conditions. The findings have allowed a better understanding of the processes involved in the loss of function after central nervous system (CNS) damage, and clarified the substrates of specific symptoms (e.g., cognitive impairment and fatigue), which should aid clinical recovery and help in the monitoring of disease progression.In this review, important examples of how the application of different MRI techniques in MS might provide relevant information on the human brain are discussed. These include how damage to strategic white matter tracts can cause symptoms due to a disconnection mechanism and how involvement of a specific brain network, independent of the underlying pathological substrate, might determine certain symptoms. The role of functional and structural plasticity in clinical recovery (following an acute relapse or promoted by rehabilitation) and the mechanisms that might become the target of treatment aimed at function recovery are also considered. The ways in which network- and system-based analysis can reshape current understanding of the brain structure-function relationships are discussed. Finally, there is speculation about the relevance of inherited or acquired factors, such as age, comorbidity, brain reserve and cognitive reserve, which are likely to influence the relation between CNS damage and disease clinical manifestations.},
author = {Filippi, Massimo and Preziosa, Paolo and Rocca, Maria A.},
booktitle = {NeuroImage},
doi = {10.1016/j.neuroimage.2017.09.021},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Filippi, Preziosa, Rocca - 2017 - Brain mapping in multiple sclerosis Lessons learned about the human brain.pdf:pdf},
isbn = {3902264330},
issn = {10959572},
keywords = {Brain networks,Diffusion tensor MRI,Disconnection syndrome,Functional MRI,Multiple sclerosis,Neuroplasticity,Symptoms},
pmid = {28917696},
publisher = {Elsevier Inc.},
title = {{Brain mapping in multiple sclerosis: Lessons learned about the human brain}},
url = {http://dx.doi.org/10.1016/j.neuroimage.2017.09.021},
year = {2017}
}
@article{Sarapas2017,
abstract = {Although researchers have long hypothesized a relationship between attention and anxiety, theoretical and empirical accounts of this relationship have conflicted. We attempted to resolve these conflicts by examining relationships of attentional abilities with responding to predictable and unpredictable threat – related but distinct motivational process implicated in a number of anxiety disorders. Eighty-one individuals completed a behavioral task assessing efficiency of three components of attention – alerting, orienting, and executive control (Attention Network Test - Revised). We also assessed startle responding during anticipation of both predictable, imminent threat (of mild electric shock) and unpredictable contextual threat. Faster alerting and slower disengaging from non-emotional attention cues were related to heightened responding to unpredictable threat, whereas poorer executive control of attention was related to heightened responding to predictable threat. This double dissociation helps to integrate models of attention and anxiety and may be informative for treatment development.},
author = {Sarapas, Casey and Weinberg, Anna and Langenecker, Scott A. and Shankman, Stewart A.},
doi = {10.1016/j.bandc.2016.09.012},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sarapas et al. - 2017 - Relationships among attention networks and physiological responding to threat.pdf:pdf},
isbn = {0278-2626},
issn = {10902147},
journal = {Brain and Cognition},
keywords = {Anxiety,Attention,Cognition,Executive functioning,Fear,Predictability,Startle},
pages = {63--72},
pmid = {27816781},
publisher = {Elsevier Inc.},
title = {{Relationships among attention networks and physiological responding to threat}},
url = {http://dx.doi.org/10.1016/j.bandc.2016.09.012},
volume = {111},
year = {2017}
}
@article{Guan2018,
abstract = {Intelligent vehicles need to detect new classes of traffic objects while keeping the performance of old ones. Deep convolution neural network (DCNN) based detector has shown superior performance, however, DCNN is ill-equipped for incremental learning, i.e., a DCNN based vehicle detector trained on traffic sign dataset will catastrophic forget how to detect vehicles. In this paper, we propose a novel method to alleviate this problem, our key insight is that the original class of objects also appears in new task data, by utilizing these objects, our method effectively keeps the detection accuracy of original models while incremental learning to detect new classes of objects. Detailed experiments on PASCAL VOC dataset and TSD-max database verified the effectiveness of our method.},
author = {Guan, Linting and Wu, Yan and Zhao, Junqiao and Ye, Chen},
doi = {10.1109/IVS.2018.8500673},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guan et al. - 2018 - Learn to Detect Objects Incrementally.pdf:pdf},
isbn = {9781538644522},
journal = {IEEE Intelligent Vehicles Symposium, Proceedings},
keywords = {continual learning,incremental learning,object detection},
mendeley-tags = {continual learning,incremental learning,object detection},
number = {Iv},
pages = {403--408},
publisher = {IEEE},
title = {{Learn to Detect Objects Incrementally}},
volume = {2018-June},
year = {2018}
}
@inproceedings{Aljundi2019d,
author = {Aljundi, Rahaf and Lin, Min and Goujaud, Baptiste and Bengio, Yoshua},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {Wallach, H and Larochelle, H and Beygelzimer, A and d\textquotesingle Alch{\'{e}}-Buc, F and Fox, E and Garnett, R},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aljundi et al. - 2019 - Gradient Based Sample Selection For Online Continual Learning.pdf:pdf},
keywords = {[cifar],[mnist]},
mendeley-tags = {[cifar],[mnist]},
pages = {11816--11825},
publisher = {Curran Associates, Inc.},
title = {{Gradient Based Sample Selection For Online Continual Learning}},
url = {http://papers.nips.cc/paper/9354-gradient-based-sample-selection-for-online-continual-learning.pdf},
year = {2019}
}
@article{Revolution2007,
author = {Revolution, The Industrial},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Revolution - 2007 - Chapter 1 The Industrial Revolution.pdf:pdf},
pages = {1--6},
title = {{Chapter 1 The Industrial Revolution}},
year = {2007}
}
@article{Cells1889,
author = {Cells, Fuel},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cells - 1889 - Fuel Cells and Hydrogen History of Fuel Cells Polymer Electrolyte Membrane Fuel Cells ( PEMFCs ).pdf:pdf},
title = {{Fuel Cells and Hydrogen History of Fuel Cells Polymer Electrolyte Membrane Fuel Cells ( PEMFCs )}},
year = {1889}
}
@article{Mahdavipour2016,
abstract = {Image processing technique (IPT) is a computational technique which is a simple, wide and great for many purposes. In this paper, we used IPT to obtain plasma source such as sun and sunspot temperatures. Sun image was taken by a telescope and DSLR camera and imported to MATLAB software. Using the IPT, we cropped two areas and evaluated their RGB values, using a code which was written according to Python software. We computed wavelengths and then by substituting wavelengths in Wien's law, we obtained sun's surface and sunspot temperature's. The temperature errors for surface and sunspot were 0.57% and 13% respectively.},
author = {Mahdavipour, B. and Hatami, A. and {Salar Elahi}, A.},
doi = {10.1016/j.rinp.2016.11.042},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mahdavipour, Hatami, Salar Elahi - 2016 - Results on plasma temperature measurement using an image processing technique.pdf:pdf},
issn = {22113797},
journal = {Results in Physics},
keywords = {Image processing technique,Plasma temperature},
pages = {1008--1011},
publisher = {The Author},
title = {{Results on plasma temperature measurement using an image processing technique}},
url = {http://dx.doi.org/10.1016/j.rinp.2016.11.042},
volume = {6},
year = {2016}
}
@article{CHRISTIAN2002,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {CHRISTIAN, J.W.},
doi = {10.1016/B978-008044019-4/50031-3},
eprint = {arXiv:1011.1669v3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/CHRISTIAN - 2002 - Shape Memory Alloys.pdf:pdf},
isbn = {978-0-387-47684-1},
issn = {978-953-307-106-0},
journal = {The Theory of Transformations in Metals and Alloys},
pages = {1102--1113},
pmid = {25246403},
title = {{Shape Memory Alloys}},
url = {http://linkinghub.elsevier.com/retrieve/pii/B9780080440194500313},
year = {2002}
}
@article{He2017,
abstract = {We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework. We show top results in all three tracks of the COCO suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without bells and whistles, Mask R-CNN outperforms all existing, single-model entries on every task, including the COCO 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code has been made available at: https://github.com/facebookresearch/Detectron},
archivePrefix = {arXiv},
arxivId = {arXiv:1703.06870v3},
author = {He, Kaiming and Gkioxari, Georgia and Dollar, Piotr and Girshick, Ross},
doi = {10.1109/ICCV.2017.322},
eprint = {arXiv:1703.06870v3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/He et al. - 2017 - Mask R-CNN.pdf:pdf},
isbn = {9781538610329},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {2980--2988},
title = {{Mask R-CNN}},
volume = {2017-Octob},
year = {2017}
}
@inproceedings{Qu2020,
abstract = {This paper studies learning logic rules for reasoning on knowledge graphs. Logic rules provide interpretable explanations when used for prediction as well as being able to generalize to other tasks, and hence are critical to learn. Existing methods either suffer from the problem of searching in a large search space (e.g., neural logic programming) or ineffective optimization due to sparse rewards (e.g., techniques based on reinforcement learning). To address these limitations, this paper proposes a probabilistic model called RNNLogic. RNNLogic treats logic rules as a latent variable, and simultaneously trains a rule generator as well as a reasoning predictor with logic rules. We develop an EM-based algorithm for optimization. In each iteration, the reasoning predictor is updated to explore some generated logic rules for reasoning. Then in the E-step, we select a set of high-quality rules from all generated rules with both the rule generator and reasoning predictor via posterior inference; and in the M-step, the rule generator is updated with the rules selected in the E-step. Experiments on four datasets prove the effectiveness of RNNLogic.},
archivePrefix = {arXiv},
arxivId = {2010.04029},
author = {Qu, Meng and Chen, Junkun and Xhonneux, Louis Pascal and Bengio, Yoshua and Tang, Jian},
booktitle = {Iclr 2021},
eprint = {2010.04029},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qu et al. - 2020 - Rnnlogic Learning logic rules for reasoning on knowledge graphs.pdf:pdf},
issn = {23318422},
keywords = {knowledge graphs,logic,neural networks,reasoning},
mendeley-tags = {knowledge graphs,logic,neural networks,reasoning},
pages = {1--19},
title = {{Rnnlogic: Learning logic rules for reasoning on knowledge graphs}},
year = {2020}
}
@article{Sapna2012a,
abstract = {Data Mining aims at discovering knowledge out of data and presenting it in a form that is easily compressible to humans. Data Mining represents a process developed to examine large amounts of data routinely collected. The term also refers to a collection of tools used to perform the process. One of the useful applications in the field of medicine is the incurable chronic disease diabetes. Data Mining algorithm is used for testing the accuracy in predicting diabetic status. Fuzzy Systems are been used for solving a wide range of problems in different application domain and Genetic Algorithm for designing. Fuzzy systems allows in introducing the learning and adaptation capabilities. Neural Networks are efficiently used for learning membership functions. Diabetes occurs throughout the world, but Type 2 is more common in the most developed countries. The greater increase in prevalence is however expected in Asia and Africa where most patients will likely be found by 2030. This paper is proposed on the Levenberg – Marquardt algorithm which is specifically designed to minimize sum-of-square error functions. Levernberg-Marquardt algorithm gives the best performance in the prediction of diabetes compared to any other backpropogation algorithm.},
author = {Sapna, S},
doi = {10.5121/csit.2012.2438},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sapna - 2012 - Backpropagation Learning Algorithm Based on Levenberg Marquardt Algorithm.pdf:pdf},
isbn = {9781921987052},
journal = {Computer Science & Information Technology ( CS & IT )},
pages = {393--398},
title = {{Backpropagation Learning Algorithm Based on Levenberg Marquardt Algorithm}},
url = {http://www.airccj.org/CSCP/vol2/csit2438.pdf},
year = {2012}
}
@article{Kumar2013,
author = {Kumar, Gagandeep},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kumar - 2013 - Energy Efficient Clustering Scheme Based On Grid Optimization using Genetic Algorithm for Wireless Sensor Networks.pdf:pdf},
keywords = {-wireless sensor networks,ee-leach,ee-leach-mimo scheme,energy efficient clustering,grid optimization,leach,leach-,mimo,network lifetime},
pages = {4--8},
title = {{Energy Efficient Clustering Scheme Based On Grid Optimization using Genetic Algorithm for Wireless Sensor Networks}},
year = {2013}
}
@article{Moritz2017,
abstract = {The imputeTS package specializes on univariate time series imputation. It offers multiple state-of-the-art imputation algorithm implementations along with plotting functions for time series missing data statistics. While imputation in general is a well-known problem and widely covered by R packages, finding packages able to fill missing values in univariate time series is more complicated. The reason for this lies in the fact, that most imputation algorithms rely on inter-attribute correlations, while univariate time series imputation instead needs to employ time dependencies. This paper provides an introduction to the imputeTS package and its provided algorithms and tools. Furthermore, it gives a short overview about univariate time series imputation in R.},
author = {Moritz, Steffen and Bartz-Beielstein, Thomas},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Moritz, Bartz-Beielstein - 2017 - imputeTS Time Series Missing Value Imputation in R.pdf:pdf},
issn = {20734859},
journal = {The R Journal},
number = {1},
pages = {207--218},
title = {{imputeTS: Time Series Missing Value Imputation in R}},
url = {https://cran.r-project.org/web/packages/imputeTS/vignettes/imputeTS-Time-Series-Missing-Value-Imputation-in-R.pdf},
volume = {9},
year = {2017}
}
@article{Rifkin2008,
abstract = {... a world in which people can live well and within the limits of the planet.” —Bj{\"{o}}rn Stigson, president of the World Business Council for Sustainable Development “As the chairman of a global real estate services company, I'm convinced that Jeremy Rifkin's vision of rethinking ...},
author = {Rifkin, J.},
doi = {10.1049/et:20080718},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rifkin - 2008 - The third industrial revolution.pdf:pdf},
isbn = {978-0230341975},
issn = {1750-9637},
journal = {Engineering & Technology},
number = {7},
pages = {26--27},
title = {{The third industrial revolution}},
url = {http://digital-library.theiet.org/content/journals/10.1049/et_20080718},
volume = {3},
year = {2008}
}
@article{Zenke2017,
abstract = {While deep learning has led to remarkable advances across diverse applications, it struggles in domains where the data distribution changes over the course of learning. In stark contrast, biological neural networks continually adapt to changing domains, possibly by leveraging complex molecular machinery to solve many tasks simultaneously. In this study, we introduce intelligent synapses that bring some of this biological complexity into artificial neural networks. Each synapse accumulates task relevant information over time, and exploits this information to rapidly store new memories without forgetting old ones. We evaluate our approach on continual learning of classification tasks, and show that it dramatically reduces forgetting while maintaining computational efficiency.},
archivePrefix = {arXiv},
arxivId = {1703.04200},
author = {Zenke, Friedemann and Poole, Ben and Ganguli, Surya},
eprint = {1703.04200},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zenke, Poole, Ganguli - 2017 - Continual learning through synaptic intelligence.pdf:pdf},
isbn = {9781510855144},
journal = {34th International Conference on Machine Learning, ICML 2017},
pages = {6072--6082},
title = {{Continual learning through synaptic intelligence}},
volume = {8},
year = {2017}
}
@article{Figueiredo,
author = {Figueiredo, M.a.T. and Nowak, R.D.},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Figueiredo, Nowak - Unknown - An EM Algorithm for Wavelet-Based Image Restoration.pdf:pdf},
journal = {Ieee},
title = {{An EM Algorithm for Wavelet-Based Image Restoration}}
}
@article{Mudronja2017,
author = {Mudronja, Luka and Mati{\'{c}}, Petar and Katalini{\'{c}}, Marko},
doi = {10.7225/toms.v06.n01.00x},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mudronja, Mati{\'{c}}, Katalini{\'{c}} - 2017 - Data-Based Modelling of Significant Wave Height in the Adriatic Sea.pdf:pdf},
issn = {18483313},
pages = {1--9},
title = {{Data-Based Modelling of Significant Wave Height in the Adriatic Sea}},
year = {2017}
}
@article{Rosca2020,
abstract = {How sensitive should machine learning models be to input changes? We tackle the question of model smoothness and show that it is a useful inductive bias which aids generalization, adversarial robustness, generative modeling and reinforcement learning. We explore current methods of imposing smoothness constraints and observe they lack the flexibility to adapt to new tasks, they don't account for data modalities, they interact with losses, architectures and optimization in ways not yet fully understood. We conclude that new advances in the field are hinging on finding ways to incorporate data, tasks and learning into our definitions of smoothness.},
archivePrefix = {arXiv},
arxivId = {2012.07969},
author = {Rosca, Mihaela and Weber, Theophane and Gretton, Arthur and Mohamed, Shakir},
eprint = {2012.07969},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rosca et al. - 2020 - A case for new neural network smoothness constraints.pdf:pdf},
keywords = {constraint,inductive bias},
mendeley-tags = {constraint,inductive bias},
number = {1},
pages = {1--13},
title = {{A case for new neural network smoothness constraints}},
url = {http://arxiv.org/abs/2012.07969},
year = {2020}
}
@article{Brinegar2014,
author = {Brinegar, Kathleen and Weddle, Elyse},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brinegar, Weddle - 2014 - The correlation between makeup usage and self-esteem.pdf:pdf},
journal = {Full Thesis},
number = {1},
pages = {1--16},
title = {{The correlation between makeup usage and self-esteem}},
url = {http://vault.hanover.edu/$\sim$altermattw/courses/344/papers/2014/BrinegarWeddle.pdf},
volume = {344},
year = {2014}
}
@article{Klenk2013,
abstract = {Cross-domain analogies are a powerful method for learning new domains. This paper extends the Domain Transfer via Analogy (DTA) method with persistent mappings, correspondences between domains that are incrementally built up as a cognitive system gains experience with a new domain. DTA uses analogies between pairs of textbook example problems, or worked solutions, to create a domain mapping between a familiar and a new domain. This mapping enables the initialization of a new domain theory. Another analogy is then made between the domain theories themselves, providing additional conjectures about the new domain. After these conjectures are verified, the successful mappings are stored as persistent mappings to constrain future analogies between the domains. We show that DTA plus persistent mappings enables a Companion, the first structure mapping cognitive architecture, to learn the equation schemas and control knowledge necessary to solve problems in three domains (rotational mechanics, electricity, and heat) by analogy with linear mechanics. We provide a detailed analysis categorizing transfer failures. As with people, the most difficult step in cross-domain analogy is identifying an appropriate example. Once an analogous example has been found, DTA successfully transfers the domain knowledge necessary to solve the problem in the new domain 78% of the time. Furthermore, we illustrate how persistent mappings assist in retrieval of analogous examples and overcoming two types of mapping failures. {\textcopyright} 2012 Elsevier B.V. All rights reserved.},
author = {Klenk, Matthew and Forbus, Ken},
doi = {10.1016/j.artint.2012.11.002},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Klenk, Forbus - 2013 - Exploiting persistent mappings in cross-domain analogical learning of physical domains.pdf:pdf},
isbn = {0004-3702},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {Analogical learning,Cognitive systems,Cross-domain analogy,Physics problem-solving},
pages = {398--417},
publisher = {Elsevier B.V.},
title = {{Exploiting persistent mappings in cross-domain analogical learning of physical domains}},
url = {http://dx.doi.org/10.1016/j.artint.2012.11.002},
volume = {195},
year = {2013}
}
@article{Ding2020,
abstract = {Neural networks have achieved success in a wide array of perceptual tasks, but it is often stated that they are incapable of solving tasks that require higher-level reasoning. Two new task domains, CLEVRER and CATER, have recently been developed to focus on reasoning, as opposed to perception, in the context of spatio-temporal interactions between objects. Initial experiments on these domains found that neuro-symbolic approaches, which couple a logic engine and language parser with a neural perceptual front-end, substantially outperform fully-learned distributed networks, a finding that was taken to support the above thesis. Here, we show on the contrary that a fully-learned neural network with the right inductive biases can perform substantially better than all previous neural-symbolic models on both of these tasks, particularly on questions that most emphasize reasoning over perception. Our model makes critical use of both self-attention and learned "soft" object-centric representations, as well as BERT-style semi-supervised predictive losses. These flexible biases allow our model to surpass the previous neuro-symbolic state-of-the-art using less than 60% of available labelled data. Together, these results refute the neuro-symbolic thesis laid out by previous work involving these datasets, and they provide evidence that neural networks can indeed learn to reason effectively about the causal, dynamic structure of physical events.},
archivePrefix = {arXiv},
arxivId = {2012.08508},
author = {Ding, David and Hill, Felix and Santoro, Adam and Botvinick, Matt},
eprint = {2012.08508},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ding et al. - 2020 - Object-based attention for spatio-temporal reasoning Outperforming neuro-symbolic models with flexible distributed.pdf:pdf},
keywords = {reasoning,spatio-temporal},
mendeley-tags = {reasoning,spatio-temporal},
title = {{Object-based attention for spatio-temporal reasoning: Outperforming neuro-symbolic models with flexible distributed architectures}},
url = {http://arxiv.org/abs/2012.08508},
year = {2020}
}
@article{Krejci2017,
abstract = {Proper formulas for obtaining the fuzzy maximal eigenvalue and the corresponding fuzzy maximal eigenvector of a fuzzy pairwise comparison matrix are proposed in this paper. First, the formulas for obtaining the fuzzy maximal eigenvalue of a fuzzy pairwise comparison matrix proposed by Csutora & Buckley (2001) and by Ishizaka (2014) are reviewed, and the flaws in their formulas regarding the violation of the reciprocity of pairwise comparisons are pointed out. New formulas for obtaining the fuzzy maximal eigenvalue preserving the reciprocity of pairwise comparisons are then proposed. After, a fuzzy extension of Saaty's Consistency Index and Consistency Ratio is introduced in order to verify an acceptable level of inconsistency of a fuzzy pairwise comparison matrix. Further, the methods for obtaining the fuzzy maximal eigenvector corresponding to the fuzzy maximal eigenvalue of a fuzzy pairwise comparison matrix proposed by Wang & Chin (2006) and by Ishizaka (2014) are reviewed. The flaws in Ishizaka's method are pointed out, and Wang & Chin's method is studied and modified in order to preserve the reciprocity of pairwise comparisons. The fuzzy maximal eigenvalues and the corresponding fuzzy maximal eigenvectors obtained by the new formulas are confronted with those obtained by methods proposed by Csutora & Buckley (2001), Wang & Chin (2006) and Ishizaka (2014), and three numerical examples are given for better illustration.},
author = {Krej{\v{c}}{\'{i}}, Jana},
doi = {10.1016/j.fss.2016.03.006},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krej{\v{c}}{\'{i}} - 2017 - Fuzzy eigenvector method for obtaining normalized fuzzy weights from fuzzy pairwise comparison matrices.pdf:pdf},
issn = {01650114},
journal = {Fuzzy Sets and Systems},
keywords = {Constrained fuzzy arithmetic,Fuzzy AHP,Fuzzy maximal eigenvalue,Fuzzy maximal eigenvector,Fuzzy pairwise comparison matrix,Reciprocity},
pages = {26--43},
title = {{Fuzzy eigenvector method for obtaining normalized fuzzy weights from fuzzy pairwise comparison matrices}},
volume = {315},
year = {2017}
}
@article{Khan2021a,
abstract = {Although depth extraction with passive sensors has seen remarkable improvement with deep learning, these approaches may fail to obtain correct depth if they are exposed to environments not observed during training. Online adaptation, where the neural network trains while deployed, with unsupervised learning provides a convenient solution. However, online adaptation causes a neural network to forget the past. Thus, past training is wasted and the network is not able to provide good results if it observes past scenes. This work deals with practical online-adaptation where the input is online and temporally-correlated, and training is completely unsupervised. Regularization and replay-based methods without task boundaries are proposed to avoid catastrophic forgetting while adapting to online data. Experiments are performed on different datasets with both structure-from-motion and stereo. Results of forgetting as well as adaptation are provided, which are superior to recent methods. The proposed approach is more inline with the artificial general intelligence paradigm as the neural network learns the scene where it is deployed without any supervision (target labels and tasks) and without forgetting about the past. Code is available at github.com/umarKarim/cou_stereo and github.com/umarKarim/cou_sfm.},
archivePrefix = {arXiv},
arxivId = {2103.00369},
author = {Khan, Muhammad Umar Karim},
eprint = {2103.00369},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khan - 2021 - Towards Continual, Online, Unsupervised Depth.pdf:pdf},
keywords = {continual learning,depth estimation,incremental learning,unsupervised learning},
mendeley-tags = {continual learning,depth estimation,incremental learning,unsupervised learning},
title = {{Towards Continual, Online, Unsupervised Depth}},
url = {http://arxiv.org/abs/2103.00369},
year = {2021}
}
@article{Phaiboonnugulkij2013,
abstract = {The purpose of this study was to compare the differences in strategies used in an online language for specific purposes (LSP) speaking test in tourism with two proficiency groups of students, and to investigate the strategies that should be used for low-proficiency students to improve their LSP speaking ability. The Web-based Speaking Test in English for Tourism (WBST-EFT) and a coding scheme were used as research instruments. Descriptive statistics, the Man-Whitney U test, percentages, and qualitative content analysis from verbal reports were used in the data analysis. The findings showed that the two proficiency groups significantly and differently reported cognitive and metacognitive strategies for this LSP online speaking test. The qualitative results indicated that high-proficiency students used more complex details in all of the sub-strategies than the low-proficiency students. Low-proficiency students should be trained to effectively employ these strategies to improve their LSP speaking ability through the use of an online LSP speaking test that has been considered as an effective tool and that provides an opportunity for students to self-assess and self-practice their performances. Both strategies and online speaking tools can be used with a large number of students to develop LSP speaking ability in tourism.},
author = {Phaiboonnugulkij, Malinee and Prapphal, Kanchana},
doi = {10.5539/elt.v6n9p19},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Phaiboonnugulkij, Prapphal - 2013 - Online speaking strategy assessment for improving speaking ability in the area of language for speci.pdf:pdf},
issn = {19164742},
journal = {English Language Teaching},
keywords = {English for tourism speaking performance,Language for specific purposes,Online speaking test,Speaking strategies},
number = {9},
pages = {19--29},
title = {{Online speaking strategy assessment for improving speaking ability in the area of language for specific purposes: The case of tourism}},
volume = {6},
year = {2013}
}
@article{Vinyals2015,
abstract = {We introduce a new neural architecture to learn the conditional probability of an output sequence with elements that are discrete tokens corresponding to positions in an input sequence. Such problems cannot be trivially addressed by existent approaches such as sequence-to-sequence [1] and Neural Turing Machines [2], because the number of target classes in each step of the output depends on the length of the input, which is variable. Problems such as sorting variable sized sequences, and various combinatorial optimization problems belong to this class. Our model solves the problem of variable size output dictionaries using a recently proposed mechanism of neural attention. It differs from the previous attention attempts in that, instead of using attention to blend hidden units of an encoder to a context vector at each decoder step, it uses attention as a pointer to select a member of the input sequence as the output. We call this architecture a Pointer Net (Ptr-Net). We show Ptr-Nets can be used to learn approximate solutions to three challenging geometric problems - finding planar convex hulls, computing Delaunay triangulations, and the planar Travelling Salesman Problem - using training examples alone. Ptr-Nets not only improve over sequence-to-sequence with input attention, but also allow us to generalize to variable size output dictionaries. We show that the learnt models generalize beyond the maximum lengths they were trained on. We hope our results on these tasks will encourage a broader exploration of neural learning for discrete problems.},
archivePrefix = {arXiv},
arxivId = {1506.03134},
author = {Vinyals, Oriol and Fortunato, Meire and Jaitly, Navdeep},
eprint = {1506.03134},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vinyals, Fortunato, Jaitly - 2015 - Pointer networks.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
keywords = {architecture,neural networks},
mendeley-tags = {architecture,neural networks},
pages = {2692--2700},
title = {{Pointer networks}},
url = {https://github.com/sblayush/Tensorflow-Attention},
volume = {2015-Janua},
year = {2015}
}
@article{Kurochkin2020,
abstract = {Time series modelling is essential for solving tasks such as predictive maintenance, quality control and optimisation. Deep learning is widely used for solving such problems. When managing complex manufacturing process with neural networks, engineers need to know why machine learning model made specific decision and what are possible outcomes of following model recommendation. In this paper we develop framework for capturing and explaining temporal dependencies in time series data using deep neural networks and test it on various synthetic and real world datasets.},
archivePrefix = {arXiv},
arxivId = {2011.07551},
author = {Kurochkin, Alexey},
eprint = {2011.07551},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kurochkin - 2020 - Discovering long term dependencies in noisy time series data using deep learning.pdf:pdf},
journal = {arXiv},
keywords = {time series},
mendeley-tags = {time series},
month = {nov},
pages = {1--12},
title = {{Discovering long term dependencies in noisy time series data using deep learning}},
url = {https://github.com/KurochkinAlexey/discovering-long-term-dependencies-in-noisy-time-series-data http://arxiv.org/abs/2011.07551},
year = {2020}
}
@article{Konkle2012,
abstract = {When we recognize an object, do we automatically know how big it is in the world? We employed a Stroop-like paradigm, in which two familiar objects were presented at different visual sizes on the screen. Observers were faster to indicate which was bigger or smaller on the screen when the real-world size of the objects was congruent with the visual size than when it was incongruent-demonstrating a familiar-size Stroop effect. Critically, the real-world size of the objects was irrelevant for the task. This Stroop effect was also present when only one item was present at a congruent or incongruent visual size on the display. In contrast, no Stroop effect was observed for participants who simply learned a rule to categorize novel objects as big or small. These results show that people access the familiar size of objects without the intention of doing so, demonstrating that real-world size is an automatic property of object representation. {\textcopyright} 2012 American Psychological Association.},
author = {Konkle, Talia and Oliva, Aude},
doi = {10.1037/a0028294},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Konkle, Oliva - 2012 - A familiar-size Stroop effect Real-world size is an automatic property of object representation.pdf:pdf},
issn = {00961523},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
keywords = {Familiar size,Object representation,Real-world size,Stroop effect,Visual size},
number = {3},
pages = {561--569},
pmid = {22545601},
title = {{A familiar-size Stroop effect: Real-world size is an automatic property of object representation}},
volume = {38},
year = {2012}
}
@article{Schneider2021,
abstract = {When engineers train deep learning models, they are very much "flying blind". Commonly used approaches for real-time training diagnostics, such as monitoring the train/test loss, are limited. Assessing a network's training process solely through these performance indicators is akin to debugging software without access to internal states through a debugger. To address this, we present Cockpit, a collection of instruments that enable a closer look into the inner workings of a learning machine, and a more informative and meaningful status report for practitioners. It facilitates the identification of learning phases and failure modes, like ill-chosen hyperparameters. These instruments leverage novel higher-order information about the gradient distribution and curvature, which has only recently become efficiently accessible. We believe that such a debugging tool, which we open-source for PyTorch, represents an important step to improve troubleshooting the training process, reveal new insights, and help develop novel methods and heuristics.},
archivePrefix = {arXiv},
arxivId = {2102.06604},
author = {Schneider, Frank and Dangel, Felix and Hennig, Philipp},
eprint = {2102.06604},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schneider, Dangel, Hennig - 2021 - Cockpit A Practical Debugging Tool for Training Deep Neural Networks.pdf:pdf},
keywords = {ml debugging,mlops,tools},
mendeley-tags = {ml debugging,mlops,tools},
number = {Section 3},
title = {{Cockpit: A Practical Debugging Tool for Training Deep Neural Networks}},
url = {http://arxiv.org/abs/2102.06604 https://github.com/ahthie7u/cockpit},
year = {2021}
}
@article{Jaffe1954a,
abstract = {Abstract unavailable.},
author = {Jaffe, B. and Roth, R. S. and Marzullo, S.},
doi = {10.1063/1.1721741},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jaffe, Roth, Marzullo - 1954 - Piezoelectric properties of Lead zirconate-Lead titanate solid-solution ceramics 8.pdf:pdf},
isbn = {0021-8979},
issn = {00218979},
journal = {Journal of Applied Physics},
number = {6},
pages = {809--810},
title = {{Piezoelectric properties of Lead zirconate-Lead titanate solid-solution ceramics [8]}},
volume = {25},
year = {1954}
}
@article{Sagonas2017,
abstract = {The unconstrained acquisition of facial data in real-world conditions may result in face images with signif-icant pose variations, illumination changes, and occlusions, affecting the performance of facial landmark localization and recognition methods. In this paper, a novel method, robust to pose, illumination variations, and occlusions is pro-posed for joint face frontalization and landmark localization. Unlike the state-of-the-art methods for landmark localiza-tion and pose correction, where large amount of manually annotated images or 3D facial models are required, the pro-posed method relies on a small set of frontal images only. By observing that the frontal facial image of both humans and animals, is the one having the minimum rank of all different poses, a model which is able to jointly recover the frontalized version of the face as well as the facial landmarks is devised. To this end, a suitable optimization problem is solved, con-cerning minimization of the nuclear norm (convex surrogate of the rank function) and the matrix 1 norm accounting for occlusions. The proposed method is assessed in frontal view reconstruction of human and animal faces, landmark localization, pose-invariant face recognition, face verifica-tion in unconstrained conditions, and video inpainting by conducting experiment on 9 databases. The experimental results demonstrate the effectiveness of the proposed method in comparison to the state-of-the-art methods for the target problems.},
author = {Sagonas, Christos and Panagakis, Yannis and Zafeiriou, Stefanos and Pantic, Maja},
doi = {10.1007/s11263-016-0920-7},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sagonas et al. - 2017 - Robust Statistical Frontalization of Human and Animal Faces.pdf:pdf},
issn = {15731405},
journal = {International Journal of Computer Vision},
keywords = {Face recognition,Landmark localization,Low rank,Pose normalization,Sparsity},
number = {2},
pages = {270--291},
publisher = {Springer US},
title = {{Robust Statistical Frontalization of Human and Animal Faces}},
volume = {122},
year = {2017}
}
@article{University2010,
author = {University, Wayne State},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/University - 2010 - Behavioral Interview Techniques – The STAR Approach How to Behave in a Behavior-Based Interview.pdf:pdf},
title = {{Behavioral Interview Techniques – The STAR Approach How to Behave in a Behavior-Based Interview}},
year = {2010}
}
@article{AlvarezFernandez2018,
abstract = {Whether or not alternative fuel vehicles (AFVs) will finally find a place in the global mass-market or even will dominate the vehicle segment will depend on several success factors: reduction of customer anxiety, fast recharging, better charging infrastructure, environmental justice policies and some others. Current technological advances in battery electric vehicles and hydrogen fuelled electric vehicles could represent a hopefully option in the near future. Nevertheless, and until electric/hydrogen technological barriers are not torn down, both power architecture do not have an opportunity to be fully introduced in the vehicle market. In this paper, the authors present a powertrain architecture concept based in current fossil fuel extender range, but changing it to a hydrogen fuel cell stack system that works as range extender. The objective is to probe how optimization techniques, by the inclusion of genetic algorithms, could be a crucial help when planning the fuel consumption/selection. The paper ambition is to highlight the possibilities of this powertrain and its appropriated management to allow hydrogen become an energy carrier feasible today in the automotive world.},
author = {{{\'{A}}lvarez Fern{\'{a}}ndez}, Roberto and {Corbera Caraballo}, Sergio and {Beltr{\'{a}}n Cilleruelo}, Fernando and Lozano, J. Antonio},
doi = {10.1016/j.rser.2017.08.047},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/{\'{A}}lvarez Fern{\'{a}}ndez et al. - 2018 - Fuel optimization strategy for hydrogen fuel cell range extender vehicles applying genetic algorithm.pdf:pdf},
issn = {18790690},
journal = {Renewable and Sustainable Energy Reviews},
keywords = {Electric vehicle,Extended range,Fuel cell,Genetic algorithm,Optimization,Simulation},
number = {April 2017},
pages = {655--668},
publisher = {Elsevier Ltd},
title = {{Fuel optimization strategy for hydrogen fuel cell range extender vehicles applying genetic algorithms}},
url = {http://dx.doi.org/10.1016/j.rser.2017.08.047},
volume = {81},
year = {2018}
}
@inproceedings{Chaudhry2019a,
abstract = {In lifelong learning, the learner is presented with a sequence of tasks, incrementally building a data-driven prior which may be leveraged to speed up learning of a new task. In this work, we investigate the efficiency of current lifelong approaches, in terms of sample complexity, computational and memory cost. Towards this end, we first introduce a new and a more realistic evaluation protocol, whereby learners observe each example only once and hyper-parameter selection is done on a small and disjoint set of tasks, which is not used for the actual learning experience and evaluation. Second, we introduce a new metric measuring how quickly a learner acquires a new skill. Third, we propose an improved version of GEM (Lopez-Paz & Ranzato, 2017), dubbed Averaged GEM (A-GEM), which enjoys the same or even better performance as GEM, while being almost as computationally and memory efficient as EWC (Kirkpatrick et al., 2016) and other regularization-based methods. Finally, we show that all algorithms including A-GEM can learn even more quickly if they are provided with task descriptors specifying the classification tasks under consideration. Our experiments on several standard lifelong learning benchmarks demonstrate that A-GEM has the best trade-off between accuracy and efficiency.1},
archivePrefix = {arXiv},
arxivId = {1812.00420},
author = {Chaudhry, Arslan and Marc'Aurelio, Ranzato and Rohrbach, Marcus and Elhoseiny, Mohamed},
booktitle = {7th International Conference on Learning Representations, ICLR 2019},
eprint = {1812.00420},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chaudhry et al. - 2019 - Efficient lifelong learning with A-GEM.pdf:pdf},
pages = {1--20},
title = {{Efficient lifelong learning with A-GEM}},
year = {2019}
}
@article{Shekarian2017,
abstract = {Over the years since the advancement of inventory management and fuzzy set theories, a vast number of studies have been published to integrate these concepts. Nonetheless, no comprehensive and systematic literature review can be found that analyzed the studies in this research stream. It motivated us to conduct this survey as a systematic and comprehensive review in the field of fuzzy inventory management to identify major achievements attained so far and shed light on future directions. First, the earlier review papers are presented to reveal the necessity of this study, and then methodology applied in collecting sample papers is described, followed by an in-depth analysis of the papers. Totally, a sample of 210 papers is identified and classified according to the common characteristics of the models. Several aspects of the models are assessed that led to identification of some areas overlooked by researchers so far.},
author = {Shekarian, Ehsan and Kazemi, Nima and Abdul-Rashid, Salwa Hanim and Olugu, Ezutah Udoncy},
doi = {10.1016/j.asoc.2017.01.013},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shekarian et al. - 2017 - Fuzzy inventory models A comprehensive review.pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {EOQ,EPQ,Fuzzy set theory,Inventory,Review},
pages = {588--621},
publisher = {Elsevier B.V.},
title = {{Fuzzy inventory models: A comprehensive review}},
url = {http://dx.doi.org/10.1016/j.asoc.2017.01.013},
volume = {55},
year = {2017}
}
@article{PutraAdityaRiska;Candradewi2017,
author = {{Putra, Aditya Riska; Candradewi}, Ika},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Putra, Aditya Riska Candradewi - 2017 - Deteksi Ketersediaan Slot Parkir Berbasis Pengolahan Citra Digital Menggunakan Metode Histogram.pdf:pdf},
journal = {Ijeis},
keywords = {Candradewi Ika,Putra Aditya Riska},
number = {1},
pages = {13--24},
title = {{Deteksi Ketersediaan Slot Parkir Berbasis Pengolahan Citra Digital Menggunakan Metode Histogram of Oriented Gradients dan Support Vector Machine 1}},
volume = {7},
year = {2017}
}
@article{Ouyang2019,
abstract = {Pinpointing subcellular protein localizations from microscopy images is easy to the trained eye, but challenging to automate. Based on the Human Protein Atlas image collection, we held a competition to identify deep learning solutions to solve this task. Challenges included training on highly imbalanced classes and predicting multiple labels per image. Over 3 months, 2,172 teams participated. Despite convergence on popular networks and training techniques, there was considerable variety among the solutions. Participants applied strategies for modifying neural networks and loss functions, augmenting data and using pretrained networks. The winning models far outperformed our previous effort at multi-label classification of protein localization patterns by $\sim$20%. These models can be used as classifiers to annotate new images, feature extractors to measure pattern similarity or pretrained networks for a wide range of biological applications.},
author = {Ouyang, Wei and Winsnes, Casper F. and Hjelmare, Martin and Cesnik, Anthony J. and {\AA}kesson, Lovisa and Xu, Hao and Sullivan, Devin P. and Dai, Shubin and Lan, Jun and Jinmo, Park and Galib, Shaikat M. and Henkel, Christof and Hwang, Kevin and Poplavskiy, Dmytro and Tunguz, Bojan and Wolfinger, Russel D. and Gu, Yinzheng and Li, Chuanpeng and Xie, Jinbin and Buslov, Dmitry and Fironov, Sergei and Kiselev, Alexander and Panchenko, Dmytro and Cao, Xuan and Wei, Runmin and Wu, Yuanhao and Zhu, Xun and Tseng, Kuan Lun and Gao, Zhifeng and Ju, Cheng and Yi, Xiaohan and Zheng, Hongdong and Kappel, Constantin and Lundberg, Emma},
doi = {10.1038/s41592-019-0658-6},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ouyang et al. - 2019 - Analysis of the Human Protein Atlas Image Classification competition.pdf:pdf},
issn = {15487105},
journal = {Nature Methods},
keywords = {application,deep learning,imbalanced dataset,multi-label},
mendeley-tags = {application,deep learning,imbalanced dataset,multi-label},
number = {12},
pages = {1254--1261},
pmid = {31780840},
title = {{Analysis of the Human Protein Atlas Image Classification competition}},
volume = {16},
year = {2019}
}
@article{Ullrich2019,
abstract = {The success of deep learning in numerous application domains created the desire to run and train them on mobile devices. This however, conflicts with their computationally, memory and energy intense nature, leading to a growing interest in compression. Recent work by Han et al. (2015a) propose a pipeline that involves retraining, pruning and quantization of neural network weights, obtaining state-of-the-art compression rates. In this paper, we show that competitive compression rates can be achieved by using a version of”soft weight-sharing” (Nowlan & Hinton, 1992). Our method achieves both quantization and pruning in one simple (re-)training procedure. This point of view also exposes the relation between compression and the minimum description length (MDL) principle.},
archivePrefix = {arXiv},
arxivId = {1702.04008},
author = {Ullrich, Karen and Welling, Max and Meeds, Edward},
eprint = {1702.04008},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ullrich, Welling, Meeds - 2019 - Soft weight-sharing for neural network compression.pdf:pdf},
journal = {5th International Conference on Learning Representations, ICLR 2017 - Conference Track Proceedings},
pages = {1--16},
title = {{Soft weight-sharing for neural network compression}},
year = {2019}
}
@article{Kurle2020,
author = {Kurle, Richard and Cseke, Botond},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kurle, Cseke - 2020 - Continual Learning With Bayesian Neural Networks for Non-Stationary Data.pdf:pdf},
journal = {International Conference on Learning Representations (2020)},
pages = {1--23},
title = {{Continual Learning With Bayesian Neural Networks for Non-Stationary Data}},
year = {2020}
}
@inproceedings{QuangPhamChenghaoLiuDoyenSahoo2021,
abstract = {Continual learning methods with fixed architectures rely on a single network to learn models that can perform well on all tasks. As a result, they often only accommodate common features of those tasks but neglect each task's specific features. On the other hand, dynamic architecture methods can have a separate network for each task, but they are too expensive to train and not scalable in practice, especially in online settings. To address this problem, we propose a novel online continual learning method named “Contextual Transformation Networks” (CTN) to efficiently model the task-specific features while enjoying neglectable complexity overhead compared to other fixed architecture methods. Moreover, inspired by the Complementary Learning Systems (CLS) theory, we propose a novel dual memory design and an objective to train CTN that can address both catastrophic forgetting and knowledge transfer simultaneously. Our extensive experiments show that CTN is competitive with a large scale dynamic architecture network and consistently outperforms other fixed architecture methods under the same standard backbone. We will release our implementation upon acceptance.},
author = {Pham, Quang and Liu, Chenghao and Sahoo, Doyen and HOI, Steven},
booktitle = {Iclr 2021},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2021 - Contextual Transformation Networks For Online Continual Learning(2).pdf:pdf},
keywords = {architectural,continual learning,dual memory,online learning},
mendeley-tags = {architectural,continual learning,dual memory,online learning},
number = {2021},
pages = {1--15},
title = {{Contextual Transformation Networks For Online Continual Learning}},
volume = {10},
year = {2021}
}
@book{Rockmann2017,
abstract = {Conserving nature requires the management of people and managing together with people. Marine management relies on scientific knowledge and expertise but is also inherently political, as it deals with aspects of resource access. Both local knowledge of practitioners and stakeholders' world views, values, and perceptions are important, adding to the scientific knowledge base and to understanding the management context. This chapter synthesizes existing literature and reviews on stakeholder participation. We analyze two marine management cases using eight key features of participation. The analyses illustrate that a participatory process can still not be successful if an underpinning participatory philosophy and clear objectives are lacking, participation is delayed and not well institutionalized. Clarity is needed about the participatory philosophy and process objective. The goal can be sharing knowledge or negotiating a decision. The increased need of stakeholder knowledge requires clarity about which of the two is driving the process. Rules of the game, including roles, responsibilities, and mandate need to be clear to all participants from the beginning.},
author = {R{\"{o}}ckmann, Christine and Kraan, Marloes and Goldsborough, David and van Hoof, Luc},
booktitle = {Conservation for the Anthropocene Ocean: Interdisciplinary Science in Support of Nature and People},
doi = {10.1016/B978-0-12-805375-1.00014-3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/R{\"{o}}ckmann et al. - 2017 - Stakeholder Participation in Marine Management The Importance of Transparency and Rules for Participation.pdf:pdf},
isbn = {9780128092989},
keywords = {Knowledge sharing,Negotiation,Participatory philosophy,Perceptions,Process,Stakeholder involvement},
pages = {289--306},
title = {{Stakeholder Participation in Marine Management: The Importance of Transparency and Rules for Participation}},
year = {2017}
}
@article{Variables,
author = {Variables, Same and Values, New},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Variables, Values - Unknown - How to enter missing data in SPSS.pdf:pdf},
pages = {5--6},
title = {{How to enter missing data in SPSS}}
}
@article{Meher2006,
abstract = {Biodiesel is gaining more and more importance as an attractive fuel due to the depleting fossil fuel resources. Chemically biodiesel is monoalkyl esters of long chain fatty acids derived from renewable feed stock like vegetable oils and animal fats. It is produced by transesterification in which, oil or fat is reacted with a monohydric alcohol in presence of a catalyst. The process of transesterification is affected by the mode of reaction condition, molar ratio of alcohol to oil, type of alcohol, type and amount of catalysts, reaction time and temperature and purity of reactants. In the present paper various methods of preparation of biodiesel with different combination of oil and catalysts have been described. The technical tools and processes for monitoring the transesterification reactions like TLC, GC, HPLC, GPC,1H NMR and NIR have also been summarized. In addition, fuel properties and specifications provided by different countries are discussed.},
author = {Meher, L. C. and {Vidya Sagar}, D. and Naik, S. N.},
doi = {10.1016/j.rser.2004.09.002},
isbn = {1364-0321},
issn = {13640321},
journal = {Renewable and Sustainable Energy Reviews},
keywords = {Analytical methods,Biodiesel,Fatty acid alkyl esters,Reaction condition,Transesterification,Vegetable oil},
number = {3},
pages = {248--268},
pmid = {1741},
title = {{Technical aspects of biodiesel production by transesterification - A review}},
volume = {10},
year = {2006}
}
@article{Bahri2021,
abstract = {Detecting out-of-distribution (OOD) examples is critical in many applications. We propose an unsupervised method to detect OOD samples using a $k$-NN density estimate with respect to a classification model's intermediate activations on in-distribution samples. We leverage a recent insight about label smoothing, which we call the \emph{Label Smoothed Embedding Hypothesis}, and show that one of the implications is that the $k$-NN density estimator performs better as an OOD detection method both theoretically and empirically when the model is trained with label smoothing. Finally, we show that our proposal outperforms many OOD baselines and also provide new finite-sample high-probability statistical results for $k$-NN density estimation's ability to detect OOD examples.},
archivePrefix = {arXiv},
arxivId = {2102.05131},
author = {Bahri, Dara and Jiang, Heinrich and Tay, Yi and Metzler, Donald},
eprint = {2102.05131},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bahri et al. - 2021 - Label Smoothed Embedding Hypothesis for Out-of-Distribution Detection.pdf:pdf},
keywords = {out-of-distribution},
mendeley-tags = {out-of-distribution},
title = {{Label Smoothed Embedding Hypothesis for Out-of-Distribution Detection}},
url = {http://arxiv.org/abs/2102.05131},
year = {2021}
}
@article{Hannula2004,
abstract = {This paper presents some preliminary results of the longitudinal aspect of a research project on self-confidence and understanding in mathematics. We have collected a survey data of 3057 fifth-graders and seventh-graders and a follow-up data of ten classes (191 pupils) one and a half years later. The longitudinal data indicates that the learning of mathematics is influenced by a pupil's mathematics-related beliefs, especially self-confidence. Pupils' level of understanding fractions also influences their developing understanding of infinity. These relationships between different variables depend also on pupils' gender and age.},
author = {Hannula, Markku S. and Maijala, Hanna and Pehkonen, Erkki},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hannula, Maijala, Pehkonen - 2004 - Development of understanding and self-confidence in mathematics Grades 5-8.pdf:pdf},
journal = {Proceedings of the 28th Conference for the International Group for the Psychology of Mathematics Education},
pages = {17--24},
title = {{Development of understanding and self-confidence in mathematics; Grades 5-8}},
url = {http://www.kurims.kyoto-u.ac.jp/EMIS/proceedings/PME28/RR/RR162_Hannula.pdf},
volume = {3},
year = {2004}
}
@article{Chrysos2018,
abstract = {Recently, technologies such as face detection, facial landmark localisation and face recognition and verification have matured enough to provide effective and efficient solutions for imagery captured under arbitrary conditions (referred to as "in-the-wild"). This is partially attributed to the fact that comprehensive "in-the-wild" benchmarks have been developed for face detection, landmark localisation and recognition/verification. A very important technology that has not been thoroughly evaluated yet is deformable face tracking "in-the-wild". Until now, the performance has mainly been assessed qualitatively by visually assessing the result of a deformable face tracking technology on short videos. In this paper, we perform the first, to the best of our knowledge, thorough evaluation of state-of-the-art deformable face tracking pipelines using the recently introduced 300VW benchmark. We evaluate many different architectures focusing mainly on the task of on-line deformable face tracking. In particular, we compare the following general strategies: (a) generic face detection plus generic facial landmark localisation, (b) generic model free tracking plus generic facial landmark localisation, as well as (c) hybrid approaches using state-of-the-art face detection, model free tracking and facial landmark localisation technologies. Our evaluation reveals future avenues for further research on the topic.},
archivePrefix = {arXiv},
arxivId = {1603.06015},
author = {Chrysos, Grigorios G. and Antonakos, Epameinondas and Snape, Patrick and Asthana, Akshay and Zafeiriou, Stefanos},
doi = {10.1007/s11263-017-0999-5},
eprint = {1603.06015},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chrysos et al. - 2018 - A Comprehensive Performance Evaluation of Deformable Face Tracking “In-the-Wild”.pdf:pdf},
issn = {15731405},
journal = {International Journal of Computer Vision},
keywords = {Deformable face tracking,Face detection,Facial landmark localisation,Long-term tracking,Model free tracking},
number = {2-4},
pages = {198--232},
publisher = {Springer US},
title = {{A Comprehensive Performance Evaluation of Deformable Face Tracking “In-the-Wild”}},
volume = {126},
year = {2018}
}
@article{Ayub2021a,
archivePrefix = {arXiv},
arxivId = {arXiv:2003.03196v3},
author = {Ayub, Ali and Wagner, Alan R.},
eprint = {arXiv:2003.03196v3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ayub, Wagner - 2021 - EEC Learning to Encode and Regenerate Images for Continual Learning.pdf:pdf},
keywords = {continual learning,replay},
mendeley-tags = {continual learning,replay},
pages = {1--16},
title = {{EEC: Learning to Encode and Regenerate Images for Continual Learning}},
year = {2021}
}
@book{Coatings,
author = {Coatings, Smart},
isbn = {9781782421207},
title = {{No Title}}
}
@article{You2020b,
abstract = {Neural networks are often represented as graphs of connections between neurons. However, despite their wide use, there is currently little understanding of the relationship between the graph structure of the neural network and its predictive performance. Here we systematically investigate how does the graph structure of neural networks affect their predictive performance. To this end, we develop a novel graph-based representation of neural networks called relational graph, where layers of neural network computation correspond to rounds of message exchange along the graph structure. Using this representation we show that: (1) a sweet spot of relational graphs leads to neural networks with significantly improved predictive performance; (2) neural networks performance is approximately a smooth function of the clustering coefficient and average path length of its relational graph; (3) our findings are consistent across many different tasks and datasets; (4) the sweet spot can be identified efficiently; (5) top-performing neural networks have graph structure surprisingly similar to those of real biological neural networks. Our work opens new directions for the design of neural architectures and the understanding on neural networks in general.},
archivePrefix = {arXiv},
arxivId = {2007.06559},
author = {You, Jiaxuan and Leskovec, Jure and He, Kaiming and Xie, Saining},
eprint = {2007.06559},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/You et al. - 2020 - Graph Structure of Neural Networks.pdf:pdf;:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/You et al. - 2020 - Graph Structure of Neural Networks(3).pdf:pdf},
journal = {arXiv},
title = {{Graph Structure of Neural Networks}},
year = {2020}
}
@article{Nawawi2015,
author = {Nawawi, Sherly Novita Sari and Sulistyorini, Rahayu and Martono, Yohanes},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nawawi, Sulistyorini, Martono - 2015 - Studi Optimalisasi Perparkiran dan Pedestrian di Fakultas Teknik Jurusan Sipil Universitas Lampun.pdf:pdf},
keywords = {parking,pedestrian,transportation},
number = {1},
pages = {71--80, ISSN 2303--0011},
title = {{Studi Optimalisasi Perparkiran dan Pedestrian di Fakultas Teknik Jurusan Sipil Universitas Lampung}},
volume = {3},
year = {2015}
}
@article{Hinton2021,
abstract = {This paper does not describe a working system. Instead, it presents a single idea about representation which allows advances made by several different groups to be combined into an imaginary system called GLOM. The advances include transformers, neural fields, contrastive representation learning, distillation and capsules. GLOM answers the question: How can a neural network with a fixed architecture parse an image into a part-whole hierarchy which has a different structure for each image? The idea is simply to use islands of identical vectors to represent the nodes in the parse tree. If GLOM can be made to work, it should significantly improve the interpretability of the representations produced by transformer-like systems when applied to vision or language},
archivePrefix = {arXiv},
arxivId = {2102.12627},
author = {Hinton, Geoffrey},
eprint = {2102.12627},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hinton - 2021 - How to represent part-whole hierarchies in a neural network.pdf:pdf},
keywords = {deep learning,neural networks,theory},
mendeley-tags = {deep learning,neural networks,theory},
month = {feb},
pages = {18},
title = {{How to represent part-whole hierarchies in a neural network}},
url = {http://arxiv.org/abs/2102.12627},
year = {2021}
}
@article{Salman2020,
abstract = {Transfer learning is a widely-used paradigm in deep learning, where models pre-trained on standard datasets can be efficiently adapted to downstream tasks. Typically, better pre-trained models yield better transfer results, suggesting that initial accuracy is a key aspect of transfer learning performance. In this work, we identify another such aspect: we find that adversarially robust models, while less accurate, often perform better than their standard-trained counterparts when used for transfer learning. Specifically, we focus on adversarially robust ImageNet classifiers, and show that they yield improved accuracy on a standard suite of downstream classification tasks. Further analysis uncovers more differences between robust and standard models in the context of transfer learning. Our results are consistent with (and in fact, add to) recent hypotheses stating that robustness leads to improved feature representations. Our code and models are available at https://github.com/Microsoft/robust-models-transfer.},
archivePrefix = {arXiv},
arxivId = {2007.08489},
author = {Salman, Hadi and Ilyas, Andrew and Engstrom, Logan and Kapoor, Ashish and Madry, Aleksander},
eprint = {2007.08489},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Salman et al. - 2020 - Do Adversarially Robust ImageNet Models Transfer Better.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {adversarial learning,imagenet,robustness,transfer learning},
mendeley-tags = {adversarial learning,imagenet,robustness,transfer learning},
title = {{Do Adversarially Robust ImageNet Models Transfer Better?}},
year = {2020}
}
@article{Spence2009,
author = {Spence, Charles},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Spence - 2009 - M Ultimodal I Nteractions.pdf:pdf},
number = {January},
pages = {599--606},
title = {{M Ultimodal I Nteractions :}},
year = {2009}
}
@inproceedings{Campo2020a,
abstract = {This paper proposes a method for performing continual learning of predictive models that facilitate the inference of future frames in video sequences. For a first given experience, an initial Variational Autoencoder, together with a set of fully connected neural networks are utilized to respectively learn the appearance of video frames and their dynamics at the latent space level. By employing an adapted Markov Jump Particle Filter, the proposed method recognizes new situations and integrates them as predictive models avoiding catastrophic forgetting of previously learned tasks. For evaluating the proposed method, this article uses video sequences from a vehicle that performs different tasks in a controlled environment.},
archivePrefix = {arXiv},
arxivId = {2006.01945},
author = {Campo, Damian and Slavic, Giulia and Baydoun, Mohamad and Marcenaro, Lucio and Regazzoni, Carlo},
booktitle = {2020 IEEE International Conference on Image Processing (ICIP)},
doi = {10.1109/ICIP40778.2020.9190980},
eprint = {2006.01945},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Campo et al. - 2020 - Continual Learning Of Predictive Models In Video Sequences Via Variational Autoencoders.pdf:pdf},
isbn = {978-1-7281-6395-6},
issn = {15224880},
keywords = {Continual learning,continual learning,incremental learning,kalman filter,lifelong learning,particle filter,variational autoencoder,video prediction,video understanding},
mendeley-tags = {continual learning,incremental learning,video prediction,video understanding},
month = {oct},
pages = {753--757},
publisher = {IEEE},
title = {{Continual Learning Of Predictive Models In Video Sequences Via Variational Autoencoders}},
url = {https://ieeexplore.ieee.org/document/9190980/},
volume = {2020-Octob},
year = {2020}
}
@article{DeGiacomo2013,
abstract = {The behavior composition problem amounts to realizing a virtual desired module (e.g., a surveillance agent system) by suitably coordinating (and re-purposing) the execution of a set of available modules (e.g., a video camera, vacuum cleaner, a robot, etc.). In particular, we investigate techniques to synthesize a controller implementing a fully controllable target behavior by suitably coordinating available partially controllable behaviors that are to execute within a shared, fully observable, but partially predictable (i.e., non-deterministic), environment. Both behaviors and environment are represented as arbitrary finite state transition systems. The technique we propose is directly based on the idea that the controller job is to coordinate the concurrent execution of the available behaviors so as to "mimic" the target behavior. To this end, we exploit a variant of the formal notion of simulation to formally capture the notion of "mimicking", and we show that the technique proposed is sound and complete, optimal with respect to computational complexity, and robust for different kind of system failures. In addition, we demonstrate that the technique is well suited for highly efficient implementation based on synthesis by model checking technologies, by relating the problem to that of finding a winning strategy in a special safety game and explaining how to actually solve it using an existing verification tool. {\textcopyright} 2013 Elsevier B.V. All rights reserved.},
author = {{De Giacomo}, Giueeppe and Patrizi, Fabio and Sardi{\~{n}}a, Sebastian},
doi = {10.1016/j.artint.2012.12.001},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Giacomo, Patrizi, Sardi{\~{n}}a - 2013 - Automatic behavior composition synthesis.pdf:pdf},
isbn = {0004-3702},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {Automated planning,Intelligent agents,Knowledge representation and reasoning,Reasoning about actions and change,Synthesis of reactive systems},
pages = {106--142},
publisher = {Elsevier B.V.},
title = {{Automatic behavior composition synthesis}},
url = {http://dx.doi.org/10.1016/j.artint.2012.12.001},
volume = {196},
year = {2013}
}
@article{Kirkpatrick2017a,
abstract = {The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence. Until now neural networks have not been capable of this and it has been widely thought that catastrophic forgetting is an inevitable feature of connectionist models. We show that it is possible to overcome this limitation and train networks that can maintain expertise on tasks that they have not experienced for a long time. Our approach remembers old tasks by selectively slowing down learning on the weights important for those tasks. We demonstrate our approach is scalable and effective by solving a set of classification tasks based on a hand-written digit dataset and by learning several Atari 2600 games sequentially.},
archivePrefix = {arXiv},
arxivId = {1612.00796},
author = {Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A. and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and Hassabis, Demis and Clopath, Claudia and Kumaran, Dharshan and Hadsell, Raia},
doi = {10.1073/pnas.1611835114},
eprint = {1612.00796},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kirkpatrick et al. - 2017 - Overcoming catastrophic forgetting in neural networks.pdf:pdf},
issn = {10916490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Artificial intelligence,Continual learning,Deep learning,Stability plasticity,Synaptic consolidation},
number = {13},
pages = {3521--3526},
pmid = {28292907},
title = {{Overcoming catastrophic forgetting in neural networks}},
url = {https://github.com/ariseff/overcoming-catastrophic https://github.com/stokesj/EWC},
volume = {114},
year = {2017}
}
@article{Liu2020j,
abstract = {Elastic weight consolidation (EWC) has been successfully applied for general incremental learning to overcome the catastrophic forgetting issue. It adaptively constrains each parameter of the new model not to deviate much from its counterpart in the old model during fine-tuning on new class data sets, according to its importance weight for old tasks. However, the previous study demonstrates that it still suffers from catastrophic forgetting when directly used in object detection. In this article, we show EWC is effective for incremental object detection if with critical adaptations. First, we conduct controlled experiments to identify two core issues why EWC fails if trivially applied to incremental detection: 1) the absence of old class annotations in new class images makes EWC misclassify objects of old classes in these images as background and 2) the quadratic regularization loss in EWC easily leads to gradient explosion when balancing old and new classes. Then, based on the abovementioned findings, we propose the corresponding solutions to tackle these issues: 1) utilize pseudobounding box annotations of old classes on new data sets to compensate for the absence of old class annotations and 2) adopt a novel Huber regularization instead of the original quadratic loss to prevent from unstable training. Finally, we propose a general EWC-based incremental object detection framework and implement it under both Fast R-CNN and Faster R-CNN, showing its flexibility and versatility. In terms of either the final performance or the performance drop with respect to the upper bound of joint training on all seen classes, evaluations on the PASCAL VOC and COCO data sets show that our method achieves a new state of the art.},
author = {Liu, Liyang and Kuang, Zhanghui and Chen, Yimin and Xue, Jing-Hao and Yang, Wenming and Zhang, Wayne},
doi = {10.1109/tnnls.2020.3002583},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2020 - IncDet In Defense of Elastic Weight Consolidation for Incremental Object Detection.pdf:pdf},
issn = {2162-237X},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {continual learning,incremental learning,object detection},
mendeley-tags = {continual learning,incremental learning,object detection},
pages = {1--14},
title = {{IncDet: In Defense of Elastic Weight Consolidation for Incremental Object Detection}},
year = {2020}
}
@article{Liu2021e,
abstract = {Deep models are vulnerable to catastrophic forgetting when fine-tuned on new data. Popular distillation-based methods usually neglect the relations between data samples and may eventually forget essential structural knowledge. To solve these shortcomings, we propose a structural graph knowledge distillation based incremental learning framework to preserve both the positions of samples and their relations. Firstly, a memory knowledge graph (MKG) is generated to fully characterize the structural knowledge of historical tasks. Secondly, we develop a graph interpolation mechanism to enrich the domain of knowledge and alleviate the inter-class sample imbalance issue. Thirdly, we introduce structural graph knowledge distillation to transfer the knowledge of historical tasks. Comprehensive experiments on three datasets validate the proposed method.},
author = {Liu, Yu and Hong, Xiaopeng and Tao, Xiaoyu and Dong, Songlin and Shi, Jingang and Gong, Yihong},
doi = {10.1145/3469877.3490598},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2021 - Structural Knowledge Organization and Transfer for Class-Incremental Learning.pdf:pdf},
isbn = {9781450386074},
journal = {ACM International Conference Proceeding Series},
keywords = {Incremental learning,catastrophic forgetting.,continual learning},
mendeley-tags = {continual learning},
title = {{Structural Knowledge Organization and Transfer for Class-Incremental Learning}},
year = {2021}
}
@article{Wang2018,
abstract = {This paper further investigates axiomatic characterizations of lower fuzzy rough approximation operators determined by a semicontinuous fuzzy implication I. The I-lower fuzzy rough approximation operators on a general fuzzy relation can be characterized by only one axiom. The axiomatic characterizations of I-lower fuzzy rough approximation operators are studied in two approaches, which characterize abstract I-lower fuzzy rough approximation operators with ordinary fuzzy operations on fuzzy sets and product operation, respectively. Considering the properties of fuzzy implications, different axioms are proposed for I-lower fuzzy rough approximation operators, which are determined by an S-implication, an R-implication and a fuzzy implication satisfying left neutrality property and regular property, respectively. When the fuzzy relation is special, such as serial, reflexive, symmetric and so on, I-lower fuzzy rough approximation operators can also be characterized by a single axiom.},
author = {Wang, Chun Yong},
doi = {10.1016/j.fss.2017.05.007},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang - 2018 - Single axioms for lower fuzzy rough approximation operators determined by fuzzy implications.pdf:pdf},
issn = {01650114},
journal = {Fuzzy Sets and Systems},
keywords = {Fuzzy implication,Fuzzy relation,Fuzzy rough set,I-lower fuzzy rough approximation operator},
number = {May},
pages = {148--166},
publisher = {Elsevier B.V.},
title = {{Single axioms for lower fuzzy rough approximation operators determined by fuzzy implications}},
url = {http://dx.doi.org/10.1016/j.fss.2017.05.007},
volume = {336},
year = {2018}
}
@article{Scott2015,
abstract = {Many American women suffer from poor body image and low self-confidence. Wearing makeup is something they can do to quickly and temporarily change their appearance, thus increasing confidence. The current study is an exploration of the relationship between cosmetics, their match to certain situations, and the resulting anxiety levels. Anxiety was used as a measure of confidence. Participants altered their makeup in three different styles in two actual situations. After each situation, the participants filled out a short survey about their feelings about the makeup and the situation they were in. The Spielberger state-trait anxiety survey was used to gauge anxiety. It was thought that less anxiety would be felt when makeup matched the situation. Implications for the findings are discussed.},
author = {Scott, Sarah},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Scott - 2015 - Influence of Cosmetics on the Confidende of College Women An Exploratory Study.pdf:pdf},
title = {{Influence of Cosmetics on the Confidende of College Women: An Exploratory Study}},
year = {2015}
}
@article{Prade1993a,
author = {Prade, Didier Dubois and Henri},
title = {{Fuzzy Sets for Intelligent Systems}},
year = {1993}
}
@article{Huang2015,
abstract = {Renewable ethanol and isopropanol were employed for lipid transesterification in wet microalgae cells to produce biodiesel with low crystallization temperature and reduce the alcohol volume needed for biodiesel production. Decreased droplet size and lipid polarity were observed after transesterification with alcohol in microalgae cells. Such decrease was beneficial in extracting lipid from microalgae with apolar hexane. The effects of reaction temperature, reaction time, and alcohol volume on microwave-assisted transesterification with ethanol and isopropanol were investigated, and results were compared with those with methanol. Microwave-assisted transesterification with ethanol and isopropanol, which were more miscible with lipid in cells, resulted in higher fatty acid alkyl ester (FAAE) yields than that with methanol when the reaction temperature was lower than 90 °C. The ethanol and isopropanol volumes in the transesterification with 95% FAAE yield were only 75% of the methanol volume. The crystallization temperatures (0.19 °C and -3.15 °C) of biodiesels produced from wet microalgae through lipid transesterification in cells with ethanol and isopropanol were lower than that with methanol (2.08 °C), which was favorable for biodiesel flow in cold districts and winter.},
author = {Huang, Rui and Cheng, Jun and Qiu, Yi and Li, Tao and Zhou, Junhu and Cen, Kefa},
doi = {10.1016/j.enconman.2015.08.036},
isbn = {0960-8524},
issn = {01968904},
journal = {Energy Conversion and Management},
keywords = {Biodiesel,Crystallization temperature,Ethanol,Isopropanol,Microwave-assisted transesterification,Wet microalgae cell},
pages = {791--797},
pmid = {21123059},
publisher = {Elsevier Ltd},
title = {{Using renewable ethanol and isopropanol for lipid transesterification in wet microalgae cells to produce biodiesel with low crystallization temperature}},
url = {http://dx.doi.org/10.1016/j.enconman.2015.08.036},
volume = {105},
year = {2015}
}
@article{An2017,
abstract = {Visual tracking is a challenging computer vision task due to the significant observation changes of the target. By contrast, the tracking task is relatively easy for humans. In this article, we propose a tracker inspired by the cognitive psychological memory mechanism, which decomposes the tracking task into sensory memory register, short-term memory tracker, and long-term memory tracker like humans. The sensory memory register captures information with three-dimensional perception; the short-term memory tracker builds the highly plastic observation model via memory rehearsal; the long-term memory tracker builds the highly stable observation model via memory encoding and retrieval. With the cooperative models, the tracker can easily handle various tracking scenarios. In addition, an appearance-shape learning method is proposed to update the two-dimensional appearance model and three-dimensional shape model appropriately. Extensive experimental results on a large-scale benchmark data set demonstrate that the proposed method outperforms the state-of-the-art two-dimensional and three-dimensional trackers in terms of efficiency, accuracy, and robustness.},
author = {An, Ning and Sun, Shi Ying and Zhao, Xiao Guang and Hou, Zeng Guang},
doi = {10.1177/1729881417692313},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/An et al. - 2017 - Remember like humans Visual tracking with cognitive psychological memory model.pdf:pdf},
issn = {17298814},
journal = {International Journal of Advanced Robotic Systems},
keywords = {3-D perception.,Visual object tracking,biologically inspired vision,cognitive psychological memory model,continual learning,incremental learning,tracking,visual tracking},
mendeley-tags = {continual learning,incremental learning,tracking,visual tracking},
number = {1},
pages = {1--9},
title = {{Remember like humans: Visual tracking with cognitive psychological memory model}},
volume = {14},
year = {2017}
}
@article{Prabhu2020a,
abstract = {We discuss a general formulation for the Continual Learning (CL) problem for classification-a learning task where a stream provides samples to a learner and the goal of the learner, depending on the samples it receives, is to continually upgrade its knowledge about the old classes and learn new ones. Our formulation takes inspiration from the open-set recognition problem where test scenarios do not necessarily belong to the training distribution. We also discuss various quirks and assumptions encoded in recently proposed approaches for CL. We argue that some oversimplify the problem to an extent that leaves it with very little practical importance, and makes it extremely easy to perform well on. To validate this, we propose GDumb that (1) greedily stores samples in memory as they come and; (2) at test time, trains a model from scratch using samples only in the memory. We show that even though GDumb is not specifically designed for CL problems, it obtains state-of-the-art accuracies (often with large margins) in almost all the experiments when compared to a multitude of recently proposed algorithms. Surprisingly, it outperforms approaches in CL formulations for which they were specifically designed. This, we believe, raises concerns regarding our progress in CL for classification. Overall, we hope our formulation, characterizations and discussions will help in designing realistically useful CL algorithms, and GDumb will serve as a strong contender for the same.},
author = {Prabhu, Ameya and Torr, Philip H. S. and Dokania, Puneet K.},
doi = {10.1007/978-3-030-58536-5_31},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Prabhu, Torr, Dokania - 2020 - GDumb A Simple Approach that Questions Our Progress in Continual Learning(3).pdf:pdf},
issn = {16113349},
pages = {524--540},
title = {{GDumb: A Simple Approach that Questions Our Progress in Continual Learning}},
year = {2020}
}
@article{Ng2019,
abstract = {Images are uploaded to the Internet over time which makes concept drifting and distribution change in semantic classes unavoidable. Current hashing methods being trained using a given static database may not be suitable for nonstationary semantic image retrieval problems. Moreover, directly retraining a whole hash table to update knowledge coming from new arriving image data may not be efficient. Therefore, this paper proposes a new incremental hash-bit learning method. At the arrival of new data, hash bits are selected from both existing and newly trained hash bits by an iterative maximization of a 3-component objective function. This objective function is also used to weight selected hash bits to re-rank retrieved images for better semantic image retrieval results. The three components evaluate a hash bit in three different angles: 1) information preservation; 2) partition balancing; and 3) bit angular difference. The proposed method combines knowledge retained from previously trained hash bits and new semantic knowledge learned from the new data by training new hash bits. In comparison to table-based incremental hashing, the proposed method automatically adjusts the number of bits from old data and new data according to the concept drifting in the given data via the maximization of the objective function. Experimental results show that the proposed method outperforms existing stationary hashing methods, table-based incremental hashing, and online hashing methods in 15 different simulated nonstationary data environments.},
author = {Ng, Wing W.Y. and Tian, Xing and Pedrycz, Witold and Wang, Xizhao and Yeung, Daniel S.},
doi = {10.1109/TCYB.2018.2846760},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ng et al. - 2019 - Incremental Hash-Bit Learning for Semantic Image Retrieval in Nonstationary Environments.pdf:pdf},
issn = {21682275},
journal = {IEEE Transactions on Cybernetics},
keywords = {Concept drift,continual learning,hash bit learning,hashing,image retrieval,incremental learning,nonstationary environment},
mendeley-tags = {continual learning,image retrieval,incremental learning},
number = {11},
pages = {3844--3858},
title = {{Incremental Hash-Bit Learning for Semantic Image Retrieval in Nonstationary Environments}},
volume = {49},
year = {2019}
}
@article{Student2010,
abstract = {In this article, it has been established that voltage generated in a microbial fuel cell decreases linearly with respect to time. In other words, the first order derivative of voltage generated with respect to time is a negative constant. Thus the rate of change of voltage generated with respect to time has been established to be independent of time. It has been found that a mixture of biowastes can actually result in higher extractable current than any single component although this is not always true in general. Further, it has been found that when a component results in higher voltage production, it ends up reducing the cell life.},
author = {Student, Formerly M Tech},
doi = {10.1016/j.tibtech.2005.04.008},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Student - 2010 - Electricity Generation from Biowaste Based Microbial Fuel Cells.pdf:pdf},
journal = {International Journal of Energy, Information and Communications},
keywords = {conversion of chemical energy,renewable energy technology,to electrical energy},
number = {1},
pages = {77--92},
title = {{Electricity Generation from Biowaste Based Microbial Fuel Cells}},
volume = {1},
year = {2010}
}
@article{Shaw2006,
abstract = {The infrared spectrum of a mixture serves as the basis to quantitate its constituents, and a number of common clinical chemistry tests have proven to be feasible using this approach. This article reviews the infrared spectroscopy-based analytical methods that have been developed for consideration in clinical assays, including serum analysis, urine analysis, amniotic fluid assays for the estimation of fetal lung maturity, and others. Because of the widespread interest in the potential for in vivo measurement of blood glucose using near infrared spectroscopy, a separate section is devoted to the analysis of glucose in whole blood. A related technique uses the infrared spectrum of biomedical specimens directly as a diagnostic tool. For example, the spectra of serum and synovial fluid have proven to be useful in the diagnosis of metabolic disorders and arthritis, respectively, without explicitly recovering their chemical composition from the spectra. Rather, characteristic spectral features and patterns have been identified as the basis to distinguish spectra corresponding to healthy patients from those corresponding to diseased patients. These applications are reviewed here. Issues such as ease of use, speed, reliability, sample size, and calibration stability all play important roles in governing the practical acceptability of infrared spectroscopy-based analytical methods. To provide a framework to illustrate these issues, descriptions are included for the various procedures that have been explored to wed spectroscopy to clinical chemistry.},
author = {Shaw, R. Anthony and Mantsch, Henry H.},
doi = {10.1002/9780470027318.a0106},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shaw, Mantsch - 2006 - Infrared Spectroscopy in Clinical and Diagnostic Analysis.pdf:pdf},
isbn = {9780470027318},
journal = {Encyclopedia of Analytical Chemistry},
title = {{Infrared Spectroscopy in Clinical and Diagnostic Analysis}},
url = {http://doi.wiley.com/10.1002/9780470027318.a0106},
year = {2006}
}
@article{Mundt2020,
abstract = {Current deep learning research is dominated by benchmark evaluation. A method is regarded as favorable if it empirically performs well on the dedicated test set. This mentality is seamlessly reflected in the resurfacing area of continual learning, where consecutively arriving sets of benchmark data are investigated. The core challenge is framed as protecting previously acquired representations from being catastrophically forgotten due to the iterative parameter updates. However, comparison of individual methods is nevertheless treated in isolation from real world application and typically judged by monitoring accumulated test set performance. The closed world assumption remains predominant. It is assumed that during deployment a model is guaranteed to encounter data that stems from the same distribution as used for training. This poses a massive challenge as neural networks are well known to provide overconfident false predictions on unknown instances and break down in the face of corrupted data. In this work we argue that notable lessons from open set recognition, the identification of statistically deviating data outside of the observed dataset, and the adjacent field of active learning, where data is incrementally queried such that the expected performance gain is maximized, are frequently overlooked in the deep learning era. Based on these forgotten lessons, we propose a consolidated view to bridge continual learning, active learning and open set recognition in deep neural networks. Our results show that this not only benefits each individual paradigm, but highlights the natural synergies in a common framework. We empirically demonstrate improvements when alleviating catastrophic forgetting, querying data in active learning, selecting task orders, while exhibiting robust open world application where previously proposed methods fail.},
archivePrefix = {arXiv},
arxivId = {2009.01797},
author = {Mundt, Martin and Hong, Yong Won and Pliushch, Iuliia and Ramesh, Visvanathan},
eprint = {2009.01797},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mundt et al. - 2020 - A Wholistic View of Continual Learning with Deep Neural Networks Forgotten Lessons and the Bridge to Active and Op.pdf:pdf},
keywords = {continual learning,review,survey},
mendeley-tags = {continual learning,review,survey},
pages = {1--32},
title = {{A Wholistic View of Continual Learning with Deep Neural Networks: Forgotten Lessons and the Bridge to Active and Open World Learning}},
url = {http://arxiv.org/abs/2009.01797},
year = {2020}
}
@book{Teixeira2012,
abstract = {The use of natural ventilation systems may contribute considerably to the reduction of the energy consumption, while providing adequate comfort levels and hygiene standards for the occupants. Computational Fluid Dynamics (CFD) techniques are becoming increasingly attractive in the design of ventilation systems. In this work, tests on a validated CFD model, which simulates the air flow inside a standard building, were carried out in order to obtain a suitable tool to predict ventilation performance and therefore optimize the building ventilation design. The model solves the mass, momentum and energy for the air flow, coupled with the k-$\epsilon$ turbulence model. The equations are solved by a FV discretization technique in a structured grid. Appropriated boundary conditions and the dimension of the domain were studied for more accuracy in numeric simulation. The influence of the free stream velocity profile and wind direction upon the efficiency of a natural ventilation system under isothermal conditions has been tested. The results obtained so far confirm the validity of the implemented model and its possible use for the optimal design of natural ventilation systems.},
author = {Teixeira, Jos{\'{e}} Carlos and Lomba, Ricardo and Teixeira, Senhorinha F.C.F. and Lobarinhas, Pedro},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-31137-6_15},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Teixeira et al. - 2012 - Application of CFD tools to optimize natural building ventilation design.pdf:pdf},
isbn = {9783642311369},
issn = {03029743},
keywords = {Computational Fluid Dynamics (CFD),Natural ventilation,Sustainable systems},
number = {PART 3},
pages = {202--216},
title = {{Application of CFD tools to optimize natural building ventilation design}},
volume = {7335 LNCS},
year = {2012}
}
@article{Liu2020,
abstract = {Overcoming catastrophic forgetting in neural networks is a long-standing and core research objective for incremental learning. Notable studies have shown regularization strategies enable the network to remember previously acquired knowledge devoid of heavy forgetting. Since those regularization strategies are mostly associated with classifier outputs, we propose a MUlti-Classifier (MUC) incremental learning paradigm that integrates an ensemble of auxiliary classifiers to estimate more effective regularization constraints. Additionally, we extend two common methods, focusing on parameter and activation regularization, from the conventional single-classifier paradigm to MUC. Our classifier ensemble promotes regularizing network parameters or activations when moving to learn the next task. Under the setting of task-agnostic evaluation, our experimental results on CIFAR-100 and Tiny ImageNet incremental benchmarks show that our method outperforms other baselines. Specifically, MUC obtains 3%–5% accuracy boost and 4%–5% decline of forgetting ratio, compared with MAS and LwF. Our code is available at https://github.com/Liuy8/MUC.},
author = {Liu, Yu and Parisot, Sarah and Slabaugh, Gregory and Jia, Xu and Leonardis, Ales and Tuytelaars, Tinne},
doi = {10.1007/978-3-030-58574-7_42},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2020 - More Classifiers, Less Forgetting A Generic Multi-classifier Paradigm for Incremental Learning.pdf:pdf},
isbn = {9783030585730},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Classifier ensemble,Incremental learning,Regularization,continual learning,regularization},
mendeley-tags = {continual learning,regularization},
pages = {699--716},
title = {{More Classifiers, Less Forgetting: A Generic Multi-classifier Paradigm for Incremental Learning}},
url = {https://github.com/visionyuliu/MUC},
volume = {12371 LNCS},
year = {2020}
}
@article{Gahleitner2013,
abstract = {An increasingly large percentage of power is being generated from renewable energy sources with intermittent and fluctuating outputs. Therefore there is a growing need for energy storage. With power-to-gas, excess electricity is converted into hydrogen by water electrolysis, which can be stored and, when needed, can be reconverted into electricity with fuel cells. Besides the energy vector for electricity, mobility and heat, hydrogen can be utilized as a raw material for the chemical industry or further be used for the synthesis of various hydrocarbon fuels such as methane. This article is an international review of numerous power-to-gas pilot plants that have either already been realized or are being planned. It provides information about their installed components and capacities as well as about operating experience that has been had with them. In many of the projects it was concluded that the design and sizing, control strategy and system integration of the power-to-gas plants have a great influence on their overall efficiency, reliability and economics. Topics for further research are the improvement of the efficiency, reliability, lifetime and costs of electrolyzers and fuel cells and better ways of dealing with power sources. In order to improve the overall performance, the reduction of auxiliary equipment and the continuous long-term operation of power-to-gas pilot plants will be necessary. The further development of codes and standards for permits to operate, as well as of hydrogen components and control strategies, would bring additional benefits for power-to-gas systems. It is also recommended that optimum system configurations and components be determined with regard to the available infrastructure and the type of application involved. Copyright {\textcopyright} 2012, Hydrogen Energy Publications, LLC.},
author = {Gahleitner, Gerda},
doi = {10.1016/j.ijhydene.2012.12.010},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gahleitner - 2013 - Hydrogen from renewable electricity An international review of power-to-gas pilot plants for stationary applications.pdf:pdf},
isbn = {03603199},
issn = {03603199},
journal = {International Journal of Hydrogen Energy},
keywords = {Electrolyzer,Energy storage,Fuel cell,Pilot plant,Power-to-gas,Renewable hydrogen},
number = {5},
pages = {2039--2061},
publisher = {Elsevier Ltd},
title = {{Hydrogen from renewable electricity: An international review of power-to-gas pilot plants for stationary applications}},
url = {http://dx.doi.org/10.1016/j.ijhydene.2012.12.010},
volume = {38},
year = {2013}
}
@article{Reynaldi2012,
abstract = {In this paper, finite element based neural network is developed. The purpose is to solve differential equation and inverse problem of differential equation. Inverse problem of differential equation is a problem to solve for parameters of differential equation, assuming that the solution of the differential equation is already known beforehand. Inverse problem mainly used to approximate physical parameters of material. Finite element method will be combined with artificial neural network using back propagation algorithm to solve differential equation and Levenberg-Marquardt training algorithm to solve inverse differential problem. By using proposed method, inverse matrix calculation will not be needed for solving both differential equation and inverse differential problem. From any given differential equation, the solution will be solved first. And the solution is used to validate the parameter in differential equation, namely to solve inverse problem of that differential equation.},
author = {Reynaldi, Arnold and Lukas, Samuel and Margaretha, Helena},
doi = {10.1109/EMS.2012.56},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Reynaldi, Lukas, Margaretha - 2012 - Backpropagation and Levenberg-Marquardt algorithm for training finite element neural network.pdf:pdf},
isbn = {9780769549262},
journal = {Proceedings - UKSim-AMSS 6th European Modelling Symposium, EMS 2012},
keywords = {Levenberg-Marquardt algorithm,artificial neural network,backpropagation algorithm,finite element method,inverse differential problem},
number = {2},
pages = {89--94},
title = {{Backpropagation and Levenberg-Marquardt algorithm for training finite element neural network}},
year = {2012}
}
@article{Volpi2020,
abstract = {Most standard learning approaches lead to fragile models which are prone to drift when sequentially trained on samples of a different nature - the well-known "catastrophic forgetting" issue. In particular, when a model consecutively learns from different visual domains, it tends to forget the past ones in favor of the most recent. In this context, we show that one way to learn models that are inherently more robust against forgetting is domain randomization - for vision tasks, randomizing the current domain's distribution with heavy image manipulations. Building on this result, we devise a meta-learning strategy where a regularizer explicitly penalizes any loss associated with transferring the model from the current domain to different "auxiliary" meta-domains, while also easing adaptation to them. Such meta-domains, are also generated through randomized image manipulations. We empirically demonstrate in a variety of experiments - spanning from classification to semantic segmentation - that our approach results in models that are less prone to catastrophic forgetting when transferred to new domains.},
archivePrefix = {arXiv},
arxivId = {2012.04324},
author = {Volpi, Riccardo and Larlus, Diane and Rogez, Gr{\'{e}}gory},
eprint = {2012.04324},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Volpi, Larlus, Rogez - 2020 - Continual Adaptation of Visual Representations via Domain Randomization and Meta-learning.pdf:pdf},
title = {{Continual Adaptation of Visual Representations via Domain Randomization and Meta-learning}},
url = {http://arxiv.org/abs/2012.04324},
year = {2020}
}
@article{Bahng2019,
abstract = {Many machine learning algorithms are trained and evaluated by splitting data from a single source into training and test sets. While such focus on in-distribution learning scenarios has led interesting advances, it has not been able to tell if models are relying on dataset biases as shortcuts for successful prediction (e.g., using snow cues for recognising snowmobiles). Such biased models fail to generalise when the bias shifts to a different class. The cross-bias generalisation problem has been addressed by de-biasing training data through augmentation or re-sampling, which are often prohibitive due to the data collection cost (e.g., collecting images of a snowmobile on a desert) and the difficulty of quantifying or expressing biases in the first place. In this work, we propose a novel framework to train a de-biased representation by encouraging it to be different from a set of representations that are biased by design. This tactic is feasible in many scenarios where it is much easier to define a set of biased representations than to define and quantify bias. Our experiments and analyses show that our method discourages models from taking bias shortcuts, resulting in improved performances on de-biased test data.},
archivePrefix = {arXiv},
arxivId = {1910.02806},
author = {Bahng, Hyojin and Chun, Sanghyuk and Yun, Sangdoo and Choo, Jaegul and Oh, Seong Joon},
eprint = {1910.02806},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bahng et al. - 2019 - Learning de-biased representations with biased representations.pdf:pdf},
journal = {arXiv},
title = {{Learning de-biased representations with biased representations}},
year = {2019}
}
@article{Mahesh2015,
abstract = {This research paper deals with the synthesis of a heterogeneous catalyst (KBr/CaO) from commercial calcium oxide and potassium bromide by wet impregnation method. This solid catalyst was tested for transesterification of waste cooking oil (WCO). The synthesized catalyst was characterized by Fourier Transform Infrared spectrometry (FTIR), X-ray Diffraction (XRD) and Scanning Electron Microscopy (SEM) techniques. Transesterification reaction parameters were varied to obtain the maximum yield of biodiesel. Response Surface Methodology (RSM) using Central Composite Design (CCD) was employed to study the effect of the process variables like methanol to oil ratio, catalyst loading and reaction time. The optimum conditions obtained using regression models were found to be 12:1 methanol: oil ratio, 3 wt% catalyst loading and 1.8 h reaction time. The composition of FAME was determined using Gas Chromatography-Mass Spectrometry (GC-MS). The performance and emission characteristics for various blends of biodiesel (B10, B20, B50 and B100) were investigated in a four stroke direct injection diesel engine. The results indicated that the brake thermal efficiency, particulate matter, unburned hydrocarbons, carbon monoxide emissions reduced with increased concentration of biodiesel in the fuel blends, whereas the specific fuel consumption, NOxemissions and exhaust gas temperature increased.},
author = {Mahesh, Sneha E. and Ramanathan, Anand and Begum, K. M.Meera S. and Narayanan, Anantharaman},
doi = {10.1016/j.enconman.2014.12.031},
isbn = {0378-3820},
issn = {01968904},
journal = {Energy Conversion and Management},
keywords = {Biodiesel,CCD,RSM,Transesterification,Waste cooking oil},
pages = {442--450},
pmid = {23186664},
publisher = {Elsevier Ltd},
title = {{Biodiesel production from waste cooking oil using KBr impregnated CaO as catalyst}},
url = {http://dx.doi.org/10.1016/j.enconman.2014.12.031},
volume = {91},
year = {2015}
}
@article{Tripathi2017,
author = {Tripathi, Harikesh and Pradhan, Nandita},
doi = {10.1109/ICCCCM.2016.7918264},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tripathi, Pradhan - 2017 - Reliability optimization of electronics module by derating using genetic algorithm.pdf:pdf},
isbn = {9781467390842},
journal = {ICCCCM 2016 - 2nd IEEE International Conference on Control Computing Communication and Materials},
keywords = {Derating,Full bridge converter circuit,Genetic Algorithm,Reliability and failure rate of components},
number = {Iccccm},
title = {{Reliability optimization of electronics module by derating using genetic algorithm}},
year = {2017}
}
@article{Shoubi2014,
abstract = {A sustainable building is constructed of materials that could decrease environmental impacts, such as energy usage, during the lifecycle of the building. Building Information Modeling (BIM) has been identified as an effective tool for building performance analysis virtually in the design stage. The main aims of this study were to assess various combinations of materials using BIM and identify alternative, sustainable solutions to reduce operational energy consumption. The amount of energy consumed by a double story bungalow house in Johor, Malaysia, and assessments of alternative material configurations to determine the best energy performance were evaluated by using Revit Architecture 2012 and Autodesk Ecotect Analysis software to show which of the materials helped in reducing the operational energy use of the building to the greatest extent throughout its annual life cycle. At the end, some alternative, sustainable designs in terms of energy savings have been suggested.},
author = {Shoubi, Mojtaba Valinejad and Shoubi, Masoud Valinejad and Bagchi, Ashutosh and Barough, Azin Shakiba},
doi = {10.1016/j.asej.2014.09.006},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shoubi et al. - 2014 - Reducing the operational energy demand in buildings using building information modeling tools and sustainability.pdf:pdf},
issn = {20904479},
journal = {Ain Shams Engineering Journal},
keywords = {Annual lifecycle assessment,Building information modeling,Energy consumption,Energy efficient building,Environmental impacts,Sustainable building},
number = {1},
pages = {41--55},
publisher = {Faculty of Engineering, Ain Shams University},
title = {{Reducing the operational energy demand in buildings using building information modeling tools and sustainability approaches}},
url = {http://dx.doi.org/10.1016/j.asej.2014.09.006},
volume = {6},
year = {2014}
}
@article{ANSI/ISA1976,
author = {ANSI/ISA},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/ANSIISA - 1976 - Binary Logic Diagrams for Process Operations.pdf:pdf},
isbn = {0876643314},
number = {R},
pages = {1--28},
title = {{Binary Logic Diagrams for Process Operations}},
volume = {1976},
year = {1976}
}
@article{Montavon2017,
author = {Montavon, Gr{\'{e}}goire and Samek, Wojciech and M{\"{u}}ller, Klaus-robert},
doi = {10.1016/j.dsp.2017.10.011},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Montavon, Samek, M{\"{u}}ller - 2017 - Methods for Interpreting and Understanding Deep Neural Networks.pdf:pdf},
issn = {1051-2004},
journal = {Digital Signal Processing},
keywords = {activation maximization,deep neural networks,layer-wise,relevance propagation,sensitivity analysis,taylor decomposition},
publisher = {Elsevier Inc.},
title = {{Methods for Interpreting and Understanding Deep Neural Networks}},
url = {https://doi.org/10.1016/j.dsp.2017.10.011},
year = {2017}
}
@article{Pravin2008,
author = {Pravin, M. and Vijayachitra, S.},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pravin, Vijayachitra - 2008 - Process optimization using genetic algorithms.pdf:pdf},
keywords = {- fuzzy,clustering analysis,genetic algorithm and optimization},
pages = {1--6},
title = {{Process optimization using genetic algorithms}},
year = {2008}
}
@article{Martins2016,
abstract = {We propose sparsemax, a new activation function similar to the traditional softmax, but able to output sparse probabilities. After deriving its properties, we show how its Jacobian can be efficiently computed, enabling its use in a network trained with backpropagation. Then, we propose a new smooth and convex loss function which is the sparsemax analogue of the logistic loss. We reveal an unexpected connection between this new loss and the Huber classification loss. We obtain promising empirical results in multi-label classification problems and in attention-based neural networks for natural language inference. For the latter, we achieve a similar performance as the traditional softmax, but with a selective, more compact, attention focus.},
archivePrefix = {arXiv},
arxivId = {1602.02068},
author = {Martins, Andr{\'{e}} F. T. and Astudillo, Ram{\'{o}}n Fernandez},
eprint = {1602.02068},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Martins, Astudillo - 2016 - From Softmax to Sparsemax A Sparse Model of Attention and Multi-Label Classification.pdf:pdf},
isbn = {9781510829008},
journal = {33rd International Conference on Machine Learning, ICML 2016},
month = {feb},
pages = {2432--2443},
title = {{From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification}},
url = {http://arxiv.org/abs/1602.02068},
volume = {4},
year = {2016}
}
@article{Li2020a,
abstract = {Few-shot learning is challenging due to its very limited data and labels. Recent studies in big transfer (BiT) show that few-shot learning can greatly benefit from pretraining on large scale labeled dataset in a different domain. This paper asks a more challenging question: "can we use as few as possible labels for few-shot learning in both pretraining (with no labels) and fine-tuning (with fewer labels)?". Our key insight is that the clustering of target samples in the feature space is all we need for few-shot finetuning. It explains why the vanilla unsupervised pretraining (poor clustering) is worse than the supervised one. In this paper, we propose transductive unsupervised pretraining that achieves a better clustering by involving target data even though its amount is very limited. The improved clustering result is of great value for identifying the most representative samples ("eigen-samples") for users to label, and in return, continued finetuning with the labeled eigen-samples further improves the clustering. Thus, we propose eigen-finetuning to enable fewer shot learning by leveraging the co-evolution of clustering and eigen-samples in the finetuning. We conduct experiments on 10 different few-shot target datasets, and our average few-shot performance outperforms both vanilla inductive unsupervised transfer and supervised transfer by a large margin. For instance, when each target category only has 10 labeled samples, the mean accuracy gain over the above two baselines is 9.2% and 3.42 respectively.},
archivePrefix = {arXiv},
arxivId = {2012.05899},
author = {Li, Suichan and Chen, Dongdong and Chen, Yinpeng and Yuan, Lu and Zhang, Lei and Chu, Qi and Yu, Nenghai},
eprint = {2012.05899},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2020 - Are Fewer Labels Possible for Few-shot Learning.pdf:pdf},
keywords = {few-shot learning},
mendeley-tags = {few-shot learning},
title = {{Are Fewer Labels Possible for Few-shot Learning?}},
url = {http://arxiv.org/abs/2012.05899},
year = {2020}
}
@article{Zhang2019g,
abstract = {Long-term visual tracking is one of the most challenging problems in computer vision and is closer to practical application needs. In long-term video sequences, tracking targets often undergo dramatic appearance changes over time due to various factors such as scale variation, illumination change, occlusions and so on. In this work, we propose a novel robust long-term tracking framework based on continual learning and dynamic sample set modules. We transform the online tracking process into a continual learning process of the target model, and continuously learn various appearance changes to adapt to different scenarios. The continual learning module distills the beneficial knowledge of the old network to the new network through warm-up and joint training to achieve a comprehensive and holistic memory of the target appearance. Combining the dynamic sample set can effectively balance the short-term memory and long-term memory of the model, and establish a near-complete target appearance description in the long-term dimension to cope with various challenging situations. Experimental results on the large-scale long-term benchmark datasets LaSOT and UAV20L show that the proposed method performs favourably against other state-of-the-art trackers.},
author = {Zhang, Hui and Zhu, Mu and Zhang, Jing and Zhuo, Li},
doi = {10.1109/ACCESS.2019.2960321},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2019 - Long-Term Visual Object Tracking via Continual Learning.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Long-term visual tracking,continual learning,dynamic sample set,incremental learning,tracking,visual tracking,warm-up and joint training},
mendeley-tags = {continual learning,incremental learning,tracking,visual tracking},
pages = {182548--182558},
publisher = {IEEE},
title = {{Long-Term Visual Object Tracking via Continual Learning}},
volume = {7},
year = {2019}
}
@article{Vyunishev2017,
abstract = {We propose an elegant approach to produce photonic bandgap (PBG) structures with multiple photonic bandgaps by constructing quasiperiodic photonic crystals (QPPCs) composed of a superposition of photonic lattices with different periods. Generally, QPPC structures exhibit both aperiodicity and multiple PBGs due to their long-range order. They are described by a simple analytical expression, instead of quasiperiodic tiling approaches based on substitution rules. Here we describe the optical properties of QPPCs exhibiting two PBGs that can be tuned independently. PBG interband spacing and its depth can be varied by choosing appropriate reciprocal lattice vectors and their amplitudes. These effects are confirmed by the proof-of-concept measurements made for the porous silicon-based QPPC of the appropriate design.},
author = {Vyunishev, Andrey M. and Pankin, Pavel S. and Svyakhovskiy, Sergey E. and Timofeev, Ivan V. and Vetrov, Stepan Ya.},
doi = {10.1364/OL.42.003602},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vyunishev et al. - 2017 - Quasiperiodic one-dimensional photonic crystals with adjustable multiple photonic bandgaps.pdf:pdf},
issn = {0146-9592},
journal = {Optics Letters},
number = {18},
pages = {3602},
title = {{Quasiperiodic one-dimensional photonic crystals with adjustable multiple photonic bandgaps}},
url = {https://www.osapublishing.org/abstract.cfm?URI=ol-42-18-3602},
volume = {42},
year = {2017}
}
@article{Saha2020,
abstract = {Pooling operators are key components in most Convolutional Neural Networks (CNNs) as they serve to downsample images, aggregate feature information, and increase receptive field. However, standard pooling operators reduce the feature size gradually to avoid significant loss in information via gross aggregation. Consequently, CNN architectures tend to be deep, computationally expensive and challenging to deploy on RAM constrained devices. We introduce RNNPool, a novel pooling operator based on Recurrent Neural Networks (RNNs), that efficiently aggregate features over large patches of an image and rapidly downsamples its size. Our empirical evaluation indicates that an RNNPool layer(s) can effectively replace multiple blocks in a variety of architectures such as MobileNets (Sandler et al., 2018), DenseNet (Huang et al., 2017) and can be used for several vision tasks like image classification and face detection. That is, RNNPool can significantly decrease computational complexity and peak RAM usage for inference while retaining comparable accuracy. Further, we use RNNPool to construct a novel real-time face detection method that achieves state-of-the-art MAP within computational budget afforded by a tiny Cortex M4 microcontroller with - 256 KB RAM.},
archivePrefix = {arXiv},
arxivId = {2002.11921},
author = {Saha, Oindrila and Kusupati, Aditya and Simhadri, Harsha Vardhan and Varma, Manik and Jain, Prateek},
eprint = {2002.11921},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saha et al. - 2020 - RNNPool Efficient non-linear pooling for RAM constrained inference.pdf:pdf},
journal = {arXiv},
keywords = {efficient,module,pooling},
mendeley-tags = {efficient,module,pooling},
number = {NeurIPS},
pages = {1--25},
title = {{RNNPool: Efficient non-linear pooling for RAM constrained inference}},
url = {https://github.com/microsoft/EdgeML/blob/master/pytorch/edgeml_pytorch/graph/rnnpool.py https://arxiv.org/pdf/2002.11921.pdf},
year = {2020}
}
@article{Macauley2014,
abstract = {Regular durability testing of heavy duty fuel cell systems for transit bus application requires several thousand hours of operation, which is costly and time consuming. Alternatively, accelerated durability tests are able to generate failure modes observed in field operation in a compressed time period, by applying enhanced levels of stress. The objective of the present work is to design and validate an accelerated membrane durability test (AMDT) for heavy duty fuel cells under bus related conditions. The proposed AMDTgenerates bus relevant membrane failure modes in a fewhundred hours, which is more than an order ofmagnitude faster than for regular duty cycle testing. Elevated voltage, temperature, and oxidant levels are used to accelerate membrane chemical stress, while relative humidity (RH) cycling is used to induce mechanical stress. RH cycling is found to significantly reduce membrane life-time compared to constant RH conditions. The role of a platinum band in the membrane is investigated and membranes with Pt bands demonstrate a considerable life-time extension under AMDT conditions, with minimal membrane degradation. Overall, this research serves to establish a benchmark AMDT that can rapidly and reliably evaluate membrane stability under simulated heavy duty fuel cell conditions.},
author = {Macauley, N. and Alavijeh, A. S. and Watson, M. and Kolodziej, J. and Lauritzen, M. and Knights, S. and Wang, G. and Kjeang, E.},
doi = {10.1149/2.0671501jes},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Macauley et al. - 2014 - Accelerated Membrane Durability Testing of Heavy Duty Fuel Cells.pdf:pdf},
issn = {0013-4651},
journal = {Journal of the Electrochemical Society},
number = {1},
pages = {F98--F107},
title = {{Accelerated Membrane Durability Testing of Heavy Duty Fuel Cells}},
url = {http://jes.ecsdl.org/cgi/doi/10.1149/2.0671501jes},
volume = {162},
year = {2014}
}
@article{Jaffe1954,
abstract = {Abstract unavailable.},
author = {Jaffe, B. and Roth, R. S. and Marzullo, S.},
doi = {10.1063/1.1721741},
isbn = {0021-8979},
issn = {00218979},
journal = {Journal of Applied Physics},
number = {6},
pages = {809--810},
title = {{Piezoelectric properties of Lead zirconate-Lead titanate solid-solution ceramics [8]}},
volume = {25},
year = {1954}
}
@article{Baroutian2010,
abstract = {In this study, potassium hydroxide catalyst supported on palm shell activated carbon was developed for transesterification of palm oil. The Central Composite Design (CCD) of the Response Surface Methodology (RSM) was employed to investigate the effects of reaction temperature, catalyst loading and methanol to oil molar ratio on the production of biodiesel using activated carbon supported catalyst. The highest yield was obtained at 64.1 ??C reaction temperature, 30.3 wt.% catalyst loading and 24:1 methanol to oil molar ratio. The physical and chemical properties of the produced biodiesel met the standard specifications. This study proves that activated carbon supported potassium hydroxide is an effective catalyst for transesterification of palm oil. ?? 2010 Elsevier B.V.},
author = {Baroutian, Saeid and Aroua, Mohamed Kheireddine and Raman, Abdul Aziz Abdul and Sulaiman, Nik Meriam Nik},
doi = {10.1016/j.fuproc.2010.05.009},
isbn = {0378-3820},
issn = {03783820},
journal = {Fuel Processing Technology},
keywords = {Biodiesel,Optimization,Potassium hydroxide},
number = {11},
pages = {1378--1385},
publisher = {Elsevier B.V.},
title = {{Potassium hydroxide catalyst supported on palm shell activated carbon for transesterification of palm oil}},
url = {http://dx.doi.org/10.1016/j.fuproc.2010.05.009},
volume = {91},
year = {2010}
}
@article{Yu2018,
abstract = {To reduce the significant redundancy in deep Convolutional Neural Networks (CNNs), most existing methods prune neurons by only considering the statistics of an individual layer or two consecutive layers (e.g., prune one layer to minimize the reconstruction error of the next layer), ignoring the effect of error propagation in deep networks. In contrast, we argue that for a pruned network to retain its predictive power, it is essential to prune neurons in the entire neuron network jointly based on a unified goal: Minimizing the reconstruction error of important responses in the 'final response layer' (FRL), which is the second-to-last layer before classification. Specifically, we apply feature ranking techniques to measure the importance of each neuron in the FRL, formulate network pruning as a binary integer optimization problem, and derive a closed-form solution to it for pruning neurons in earlier layers. Based on our theoretical analysis, we propose the Neuron Importance Score Propagation (NISP) algorithm to propagate the importance scores of final responses to every neuron in the network. The CNN is pruned by removing neurons with least importance, and it is then fine-tuned to recover its predictive power. NISP is evaluated on several datasets with multiple CNN models and demonstrated to achieve significant acceleration and compression with negligible accuracy loss.},
archivePrefix = {arXiv},
arxivId = {1711.05908},
author = {Yu, Ruichi and Li, Ang and Chen, Chun Fu and Lai, Jui Hsin and Morariu, Vlad I. and Han, Xintong and Gao, Mingfei and Lin, Ching Yung and Davis, Larry S.},
doi = {10.1109/CVPR.2018.00958},
eprint = {1711.05908},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu et al. - 2018 - NISP Pruning Networks Using Neuron Importance Score Propagation.pdf:pdf},
isbn = {9781538664209},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {9194--9203},
title = {{NISP: Pruning Networks Using Neuron Importance Score Propagation}},
year = {2018}
}
@article{Tran2016,
abstract = {PURPOSE This study evaluated pathological response to neoadjuvant chemotherapy using quantitative ultrasound (QUS) and diffuse optical spectroscopy imaging (DOSI) biomarkers in locally advanced breast cancer (LABC). MATERIALS AND METHODS The institution's ethics review board approved this study. Subjects (n = 22) gave written informed consent prior to participating. US and DOSI data were acquired, relative to the start of neoadjuvant chemotherapy, at weeks 0, 1, 4, 8 and preoperatively. QUS parameters including the mid-band fit (MBF), 0-MHz intercept (SI), and the spectral slope (SS) were determined from tumor ultrasound data using spectral analysis. In the same patients, DOSI was used to measure parameters relating to tumor hemoglobin and composition. Discriminant analysis and receiver-operating characteristic (ROC) analysis was used to classify clinical and pathological response during treatment and to estimate the area under the curve (AUC). Additionally, multivariate analysis was carried out for pairwise QUS/DOSI parameter combinations using a logistic regression model. RESULTS Individual QUS and DOSI parameters, including the (SI), oxy-hemoglobin (HbO2), and total hemoglobin (HbT) were significant markers for response after one week of treatment (p < 0.01). Multivariate (pairwise) combinations increased the sensitivity, specificity and AUC at this time; the SI + HbO2 showed a sensitivity/specificity of 100%, and an AUC of 1.0. CONCLUSIONS QUS and DOSI demonstrated potential as coincident markers for treatment response and may potentially facilitate response-guided therapies. Multivariate QUS and DOSI parameters increased the sensitivity and specificity of classifying LABC patients as early as one week after treatment.},
author = {Tran, William T. and Childs, Charmaine and Chin, Lee and Slodkowska, Elzbieta and Sannachi, Lakshmanan and Tadayyon, Hadi and Watkins, Elyse and Wong, Sharon Lemon and Curpen, Belinda and Kaffas, Ahmed El and Al-Mahrouki, Azza and Sadeghi-Naini, Ali and Czarnota, Gregory J.},
doi = {10.18632/oncotarget.7844},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tran et al. - 2016 - Multiparametric monitoring of chemotherapy treatment response in locally advanced breast cancer using quantitative.pdf:pdf},
issn = {1949-2553},
journal = {Oncotarget},
keywords = {diffuse optical spectroscopy,locally advanced breast cancer,neoadjuvant chemotherapy,quantitative ultrasound,treatment monitoring},
number = {15},
pmid = {26942698},
title = {{Multiparametric monitoring of chemotherapy treatment response in locally advanced breast cancer using quantitative ultrasound and diffuse optical spectroscopy}},
url = {http://www.oncotarget.com/fulltext/7844},
volume = {7},
year = {2016}
}
@article{Doersch2015,
abstract = {This work explores the use of spatial context as a source of free and plentiful supervisory signal for training a rich visual representation. Given only a large, unlabeled image collection, we extract random pairs of patches from each image and train a convolutional neural net to predict the position of the second patch relative to the first. We argue that doing well on this task requires the model to learn to recognize objects and their parts. We demonstrate that the feature representation learned using this within-image context indeed captures visual similarity across images. For example, this representation allows us to perform unsupervised visual discovery of objects like cats, people, and even birds from the Pascal VOC 2011 detection dataset. Furthermore, we show that the learned ConvNet can be used in the R-CNN framework [19] and provides a significant boost over a randomly-initialized ConvNet, resulting in state-of-the-art performance among algorithms which use only Pascal-provided training set annotations.},
archivePrefix = {arXiv},
arxivId = {1505.05192},
author = {Doersch, Carl and Gupta, Abhinav and Efros, Alexei A.},
doi = {10.1109/ICCV.2015.167},
eprint = {1505.05192},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Doersch, Gupta, Efros - 2015 - Unsupervised visual representation learning by context prediction.pdf:pdf},
isbn = {9781467383912},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {1422--1430},
title = {{Unsupervised visual representation learning by context prediction}},
volume = {2015 Inter},
year = {2015}
}
@article{Somnuk2014,
abstract = {High free fatty acid (FFA) reduction in mixed crude palm oil (MCPO) was performed with methanol (MeOH) and sulfuric acid (H2SO4) as acid catalyst using the circulation process through static mixer reactor. In this study, the response surface methodology (RSM) was adopted to optimize the acid value in esterified oil after esterification process (first-step) in lab-scale. The results showed that acid value was reduced from 30 mgKOH g-1to 2 mgKOH g-1, when 19.8 vol.% MeOH, 2.0 vol.% H2SO4, reaction temperature 60 C, 40 L h-1of MCPO, 50 min reaction time, and 5-m of static mixer in length, were used in the lab-scale. This recommended condition was used to develop the pilot-scale process in which the scaling up of the FFA reduction from 5 L MCPO of lab-scale to 60 L MCPO of pilot-scale, which was designed on the basis of a simple operation and maintenance. In the pilot-scale process, the lower 1 mgKOH g-1of acid value was achieved when it was conducted at the reaction time of 50 min. In the base-catalyzed transesterification (second-step) of pilot-scale process, the 98.65 wt.% of methyl ester purity was achieved when the following condition: 20 vol.% MeOH, 8 gKOH L-1oil, and 60 min reaction time at 60 C, was used to produce biodiesel. {\textcopyright} 2014 Elsevier Ltd. All rights reserved.},
author = {Somnuk, Krit and Niseng, Suhdee and Prateepchaikul, Gumpon},
doi = {10.1016/j.enconman.2014.01.059},
isbn = {0196-8904},
issn = {01968904},
journal = {Energy Conversion and Management},
keywords = {Acid catalyst,Circulation,Esterification,Mixed crude palm oil,Static mixer},
pages = {374--381},
publisher = {Elsevier Ltd},
title = {{Optimization of high free fatty acid reduction in mixed crude palm oils using circulation process through static mixer reactor and pilot-scale of two-step process}},
url = {http://dx.doi.org/10.1016/j.enconman.2014.01.059},
volume = {80},
year = {2014}
}
@book{LevinP.Poe,
author = {{Levin, P. Poe}, M.},
isbn = {9780128053751},
title = {{Conservation for the Anthropocene Ocean}}
}
@article{Mallya2018,
author = {Mallya, Arun and Lazebnik, Svetlana},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mallya, Lazebnik - 2018 - PackNet Adding Multiple Tasks to a Single Network by Iterative Pruning.pdf:pdf},
pages = {7765--7773},
title = {{PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning}},
year = {2018}
}
@article{Benabou2002,
abstract = {We analyze the value placed by rational agents on self-confidence, and the strategies employed in its pursuit. Confidence in one's abilities generally enhances motivation, making it a valuable asset for individuals with imperfect willpower. This demand for self-serving beliefs (which can also arise from hedonic or signaling motives) must be weighed against the risks of overconfidence. On the supply side, we develop a model of self-deception through endogenous memory that reconciles the motivated and rational features of human cognition. The resulting intrapersonal game of strategic communication typically leads to multiple equilibria While "positive thinking" can improve welfare, it can also be self-defeating (and nonetheless pursued). Believe what is in the line of your needs, for only by such belief is the need fulfilled Have faith that you can successfully make it, and your feet are nerved to its accomplishment [William James, Principles of Psychology].},
author = {Benabou, Roland and Tirole, Jean},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Benabou, Tirole - 2002 - Self-Confidence and Personal Motivation.pdf:pdf},
number = {June 1999},
title = {{Self-Confidence and Personal Motivation*}},
url = {http://qje.oxfordjournals.org/},
year = {2002}
}
@article{Lesort2019a,
abstract = {Which generative model is the most suitable for Continual Learning? This paper aims at evaluating and comparing generative models on disjoint sequential image generation tasks. We investigate how several models learn and forget, considering various strategies: rehearsal, regularization, generative replay and fine-tuning. We used two quantitative metrics to estimate the generation quality and memory ability. We experiment with sequential tasks on three commonly used benchmarks for Continual Learning (MNIST, Fashion MNIST and CIFAR10). We found that among all models, the original GAN performs best and among Continual Learning strategies, generative replay outperforms all other methods. Even if we found satisfactory combinations on MNIST and Fashion MNIST, training generative models sequentially on CIFAR10 is particularly instable, and remains a challenge. Our code is available online1.},
archivePrefix = {arXiv},
arxivId = {1812.09111},
author = {Lesort, Timothee and Caselles-Dupre, Hugo and Garcia-Ortiz, Michael and Stoian, Andrei and Filliat, David},
doi = {10.1109/IJCNN.2019.8851986},
eprint = {1812.09111},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lesort et al. - 2019 - Generative Models from the perspective of Continual Learning.pdf:pdf},
isbn = {9781728119854},
journal = {Proceedings of the International Joint Conference on Neural Networks},
title = {{Generative Models from the perspective of Continual Learning}},
volume = {2019-July},
year = {2019}
}
@article{Levashina2014,
abstract = {In the 20 years since frameworks of employment interview structure have been developed, a considerable body of empirical research has accumulated. We summarize and critically examine this literature by fo-cusing on the 8 main topics that have been the focus of attention: (a) the definition of structure; (b) reducing bias through structure; (c) impres-sion management in structured interviews; (d) measuring personality via structured interviews; (e) comparing situational versus past-behavior questions; (f) developing rating scales; (g) probing, follow-up, prompt-ing, and elaboration on questions; and (h) reactions to structure. For each topic, we review and critique research and identify promising di-rections for future research. When possible, we augment the traditional narrative review with meta-analytic review and content analysis. We concluded that much is known about structured interviews, but there are still many unanswered questions. We provide 12 propositions and 19 research questions to stimulate further research on this important topic.},
author = {Levashina, Julia and Hartwell, Christopher J. and Morgeson, Frederick P. and Campion, Michael A.},
doi = {10.1111/peps.12052},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Levashina et al. - 2014 - The structured employment interview Narrative and quantitative review of the research literature.pdf:pdf},
isbn = {1744-6570},
issn = {00315826},
journal = {Personnel Psychology},
number = {1},
pages = {241--293},
title = {{The structured employment interview: Narrative and quantitative review of the research literature}},
volume = {67},
year = {2014}
}
@book{Orellana2005,
author = {Orellana, G and Moreno-Bondi, MC},
booktitle = {Springer series on chemical sensors and biosensors},
isbn = {9783540365679},
pages = {175--180},
title = {{Springer series on chemical sensors and biosensors}},
url = {http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:Springer+Series+on+Chemical+Sensors+and+Biosensors#5},
volume = {5},
year = {2005}
}
@article{DeGirolamo2017a,
abstract = {Wave forecasting may represent a useful tool for safety assessment of maritime works and activities. To date, wave forecasting uncertainty is usually corrected by using either the mean calibration factor or the time series method. However, within the frame of maritime work management it is necessary to forecast – with an acceptable probability of error – whether or not the significant wave height at a given location will exceed a prefixed threshold within a specified temporal window, so as to assess the safety of the specified temporal window with respect to the activity to be carried out. The present paper aims to illustrate a general criterion useful to correct wave forecast, i.e. to provide an engineering tool able to assess the safety of the temporal window needed to complete a specified maritime work. The paper provides a detailed description of the method, together with the application to a real case.},
author = {{De Girolamo}, P. and {Di Risio}, M. and Beltrami, G. M. and Bellotti, G. and Pasquali, D.},
doi = {10.1016/j.apor.2016.11.006},
issn = {01411187},
journal = {Applied Ocean Research},
keywords = {Maritime activities safety,Probabilistic wave forecasting,Wave forecasting},
pages = {18--26},
publisher = {Elsevier Ltd},
title = {{The use of wave forecasts for maritime activities safety assessment}},
url = {http://dx.doi.org/10.1016/j.apor.2016.11.006},
volume = {62},
year = {2017}
}
@inproceedings{Xia2021,
abstract = {Unsupervised Domain Adaptation solves knowledge transfer along with the coexistence of well-annotated source domain and unlabeled target instances. However, the source domain in many practical applications is not always accessible due to data privacy or the insufficient memory storage for small devices. This scenario defined as Source-free Domain Adaptation only allows accessing the well-trained source model for target learning. To address the challenge of source data unavailability, we develop an Adaptive Adversarial Network (A 2 Net) including three components. Specifically, the first one named Adaptive Ad-versarial Inference seeks a target-specific classifier to advance the recognition of samples which the provided source-specific classifier difficultly identifies. Then, the Contrastive Category-wise Matching module exploits the positive relation of every two target images to enforce the compactness of subspace for each category. Thirdly, Self-Supervised Rotation facilitates the model to learn additional semantics from target images by themselves. Extensive experiments on the popular cross-domain benchmarks verify the effectiveness of our proposed model on solving adaptation task without any source data.},
author = {Xia, Haifeng and Zhao, Handong and Ding, Zhengming},
booktitle = {International Conference on Computer Vision},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xia, Zhao, Ding - 2021 - Adaptive Adversarial Network for Source-free Domain Adaptation.pdf:pdf},
keywords = {domain adaptation,source-free},
mendeley-tags = {domain adaptation,source-free},
pages = {9010--9019},
title = {{Adaptive Adversarial Network for Source-free Domain Adaptation}},
year = {2021}
}
@article{Jacot2018,
abstract = {At initialization, artificial neural networks (ANNs) are equivalent to Gaussian processes in the infinite-width limit (12; 9), thus connecting them to kernel methods. We prove that the evolution of an ANN during training can also be described by a kernel: during gradient descent on the parameters of an ANN, the network function f$\theta$ (which maps input vectors to output vectors) follows the kernel gradient of the functional cost (which is convex, in contrast to the parameter cost) w.r.t. a new kernel: the Neural Tangent Kernel (NTK). This kernel is central to describe the generalization features of ANNs. While the NTK is random at initialization and varies during training, in the infinite-width limit it converges to an explicit limiting kernel and it stays constant during training. This makes it possible to study the training of ANNs in function space instead of parameter space. Convergence of the training can then be related to the positive-definiteness of the limiting NTK. We then focus on the setting of least-squares regression and show that in the infinite-width limit, the network function f$\theta$ follows a linear differential equation during training. The convergence is fastest along the largest kernel principal components of the input data with respect to the NTK, hence suggesting a theoretical motivation for early stopping. Finally we study the NTK numerically, observe its behavior for wide networks, and compare it to the infinite-width limit.},
archivePrefix = {arXiv},
arxivId = {1806.07572},
author = {Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'{e}}ment},
eprint = {1806.07572},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jacot, Gabriel, Hongler - 2018 - Neural tangent kernel Convergence and generalization in neural networks.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
keywords = {convergence,generalization,neural tangent kernel,optimization,theory},
mendeley-tags = {convergence,generalization,neural tangent kernel,optimization,theory},
number = {5},
pages = {8571--8580},
title = {{Neural tangent kernel: Convergence and generalization in neural networks}},
volume = {2018-Decem},
year = {2018}
}
@article{Cosgun2014,
abstract = {In this study, the pricing problem of a transportation service provider company is considered. Our goal is to find optimal prices by using probabilistic dynamic programming. A fuzzy IF-THEN-rule based system is used to identify the demand levels under different prices and other characteristics of the journey. The results obtained by optimal price policies show that the revenue increases by applying dynamic pricing policy instead of fixed pricing. Thus, the diversification of pricing policies under different conditions is beneficial for the company.},
author = {Coşgun, {\"{O}}zlem and Ekinci, Yeliz and Yanik, Seda},
doi = {10.1016/j.knosys.2014.04.015},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Coşgun, Ekinci, Yanik - 2014 - Fuzzy rule-based demand forecasting for dynamic pricing of a maritime company.pdf:pdf},
isbn = {9789814417730},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Demand forecasting,Dynamic pricing,Dynamic programming,Fuzzy IF-THEN rules,Transportation},
number = {May},
pages = {88--96},
title = {{Fuzzy rule-based demand forecasting for dynamic pricing of a maritime company}},
volume = {70},
year = {2014}
}
@article{Roschat2016,
abstract = {In this study, hydrated lime-derived calcium oxide (CaO) was used as a catalyst for the transesterification of palm oil. The catalysts were characterized by TG-DTA, XRD, XRF, FT-IR, SEM, Hammett indicator method, TPD-CO2and BET by N2adsorption. Under the optimal conditions at catalyst loading of 6 wt.%, methanol/oil molar ratio of 15:1, reaction temperature 65 °C, and stirring rate of 200 rpm; 97% yield of biodiesel could be achieved in 2 h. Effects of water amount were investigated and the catalyst could tolerate high water content of 5 wt.%. The kinetic of the reaction followed pseudo-first order with the activation energy (Ea) of 121.12 kJ/mol and frequency factor (A) of 1.203 × 1017min-1. After treatments, high quality biodiesel was obtained which indicated that the very cheap hydrated lime-derived CaO showed excellent catalytic activity and high potential for applications in biodiesel production.},
author = {Roschat, Wuttichai and Siritanon, Theeranun and Yoosuk, Boonyawan and Promarak, Vinich},
doi = {10.1016/j.enconman.2015.11.036},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roschat et al. - 2016 - Biodiesel production from palm oil using hydrated lime-derived CaO as a low-cost basic heterogeneous catalyst.pdf:pdf},
isbn = {01968904},
issn = {01968904},
journal = {Energy Conversion and Management},
keywords = {Biodiesel,Calcium oxide,Hydrated lime,Palm oil,Transesterification},
pages = {459--467},
publisher = {Elsevier Ltd},
title = {{Biodiesel production from palm oil using hydrated lime-derived CaO as a low-cost basic heterogeneous catalyst}},
url = {http://dx.doi.org/10.1016/j.enconman.2015.11.036},
volume = {108},
year = {2016}
}
@article{Abebe2016,
abstract = {We propose robust multi-dimensional motion features for human activity recognition from first-person videos. The proposed features encode information about motion magnitude, direction and variation, and combine them with virtual inertial data generated from the video itself. The use of grid flow representation, per-frame normalization and temporal feature accumulation enhances the robustness of our new representation. Results on multiple datasets demonstrate that the proposed feature representation outperforms existing motion features, and importantly it does so independently of the classifier. Moreover, the proposed multi-dimensional motion features are general enough to make them suitable for vision tasks beyond those related to wearable cameras.},
author = {Abebe, Girmaw and Cavallaro, Andrea and Parra, Xavier},
doi = {10.1016/j.cviu.2015.10.015},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abebe, Cavallaro, Parra - 2016 - Robust multi-dimensional motion features for first-person vision activity recognition.pdf:pdf},
issn = {1090235X},
journal = {Computer Vision and Image Understanding},
keywords = {First-person vision,Grid optical flow,Human activity recognition,Inertial data,Wearable camera},
pages = {229--248},
publisher = {Elsevier Inc.},
title = {{Robust multi-dimensional motion features for first-person vision activity recognition}},
volume = {149},
year = {2016}
}
@article{Medathati2015,
abstract = {Studies in biological vision have always been a great source of inspiration for design of computer vision algorithms. In the past, several successful methods were designed with varying degrees of correspondence with biological vision studies, ranging from purely functional inspiration to methods that utilise models that were primarily developed for explaining biological observations. Even though it seems well recognised that computational models of biological vision can help in design of computer vision algorithms, it is a non-trivial exercise for a computer vision researcher to mine relevant information from biological vision literature as very few studies in biology are organised at a task level. In this paper we aim to bridge this gap by providing a computer vision task centric presentation of models primarily originating in biological vision studies. Not only do we revisit some of the main features of biological vision and discuss the foundations of existing computational studies modelling biological vision, but also we consider three classical computer vision tasks from a biological perspective: image sensing, segmentation and optical flow. Using this task-centric approach, we discuss well-known biological functional principles and compare them with approaches taken by computer vision. Based on this comparative analysis of computer and biological vision, we present some recent models in biological vision and highlight a few models that we think are promising for future investigations in computer vision. To this extent, this paper provides new insights and a starting point for investigators interested in the design of biology-based computer vision algorithms and pave a way for much needed interaction between the two communities leading to the development of synergistic models of artificial and biological vision.},
author = {Medathati, N. V.Kartheek and Neumann, Heiko and Masson, Guillaume S. and Kornprobst, Pierre},
doi = {10.1016/j.cviu.2016.04.009},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Medathati et al. - 2015 - Bio-inspired computer vision Towards a synergistic approach of artificial and biological vision.pdf:pdf},
isbn = {1077-3142},
issn = {1090235X},
journal = {Computer Vision and Image Understanding},
keywords = {Canonical computations,Dynamic sensors,Event based processing,Feedback,Form-motion interactions,Lateral interactions,Multiplexed representation,Population coding,Soft selectivity},
pages = {1--30},
publisher = {Elsevier Inc.},
title = {{Bio-inspired computer vision: Towards a synergistic approach of artificial and biological vision}},
volume = {150},
year = {2015}
}
@article{Ske1997,
author = {Ske, Frank R},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ske - 1997 - Sea Level Forecasts Using Neural Networks.pdf:pdf},
number = {1},
title = {{Sea Level Forecasts Using Neural Networks}},
volume = {49},
year = {1997}
}
@article{Guidelines2020,
author = {Guidelines, Bmvc Author},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guidelines - 2020 - Self Supervision for Attention Networks.pdf:pdf},
keywords = {attention networks,self-supervised learning},
mendeley-tags = {attention networks,self-supervised learning},
pages = {726--735},
title = {{Self Supervision for Attention Networks}},
year = {2020}
}
@article{DaSilva2016,
abstract = {{\textcopyright} The Author(s) 2016. This study reports the use of PtAu/C electrocatalysts with different atomic ratios (90:10, 70:30 and 50:50) supported on Vulcan XC 72 carbon and prepared by the sodium borohydride method toward formate electrooxidation in alkaline media. The materials were characterized by X-ray diffraction, showing peaks characteristics of Pt and Au face-centered-cubic structures, and also by transmission electron micrographs that show the nanoparticles well dispersed on carbon and a mean particle size between 4 and 5 nm for all electrocatalysts. Electrochemical experiments show PtAu/C as promising catalysts toward formate oxidation, while single cell experiments reveal PtAu/C 90:10 as the best material since it provides a power density higher than Pt/C. The incorporation of Au could increase formate oxidation for more than one reason: (i) a facilitated rupture of C–H bond; (ii) the Au/oxide interface or (iii) by regenerating active sites.},
author = {da Silva, Sirlane G. and Silva, J{\'{u}}lio C{\'{e}}sar M and Buzzo, Guilherme S. and Neto, Almir O. and Assump{\c{c}}{\~{a}}o, M{\^{O}}nica H M T},
doi = {10.1007/s40243-016-0079-8},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/da Silva et al. - 2016 - Use of ptauc electrocatalysts toward formate oxidation Electrochemical and fuel cell considerations.pdf:pdf},
issn = {21941467},
journal = {Materials for Renewable and Sustainable Energy},
keywords = {Borohydride process,Direct formate fuel cell,Formate oxidation,PtAu/C electrocatalysts},
number = {4},
title = {{Use of ptau/c electrocatalysts toward formate oxidation: Electrochemical and fuel cell considerations}},
volume = {5},
year = {2016}
}
@article{Pomponi2020,
abstract = {Continual learning of deep neural networks is a key requirement for scaling them up to more complex applicative scenarios and for achieving real lifelong learning of these architectures. Previous approaches to the problem have considered either the progressive increase in the size of the networks, or have tried to regularize the network behavior to equalize it with respect to previously observed tasks. In the latter case, it is essential to understand what type of information best represents this past behavior. Common techniques include regularizing the past outputs, gradients, or individual weights. In this work, we propose a new, relatively simple and efficient method to perform continual learning by regularizing instead the network internal embeddings. To make the approach scalable, we also propose a dynamic sampling strategy to reduce the memory footprint of the required external storage. We show that our method performs favorably with respect to state-of-the-art approaches in the literature, while requiring significantly less space in memory and computational time. In addition, inspired by to recent works, we evaluate the impact of selecting a more flexible model for the activation functions inside the network, evaluating the impact of catastrophic forgetting on the activation functions themselves.},
archivePrefix = {arXiv},
arxivId = {1909.03742},
author = {Pomponi, Jary and Scardapane, Simone and Lomonaco, Vincenzo and Uncini, Aurelio},
doi = {10.1016/j.neucom.2020.01.093},
eprint = {1909.03742},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pomponi et al. - 2020 - Efficient continual learning in neural networks with embedding regularization.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Catastrophic forgetting,Continual learning,Embedding,Regularization,Trainable activation functions,continual learning,regularization},
mendeley-tags = {continual learning,regularization},
month = {sep},
pages = {139--148},
title = {{Efficient continual learning in neural networks with embedding regularization}},
url = {http://arxiv.org/abs/1909.03742 http://dx.doi.org/10.1016/j.neucom.2020.01.093},
volume = {397},
year = {2020}
}
@article{Choong2009,
abstract = {Missing value estimation is important in DNA microarray data analysis. A number of algorithms have been developed to solve this problem, but they have several limitations. Most existing algorithms are not able to deal with the situation where a particular time point (column) of the data is missing entirely. In this paper, we present an autoregressive-model-based missing value estimation method (ARLSimpute) that takes into account the dynamic property of microarray temporal data and the local similarity structures in the data. ARLSimpute is especially effective for the situation where a particular time point contains many missing values or where the entire time point is missing. Experiment results suggest that our proposed algorithm is an accurate missing value estimator in comparison with other imputation methods on simulated as well as real microarray time series datasets.},
author = {Choong, Miew Keen and Charbit, Maurice and Yan, Hong},
doi = {10.1109/TITB.2008.2007421},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Choong, Charbit, Yan - 2009 - Autoregressive-model-based missing value estimation for DNA microarray time series data.pdf:pdf},
issn = {1558-0032},
journal = {IEEE transactions on information technology in biomedicine : a publication of the IEEE Engineering in Medicine and Biology Society},
keywords = {Algorithms,Animals,Computer Simulation,Data Interpretation, Statistical,Gene Expression Profiling,Gene Expression Profiling: statistics & numerical,Humans,Models, Genetic,Models, Statistical,Oligonucleotide Array Sequence Analysis,Oligonucleotide Array Sequence Analysis: statistic},
number = {1},
pages = {131--7},
pmid = {19129032},
title = {{Autoregressive-model-based missing value estimation for DNA microarray time series data.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19129032},
volume = {13},
year = {2009}
}
@article{Bisht2016a,
abstract = {This study proposes a fuzzy time series forecasting method based on hesitant fuzzy sets for forecasting in the environment of hesitant information. The proposed method addresses the problem of establishing a common membership grade for the situation when multiple fuzzification methods are available to fuzzify time series data. An aggregation operator for aggregating hesitant information is also proposed in the study. The proposed method is implemented to forecast enrollment at University of Alabama and price of state bank of India (SBI) share at Bombay stock exchange (BSE), India. In both time series data are fuzzified with triangular fuzzy sets constructed using intervals of equal and unequal length. The performance of the proposed method in forecasting student enrollments and SBI share price is measured in terms of root mean square and average forecasting errors. Statistical validation and performance analysis is also carried out to validate the proposed forecasting method.},
author = {Bisht, Kamlesh and Kumar, Sanjay},
doi = {10.1016/j.eswa.2016.07.044},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bisht, Kumar - 2016 - Fuzzy time series forecasting method based on hesitant fuzzy sets.pdf:pdf},
isbn = {0957-4174},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Aggregation operator,Forecasting,Fuzzy logical relation,Fuzzy time series,Hesitant fuzzy set,Time invariant},
pages = {557--568},
publisher = {Elsevier Ltd},
title = {{Fuzzy time series forecasting method based on hesitant fuzzy sets}},
volume = {64},
year = {2016}
}
@article{Subbaraman2015,
abstract = {Silicon photonics has experienced phenomenal transformations over the last\n decade. In this paper, we present some of the notable advances in silicon-based\n passive and active optical interconnect components, and highlight some of our\n key contributions. Light is also cast on few other parallel technologies that\n are working in tandem with silicon-based structures, and providing unique\n functions not achievable with any single system acting alone. With an increasing\n utilization of CMOS foundries for silicon photonics fabrication, a viable path\n for realizing extremely low-cost integrated optoelectronics has been paved.\n These advances are expected to benefit several application domains in the years\n to come, including communication networks, sensing, and nonlinear systems.},
author = {Subbaraman, Harish and Xu, Xiaochuan and Hosseini, Amir and Zhang, Xingyu and Zhang, Yang and Kwong, David and Chen, Ray T.},
doi = {10.1364/OE.23.002487},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Subbaraman et al. - 2015 - Recent advances in silicon-based passive and active optical interconnects.pdf:pdf},
isbn = {1094-4087},
issn = {1094-4087},
journal = {Optics Express},
number = {3},
pages = {2487},
pmid = {25836116},
title = {{Recent advances in silicon-based passive and active optical interconnects}},
url = {https://www.osapublishing.org/abstract.cfm?URI=oe-23-3-2487},
volume = {23},
year = {2015}
}
@article{Joseph2020c,
abstract = {In a real-world setting, object instances from new classes may be continuously encountered by object detectors. When existing object detectors are applied to such scenarios, their performance on old classes deteriorates significantly. A few efforts have been reported to address this limitation, all of which apply variants of knowledge distillation to avoid catastrophic forgetting. We note that although distillation helps to retain previous learning, it obstructs fast adaptability to new tasks, which is a critical requirement for incremental learning. In this pursuit, we propose a meta-learning approach that learns to reshape model gradients, such that information across incremental tasks is optimally shared. This ensures a seamless information transfer via a meta-learned gradient preconditioning that minimizes forgetting and maximizes knowledge transfer. In comparison to existing meta-learning methods, our approach is task-agnostic, allows incremental addition of new-classes and scales to large-sized models for object detection. We evaluate our approach on a variety of incremental settings defined on PASCAL-VOC and MS COCO datasets, demonstrating significant improvements over state-of-the-art.},
archivePrefix = {arXiv},
arxivId = {2003.08798},
author = {Joseph, K. J. and Rajasegaran, Jathushan and Khan, Salman and Khan, Fahad Shahbaz and Balasubramanian, Vineeth N. and Shao, Ling},
eprint = {2003.08798},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Joseph et al. - 2020 - Incremental object detection via meta-learning(3).pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {Deep Neural Networks,Incremental Object Detection,continual learning,incremental learning,object detection},
mendeley-tags = {continual learning,incremental learning,object detection},
number = {8},
pages = {1--8},
title = {{Incremental object detection via meta-learning}},
volume = {14},
year = {2020}
}
@article{Nakatani2009,
abstract = {Transesterification of soybean oil catalyzed by combusted oyster shell, which is waste material from shellfish farms, was examined. Powdered oyster shell combusted at a temperature above 700 °C, at which point the calcium carbonate of oyster shell transformed to calcium oxide, acted as a catalyst in the transesterification of soybean oil. On the basis of factorial design, the reaction conditions of catalyst concentration and reaction time were optimized in terms of the fatty acid methyl ester concentration expressed as biodiesel purity. Under the optimized reaction conditions of a catalyst concentration and reaction time of 25wt.%. and 5 h, respectively, the biodiesel yield, expressed relative to the amount of soybean oil poured into the reaction vial, was more than 70% with high biodiesel purity. These results indicate oyster shell waste combusted at high temperature can be reused in biodiesel production as a catalyst. {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
author = {Nakatani, Nobutake and Takamori, Hitoshi and Takeda, Kazuhiko and Sakugawa, Hiroshi},
doi = {10.1016/j.biortech.2008.09.007},
isbn = {0960-8524},
issn = {09608524},
journal = {Bioresource Technology},
keywords = {Biodiesel,Factorial design,Oyster shell,Soybean oil,Transesterification},
number = {3},
pages = {1510--1513},
pmid = {18926696},
publisher = {Elsevier Ltd},
title = {{Transesterification of soybean oil using combusted oyster shell waste as a catalyst}},
url = {http://dx.doi.org/10.1016/j.biortech.2008.09.007},
volume = {100},
year = {2009}
}
@article{Liu2019,
abstract = {Federated learning (FL) provides a communication-efficient approach to solve machine learning problems concerning distributed data, without sending raw data to a central server. However, existing works on FL only utilize first-order gradient descent (GD) and do not consider the preceding iterations to gradient update which can potentially accelerate convergence. In this paper, we consider momentum term which relates to the last iteration. The proposed momentum federated learning (MFL) uses momentum gradient descent (MGD) in the local update step of FL system. We establish global convergence properties of MFL and derive an upper bound on MFL convergence rate. Comparing the upper bounds on MFL and FL convergence rate, we provide conditions in which MFL accelerates the convergence. For different machine learning models, the convergence performance of MFL is evaluated based on experiments with MNIST dataset. Simulation results comfirm that MFL is globally convergent and further reveal significant convergence improvement over FL.},
archivePrefix = {arXiv},
arxivId = {1910.03197},
author = {Liu, Wei and Chen, Li and Chen, Yunfei and Zhang, Wenyi},
eprint = {1910.03197},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2019 - Accelerating Federated Learning via Momentum Gradient Descent.pdf:pdf},
title = {{Accelerating Federated Learning via Momentum Gradient Descent}},
url = {http://arxiv.org/abs/1910.03197},
year = {2019}
}
@article{Battaglia2018,
abstract = {Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between "hand-engineering" and "end-to-end" learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.},
archivePrefix = {arXiv},
arxivId = {1806.01261},
author = {Battaglia, Peter W. and Hamrick, Jessica B. and Bapst, Victor and Sanchez-Gonzalez, Alvaro and Zambaldi, Vinicius and Malinowski, Mateusz and Tacchetti, Andrea and Raposo, David and Santoro, Adam and Faulkner, Ryan and Gulcehre, Caglar and Song, Francis and Ballard, Andrew and Gilmer, Justin and Dahl, George and Vaswani, Ashish and Allen, Kelsey and Nash, Charles and Langston, Victoria and Dyer, Chris and Heess, Nicolas and Wierstra, Daan and Kohli, Pushmeet and Botvinick, Matt and Vinyals, Oriol and Li, Yujia and Pascanu, Razvan},
eprint = {1806.01261},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Battaglia et al. - 2018 - Relational inductive biases, deep learning, and graph networks.pdf:pdf},
month = {jun},
title = {{Relational inductive biases, deep learning, and graph networks}},
url = {http://arxiv.org/abs/1806.01261},
year = {2018}
}
@article{Ali2017,
abstract = {In this work, active vibration mitigation for smart single link manipulator is presented. Two piezoelectric transducers were utilized to act as actuator and sensor respectively. Classical Proportional (P) controller was tested numerically and experimentally. The comparison between measured results showed good agreement. The proposed work includes the introducing of fuzzy logic for tuning controller's gain within finite element method. Classical Proportional-Integral (PI), Fuzzy-P and Fuzzy-PI controllers were totally integrated as a series of [IF-Then] states and solved numerically by using Finite Element (FE) solver (ANSYS). Proposed method will pave the way on solving the tuning process totally within single FE solver with high efficiency. Proposed method satisfied mitigation in the overall free response with about 52% and 74% of the manipulator settling time when Fuzzy-P and Fuzzy-PI controllers were activated respectively. This contribution can be utilized for many other applications related to fuzzy topics.},
author = {Ali, Ahmed A. and Lateef, Rana Abdul Rahman and Saeed, Mahmood Wael},
doi = {10.1016/j.jestch.2017.08.001},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ali, Lateef, Saeed - 2017 - Intelligent tuning of vibration mitigation process for single link manipulator using fuzzy logic.pdf:pdf},
issn = {22150986},
journal = {Engineering Science and Technology, an International Journal},
keywords = {Active vibration control,Finite element method,Fuzzy logic,Manipulator},
number = {4},
pages = {1233--1241},
publisher = {Karabuk University},
title = {{Intelligent tuning of vibration mitigation process for single link manipulator using fuzzy logic}},
url = {https://doi.org/10.1016/j.jestch.2017.08.001},
volume = {20},
year = {2017}
}
@article{Zhang2016,
author = {Zhang, Cong and Chen, Haoyong and Lei, Jia and Liang, Zipeng},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2016 - Solution of Interval Reactive Power Optimization U sing Genetic Algorithm.pdf:pdf},
isbn = {9781509054176},
pages = {1096--1100},
title = {{Solution of Interval Reactive Power Optimization U sing Genetic Algorithm}},
year = {2016}
}
@article{Kaspar2015,
abstract = {Hydroxide exchangemembranefuel cells(HEMFCs)are an emerging low-cost alternative to conventional proton exchangemembrane fuel cells. In addition to producing water at the anode, HEMFCs consume water at the cathode, leading to distinctive water transport behavior.We report that gas diffusion layer (GDL) wetproofing strictly lowers cell performance, but that the penalty is much higher when the anode side is wetproofed compared to the cathode side.We attribute this penalty primarily to mass transport losses from anode flooding, suggesting that cathode humidificationmay be more beneficial than anode humidification for this device. GDLswith little or no wetproofing perform best, yielding a competitive peak power density of 737mWcm−2.},
author = {Kaspar, R. B. and Letterio, M. P. and Wittkopf, J. A. and Gong, K. and Gu, S. and Yan, Y.},
doi = {10.1149/2.0131506jes},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kaspar et al. - 2015 - Manipulating Water in High-Performance Hydroxide Exchange Membrane Fuel Cells through Asymmetric Humidification a.pdf:pdf},
issn = {0013-4651},
journal = {Journal of the Electrochemical Society},
number = {6},
pages = {F483--F488},
title = {{Manipulating Water in High-Performance Hydroxide Exchange Membrane Fuel Cells through Asymmetric Humidification and Wetproofing}},
url = {http://jes.ecsdl.org/cgi/doi/10.1149/2.0131506jes},
volume = {162},
year = {2015}
}
@article{Redmon2017,
abstract = {We introduce YOLO9000, a state-of-the-art, real-time object detection system that can detect over 9000 object categories. First we propose various improvements to the YOLO detection method, both novel and drawn from prior work. The improved model, YOLOv2, is state-of-the-art on standard detection tasks like PASCAL VOC and COCO. At 67 FPS, YOLOv2 gets 76.8 mAP on VOC 2007. At 40 FPS, YOLOv2 gets 78.6 mAP, outperforming state-of-the-art methods like Faster RCNN with ResNet and SSD while still running significantly faster. Finally we propose a method to jointly train on object detection and classification. Using this method we train YOLO9000 simultaneously on the COCO detection dataset and the ImageNet classification dataset. Our joint training allows YOLO9000 to predict detections for object classes that don't have labelled detection data. We validate our approach on the ImageNet detection task. YOLO9000 gets 19.7 mAP on the ImageNet detection validation set despite only having detection data for 44 of the 200 classes. On the 156 classes not in COCO, YOLO9000 gets 16.0 mAP. But YOLO can detect more than just 200 classes; it predicts detections for more than 9000 different object categories. And it still runs in real-time.},
archivePrefix = {arXiv},
arxivId = {arXiv:1612.08242v1},
author = {Redmon, Joseph and Farhadi, Ali},
doi = {10.1109/CVPR.2017.690},
eprint = {arXiv:1612.08242v1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Redmon, Farhadi - 2017 - YOLO9000 Better, faster, stronger.pdf:pdf},
isbn = {9781538604571},
journal = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
pages = {6517--6525},
title = {{YOLO9000: Better, faster, stronger}},
volume = {2017-Janua},
year = {2017}
}
@article{Siminski2017,
abstract = {Neuro-fuzzy systems have been proved to be an efficient tool for modelling real life systems. They are precise and have ability to generalise knowledge from presented data. Neuro-fuzzy systems use fuzzy sets – most commonly type-1 fuzzy sets. Type-2 fuzzy sets model uncertainties better than type-1 fuzzy sets because of their fuzzy membership function. Unfortunately computational complexity of type reduction in general type-2 systems is high enough to hinder their practical application. This burden can be alleviated by application of interval type-2 fuzzy sets. The paper presents an interval type-2 neuro-fuzzy system with interval type-2 fuzzy sets both in premises (Gaussian interval type-2 fuzzy sets with uncertain fuzziness) and consequences (trapezoid interval type-2 fuzzy set). The inference mechanism is based on the interval type-2 fuzzy {\L}ukasiewicz, Reichenbach, Kleene-Dienes, or Brouwer–G{\"{o}}del implications. The paper is accompanied by numerical examples. The system can elaborate models with lower error rate than type-1 neuro-fuzzy system with implication-based inference mechanism. The system outperforms some known type-2 neuro-fuzzy systems.},
author = {Siminski, Krzysztof},
doi = {10.1016/j.eswa.2017.02.046},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Siminski - 2017 - Interval type-2 neuro-fuzzy system with implication-based inference mechanism.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Fuzzy inference systems,Implication-based rules,Interval type-2 fuzzy sets,Neuro-fuzzy systems},
pages = {140--152},
publisher = {Elsevier Ltd},
title = {{Interval type-2 neuro-fuzzy system with implication-based inference mechanism}},
volume = {79},
year = {2017}
}
@article{MyThanh2017,
abstract = {The objective of this study is to understand how and to what extend illegal parking should be legalized, giving the benefit for parking users, urban planning, and transport planning. From literature, the policies and theories based on the lessons from other countries have provided the basis that can be applied in investigating a new parking management paradigm. Empirical surveys are conducted to examine the parking conditions, parking user's behavior and the consequence of illegal parking spaces in the core city center in Hanoi, Vietnam. Then, the requirements of para-parking (legalization of illegal parking spaces) are formulated including the change process that involves parking authorities, parking operators, and parking users. An in-depth analyze is undertaken to look at opportunities, risks and forms of para-parking and finally a proposal for a qualitative economic impact assessment of parking facility investment is given.},
author = {{My Thanh}, Truong Thi and Friedrich, Hanno},
doi = {10.1016/j.trpro.2017.05.374},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/My Thanh, Friedrich - 2017 - Legalizing the illegal parking, a solution for parking scarcity in developing countries.pdf:pdf},
issn = {23521465},
journal = {Transportation Research Procedia},
keywords = {developing cities,illegal parking,parking management},
pages = {4954--4969},
publisher = {Elsevier B.V.},
title = {{Legalizing the illegal parking, a solution for parking scarcity in developing countries}},
url = {http://dx.doi.org/10.1016/j.trpro.2017.05.374},
volume = {25},
year = {2017}
}
@inproceedings{Zhai2019,
abstract = {Lifelong learning is challenging for deep neural networks due to their susceptibility to catastrophic forgetting. Catastrophic forgetting occurs when a trained network is not able to maintain its ability to accomplish previously learned tasks when it is trained to perform new tasks. We study the problem of lifelong learning for generative models, extending a trained network to new conditional generation tasks without forgetting previous tasks, while assuming access to the training data for the current task only. In contrast to state-of-the-art memory replay based approaches which are limited to label-conditioned image generation tasks, a more generic framework for continual learning of generative models under different conditional image generation settings is proposed in this paper. Lifelong GAN employs knowledge distillation to transfer learned knowledge from previous networks to the new network. This makes it possible to perform image-conditioned generation tasks in a lifelong learning setting. We validate Lifelong GAN for both image-conditioned and label-conditioned generation tasks, and provide qualitative and quantitative results to show the generality and effectiveness of our method.},
author = {Zhai, Mengyao and Chen, Lei and Tung, Fred and He, Jiawei and Nawhal, Megha and Mori, Greg},
booktitle = {2019 IEEE/CVF International Conference on Computer Vision (ICCV)},
doi = {10.1109/ICCV.2019.00285},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhai et al. - 2019 - Lifelong GAN Continual Learning for Conditional Image Generation.pdf:pdf},
isbn = {978-1-7281-4803-8},
issn = {23318422},
keywords = {continual learning,gan,generative model,image generation,incremental learning},
mendeley-tags = {continual learning,gan,generative model,image generation,incremental learning},
month = {oct},
pages = {2759--2768},
publisher = {IEEE},
title = {{Lifelong GAN: Continual Learning for Conditional Image Generation}},
url = {https://ieeexplore.ieee.org/document/9009516/},
year = {2019}
}
@article{Li2016a,
abstract = {This paper presents an optimisation method for reducing the number of
input channels and the complexity of the feed-forward NARX neural
network (NN) without compromising the accuracy of the NN model. By
utilising the correlation analysis method, the most significant
regressors are selected to form the input layer of the NN structure.
Applications of vehicle handling and ride model identification are
presented in this paper to demonstrate the optimisation technique, and
the optimal input layer structure and the optimal number of neurons for
the NN models are investigated. The results show that the developed NN
model requires significantly fewer coefficients and less training time
while maintaining high simulation accuracy compared with that of the
unoptimised model.},
author = {Li, Zongyan and Best, Matt},
doi = {10.1504/IJMIC.2016.075814},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Best - 2016 - Structure optimisation of input layer for feed-forward NARX neural network.pdf:pdf},
issn = {1746-6172},
journal = {International Journal of Modelling, Identification and Control},
keywords = {by work on developing,correlation analysis,dynamics using system,f-ratio,his paper is motivated,levenberg-marquardt,mse,narx,neural network,optimisation,order models for vehicle,reduced},
number = {3},
pages = {217},
title = {{Structure optimisation of input layer for feed-forward NARX neural network}},
url = {http://www.inderscience.com/link.php?id=75814},
volume = {25},
year = {2016}
}
@article{Anava2015,
author = {Anava, Oren},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Anava - 2015 - Online Time Series Prediction with Missing Data.pdf:pdf},
title = {{Online Time Series Prediction with Missing Data}},
year = {2015}
}
@article{Kemker2018,
abstract = {Deep neural networks are used in many state-of-the-art systems for machine perception. Once a network is trained to do a specific task, e.g., bird classification, it cannot easily be trained to do new tasks, e.g., incrementally learning to recognize additional bird species or learning an entirely different task such as flower recognition. When new tasks are added, typical deep neural networks are prone to catastrophically forgetting previous tasks. Networks that are capable of assimilating new information incrementally, much like how humans form new memories over time, will be more efficient than retraining the model from scratch each time a new task needs to be learned. There have been multiple attempts to develop schemes that mitigate catastrophic forgetting, but these methods have not been directly compared, the tests used to evaluate them vary considerably, and these methods have only been evaluated on small-scale problems (e.g., MNIST). In this paper, we introduce new metrics and benchmarks for directly comparing five different mechanisms designed to mitigate catastrophic forgetting in neural networks: regularization, ensembling, rehearsal, dual-memory, and sparse-coding. Our experiments on real-world images and sounds show that the mechanism(s) that are critical for optimal performance vary based on the incremental training paradigm and type of data being used, but they all demonstrate that the catastrophic forgetting problem is not yet solved.},
archivePrefix = {arXiv},
arxivId = {1708.02072},
author = {Kemker, Ronald and McClure, Marc and Abitino, Angelina and Hayes, Tyler L. and Kanan, Christopher},
eprint = {1708.02072},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kemker et al. - 2018 - Measuring catastrophic forgetting in neural networks.pdf:pdf},
isbn = {9781577358008},
journal = {32nd AAAI Conference on Artificial Intelligence, AAAI 2018},
keywords = {continual learning,survey},
mendeley-tags = {continual learning,survey},
pages = {3390--3398},
title = {{Measuring catastrophic forgetting in neural networks}},
year = {2018}
}
@article{Challenges,
author = {Challenges, The and Network, Telecommunications and Crisis, Capacity and Expansion, Capacity and Potential, Capacity Expansion and Growth, Dwdm Incremental and Layer, The Optical and Layer, Unifying},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Challenges et al. - Unknown - Dense Wavelength Division Multiplexing ( DWDM ) Definition Telecommunications Network.pdf:pdf},
journal = {The International Engineering Consortium},
title = {{Dense Wavelength Division Multiplexing ( DWDM ) Definition Telecommunications Network}}
}
@article{Marx2012,
abstract = {The multidisciplinary Web of Science{\textregistered} (WoS), in particular the WoS Century of Science archive, and some other databases enable tracking historical papers published before 1960. With historical papers we enter an area of completely different publication and citation culture. There are a number of factors making the search for historical papers a daunting task: limited coverage of journals, limitations of specific subject fields, complex author names, complicated journal titles, database errors, etc. Applying bibliometrics to historical papers, ie counting citations as a measure of the impact, may require careful consideration of a large proportion of erroneous citations. It is also necessary to apply time adjustment of the citation counts.},
archivePrefix = {arXiv},
arxivId = {arXiv:1112.2903v1},
author = {Marx, Werner},
doi = {10.1023/B},
eprint = {arXiv:1112.2903v1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Marx - 2012 - Tracking historical papers and their citations.pdf:pdf},
isbn = {0802713653},
issn = {02583127},
journal = {European Science Editing},
keywords = {Bibliometrics,Citation analysis,Errors,Historical papers,Literature search,Physics},
number = {2},
pages = {35--37},
pmid = {14985640},
title = {{Tracking historical papers and their citations}},
volume = {38},
year = {2012}
}
@article{Moharram2013,
abstract = {The objective of the research is to minimize the amount of water and electrical energy needed for cooling of the solar panels, especially in hot arid regions, e.g., desert areas in Egypt. A cooling system has been developed based on water spraying of PV panels. A mathematical model has been used to determine when to start cooling of the PV panels as the temperature of the panels reaches the maximum allowable temperature (MAT). A cooling model has been developed to determine how long it takes to cool down the PV panels to its normal operating temperature, i.e., 35 C, based on the proposed cooling system. Both models, the heating rate model and the cooling rate model, are validated experimentally. Based on the heating and cooling rate models, it is found that the PV panels yield the highest output energy if cooling of the panels starts when the temperature of the PV panels reaches a maximum allowable temperature (MAT) of 45 C. The MAT is a compromise temperature between the output energy from the PV panels and the energy needed for cooling. {\textcopyright} 2013 Ain Shams University. Production and hosting by Elsevier B.V. All rights reserved.},
author = {Moharram, K. A. and Abd-Elhady, M. S. and Kandil, H. A. and El-Sherif, H.},
doi = {10.1016/j.asej.2013.03.005},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Moharram et al. - 2013 - Enhancing the performance of photovoltaic panels by water cooling.pdf:pdf},
isbn = {1001780086},
issn = {20904479},
journal = {Ain Shams Engineering Journal},
keywords = {Cooling,Overheating,Photovoltaic},
number = {4},
pages = {869--877},
publisher = {Faculty of Engineering, Ain Shams University},
title = {{Enhancing the performance of photovoltaic panels by water cooling}},
url = {http://dx.doi.org/10.1016/j.asej.2013.03.005},
volume = {4},
year = {2013}
}
@article{Larsson2016,
abstract = {We develop a fully automatic image colorization system. Our approach leverages recent advances in deep networks, exploiting both low-level and semantic representations. As many scene elements naturally appear according to multimodal color distributions, we train our model to predict per-pixel color histograms. This intermediate output can be used to automatically generate a color image, or further manipulated prior to image formation. On both fully and partially automatic colorization tasks, we outperform existing methods. We also explore colorization as a vehicle for self-supervised visual representation learning.},
archivePrefix = {arXiv},
arxivId = {1603.06668},
author = {Larsson, Gustav and Maire, Michael and Shakhnarovich, Gregory},
doi = {10.1007/978-3-319-46493-0_35},
eprint = {1603.06668},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Larsson, Maire, Shakhnarovich - 2016 - Learning representations for automatic colorization.pdf:pdf},
isbn = {9783319464923},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {577--593},
title = {{Learning representations for automatic colorization}},
volume = {9908 LNCS},
year = {2016}
}
@article{Zhang2018,
abstract = {For object detection, the two-stage approach (e.g., Faster R-CNN) has been achieving the highest accuracy, whereas the one-stage approach (e.g., SSD) has the advantage of high efficiency. To inherit the merits of both while overcoming their disadvantages, in this paper, we propose a novel single-shot based detector, called RefineDet, that achieves better accuracy than two-stage methods and maintains comparable efficiency of one-stage methods. RefineDet consists of two inter-connected modules, namely, the anchor refinement module and the object detection module. Specifically, the former aims to (1) filter out negative anchors to reduce search space for the classifier, and (2) coarsely adjust the locations and sizes of anchors to provide better initialization for the subsequent regressor. The latter module takes the refined anchors as the input from the former to further improve the regression and predict multi-class label. Meanwhile, we design a transfer connection block to transfer the features in the anchor refinement module to predict locations, sizes and class labels of objects in the object detection module. The multi-task loss function enables us to train the whole network in an end-to-end way. Extensive experiments on PASCAL VOC 2007, PASCAL VOC 2012, and MS COCO demonstrate that RefineDet achieves state-of-the-art detection accuracy with high efficiency. Code is available at https://github.com/sfzhang15/RefineDet},
archivePrefix = {arXiv},
arxivId = {arXiv:1711.06897v3},
author = {Zhang, Shifeng and Wen, Longyin and Bian, Xiao and Lei, Zhen and Li, Stan Z.},
doi = {10.1109/CVPR.2018.00442},
eprint = {arXiv:1711.06897v3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2018 - Single-Shot Refinement Neural Network for Object Detection.pdf:pdf},
isbn = {9781538664209},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {4203--4212},
title = {{Single-Shot Refinement Neural Network for Object Detection}},
year = {2018}
}
@article{Shacham2007,
abstract = {Image restoration algorithms often require previous knowledge about the point spread function (PSF) of the disturbance. Deriving the PSF manually from a degraded ideal step-edge in the image is a well known procedure intended mainly for isotropic degradations. A common image degradation that can be approximated as isotropic is the atmospheric blurring in long-distance imaging. This paper proposes an efficient method that automatically finds the best (closest to ideal) step-edge from the degraded image. The identified PSF is then used to restore the image. The existence of a good step-edge in the image may be assumed in cases such as imaging of urban areas, which is common in applications such as visual surveillance and reconnaissance. The criteria employed include the straightness and length of the edge, its strength, and the homogeneity of the step. An efficient algorithm is proposed, and results of automatic blind image restoration based on the automatically extracted PSF are shown. {\textcopyright} 2007.},
author = {Shacham, Omri and Haik, Oren and Yitzhaky, Yitzhak},
doi = {10.1016/j.patrec.2007.06.006},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shacham, Haik, Yitzhaky - 2007 - Blind restoration of atmospherically degraded images by automatic best step-edge detection.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Atmospheric blur,Blind image restoration,Blur identification,Step-edge detection},
number = {15},
pages = {2094--2103},
title = {{Blind restoration of atmospherically degraded images by automatic best step-edge detection}},
volume = {28},
year = {2007}
}
@article{Mazzia2021,
abstract = {Deep convolutional neural networks, assisted by architectural design strategies, make extensive use of data augmentation techniques and layers with a high number of feature maps to embed object transformations. That is highly inefficient and for large datasets implies a massive redundancy of features detectors. Even though capsules networks are still in their infancy, they constitute a promising solution to extend current convolutional networks and endow artificial visual perception with a process to encode more efficiently all feature affine transformations. Indeed, a properly working capsule network should theoretically achieve higher results with a considerably lower number of parameters count due to intrinsic capability to generalize to novel viewpoints. Nevertheless, little attention has been given to this relevant aspect. In this paper, we investigate the efficiency of capsule networks and, pushing their capacity to the limits with an extreme architecture with barely 160K parameters, we prove that the proposed architecture is still able to achieve state-of-the-art results on three different datasets with only 2% of the original CapsNet parameters. Moreover, we replace dynamic routing with a novel non-iterative, highly parallelizable routing algorithm that can easily cope with a reduced number of capsules. Extensive experimentation with other capsule implementations has proved the effectiveness of our methodology and the capability of capsule networks to efficiently embed visual representations more prone to generalization.},
archivePrefix = {arXiv},
arxivId = {2101.12491},
author = {Mazzia, Vittorio and Salvetti, Francesco and Chiaberge, Marcello},
eprint = {2101.12491},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mazzia, Salvetti, Chiaberge - 2021 - Efficient-CapsNet Capsule Network with Self-Attention Routing.pdf:pdf},
keywords = {capsule networks,convolutional neural networks,self-attention},
mendeley-tags = {capsule networks,convolutional neural networks,self-attention},
pages = {1--15},
title = {{Efficient-CapsNet: Capsule Network with Self-Attention Routing}},
url = {http://arxiv.org/abs/2101.12491 https://github.com/EscVM/Efficient-CapsNet},
year = {2021}
}
@article{Gooley2011,
abstract = {Context: Millions of individuals habitually expose themselves to room light in the hours before bedtime, yet the effects of this behavior on melatonin signaling are not well recognized. Objective:Wetested the hypothesis that exposure toroomlight in the late evening suppresses the onset of melatonin synthesis and shortens the duration of melatonin production. Design: In a retrospective analysis, we compared daily melatonin profiles in individuals living in room light (?200 lux) vs. dim light (?3 lux). Patients: Healthy volunteers (n ? 116, 18–30 yr) were recruited from the general population to participate in one of two studies. Setting: Participants lived in a General Clinical Research Center for at least five consecutive days. Intervention: Individuals were exposed to room light or dim light in the 8 h preceding bedtime. Outcome Measures: Melatonin duration, onset and offset, suppression, and phase angle of en- trainment were determined. Results: Compared with dim light, exposure to room light before bedtime suppressed melatonin, resulting in a later melatonin onset in 99.0% of individuals and shortening melatonin duration by about 90 min. Also, exposure to room light during the usual hours of sleep suppressed melatonin by greater than 50% in most (85%) trials. Conclusions:Thesefindingsindicatethatroomlightexertsaprofoundsuppressiveeffectonmelatonin levels and shortens the body's internal representation of night duration. Hence, chronically exposing oneself to electrical lighting in the late evening disrupts melatonin signaling and could therefore potentially impact sleep, thermoregulation, blood pressure, and glucose homeostasis.},
author = {Gooley, Joshua J. and Chamberlain, Kyle and Smith, Kurt A. and Khalsa, Sat Bir S. and Rajaratnam, Shantha M.W. and {Van Reen}, Eliza and Zeitzer, Jamie M. and Czeisler, Charles A. and Lockley, Steven W.},
doi = {10.1210/jc.2010-2098},
isbn = {1945-7197 (Electronic)\n0021-972X (Linking)},
issn = {0021972X},
journal = {Journal of Clinical Endocrinology and Metabolism},
number = {3},
pages = {463--472},
pmid = {21193540},
title = {{Exposure to room light before bedtime suppresses melatonin onset and shortens melatonin duration in humans}},
volume = {96},
year = {2011}
}
@article{Valverde2014,
abstract = {The weather natural disaster prevention for quantitative daily rainfall forecasting derived from the SACZ-ULCV weather pattern is proposed in this paper by using intertwined statistical downscaling (SD) and soft computing (SC) approaches. The fuzzy statistical downscaling (FSD) is first introduced and, then, employed for dealing with the SACZ-ULCV atmospheric circulation-type specific weather pattern for supporting daily precipitation (rainfall) forecasting. This paper also addresses the performance comparison of the FSD and the neural statistical downscaling (NSD) approaches when taking into account 12 major urban centers all over the state of S{\~{a}}o Paulo, Brazil, for the summer period. The SACZ-ULCV summer pattern is identified in meteorological satellite images when the cloudiness of the Brazilian Northeast upper level cyclonic vortices (ULCV) meets the South Atlantic convergence zone (SACZ). Increasing the convection and the cloudiness over the Southeast region of Brazil, the SACZ-ULCV causes severe rainfalls and thunderstorms with impact on the population. Finding a manner to anticipate these extreme rainfall events is of vital importance for minimizing or avoiding disasters, and saving lives. Daily rainfall forecasting had their performance improved either by using the proposed FSD or NSD in comparison to the Multilinear Regression ETA model. Results demonstrate the FSD and the NSD become feasible alternatives for achieving a correspondence from meteorological and thermo-dynamical variables to the daily rainfall variable. {\textcopyright} 2014 Elsevier B.V.},
author = {Valverde, M. C. and Araujo, Ernesto and {Campos Velho}, H.},
doi = {10.1016/j.asoc.2014.02.025},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Valverde, Araujo, Campos Velho - 2014 - Neural network and fuzzy logic statistical downscaling of atmospheric circulation-type specific.pdf:pdf},
isbn = {1281238090},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {Fuzzy logic,Natural disaster,Neural network,Rainfall forecasting,Statistical downscaling,Time-spatial series},
pages = {681--694},
publisher = {Elsevier B.V.},
title = {{Neural network and fuzzy logic statistical downscaling of atmospheric circulation-type specific weather pattern for rainfall forecasting}},
url = {http://dx.doi.org/10.1016/j.asoc.2014.02.025},
volume = {22},
year = {2014}
}
@article{Pence2016,
author = {Pence, Isaac and Mahadevan-jansen, Anita},
doi = {10.1039/c5cs00581g.Clinical},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pence, Mahadevan-jansen - 2016 - Spectroscopy.pdf:pdf},
issn = {0306-0012},
number = {7},
pages = {1958--1979},
title = {{Spectroscopy}},
volume = {45},
year = {2016}
}
@article{Sanchez2016a,
abstract = {Adequate water management represents one of the main challenges in the design and operation of polymer electrolyte membrane fuel cells. In this work, the influence of inlet gas humidification on cell performance is investigated by in-situ current density measurements obtained using the segmented cell approach. Particular attention is paid to the combined effect of cell temperature and relative humidity of the anode and cathode feed streams. When operated at 80 • C and low humidity conditions, the cell is seen to undergo a severe voltage decline that is not observed at 60 • C. The analysis shows that the variation with temperature of the water uptake rate of the gaseous streams plays a key role in determining the observed differences in performance stability. In the case of 60 • C operation, the water uptake rate of the cathode stream at 50% inlet relative humidity is roughly 30% of its value at 80 • C at the same humidification level, resulting in a significantly lower drying capacity. A simple balance of water model, able to explain the observed cell behavior, is finally presented and discussed. Energy demand has become one of the most serious concerns of modern society due to the problems related with greenhouse gas emis-sions and the depletion of fossil fuels. In this context, hydrogen is ex-pected to play an important role as future energy vector, with polymer electrolyte membrane fuel cells (PEMFCs) being the leading candi-dates to provide efficient and clean electric energy conversion during the XXI century. Recently, significant progress has been made toward meeting the challenging cost and performance targets required for the widespread use of PEMFCs, specifically in the automotive industry.},
author = {Sanchez, Daniel G. and Ruiu, Tiziana and Friedrich, K. Andreas and Sanchez-Monreal, Juan and Vera, Marcos},
doi = {10.1149/2.0071603jes},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sanchez et al. - 2016 - Analysis of the Influence of Temperature and Gas Humidity on the Performance Stability of Polymer Electrolyte Me.pdf:pdf},
issn = {0013-4651},
journal = {Journal of The Electrochemical Society},
number = {3},
pages = {F150--F159},
title = {{Analysis of the Influence of Temperature and Gas Humidity on the Performance Stability of Polymer Electrolyte Membrane Fuel Cells}},
url = {http://jes.ecsdl.org/lookup/doi/10.1149/2.0071603jes},
volume = {163},
year = {2016}
}
@article{Widyatmoko2014,
abstract = {Keaktifan mahasiswa dalam organisasi dan prestasi belajar memiliki peran serta dalam menumbuhkan kesiapan kerja mahasiswa jurusan pendidikan ekonomi Universitas Negeri Yogyakarta. Oleh karena itu, penelitian ini bertujuan untuk mengetahui pengaruh keaktifan mahasiswa dalam organisasi terhadap kesiapan kerja, pengaruh prestasi belajar terhadap kesiapan kerja, dan pengaruh keaktifan mahasiswa dan prestasi mahasiswa secara bersama-sama terhadap kesiapan kerja. Penelitian ini merupakan penelitian ex-post facto dengan pendekatan kuantitatif. Variabel dalam penelitian ini adalah keaktifan mahasiswa dalam organisasi, prestasi belajar, dan kesiapan kerja. Populasi dalam penelitian ini sebanyak 187 mahasiswa jurusan pendidikan ekonomi angkatan 2011 dan 2012. Teknik sampling yang digunakan pada penelitian ini adalah simple random sampling. Sampel penelitian berjulmal 87 mahasiswa dengan rincian 35 mahasiswa yang aktif dalam organisasi dan 52 mahasiswa yang tidak aktif dalam organisasi. Teknik pengumpulan data menggunakan angket dan dokumentasi. Teknik analisis data menggunakan regresi ganda. Hasil penelitian menunjukkan bahwa terdapat pengaruh signifikan keaktifan mahasiswa dalam organisasi dan prestasi belajar secara bersama-sama terhadap kesiapan kerja mahasiswa jurusan pendidikan ekonomi dengan nilai Fhitung 14.451 dan signifikansi sebesar 0.000; terdapat pengaruh positif signifikan keaktifan mahasiswa dalam organisasi terhadap kesiapan kerja mahasiswa jurusan pendidikan ekonomi dengan nilai thitung 4.282 dan signifikansi 0.000; terdapat pengaruh positif signifikan prestasi belajar terhadap kesiapan kerja mahasiswa jurusan pendidikan ekonomi dengan nilai thitung 2.176 dan signifikansi 0.032.},
author = {Widyatmoko, Yunindra},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Widyatmoko - 2014 - Pengaruh Keaktifan Mahasiswa dalam Organisasi dan Prestasi Belajar terhadap Kesiapan Kerja Mahasiswa Jurusan Pendidi.pdf:pdf},
journal = {Skripsi},
keywords = {Keaktifan,Kesiapan Kr,Prestasi Belajar},
pages = {114},
title = {{Pengaruh Keaktifan Mahasiswa dalam Organisasi dan Prestasi Belajar terhadap Kesiapan Kerja Mahasiswa Jurusan Pendidikan Ekonomi Universitas Negeri Yogyakarta}},
year = {2014}
}
@article{Subramanian2019,
abstract = {We present a method to produce abstractive summaries of long documents that exceed several thousand words via neural abstractive summarization. We perform a simple extractive step before generating a summary, which is then used to condition the transformer language model on relevant information before being tasked with generating a summary. We show that this extractive step significantly improves summarization results. We also show that this approach produces more abstractive summaries compared to prior work that employs a copy mechanism while still achieving higher rouge scores. Note: The abstract above was not written by the authors, it was generated by one of the models presented in this paper.},
archivePrefix = {arXiv},
arxivId = {1909.03186},
author = {Subramanian, Sandeep and Li, Raymond and Pilault, Jonathan and Pal, Christopher},
eprint = {1909.03186},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Subramanian et al. - 2019 - On Extractive and Abstractive Neural Document Summarization with Transformer Language Models.pdf:pdf},
title = {{On Extractive and Abstractive Neural Document Summarization with Transformer Language Models}},
url = {http://arxiv.org/abs/1909.03186},
year = {2019}
}
@article{Zhang2019,
abstract = {Convolutional neural networks have been widely deployed in various application scenarios. In order to extend the applications' boundaries to some accuracy-crucial domains, researchers have been investigating approaches to boost accuracy through either deeper or wider network structures, which brings with them the exponential increment of the computational and storage cost, delaying the responding time. In this paper, we propose a general training framework named self distillation, which notably enhances the performance (accuracy) of convolutional neural networks through shrinking the size of the network rather than aggrandizing it. Different from traditional knowledge distillation - a knowledge transformation methodology among networks, which forces student neural networks to approximate the softmax layer outputs of pre-trained teacher neural networks, the proposed self distillation framework distills knowledge within network itself. The networks are firstly divided into several sections. Then the knowledge in the deeper portion of the networks is squeezed into the shallow ones. Experiments further prove the generalization of the proposed self distillation framework: Enhancement of accuracy at average level is 2.65%, varying from 0.61% in ResNeXt as minimum to 4.07% in VGG19 as maximum. In addition, it can also provide flexibility of depth-wise scalable inference on resource-limited edge devices. Our codes have been released on github.},
archivePrefix = {arXiv},
arxivId = {1905.08094},
author = {Zhang, Linfeng and Song, Jiebo and Gao, Anni and Chen, Jingwei and Bao, Chenglong and Ma, Kaisheng},
doi = {10.1109/ICCV.2019.00381},
eprint = {1905.08094},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2019 - Be your own teacher Improve the performance of convolutional neural networks via self distillation.pdf:pdf},
isbn = {9781728148038},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
keywords = {knowledge distillation,self-distillation},
mendeley-tags = {knowledge distillation,self-distillation},
pages = {3712--3721},
title = {{Be your own teacher: Improve the performance of convolutional neural networks via self distillation}},
volume = {2019-Octob},
year = {2019}
}
@article{Iii,
author = {Iii, B A B},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Iii - Unknown - Bab iii metodologi pemecahan masalah.pdf:pdf},
pages = {36--41},
title = {{Bab iii metodologi pemecahan masalah}}
}
@article{Caccia2019,
abstract = {We introduce and study the problem of Online Continual Compression, where one attempts to simultaneously learn to compress and store a representative dataset from a non i.i.d data stream, while only observing each sample once. A naive application of auto-encoders in this setting encounters a major challenge: representations derived from earlier encoder states must be usable by later decoder states. We show how to use discrete auto-encoders to effectively address this challenge and introduce Adaptive Quantization Modules (AQM) to control variation in the compression ability of the module at any given stage of learning. This enables selecting an appropriate compression for incoming samples, while taking into account overall memory constraints and current progress of the learned compression. Unlike previous methods, our approach does not require any pretraining, even on challenging datasets. We show that using AQM to replace standard episodic memory in continual learning settings leads to significant gains on continual learning benchmarks. Furthermore we demonstrate this approach with larger images, LiDAR, and reinforcement learning environments.},
archivePrefix = {arXiv},
arxivId = {1911.08019},
author = {Caccia, Lucas and Belilovsky, Eugene and Caccia, Massimo and Pineau, Joelle},
eprint = {1911.08019},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Caccia et al. - 2019 - Online Learned Continual Compression with Adaptive Quantization Modules.pdf:pdf},
title = {{Online Learned Continual Compression with Adaptive Quantization Modules}},
url = {http://arxiv.org/abs/1911.08019},
year = {2019}
}
@article{Chen2013,
abstract = {This paper presents a solar radiation forecast technique based on fuzzy and neural networks, which aims to achieve a good accuracy at different weather conditions. The accuracy of forecasted solar radiation will affect the power output forecast of grid-connected photovoltaic systems which is important for power system operation and planning. The future sky conditions and temperature information is obtained from National Environment Agency (NEA) and the sky and temperature information will be classified as different fuzzy sets based on fuzzy rules. By using fuzzy logic and neural network together, the forecast results can follow the real values very well under different sky and temperature conditions. The effectiveness of the approach is validated by a case study where four different scenarios are tested. The Mean Absolute Percentage Error (MAPE) is much smaller compared with that of the other solar radiation method. {\textcopyright} 2013 Elsevier Ltd.},
author = {Chen, S. X. and Gooi, H. B. and Wang, M. Q.},
doi = {10.1016/j.renene.2013.05.011},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Gooi, Wang - 2013 - Solar radiation forecast based on fuzzy logic and neural networks.pdf:pdf},
isbn = {0960-1481},
issn = {09601481},
journal = {Renewable Energy},
keywords = {Forecast,Fuzzy logic,Neural network,Renewable energy,Solar radiation,Weather condition},
pages = {195--201},
publisher = {Elsevier Ltd},
title = {{Solar radiation forecast based on fuzzy logic and neural networks}},
url = {http://dx.doi.org/10.1016/j.renene.2013.05.011},
volume = {60},
year = {2013}
}
@article{Tang1992,
author = {Tang, Huiming and Xu, Shengrong},
doi = {10.1109/ICPR.1992.201952},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tang, Xu - 1992 - Detection of direction and wavelength of ocean wave by power spectrum of ocean wave image.pdf:pdf},
isbn = {0818629207},
issn = {10514651},
journal = {Proceedings - International Conference on Pattern Recognition},
pages = {164--166},
title = {{Detection of direction and wavelength of ocean wave by power spectrum of ocean wave image}},
volume = {3},
year = {1992}
}
@article{Liu2015a,
author = {Liu, Yaya and Qin, Keyun and Xu, Yang},
doi = {10.1109/ISKE.2015.65},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu, Qin, Xu - 2015 - Decision Making Approaches Based on Type 2 Fuzzy Soft Sets.pdf:pdf},
isbn = {978-1-4673-9323-2},
journal = {2015 10th International Conference on Intelligent Systems and Knowledge Engineering (ISKE)},
pages = {77--82},
title = {{Decision Making Approaches Based on Type 2 Fuzzy Soft Sets}},
url = {http://ieeexplore.ieee.org/document/7383028/},
year = {2015}
}
@article{Chen2017a,
abstract = {For manufacturers, forecasting the future yield of a product is a critical task. However, a yield learning process involves considerable uncertainty, rendering the task difficult. Although a few fuzzy collaborative intelligence (FCI) methods have been proposed in recent years, they are not problem-free. Hence, to overcome the challenges associated with these methods and to improve the accuracy of future yield forecasts, a heterogeneous FCI approach is proposed in this study. In this method, an expert applies mathematical-programming-based or artificial-neural-network-based methods (i.e., heterogeneous methods) to model an uncertain yield learning process. Subsequently, fuzzy intersection narrows the possible range of the future yield, and finally, an artificial neural network derives a crisp (representative) value. The effectiveness of the proposed heterogeneous FCI approach was successfully demonstrated by considering data obtained from a factory manufacturing dynamic random access memory devices. The approach achieved an average increase of 21% in the forecasting accuracy compared with existing approaches.},
author = {Chen, Toly},
doi = {10.1016/j.asoc.2017.04.009},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen - 2017 - A heterogeneous fuzzy collaborative intelligence approach for forecasting the product yield.pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {Fuzzy collaborative intelligence,Heterogeneous,Learning,Yield},
pages = {210--224},
publisher = {Elsevier B.V.},
title = {{A heterogeneous fuzzy collaborative intelligence approach for forecasting the product yield}},
url = {http://dx.doi.org/10.1016/j.asoc.2017.04.009},
volume = {57},
year = {2017}
}
@article{Woodward2015,
abstract = {We fabricate a free-standing molybdenum diselenide (MoSe2) saturable absorber by embedding liquid-phase exfoliated few-layer MoSe2 flakes into a polymer film. The MoSe2-polymer composite is used to Q-switch fiber lasers based on ytterbium (Yb), erbium (Er) and thulium (Tm) gain fiber, producing trains of microsecond-duration pulses with kilohertz repetition rates at 1060 nm, 1566 nm and 1924 nm, respectively. Such operating wavelengths correspond to sub-bandgap saturable absorption in MoSe2, which is explained in the context of edge-states, building upon studies of other semiconducting transition metal dichalcogenide (TMD)-based saturable absorbers. Our work adds few-layer MoSe2 to the growing catalog of TMDs with remarkable optical properties, which offer new opportunities for photonic devices.},
archivePrefix = {arXiv},
arxivId = {arXiv:1503.08003v1},
author = {Woodward, R. I. and Howe, R. C. T. and Runcorn, T. H. and Hu, G. and Torrisi, F. and Kelleher, E. J. R. and Hasan, T.},
doi = {10.1364/OE.23.020051},
eprint = {arXiv:1503.08003v1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Woodward et al. - 2015 - Wideband saturable absorption in few-layer molybdenum diselenide (MoSe_2) for Q-switching Yb-, Er- and Tm-doped.pdf:pdf},
isbn = {1613-6810},
issn = {1094-4087},
journal = {Optics Express},
number = {15},
pages = {20051},
pmid = {26367663},
title = {{Wideband saturable absorption in few-layer molybdenum diselenide (MoSe_2) for Q-switching Yb-, Er- and Tm-doped fiber lasers}},
url = {https://www.osapublishing.org/abstract.cfm?URI=oe-23-15-20051},
volume = {23},
year = {2015}
}
@article{Bottou2018,
abstract = {This paper provides a review and commentary on the past, present, and future of numerical optimization algorithms in the context of machine learning applications. Through case studies on text classification and the training of deep neural networks, we discuss how optimization problems arise in machine learning and what makes them challenging. A major theme of our study is that large-scale machine learning represents a distinctive setting in which the stochastic gradient (SG) method has traditionally played a central role while conventional gradient-based nonlinear optimization techniques typically falter. Based on this viewpoint, we present a comprehensive theory of a straightforward, yet versatile SG algorithm, discuss its practical behavior, and highlight opportunities for designing algorithms with improved performance. This leads to a discussion about the next generation of optimization methods for large-scale machine learning, including an investigation of two main streams of research on techniques that diminish noise in the stochastic directions and methods that make use of second-order derivative approximations.},
archivePrefix = {arXiv},
arxivId = {1606.04838},
author = {Bottou, L{\'{e}}on and Curtis, Frank E. and Nocedal, Jorge},
doi = {10.1137/16M1080173},
eprint = {1606.04838},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bottou, Curtis, Nocedal - 2018 - Optimization methods for large-scale machine learning.pdf:pdf;:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bottou, Curtis, Nocedal - 2018 - Optimization methods for large-scale machine learning(2).pdf:pdf},
issn = {00361445},
journal = {SIAM Review},
keywords = {Algorithm complexity analysis,Machine learning,Noise reduction methods,Numerical optimization,Second-order methods,Stochastic gradient methods},
number = {2},
pages = {223--311},
title = {{Optimization methods for large-scale machine learning}},
volume = {60},
year = {2018}
}
@article{Alabort-i-Medina2017,
abstract = {Active Appearance Models (AAMs) are one of the most popular and well-established techniques for modeling deformable objects in computer vision. In this paper, we study the problem of fitting AAMs using Compositional Gradient Descent (CGD) algorithms. We present a unified and complete view of these algorithms and classify them with respect to three main characteristics: i) cost function; ii) type of composition; and iii) optimization method. Furthermore, we extend the previous view by: a) proposing a novel Bayesian cost function that can be interpreted as a general probabilistic formulation of the well-known project-out loss; b) introducing two new types of composition, asymmetric and bidirectional, that combine the gradients of both image and appearance model to derive better conver- gent and more robust CGD algorithms; and c) providing new valuable insights into existent CGD algorithms by reinterpreting them as direct applications of the Schur complement and the Wiberg method. Finally, in order to encourage open research and facilitate future comparisons with our work, we make the implementa- tion of the algorithms studied in this paper publicly available as part of the Menpo Project.},
archivePrefix = {arXiv},
arxivId = {1601.00199},
author = {Alabort-i-Medina, Joan and Zafeiriou, Stefanos},
doi = {10.1007/s11263-016-0916-3},
eprint = {1601.00199},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alabort-i-Medina, Zafeiriou - 2017 - A Unified Framework for Compositional Fitting of Active Appearance Models.pdf:pdf},
issn = {15731405},
journal = {International Journal of Computer Vision},
keywords = {Active appearance models,Asymmetric and bidirectional composition,Bayesian inference,Compositional gradient descent,Non-linear optimization,Schur complement,Wiberg algorithm},
number = {1},
pages = {26--64},
publisher = {Springer US},
title = {{A Unified Framework for Compositional Fitting of Active Appearance Models}},
volume = {121},
year = {2017}
}
@article{Morini2018,
abstract = {Given a settled reduction in the present level of tax revenue, and by exploring a very large combinatorial space of tax structures, in this paper we employ a genetic algorithm in order to determine the ‘best' structure of a real world personal income tax that allows for the maximisation of the redistributive effect of the tax, while preventing all taxpayers being worse off than with the present tax structure. We take Italy as a case study.},
author = {Morini, Matteo and Pellegrino, Simone},
doi = {10.1016/j.ejor.2016.07.059},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Morini, Pellegrino - 2018 - Personal income tax reforms A genetic algorithm approach.pdf:pdf},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Genetic algorithms,Micro-simulation models,Personal income taxation,Reynolds–Smolensky index,Tax reforms},
number = {3},
pages = {994--1004},
publisher = {Elsevier B.V.},
title = {{Personal income tax reforms: A genetic algorithm approach}},
url = {https://doi.org/10.1016/j.ejor.2016.07.059},
volume = {264},
year = {2018}
}
@article{Chen2020g,
abstract = {Online continual learning is a challenging scenario where a model needs to learn 1 from a continuous stream of data without revisiting any previously encountered 2 data instances. The phenomenon of catastrophic forgetting is worsened since the 3 model should not only address the forgetting at the task-level but also at the data 4 instance-level within the same task. To mitigate this, we leverage the concept of 5 "instance awareness" in the neural network, where each data instance is classified 6 by a path in the network searched by the controller from a meta-graph. To preserve 7 the knowledge we learn from previous instances, we proposed a method to protect 8 the path by restricting the gradient updates of one instance from overriding past 9 updates calculated from previous instances if these instances are not similar. On 10},
author = {Chen, Hung-Jen and Cheng, An-Chieh and Juan, Da-Cheng and Wei, Wei and Sun, Min},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2020 - Mitigating Forgetting in Online Continual Learning via Instance-Aware Parameterization (Supplemental).pdf:pdf},
number = {NeurIPS},
pages = {1--12},
title = {{Mitigating Forgetting in Online Continual Learning via Instance-Aware Parameterization (Supplemental)}},
year = {2020}
}
@article{Zhang2020c,
abstract = {Open set recognition requires a classifier to detect samples not belonging to any of the classes in its training set. Existing methods fit a probability distribution to the training samples on their embedding space and detect outliers according to this distribution. The embedding space is often obtained from a discriminative classifier. However, such discriminative representation focuses only on known classes, which may not be critical for distinguishing the unknown classes. We argue that the representation space should be jointly learned from the inlier classifier and the density estimator (served as an outlier detector). We propose the OpenHybrid framework, which is composed of an encoder to encode the input data into a joint embedding space, a classifier to classify samples to inlier classes, and a flow-based density estimator to detect whether a sample belongs to the unknown category. A typical problem of existing flow-based models is that they may assign a higher likelihood to outliers. However, we empirically observe that such an issue does not occur in our experiments when learning a joint representation for discriminative and generative components. Experiments on standard open set benchmarks also reveal that an end-to-end trained OpenHybrid model significantly outperforms state-of-the-art methods and flow-based baselines.},
archivePrefix = {arXiv},
arxivId = {2003.12506},
author = {Zhang, Hongjie and Li, Ang and Guo, Jie and Guo, Yanwen},
doi = {10.1007/978-3-030-58580-8_7},
eprint = {2003.12506},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2020 - Hybrid Models for Open Set Recognition.pdf:pdf},
isbn = {9783030585792},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Density estimation,Flow-based model,Image classification,open-set recognition,open-world recognition},
mendeley-tags = {open-set recognition,open-world recognition},
pages = {102--117},
title = {{Hybrid Models for Open Set Recognition}},
volume = {12348 LNCS},
year = {2020}
}
@article{Meulemans2020,
abstract = {The success of deep learning, a brain-inspired form of AI, has sparked interest in understanding how the brain could similarly learn across multiple layers of neurons. However, the majority of biologically-plausible learning algorithms have not yet reached the performance of backpropagation (BP), nor are they built on strong theoretical foundations. Here, we analyze target propagation (TP), a popular but not yet fully understood alternative to BP, from the standpoint of mathematical optimization. Our theory shows that TP is closely related to Gauss-Newton optimization and thus substantially differs from BP. Furthermore, our analysis reveals a fundamental limitation of difference target propagation (DTP), a well-known variant of TP, in the realistic scenario of non-invertible neural networks. We provide a first solution to this problem through a novel reconstruction loss that improves feedback weight training, while simultaneously introducing architectural flexibility by allowing for direct feedback connections from the output to each hidden layer. Our theory is corroborated by experimental results that show significant improvements in performance and in the alignment of forward weight updates with loss gradients, compared to DTP. MSC Codes 68T07},
archivePrefix = {arXiv},
arxivId = {2006.14331},
author = {Meulemans, Alexander and Suykens, Johan A.K. and Carzaniga, Francesco S. and Sacramento, Jo{\~{a}}o and Grewe, Benjamin F.},
eprint = {2006.14331},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Meulemans et al. - 2020 - A theoretical framework for target propagation.pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
title = {{A theoretical framework for target propagation}},
url = {https://github.com/meulemansalex/theoretical_framework_for_target_propagation},
year = {2020}
}
@article{Yuan2010,
abstract = {Multiple imputation provides a useful strategy for dealing with data sets with missing values. Instead of filling in a single value for each missing value, Rubin's (1987) multiple imputation procedure replaces each missing value with a set of plausible values that represent the uncertainty about the right value to impute. These multiply imputed data sets are then analyzed by using standard procedures for complete data and combining the results from these analyses. No matter which complete-data analysis is used, the process of combining results from different imputed data sets is essentially the same. This results in valid statistical inferences that properly reflect the uncertainty due to missing values. This paper reviews methods for analyzing missing data, including basic concepts and applications of multiple imputation techniques. The paper presents SAS{\textregistered} procedures, PROC MI and PROC MIANALYZE, for creating multiple imputations for incomplete multivariate data and for analyzing results from multiply imputed data sets.},
author = {Yuan, YC},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yuan - 2010 - Multiple imputation for missing data Concepts and new development (Version 9.0).pdf:pdf},
issn = {0160-6891},
journal = {SAS Institute Inc},
pages = {1--13},
pmid = {11807922},
title = {{Multiple imputation for missing data: Concepts and new development (Version 9.0)}},
url = {http://www.math.montana.edu/$\sim$jimrc/classes/stat506/notes/multipleimputation-SAS.pdf},
year = {2010}
}
@article{Soetaredjo2011,
abstract = {A potential application of KOH/bentonite as a catalyst for biodiesel production was studied. A series of KOH/bentonite catalysts was prepared by impregnation of bentonite from Pacitan with potassium hydroxide. The ratios between KOH and bentonite were 1:20, 1:10, 1:5, 1:4, 1:3, and 1:2. The characterization of KOH/bentonite and natural bentonite was conducted by nitrogen adsorption and XRD analysis. The effects of various reaction variables on the yield of biodiesel were investigated. The highest yield of biodiesel over KOH/bentonite catalyst was 90.70 ± 2.47%. It was obtained at KOH/bentonite 1:4, reaction time of 3. h, 3% catalyst, methanol to oil ratio of 6, and the reaction temperature at 60 °C. {\textcopyright} 2010 Elsevier B.V.},
author = {Soetaredjo, Felycia Edi and Ayucitra, Aning and Ismadji, Suryadi and Maukar, Anastasia Lidya},
doi = {10.1016/j.clay.2010.12.018},
isbn = {0169-1317},
issn = {01691317},
journal = {Applied Clay Science},
keywords = {Bentonite,Biodiesel,Palm Oil,Potassium hydroxide,Solid base Catalyst,Transesterification},
number = {2},
pages = {341--346},
title = {{KOH/bentonite catalysts for transesterification of palm oil to biodiesel}},
volume = {53},
year = {2011}
}
@article{Xu2019a,
abstract = {Modeling the probability distribution of rows in tabular data and generating realistic synthetic data is a non-trivial task. Tabular data usually contains a mix of discrete and continuous columns. Continuous columns may have multiple modes whereas discrete columns are sometimes imbalanced making the modeling difficult. Existing statistical and deep neural network models fail to properly model this type of data. We design TGAN, which uses a conditional generative adversarial network to address these challenges. To aid in a fair and thorough comparison, we design a benchmark with 7 simulated and 8 real datasets and several Bayesian network baselines. TGAN outperforms Bayesian methods on most of the real datasets whereas other deep learning methods could not.},
archivePrefix = {arXiv},
arxivId = {1907.00503},
author = {Xu, Lei and Skoularidou, Maria and Cuesta-Infante, Alfredo and Veeramachaneni, Kalyan},
eprint = {1907.00503},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu et al. - 2019 - Modeling Tabular data using Conditional GAN.pdf:pdf},
keywords = {gan,tabular data},
mendeley-tags = {gan,tabular data},
month = {jun},
number = {NeurIPS},
title = {{Modeling Tabular data using Conditional GAN}},
url = {http://arxiv.org/abs/1907.00503 https://github.com/sdv-dev/CTGAN},
year = {2019}
}
@article{Chen2007,
abstract = {There is an increasing need to bring machine learning to a wide diversity of hardware devices. Current frameworks rely on vendor-specific operator libraries and optimize for a narrow range of server-class GPUs. Deploying workloads to new platforms - such as mobile phones, embedded devices, and accelerators (e.g., FPGAs, ASICs) - requires significant manual effort. We propose TVM, a compiler that exposes graph-level and operator-level optimizations to provide performance portability to deep learning workloads across diverse hardware back-ends. TVM solves optimization challenges specific to deep learning, such as high-level operator fusion, mapping to arbitrary hardware primitives, and memory latency hiding. It also automates optimization of low-level programs to hardware characteristics by employing a novel, learning-based cost modeling method for rapid exploration of code optimizations. Experimental results show that TVM delivers performance across hardware back-ends that are competitive with state-of-the-art, hand-tuned libraries for low-power CPU, mobile GPU, and server-class GPUs. We also demonstrate TVM's ability to target new accelerator back-ends, such as the FPGA-based generic deep learning accelerator. The system is open sourced and in production use inside several major companies.},
archivePrefix = {arXiv},
arxivId = {1802.04799},
author = {Chen, Tianqi and Moreau, Thierry and Jiang, Ziheng and Zheng, Lianmin and Yan, Eddie and Cowan, Meghan and Shen, Haichen and Wang, Leyuan and Hu, Yuwei and Ceze, Luis and Guestrin, Carlos and Krishnamurthy, Arvind},
eprint = {1802.04799},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2007 - TVM An automated end-to-end optimizing compiler for deep learning.pdf:pdf},
isbn = {9781939133083},
journal = {Proceedings of the 13th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2018},
number = {1},
pages = {579--594},
title = {{TVM: An automated end-to-end optimizing compiler for deep learning}},
year = {2007}
}
@book{Salam,
author = {Salam, Abdel and Makhlouf, Hamdy and Tiginyanu, Ion},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Salam, Makhlouf, Tiginyanu - Unknown - Nanocoatings and ultra-thin films Edited by.pdf:pdf},
isbn = {9781845698126},
title = {{Nanocoatings and ultra-thin films Edited by}}
}
@article{MurgaS2005,
author = {MurgaŜ, J{\'{a}}n and Sekaj, Ivan and Foltin, Martin and Miklovi{\^{c}}ov{\'{a}}, Eva},
doi = {10.3182/20050703-6-CZ-1902.01774},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/MurgaŜ et al. - 2005 - Optimization of Power System Stabilizer By Genetic Algorithm.pdf:pdf},
issn = {14746670},
journal = {IFAC Proceedings Volumes},
keywords = {genetic algorithm,parameter optimization,performance index,power,power system stabilizers,system simulation},
number = {1},
pages = {274--278},
title = {{Optimization of Power System Stabilizer By Genetic Algorithm}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1474667016377862},
volume = {38},
year = {2005}
}
@article{Liu2020d,
abstract = {In this paper, we propose a novel self-supervised representation learning method, Self-EMD, for object detection. Our method directly trained on unlabeled non-iconic image dataset like COCO, instead of commonly used iconic-object image dataset like ImageNet. We keep the convolutional feature maps as the image embedding to preserve spatial structures and adopt Earth Mover's Distance (EMD) to compute the similarity between two embeddings. Our Faster R-CNN (ResNet50-FPN) baseline achieves 39.8% mAP on COCO, which is on par with the state of the art self-supervised methods pre-trained on ImageNet. More importantly, it can be further improved to 40.4% mAP with more unlabeled images, showing its great potential for leveraging more easily obtained unlabeled data. Code will be made available.},
archivePrefix = {arXiv},
arxivId = {2011.13677},
author = {Liu, Songtao and Li, Zeming and Sun, Jian},
eprint = {2011.13677},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu, Li, Sun - 2020 - Self-EMD Self-Supervised Object Detection without ImageNet.pdf:pdf},
title = {{Self-EMD: Self-Supervised Object Detection without ImageNet}},
url = {http://arxiv.org/abs/2011.13677},
year = {2020}
}
@article{Gao2020,
abstract = {While energy-based models (EBMs) exhibit a number of desirable properties, training and sampling on high-dimensional datasets remains challenging. Inspired by recent progress on diffusion probabilistic models, we present a diffusion recovery likelihood method to tractably learn and sample from a sequence of EBMs trained on increasingly noisy versions of a dataset. Each EBM is trained by maximizing the recovery likelihood: the conditional probability of the data at a certain noise level given their noisy versions at a higher noise level. The recovery likelihood objective is more tractable than the marginal likelihood objective, since it only requires MCMC sampling from a relatively concentrated conditional distribution. Moreover, we show that this estimation method is theoretically consistent: it learns the correct conditional and marginal distributions at each noise level, given sufficient data. After training, synthesized images can be generated efficiently by a sampling process that initializes from a spherical Gaussian distribution and progressively samples the conditional distributions at decreasingly lower noise levels. Our method generates high fidelity samples on various image datasets. On unconditional CIFAR-10 our method achieves FID 9.60 and inception score 8.58, superior to the majority of GANs. Moreover, we demonstrate that unlike previous work on EBMs, our long-run MCMC samples from the conditional distributions do not diverge and still represent realistic images, allowing us to accurately estimate the normalized density of data even for high-dimensional datasets.},
archivePrefix = {arXiv},
arxivId = {2012.08125},
author = {Gao, Ruiqi and Song, Yang and Poole, Ben and Wu, Ying Nian and Kingma, Diederik P.},
eprint = {2012.08125},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gao et al. - 2020 - Learning Energy-Based Models by Diffusion Recovery Likelihood.pdf:pdf},
keywords = {Diffusion Recovery Likelihood,Energy-Based,self-supervised learning},
mendeley-tags = {Diffusion Recovery Likelihood,Energy-Based,self-supervised learning},
title = {{Learning Energy-Based Models by Diffusion Recovery Likelihood}},
url = {http://arxiv.org/abs/2012.08125},
year = {2020}
}
@article{Hu2020,
abstract = {Traditional deep neural networks (NNs) have significantly contributed to the state-of-the-art performance in the task of classification under various application domains. However, NNs have not considered inherent uncertainty in data associated with the class probabilities where misclassification under uncertainty may easily introduce high risk in decision making in real-world contexts (e.g., misclassification of objects in roads leads to serious accidents). Unlike Bayesian NN that indirectly infer uncertainty through weight uncertainties, evidential NNs (ENNs) have been recently proposed to explicitly model the uncertainty of class probabilities and use them for classification tasks. An ENN offers the formulation of the predictions of NNs as subjective opinions and learns the function by collecting an amount of evidence that can form the subjective opinions by a deterministic NN from data. However, the ENN is trained as a black box without explicitly considering inherent uncertainty in data with their different root causes, such as vacuity (i.e., uncertainty due to a lack of evidence) or dissonance (i.e., uncertainty due to conflicting evidence). By considering the multidimensional uncertainty, we proposed a novel uncertainty-aware evidential NN called WGAN-ENN (WENN) for solving an out-of-distribution (OOD) detection problem. We took a hybrid approach that combines Wasserstein Generative Adversarial Network (WGAN) with ENNs to jointly train a model with prior knowledge of a certain class, which has high vacuity for OOD samples. Via extensive empirical experiments based on both synthetic and real-world datasets, we demonstrated that the estimation of uncertainty by WENN can significantly help distinguish OOD samples from boundary samples. WENN outperformed in OOD detection when compared with other competitive counterparts.},
archivePrefix = {arXiv},
arxivId = {2012.13676},
author = {Hu, Yibo and Ou, Yuzhe and Zhao, Xujiang and Cho, Jin-Hee and Chen, Feng},
eprint = {2012.13676},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hu et al. - 2020 - Multidimensional Uncertainty-Aware Evidential Neural Networks.pdf:pdf},
keywords = {Evidential Neural Networks,Uncertainty-Aware},
mendeley-tags = {Evidential Neural Networks,Uncertainty-Aware},
month = {dec},
title = {{Multidimensional Uncertainty-Aware Evidential Neural Networks}},
url = {http://arxiv.org/abs/2012.13676},
year = {2020}
}
@article{Lee2004,
abstract = {Weather forecasting has been one of the most challenging problems around the world for more than half a century. Not only because of its practical value in meteorology, but it is also a typical "unbiased" time series forecasting problem in scientific research. In this paper, we propose an innovative, intelligent multiagent-based environment, namely intelligent Java Agent Development Environment (iJADE), to provide an integrated and intelligent agent-based platform in the e-commerce environment. In addition to the facilities found in contemporary agent development platforms, which focus on the autonomy and mobility of the multiagents, iJADE provides an intelligent layer (known as the "conscious layer") to implement various AI functionalities in order to produce "smart" agents. From an implementation point of view, we introduce a weather forecasting system known as iJADE WeatherMAN - a weather forecasting system that uses fuzzy-neuro-based intelligent agents for automatic weather information gathering and filtering, and for time series weather prediction. Compared with the previous studies on single point sources using a similar network and other networks, such as the radial basis function network, learning vector quantization and the Na&iuml;ve Bayesian network, our experimental results are very promising. This neural-based rainfall forecasting system is useful and can be used in parallel with traditional forecast methods that are used at the Hong Kong Observatory.},
author = {Lee, Raymond and Liu, James},
doi = {10.1109/TSMCC.2004.829302},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee, Liu - 2004 - iJADE WeatherMAN A weather forecasting system using intelligent multiagent-based fuzzy neuro network.pdf:pdf},
isbn = {1094-6977 VO  - 34},
issn = {10946977},
journal = {IEEE Transactions on Systems, Man and Cybernetics Part C: Applications and Reviews},
number = {3},
pages = {369--377},
title = {{iJADE WeatherMAN: A weather forecasting system using intelligent multiagent-based fuzzy neuro network}},
volume = {34},
year = {2004}
}
@article{Dhamija2021,
abstract = {This is a position paper that addresses the problem of Open-World learning while proposing for the underlying feature representation to be learnt using self-supervision. We also present an unifying open-world framework combining three individual research dimensions which have been explored independently \ie Incremental Learning, Out-of-Distribution detection and Open-World learning. We observe that the supervised feature representations are limited and degenerate for the Open-World setting and unsupervised feature representation is native to each of these three problem domains. Under an unsupervised feature representation, we categorize the problem of detecting unknowns as either Out-of-Label-space or Out-of-Distribution detection, depending on the data used during system training versus system testing. The incremental learning component of our pipeline is a zero-exemplar online model which performs comparatively against state-of-the-art on ImageNet-100 protocol and does not require any back-propagation or retraining of the underlying deep-network. It further outperforms the current state-of-the-art by simply using the same number of exemplars as its counterparts. To evaluate our approach for Open-World learning, we propose a new comprehensive protocol and evaluate its performance in both Out-of-Label and Out-of-Distribution settings for each incremental stage. We also demonstrate the adaptability of our approach by showing how it can work as a plug-in with any of the recently proposed self-supervised feature representation methods.},
archivePrefix = {arXiv},
arxivId = {2102.07848},
author = {Dhamija, Akshay Raj and Ahmad, Touqeer and Schwan, Jonathan and Jafarzadeh, Mohsen and Li, Chunchun and Boult, Terrance E.},
eprint = {2102.07848},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dhamija et al. - 2021 - Self-Supervised Features Improve Open-World Learning.pdf:pdf},
keywords = {continual learning,open-set recognition,open-world recognition,self-supervised learning},
mendeley-tags = {continual learning,open-set recognition,open-world recognition,self-supervised learning},
title = {{Self-Supervised Features Improve Open-World Learning}},
url = {http://arxiv.org/abs/2102.07848},
year = {2021}
}
@article{Fini,
archivePrefix = {arXiv},
arxivId = {arXiv:2112.04215v1},
author = {Fini, Enrico and Turrisi, Victor G and Ricci, Elisa and Alahari, Karteek and Mairal, Julien and Dec, C V},
eprint = {arXiv:2112.04215v1},
file = {:home/user/Downloads/2112.04215.pdf:pdf},
keywords = {continual learning,self-supervised learning},
mendeley-tags = {continual learning,self-supervised learning},
title = {{Self-Supervised Models are Continual Learners}}
}
@article{Amos2019a,
abstract = {We study the cross-entropy method (CEM) for the non-convex optimization of a continuous and parameterized objective function and introduce a differentiable variant that enables us to differentiate the output of CEM with respect to the objective function's parameters. In the machine learning setting this brings CEM inside of the end-to-end learning pipeline where this has otherwise been impossible. We show applications in a synthetic energy-based structured prediction task and in non-convex continuous control. In the control setting we show how to embed optimal action sequences into a lower-dimensional space. DCEM enables us to fine-tune CEM-based controllers with policy optimization.},
archivePrefix = {arXiv},
arxivId = {1909.12830},
author = {Amos, Brandon and Yarats, Denis},
eprint = {1909.12830},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Amos, Yarats - 2019 - The Differentiable Cross-Entropy Method.pdf:pdf},
journal = {arXiv},
month = {sep},
title = {{The Differentiable Cross-Entropy Method}},
url = {http://arxiv.org/abs/1909.12830},
year = {2019}
}
@article{Zakir,
abstract = {Cuaca selalu berubah, karena itu disadari bahwa memperkirakan cuaca tidak mudah karena di samping harus memahami sifat atmosfer atau dinamika atmosfer, diperlukan juga pengalaman dan keberanian dalam membuat keputusan suatu prakiraan. Namun demikian pendekatan-pendekatan dalam membuat prakiraan cuaca sudah banyak dikembangkan oleh negara maju meskipun pendekatan-pendekatan tersebut tidak sepenuhnya sesuai dengan keadaan cuaca pada lintang tropis seperti Indonesia. Umumnya metode yang digunakan untuk memprakirakan cuaca bersifat subjektif yaitu dengan mengintepretasikan data pengamatan dan data model prakiraan. Metode prakiraan cuaca yang subjektif ini mempunyai kelemahan sehingga perlu disempurnakan agar menjadi metode yang semi objektif, tujuannya adalah meningkatkan keakurasian prakiraan cuaca. Metode ini mempertimbangkan faktor subjektif dan objektif yang memanfaatkan parameter data pengamatan tekanan udara, dat asuhu udara, data satelit dan juga data satelit cuaca. Parameter cuaca tersebut nantinya diintegrasikan dan menjadi metode prakiraan cuaca semi objektif, hasil dari metode prakiraan cuaca semi objektif ini menunjukkan adanya peningkatan keakurasian prakiraan cuaca dari 70% menjadi 83-86%.},
author = {Zakir, Achmad},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zakir - Unknown - Analisis dan Pengembangan Sistem Metode Prakiraan Cuaca di Bidang Informasi Meteorologi.pdf:pdf},
keywords = {metode prakiraan cuaca semi objektif},
title = {{Analisis dan Pengembangan Sistem Metode Prakiraan Cuaca di Bidang Informasi Meteorologi}}
}
@article{Fayolle2014a,
abstract = {Previous research into emotion and time perception has been designed to study the time perception of emotional events themselves (e.g., facial expression). Our aim was to investigate the effect of emotions per se on the subsequent time judgment of a neutral, non-affective event. In the present study, the participants were presented with films inducing a specific mood and were subsequently given a temporal bisection task. More precisely, the participants were given two temporal bisection tasks, one before and the other after viewing the emotional film. Three emotional films were tested: one eliciting fear, another sadness, and a neutral control film. In addition, the direct mood experience was assessed using the Brief Mood Introspective Scale that was administered to the participants at the beginning and the end of the session. The results showed that the perception of time did not change after viewing either the neutral control films or the sad films although the participants reported being sadder and less aroused after than before watching the sad film clips. In contrast, the stimulus durations were judged longer after than before viewing the frightening films that were judged to increase the emotion of fear and arousal level. In combination with findings from previous studies, our data suggest that the selective lengthening effect after watching frightening films was mediated by an effect of arousal on the speed of the internal clock system.},
author = {Fayolle, Sophie and Droit-Volet, Sylvie and Gil, Sandrine},
doi = {10.1016/j.sbspro.2014.02.399},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fayolle, Droit-Volet, Gil - 2014 - Emotion and Time Perception Effects of Film-induced Mood.pdf:pdf},
isbn = {1662-5145},
issn = {18770428},
journal = {Procedia - Social and Behavioral Sciences},
keywords = {emotion,fear,mood,sadness,time perception,time perception, timing, emotion, mood, fear, sadn,timing},
number = {August},
pages = {251--252},
pmid = {21886610},
title = {{Emotion and Time Perception: Effects of Film-induced Mood}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877042814019478},
volume = {126},
year = {2014}
}
@article{VandeVen2019,
abstract = {Standard artificial neural networks suffer from the well-known issue of catastrophic forgetting, making continual or lifelong learning difficult for machine learning. In recent years, numerous methods have been proposed for continual learning, but due to differences in evaluation protocols it is difficult to directly compare their performance. To enable more structured comparisons, we describe three continual learning scenarios based on whether at test time task identity is provided and—in case it is not—whether it must be inferred. Any sequence of well-defined tasks can be performed according to each scenario. Using the split and permuted MNIST task protocols, for each scenario we carry out an extensive comparison of recently proposed continual learning methods. We demonstrate substantial differences between the three scenarios in terms of difficulty and in terms of how efficient different methods are. In particular, when task identity must be inferred (i.e., class incremental learning), we find that regularization-based approaches (e.g., elastic weight consolidation) fail and that replaying representations of previous experiences seems required for solving this scenario.},
archivePrefix = {arXiv},
arxivId = {1904.07734},
author = {van de Ven, Gido M. and Tolias, Andreas S.},
eprint = {1904.07734},
file = {:home/user/Downloads/1904.07734.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {continual learning,incremental learning,review,survey},
mendeley-tags = {continual learning,incremental learning,review,survey},
pages = {1--18},
title = {{Three scenarios for continual learning}},
year = {2019}
}
@article{Diaz-Cortes2017,
abstract = {Many processes are too complex to be manipulated quantitatively; however, humans succeed by using simple rules of thumb that are extracted from their experiences. Fuzzy logic emulates the human reasoning in the use of imprecise information to generate decisions. Unlike traditional approaches, which require a mathematical understanding of the system, fuzzy logic comprises an alternative way of processing, which permits modeling complex systems through the use of human knowledge. On the other hand, several new metaheuristic algorithms have recently been proposed with interesting results. Most of them use operators based on metaphors of natural or social elements to evolve candidate solutions. In this paper, a methodology to implement human-knowledge-based optimization strategies is presented. In the scheme, a Takagi-Sugeno Fuzzy inference system is used to reproduce a specific search strategy generated by a human expert. Therefore, the number of rules and its configuration only depend on the expert experience without considering any learning rule process. Under these conditions, each fuzzy rule represents an expert observation that models the conditions under which candidate solutions are modified in order to reach the optimal location. To exhibit the performance and robustness of the proposed method, a comparison to other well-known optimization methods is conducted. The comparison considers several standard benchmark functions which are typically found in scientific literature. The results suggest a high performance of the proposed methodology.},
author = {D{\'{i}}az-Cort{\'{e}}s, Margarita Arimatea and Cuevas, Erik and G{\'{a}}lvez, Jorge and Camarena, Octavio},
doi = {10.1016/j.asoc.2017.08.038},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/D{\'{i}}az-Cort{\'{e}}s et al. - 2017 - A new metaheuristic optimization methodology based on fuzzy logic.pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {Fuzzy logic,Fuzzy reasoning,Metaheuristic algorithms,Metaheuristics},
pages = {549--569},
publisher = {Elsevier B.V.},
title = {{A new metaheuristic optimization methodology based on fuzzy logic}},
url = {http://dx.doi.org/10.1016/j.asoc.2017.08.038},
volume = {61},
year = {2017}
}
@article{Wu2019,
abstract = {Hashing has shown great potential in large-scale image retrieval due to its storage and computation efficiency, especially the recent deep supervised hashing methods. To achieve promising performance, deep supervised hashing methods require a large amount of training data from different classes. However, when images of new categories emerge, existing deep hashing methods have to retrain the CNN model and generate hash codes for all the database images again, which is impractical for large-scale retrieval system. In this paper, we propose a novel deep hashing framework, called Deep Incremental Hashing Network (DIHN), for learning hash codes in an incremental manner. DIHN learns the hash codes for the new coming images directly, while keeping the old ones unchanged. Simultaneously, a deep hash function for query set is learned by preserving the similarities between training points. Extensive experiments on two widely used image retrieval benchmarks demonstrate that the proposed DIHN framework can significantly decrease the training time while keeping the state-of-the-art retrieval accuracy.},
author = {Wu, Dayan and Dai, Qi and Liu, Jing and Li, Bo and Wang, Weiping},
doi = {10.1109/CVPR.2019.00928},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu et al. - 2019 - Deep incremental hashing network for efficient image retrieval.pdf:pdf},
isbn = {9781728132938},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
keywords = {Categorization,Deep Learning,Recognition: Detection,Retrieval,continual learning,image retrieval,incremental learning},
mendeley-tags = {continual learning,image retrieval,incremental learning},
pages = {9061--9069},
title = {{Deep incremental hashing network for efficient image retrieval}},
volume = {2019-June},
year = {2019}
}
@article{Gupta2016,
abstract = {{\textcopyright} 2016 The Author(s). Multiwalled carbon nanotubes platinum nanocomposite has been prepared via chemical route by reduction of Pt salt on MWCNTs in ethylene glycol solution while refluxing in Argon atmosphere. The effect of different pH media during the reduction process on their physical and electrochemical properties, as well as on their performance in unit PEM fuel cell has been studied and further compared with the reaction carried out while refluxing in air as already demonstrated by the authors. The I-V performance of unit PEM fuel cell shows a peak Power density of 156 mW cm -2 with catalyst prepared in alkaline medium, an increase of  >  110 % as compared to 72 mW cm -2 obtained while employing catalyst prepared in acidic medium and tested under similar conditions. This is attributed not only to the small particle size of reduced Pt NPs, but also to its uniform distribution when reduction is carried out in alkaline medium. This has been further explained by detail reaction mechanism under alkaline conditions.},
author = {Gupta, Chanchal and Maheshwari, Priyanka H. and Dhakate, Sanjay R.},
doi = {10.1007/s40243-015-0066-5},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gupta, Maheshwari, Dhakate - 2016 - Development of multiwalled carbon nanotubes platinum nanocomposite as efficient PEM fuel cell cataly.pdf:pdf},
isbn = {4024301500},
issn = {21941467},
journal = {Materials for Renewable and Sustainable Energy},
keywords = {Carbon nanotubes,Catalyst,Fuel cell,Mid-wave potential,Polarization},
number = {1},
pages = {1--11},
publisher = {Springer Berlin Heidelberg},
title = {{Development of multiwalled carbon nanotubes platinum nanocomposite as efficient PEM fuel cell catalyst}},
volume = {5},
year = {2016}
}
@article{Qin2015,
abstract = {Black phosphorus, a newly emerged two-dimensional material, has attracted wide attention as novel photonic material. Here, multilayer black phosphorus is successfully fabricated by liquid phase exfoliation method. By employing black phosphorus as saturable absorber, we demonstrate a passively Q-switched Er-doped ZBLAN fiber laser at the wavelength of 2.8 $\mu$m. The modulation depth and saturation fluence of the black phosphorus saturable absorber are measured to be 15% and 9 $\mu$J/cm 2 , respectively. The Q-switched fiber laser delivers a maximum average power of 485 mW with corresponding pulse energy of 7.7 $\mu$J and pulse width of 1.18 $\mu$s at repetition rate of 63 kHz. To the best of our knowledge, this is the first time to demonstrate that black phosphorus can realize Q-switching of 2.8-$\mu$m fiber laser. Our research results show that black phosphorus is a promising saturable absorber for mid-infrared pulsed lasers. OCIS codes: (140.3380) Laser materials; (140.3540) Lasers, Q-switched; (140.3070) Infrared and far-infrared lasers. Topological insulators in Bi 2 Se 3 , Bi 2 Te 3 and Sb 2 Te 3 with a single Dirac cone on the surface, " Nat. Phys. 5(6), 438–442 (2009). 5. A. A. Al-Hilli and B. L. Evans, " The preparation and properties of transition metal dichalcogenide single crystals, " J. Cryst. Growth 15(2), 93–101 (1972). 6. A. Ayari, E. Cobas, O. Ogundadegbe, and M. S. Fuhrer, " Realization and electrical characterization of ultrathin crystals of layered transition-metal dichalcogenides, " J. Appl. Phys. 101(1), 014507 (2007). A graphene-based broadband optical modulator, " Nature 474(7349), 64–67 (2011). " Atomic-layer molybdenum sulfide optical modulator for visible coherent light, " Sci. Rep. 5, 11342 (2015). Tang, " Wavelength-tunable picosecond soliton fiber laser with Topological Insulator: Bi 2 Se 3 as a mode locker, " Opt. Express 20(25), 27888–27895 (2012). " Graphene mode-locked femtosecond laser at 2 $\mu$m wavelength, " Opt. Lett. 37(11), 2085–2087 (2012). 1.06 $\mu$m Q-switched ytterbium-doped fiber laser using few-layer topological insulator Bi 2 Se 3 as a saturable absorber, " Opt. Express 21(24), 29516– 29522 (2013).},
archivePrefix = {arXiv},
arxivId = {arXiv:1505.05992},
author = {Qin, Zhipeng and Xie, Guoqiang and Zhang, Han and Zhao, Chujun and Yuan, Peng and Wen, Shuangchun and Qian, Liejia},
doi = {10.1364/OE.23.024713},
eprint = {arXiv:1505.05992},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qin et al. - 2015 - Black phosphorus as saturable absorber for the Q-switched ErZBLAN fiber laser at 28 $\mu$m.pdf:pdf},
issn = {1094-4087},
journal = {Optics Express},
number = {19},
pages = {24713},
title = {{Black phosphorus as saturable absorber for the Q-switched Er:ZBLAN fiber laser at 28 $\mu$m}},
url = {https://www.osapublishing.org/abstract.cfm?URI=oe-23-19-24713},
volume = {23},
year = {2015}
}
@book{Wang2005,
author = {Wang, Li-Xin},
pages = {441},
publisher = {Prentice-Hall International},
title = {{A Course in Fuzzy Systems and Control}},
year = {2005}
}
@inproceedings{Hou2021,
abstract = {Interactive retrieval for online fashion shopping provides the ability to change image retrieval results according to the user feedback. One common problem in interactive retrieval is that a specific user interaction (e.g., changing the color of a T-shirt) causes other aspects to change inadvertently (e.g., the retrieved item has a sleeve type different than the query). This is a consequence of existing methods learning visual representations that are semantically entangled in the embedding space, which limits the controllability of the retrieved results. We propose to leverage on the semantics of visual attributes to train convolutional networks that learn attribute-specific subspaces for each attribute to obtain disentangled representations. Thus operations, such as swapping out a particular attribute value for another, impact the attribute at hand and leave others untouched. We show that our model can be tailored to deal with different retrieval tasks while maintaining its disentanglement property. We obtain state-of-the-art performance on three interactive fashion retrieval tasks: attribute manipulation retrieval, conditional similarity retrieval, and outfit complementary item retrieval. Code and models are publicly available 1 .},
author = {Hou, Yuxin and Vig, Eleonora and Donoser, Michael and Bazzani, Loris},
booktitle = {International Conference on Computer Vision},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hou et al. - 2021 - Learning Attribute-driven Disentangled Representations for Interactive Fashion Retrieval.pdf:pdf},
keywords = {disentangled representation,image retrieval},
mendeley-tags = {disentangled representation,image retrieval},
title = {{Learning Attribute-driven Disentangled Representations for Interactive Fashion Retrieval}},
url = {https://github.com/amzn/fashion-attribute-},
year = {2021}
}
@article{Buzzega2020,
abstract = {In Continual Learning, a Neural Network is trained on a stream of data whose distribution shifts over time. Under these assumptions, it is especially challenging to improve on classes appearing later in the stream while remaining accurate on previous ones. This is due to the infamous problem of catastrophic forgetting, which causes a quick performance degradation when the classifier focuses on learning new categories. Recent literature proposed various approaches to tackle this issue, often resorting to very sophisticated techniques. In this work, we show that naive rehearsal can be patched to achieve similar performance. We point out some shortcomings that restrain Experience Replay (ER) and propose five tricks to mitigate them. Experiments show that ER, thus enhanced, displays an accuracy gain of 51.2 and 26.9 percentage points on the CIFAR-10 and CIFAR-100 datasets respectively (memory buffer size 1000). As a result, it surpasses current state-of-the-art rehearsal-based methods.},
archivePrefix = {arXiv},
arxivId = {2010.05595},
author = {Buzzega, Pietro and Boschini, Matteo and Porrello, Angelo and Calderara, Simone},
eprint = {2010.05595},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Buzzega et al. - 2020 - Rethinking experience replay A bag of tricks for continual learning.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {bag of tricks,continual learning,experience replay},
mendeley-tags = {bag of tricks,continual learning,experience replay},
title = {{Rethinking experience replay: A bag of tricks for continual learning}},
url = {https://github.com/hastings24/rethinking_er?utm_source=catalyzex.com},
year = {2020}
}
@article{Neyshabur2020,
abstract = {One desired capability for machines is the ability to transfer their knowledge of one domain to another where data is (usually) scarce. Despite ample adaptation of transfer learning in various deep learning applications, we yet do not understand what enables a successful transfer and which part of the network is responsible for that. In this paper, we provide new tools and analyses to address these fundamental questions. Through a series of analyses on transferring to block-shuffled images, we separate the effect of feature reuse from learning low-level statistics of data and show that some benefit of transfer learning comes from the latter. We present that when training from pre-trained weights, the model stays in the same basin in the loss landscape and different instances of such model are similar in feature space and close in parameter space.},
archivePrefix = {arXiv},
arxivId = {2008.11687},
author = {Neyshabur, Behnam and Sedghi, Hanie and Zhang, Chiyuan},
eprint = {2008.11687},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Neyshabur, Sedghi, Zhang - 2020 - What is being transferred in transfer learning.pdf:pdf},
keywords = {transfer learning},
mendeley-tags = {transfer learning},
month = {aug},
title = {{What is being transferred in transfer learning?}},
url = {http://arxiv.org/abs/2008.11687},
year = {2020}
}
@article{Carmo2013,
abstract = {Hydrogen is often considered the best means by which to store energy coming from renewable and intermittent power sources. With the growing capacity of localized renewable energy sources surpassing the gigawatt range, a storage system of equal magnitude is required. PEM electrolysis provides a sustainable solution for the production of hydrogen, and is well suited to couple with energy sources such as wind and solar. However, due to low demand in electrolytic hydrogen in the last century, little research has been done on PEM electrolysis with many challenges still unexplored. The ever increasing desire for green energy has rekindled the interest on PEM electrolysis, thus the compilation and recovery of past research and developments is important and necessary. In this review, PEM water electrolysis is comprehensively highlighted and discussed. The challenges new and old related to electrocatalysts, solid electrolyte, current collectors, separator plates and modeling efforts will also be addressed. The main message is to clearly set the state-of-the-art for the PEM electrolysis technology, be insightful of the research that is already done and the challenges that still exist. This information will provide several future research directions and a road map in order to aid scientists in establishing PEM electrolysis as a commercially viable hydrogen production solution. Copyright {\textcopyright} 2013, Hydrogen Energy Publications, LLC. Published by Elsevier Ltd. All rights reserved.},
author = {Carmo, Marcelo and Fritz, David L. and Mergel, J{\"{u}}rgen and Stolten, Detlef},
doi = {10.1016/j.ijhydene.2013.01.151},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Carmo et al. - 2013 - A comprehensive review on PEM water electrolysis.pdf:pdf},
isbn = {0360-3199},
issn = {03603199},
journal = {International Journal of Hydrogen Energy},
keywords = {Electrocatalysts,Electrolyzer separator plates,Hydrogen economy,PEM electrolysis modeling,PEM electrolyzers,Proton exchange membrane},
number = {12},
pages = {4901--4934},
title = {{A comprehensive review on PEM water electrolysis}},
volume = {38},
year = {2013}
}
@article{Gong2020,
abstract = {Existing research into online multi-label classification, such as online sequential multi-label extreme learning machine (OSML-ELM) and stochastic gradient descent (SGD), has achieved promising performance. However, these works do not take label dependencies into consideration and lack a theoretical analysis of loss functions. Accordingly, we propose a novel online metric learning paradigm for multi-label classification to fill the current research gap. Generally, we first propose a new metric for multi-label classification which is based on k-Nearest Neighbour (kNN) and combined with large margin principle. Then, we adapt it to the online settting to derive our model which deals with massive volume ofstreaming data at a higher speed online. Specifically, in order to learn the new kNN-based metric, we first project instances in the training dataset into the label space, which make it possible for the comparisons of instances and labels in the same dimension. After that, we project both of them into a new lower dimension space simultaneously, which enables us to extract the structure of dependencies between instances and labels. Finally, we leverage the large margin and kNN principle to learn the metric with an efficient optimization algorithm. Moreover, we provide theoretical analysis on the upper bound of the cumulative loss for our method. Comprehensive experiments on a number of benchmark multi-label datasets validate our theoretical approach and illustrate that our proposed online metric learning (OML) algorithm outperforms state-of-the-art methods.},
archivePrefix = {arXiv},
arxivId = {2006.07092},
author = {Gong, Xiuwen and Yang, Jiahui and Yuan, Dong and Bao, Wei},
eprint = {2006.07092},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gong et al. - 2020 - Online Metric Learning for Multi-Label Classification.pdf:pdf},
journal = {arXiv},
keywords = {K-Nearest Neighbour (kNN),Metric Learning,Multi-label,Online Classification},
title = {{Online Metric Learning for Multi-Label Classification*}},
year = {2020}
}
@article{He2020,
abstract = {Connectionist models such as neural networks suffer from catastrophic forgetting. In this work, we study this problem from the perspective of information theory and define forgetting as the increase of description lengths of previous data when they are compressed with a sequentially learned model. In addition, we show that continual learning approaches based on variational posterior approximation and generative replay can be considered as approximations to two prequential coding methods in compression, namely, the Bayesian mixture code and maximum likelihood (ML) plug-in code. We compare these approaches in terms of both compression and forgetting and empirically study the reasons that limit the performance of continual learning methods based on variational posterior approximation. To address these limitations, we propose a new continual learning method that combines ML plug-in and Bayesian mixture codes.},
archivePrefix = {arXiv},
arxivId = {2006.15078},
author = {He, Xu and Lin, Min},
eprint = {2006.15078},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/He, Lin - 2020 - Continual learning from the perspective of compression.pdf:pdf},
journal = {arXiv},
title = {{Continual learning from the perspective of compression}},
year = {2020}
}
@article{Amid2019,
abstract = {We introduce a temperature into the exponential function and replace the softmax output layer of neural nets by a high temperature generalization. Similarly, the logarithm in the log loss we use for training is replaced by a low temperature logarithm. By tuning the two temperatures we create loss functions that are non-convex already in the single layer case. When replacing the last layer of the neural nets by our bi-temperature generalization of logistic loss, the training becomes more robust to noise. We visualize the effect of tuning the two temperatures in a simple setting and show the efficacy of our method on large data sets. Our methodology is based on Bregman divergences and is superior to a related two-temperature method using the Tsallis divergence.},
archivePrefix = {arXiv},
arxivId = {1906.03361},
author = {Amid, Ehsan and Warmuth, Manfred K. and Anil, Rohan and Koren, Tomer},
eprint = {1906.03361},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Amid et al. - 2019 - Robust Bi-Tempered Logistic Loss Based on Bregman Divergences.pdf:pdf},
number = {1},
pages = {1--14},
title = {{Robust Bi-Tempered Logistic Loss Based on Bregman Divergences}},
url = {http://arxiv.org/abs/1906.03361},
volume = {1},
year = {2019}
}
@article{Stankovic2017,
abstract = {In this paper we study several types of systems of fuzzy relation equations and inequalities composed of a given family of fuzzy relations between two sets and two unknown fuzzy relations on these sets. Solutions to these systems are pairs of fuzzy relations on the underlying sets and can be ordered coordinatewise. We show that solutions to each of these systems form a complete lattice, and provide procedures for computing the greatest solution which is less than or equal to a given pair of fuzzy relations. We also demonstrate the application of solutions to these systems in data reduction.},
author = {Stankovi{\'{c}}, Ivan and {\'{C}}iri{\'{c}}, Miroslav and Ignjatovi{\'{c}}, Jelena},
doi = {10.1016/j.fss.2017.03.011},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stankovi{\'{c}}, {\'{C}}iri{\'{c}}, Ignjatovi{\'{c}} - 2017 - Fuzzy relation equations and inequalities with two unknowns and their applications.pdf:pdf},
issn = {01650114},
journal = {Fuzzy Sets and Systems},
keywords = {Data reduction,Fuzzy formal context,Fuzzy relation,Fuzzy relation equation,Residuals of fuzzy relations,Two-mode fuzzy social network},
pages = {86--105},
title = {{Fuzzy relation equations and inequalities with two unknowns and their applications}},
volume = {322},
year = {2017}
}
@article{Ashraf2014,
author = {Ashraf, Rabia and Shah, Nagendra P.},
doi = {10.1080/10408398.2011.619671},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ashraf, Shah - 2014 - Immune System Stimulation by Probiotic Microorganisms.pdf:pdf},
journal = {Critical Reviews in Food Science and Nutrition},
number = {February},
pages = {37--41},
title = {{Immune System Stimulation by Probiotic Microorganisms}},
year = {2014}
}
@article{Balaji2020a,
abstract = {We study continual learning in the large scale setting where tasks in the input sequence are not limited to classification, and the outputs can be of high dimension. Among multiple state-of-the-art methods, we found vanilla experience replay (ER) still very competitive in terms of both performance and scalability, despite its simplicity. However, a degraded performance is observed for ER with small memory. A further visualization of the feature space reveals that the intermediate representation undergoes a distributional drift. While existing methods usually replay only the input-output pairs, we hypothesize that their regularization effect is inadequate for complex deep models and diverse tasks with small replay buffer size. Following this observation, we propose to replay the activation of the intermediate layers in addition to the input-output pairs. Considering that saving raw activation maps can dramatically increase memory and compute cost, we propose the Compressed Activation Replay technique, where compressed representations of layer activation are saved to the replay buffer. We show that this approach can achieve superior regularization effect while adding negligible memory overhead to replay method. Experiments on both the large-scale Taskonomy benchmark with a diverse set of tasks and standard common datasets (Split-CIFAR and Split-miniImageNet) demonstrate the effectiveness of the proposed method.},
archivePrefix = {arXiv},
arxivId = {2010.02418},
author = {Balaji, Yogesh and Farajtabar, Mehrdad and Yin, Dong and Mott, Alex and Li, Ang},
eprint = {2010.02418},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Balaji et al. - 2020 - The Effectiveness of Memory Replay in Large Scale Continual Learning(2).pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {continual learning,large-scale,memory-replay,rehearsal,replay},
mendeley-tags = {continual learning,large-scale,memory-replay,rehearsal,replay},
pages = {1--15},
title = {{The Effectiveness of Memory Replay in Large Scale Continual Learning}},
year = {2020}
}
@article{Suganthi2018,
abstract = {Congestion management is imperative for reliable and secure system operation in restructured power systems. Since the installation of wind farms at proper locations offers the possibility of congestion relief, this paper investigates congestion management in power systems with specific consideration of wind energy sources. The optimal location of a wind farm is determined by the Bus Sensitivity Factor and the Wind Availability Factor. Differential Evolution is a population-based heuristics algorithm used for solving non-linear optimization problems. We propose an Improved Differential Evolution based approach to ease congestion in transmission lines by generator rescheduling and installation of new wind farms. In this approach, an enhanced mutation operator is introduced to improve the performance of the Differential Evolution algorithm. A standard IEEE-30 bus system is used to evaluate the proposed algorithm under critical line outages. The simulation results show that the proposed approach is more effective than other approaches.},
author = {Suganthi, S. T. and Devaraj, D. and Ramar, K. and {Hosimin Thilagar}, S.},
doi = {10.1016/j.rser.2017.08.014},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Suganthi et al. - 2018 - An Improved Differential Evolution algorithm for congestion management in the presence of wind turbine generato.pdf:pdf},
issn = {18790690},
journal = {Renewable and Sustainable Energy Reviews},
keywords = {Bus Sensitivity Factor,Congestion management,Generation rescheduling,Improved Differential Evolution,Wind Availability Factor},
number = {September 2016},
pages = {635--642},
publisher = {Elsevier Ltd},
title = {{An Improved Differential Evolution algorithm for congestion management in the presence of wind turbine generators}},
url = {http://dx.doi.org/10.1016/j.rser.2017.08.014},
volume = {81},
year = {2018}
}
@article{Liu2021a,
abstract = {Discovering the complete set of causal relations among a group of variables is a challenging unsupervised learning problem. Often, this challenge is compounded by the fact that there are latent or hidden confounders. When only observational data is available, the problem is ill-posed, i.e. the causal relationships are non-identifiable unless strong modeling assumptions are made. When interventions are available, we provide guarantees on identifiability and learnability under mild assumptions. We assume a linear structural equation model (SEM) with independent latent factors and directed acyclic graph (DAG) relationships among the observables. Since the latent variable inference is based on independent component analysis (ICA), we call this model SEM-ICA. We use the method of moments principle to establish model identifiability. We develop efficient algorithms based on coupled tensor decomposition with linear constraints to obtain scalable and guaranteed solutions. Thus, we provide a principled approach to tackling the joint problem of causal discovery and latent variable inference.},
archivePrefix = {arXiv},
arxivId = {2101.06614},
author = {Liu, Anqi and Liu, Hao and Li, Tongxin and Karimi-Bidhendi, Saeed and Yue, Yisong and Anandkumar, Anima},
eprint = {2101.06614},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2021 - Disentangling Observed Causal Effects from Latent Confounders using Method of Moments.pdf:pdf},
keywords = {causal learning},
mendeley-tags = {causal learning},
pages = {1--13},
title = {{Disentangling Observed Causal Effects from Latent Confounders using Method of Moments}},
url = {http://arxiv.org/abs/2101.06614},
year = {2021}
}
@article{Ren2020,
abstract = {Existing approaches to few-shot learning deal with tasks that have persistent, rigid notions of classes. Typically, the learner observes data only from a fixed number of classes at training time and is asked to generalize to a new set of classes at test time. Two examples from the same class would always be assigned the same labels in any episode. In this work, we consider a realistic setting where the similarities between examples can change from episode to episode depending on the task context, which is not given to the learner. We define new benchmark datasets for this flexible few-shot scenario, where the tasks are based on images of faces (Celeb-A), shoes (Zappos50K), and general objects (ImageNet-with-Attributes). While classification baselines and episodic approaches learn representations that work well for standard few-shot learning, they suffer in our flexible tasks as novel similarity definitions arise during testing. We propose to build upon recent contrastive unsupervised learning techniques and use a combination of instance and class invariance learning, aiming to obtain general and flexible features. We find that our approach performs strongly on our new flexible few-shot learning benchmarks, demonstrating that unsupervised learning obtains more generalizable representations.},
archivePrefix = {arXiv},
arxivId = {2012.05895},
author = {Ren, Mengye and Triantafillou, Eleni and Wang, Kuan-Chieh and Lucas, James and Snell, Jake and Pitkow, Xaq and Tolias, Andreas S. and Zemel, Richard},
eprint = {2012.05895},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ren et al. - 2020 - Flexible Few-Shot Learning with Contextual Similarity.pdf:pdf},
keywords = {few-shot learning},
mendeley-tags = {few-shot learning},
title = {{Flexible Few-Shot Learning with Contextual Similarity}},
url = {http://arxiv.org/abs/2012.05895},
year = {2020}
}
@article{Abdel-Aziz2016,
abstract = {Nowadays, Information and Communication Technologies (ICTs) have spread extensively in everyday life in an unprecedented way. A great attention is paid to the ICTs while ignoring the social aspect. With the immersive invasion of internet as well as smartphones' applications and digital social networking, people become more socially connected through virtual spaces instead of meeting in physical public spaces. ICTs are categorized in this paper into four elements which are as follows: Wi-Fi networks, digital interactive media fa{\c{c}}ades, interactive public displays, and smartphones' applications in public spaces. These elements will play major roles in the public space classified into five domains which are as follows: Culture and art, education, planning and design, games and entertainment, and information and communication. Based on this classification various examples and proposals of ICTs interventions in public spaces are presented to encourage good old fashioned social interaction by creating the new social public place of this digital era. Accordingly, this study will help to find design principles that can be adopted in the design of future public spaces to meet the needs of the digital era's users with the new concepts of social life respecting the rules of place-making.},
author = {Abdel-Aziz, Ayat Ayman and Abdel-Salam, Hassan and El-Sayad, Zeyad},
doi = {10.1016/j.aej.2015.12.019},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abdel-Aziz, Abdel-Salam, El-Sayad - 2016 - The role of ICTs in creating the new social public place of the digital era.pdf:pdf},
issn = {11100168},
journal = {Alexandria Engineering Journal},
keywords = {Digital place-making,ICTs,Social interaction,Social networking,Urban places},
number = {1},
pages = {487--493},
publisher = {Faculty of Engineering, Alexandria University},
title = {{The role of ICTs in creating the new social public place of the digital era}},
url = {http://dx.doi.org/10.1016/j.aej.2015.12.019},
volume = {55},
year = {2016}
}
@article{You2019,
abstract = {Filter pruning is one of the most effective ways to accelerate and compress convolutional neural networks (CNNs). In this work, we propose a global filter pruning algorithm called Gate Decorator, which transforms a vanilla CNN module by multiplying its output by the channel-wise scaling factors, i.e. gate. When the scaling factor is set to zero, it is equivalent to removing the corresponding filter. We use Taylor expansion to estimate the change in the loss function caused by setting the scaling factor to zero and use the estimation for the global filter importance ranking. Then we prune the network by removing those unimportant filters. After pruning, we merge all the scaling factors into its original module, so no special operations or structures are introduced. Moreover, we propose an iterative pruning framework called Tick-Tock to improve pruning accuracy. The extensive experiments demonstrate the effectiveness of our approaches. For example, we achieve the state-of-the-art pruning ratio on ResNet-56 by reducing 70% FLOPs without noticeable loss in accuracy. For ResNet-50 on ImageNet, our pruned model with 40% FLOPs reduction outperforms the baseline model by 0.31% in top-1 accuracy. Various datasets are used, including CIFAR-10, CIFAR-100, CUB-200, ImageNet ILSVRC-12 and PASCAL VOC 2011. Code is available at github.com/youzhonghui/gate-decorator-pruning},
archivePrefix = {arXiv},
arxivId = {1909.08174},
author = {You, Zhonghui and Yan, Kun and Ye, Jinmian and Ma, Meng and Wang, Ping},
eprint = {1909.08174},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/You et al. - 2019 - Gate Decorator Global Filter Pruning Method for Accelerating Deep Convolutional Neural Networks.pdf:pdf},
number = {NeurIPS},
pages = {1--15},
title = {{Gate Decorator: Global Filter Pruning Method for Accelerating Deep Convolutional Neural Networks}},
url = {http://arxiv.org/abs/1909.08174},
year = {2019}
}
@article{Company,
author = {Company, Energy Service},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Company - Unknown - Workshop energy service company.pdf:pdf},
title = {{Workshop energy service company}},
volume = {5221255}
}
@article{Cranmer2019,
abstract = {We introduce an approach for imposing physically motivated inductive biases on graph networks to learn interpretable representations and improved zero-shot generalization. Our experiments show that our graph network models, which implement this inductive bias, can learn message representations equivalent to the true force vector when trained on n-body gravitational and spring-like simulations. We use symbolic regression to fit explicit algebraic equations to our trained model's message function and recover the symbolic form of Newton's law of gravitation without prior knowledge. We also show that our model generalizes better at inference time to systems with more bodies than had been experienced during training. Our approach is extensible, in principle, to any unknown interaction law learned by a graph network, and offers a valuable technique for interpreting and inferring explicit causal theories about the world from implicit knowledge captured by deep learning.},
archivePrefix = {arXiv},
arxivId = {1909.05862},
author = {Cranmer, Miles D. and Xu, Rui and Battaglia, Peter and Ho, Shirley},
eprint = {1909.05862},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cranmer et al. - 2019 - Learning Symbolic Physics with Graph Networks.pdf:pdf},
title = {{Learning Symbolic Physics with Graph Networks}},
url = {http://arxiv.org/abs/1909.05862},
year = {2019}
}
@article{Liu2020c,
abstract = {Humans are capable of learning new tasks without forgetting previous ones, while neural networks fail due to catastrophic forgetting between new and previously-learned tasks. We consider a class-incremental setting which means that the task-ID is unknown at inference time. The imbalance between old and new classes typically results in a bias of the network towards the newest ones. This imbalance problem can either be addressed by storing exemplars from previous tasks, or by using image replay methods. However, the latter can only be applied to toy datasets since image generation for complex datasets is a hard problem. We propose a solution to the imbalance problem based on generative feature replay which does not require any exemplars. To do this, we split the network into two parts: a feature extractor and a classifier. To prevent forgetting, we combine generative feature replay in the classifier with feature distillation in the feature extractor. Through feature generation, our method reduces the complexity of generative replay and prevents the imbalance problem. Our approach is computationally efficient and scalable to large datasets. Experiments confirm that our approach achieves state-of-the-art results on CIFAR-100 and ImageNet, while requiring only a fraction of the storage needed for exemplar-based continual learning. Code available at https://github.com/xialeiliu/GFR-IL.},
archivePrefix = {arXiv},
arxivId = {arXiv:2004.09199v1},
author = {Liu, Xialei and Wu, Chenshen and Menta, Mikel and Herranz, Luis and Raducanu, Bogdan and Bagdanov, Andrew D. and Jui, Shangling and van de Weijer, Joost},
eprint = {arXiv:2004.09199v1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2020 - Generative feature replay for class-incremental learning.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {continual learning,generative replay,replay},
mendeley-tags = {continual learning,generative replay,replay},
title = {{Generative feature replay for class-incremental learning}},
url = {https://github.com/xialeiliu/GFR-IL},
year = {2020}
}
@article{He2017a,
abstract = {In this paper, we introduce a new channel pruning method to accelerate very deep convolutional neural networks. Given a trained CNN model, we propose an iterative two-step algorithm to effectively prune each layer, by a LASSO regression based channel selection and least square reconstruction. We further generalize this algorithm to multi-layer and multi-branch cases. Our method reduces the accumulated error and enhance the compatibility with various architectures. Our pruned VGG-16 achieves the state-of-the-art results by 5× speed-up along with only 0.3% increase of error. More importantly, our method is able to accelerate modern networks like ResNet, Xception and suffers only 1.4%, 1.0% accuracy loss under 2× speedup respectively, which is significant.},
archivePrefix = {arXiv},
arxivId = {1707.06168},
author = {He, Yihui and Zhang, Xiangyu and Sun, Jian},
doi = {10.1109/ICCV.2017.155},
eprint = {1707.06168},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/He, Zhang, Sun - 2017 - Channel Pruning for Accelerating Very Deep Neural Networks.pdf:pdf},
isbn = {9781538610329},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {1398--1406},
title = {{Channel Pruning for Accelerating Very Deep Neural Networks}},
volume = {2017-Octob},
year = {2017}
}
@article{Jaderberg,
abstract = {In this section we present the results of two further experiments – that of MNIST addition showing spatial transformers acting on multiple objects in Sect. 1.1, and co-localisation in Sect. 1.2 showing the application to semi-supervised scenarios. We also expand upon the details of the experiments presented in the main paper. 1.1 MNIST Addition In this section we demonstrate another use case for multiple spatial transformers in parallel: to model multiple objects. We define an MNIST addition task, where the network must output the sum of the two digits given in the input. Each digit is presented in a separate 42 × 42 input channel (giving 2-channel inputs), but each digit is transformed independently, with random rotation, scale, and translation (RTS). We train fully connected (FCN), convolutional (CNN) and single spatial transformer fully connected (ST-FCN) networks, as well as spatial transformer fully connected networks with two parallel spa-tial transformers (2×ST-FCN) acting on the input image, each one taking both channels as input and transforming both channels. The two 2-channel outputs of the two spatial transformers are con-catenated into a 4-channel feature map for the subsequent FCN. As in Sect. 4.1 of the main paper,},
author = {Jaderberg, Max},
pages = {1--5},
title = {{Spatial Transformer Networks : Supplementary Material}}
}
@article{Jia2021,
abstract = {Pre-trained representations are becoming crucial for many NLP and perception tasks. While representation learning in NLP has transitioned to training on raw text without human annotations, visual and vision-language representations still rely heavily on curated training datasets that are expensive or require expert knowledge. For vision applications, representations are mostly learned using datasets with explicit class labels such as ImageNet or OpenImages. For vision-language, popular datasets like Conceptual Captions, MSCOCO, or CLIP all involve a non-trivial data collection (and cleaning) process. This costly curation process limits the size of datasets and hence hinders the scaling of trained models. In this paper, we leverage a noisy dataset of over one billion image alt-text pairs, obtained without expensive filtering or post-processing steps in the Conceptual Captions dataset. A simple dual-encoder architecture learns to align visual and language representations of the image and text pairs using a contrastive loss. We show that the scale of our corpus can make up for its noise and leads to state-of-the-art representations even with such a simple learning scheme. Our visual representation achieves strong performance when transferred to classification tasks such as ImageNet and VTAB. The aligned visual and language representations also set new state-of-the-art results on Flickr30K and MSCOCO benchmarks, even when compared with more sophisticated cross-attention models. The representations also enable cross-modality search with complex text and text + image queries.},
archivePrefix = {arXiv},
arxivId = {2102.05918},
author = {Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc V. and Sung, Yunhsuan and Li, Zhen and Duerig, Tom},
eprint = {2102.05918},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jia et al. - 2021 - Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision.pdf:pdf},
keywords = {large-scale,noisy supervision,representation learning,vision-language representation},
mendeley-tags = {large-scale,noisy supervision,representation learning,vision-language representation},
title = {{Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision}},
url = {http://arxiv.org/abs/2102.05918},
year = {2021}
}
@article{Garibaldi2003,
abstract = { The shapes of terms used in fuzzy systems have adopted several 'conventions'. Terms are almost invariably normalised (having a maximum membership value of 1), convex (having a single maximum or plateau maxima) and distinct (being restricted in their degree of overlap: often expressed as some variation on the concept that all membership values at any point in the universe of discourse sum to I across that universe). The shape of these terms are generated by certain accepted membership functions: piecewise linear functions (with restrictions), Gaussians or Sigmoids are almost exclusively used. As such these constitute only a small subset of the total set of possible shapes of terms. These conventions are largely empirical or are justified by arguments based on what might loosely be called 'fuzzy control principles'. The paper highlights a number of membership functions that developers of fuzzy systems outside the paradigm of fuzzy control may consider as alternatives. In particular, we highlight subsumed fuzzy sets, discuss the merits of non-convex fuzzy sets and present a medical application where sub-normal fuzzy sets have been used. These ideas are reinforced by examples.},
author = {Garibaldi, J.M. and John, R.I.},
doi = {10.1109/FUZZ.2003.1209428},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garibaldi, John - 2003 - Choosing membership functions of linguistic terms.pdf:pdf},
isbn = {0-7803-7810-5},
journal = {The 12th IEEE International Conference on Fuzzy Systems, 2003. FUZZ '03.},
keywords = {osing membership functions of},
pages = {578--583},
title = {{Choosing membership functions of linguistic terms}},
volume = {1},
year = {2003}
}
@article{A2017,
abstract = {Penginderaan visual atau machine vision merupakan suatu proses manipulasi data citra. Data tersebut dapat digunakan untuk melakukan intepretasi banyak hal, salah satunya yaitu pengenalan gesture. Pengenalan gesture adalah antarmuka yang dapat mengenali gerak-isyarat seorang manusia dan mentranslasikan gerakan tersebut sebagai instruksi yang dapat dipahami oleh komputer. Pengenalan gesture dapat digunakan untuk penerjemahkan bahasa isyarat pada orang tunawicara. Hal ini karena banyaknya orang yang tidak mengerti bahasa tangan orang tunawicara. Sehingga, orang tunawicara kesulitan dalam berinteraksi di masyarakat. Pada tugas akhir ini pengenalan gesture untuk penerjemahan bahasa isyarat lebih mengarah pada hand recognition, yaitu pendeteksian perubahan gerak tangan, dengan menggunakan android mobile phone sebagai divaisnya. Android mobile phone memiliki kamera untuk menangkap citra orang tuna wicara saat berkomunikasi menggunakan bahasa isyarat berupa gerakan tangan. Selanjutnya, citra diproses oleh processing unit android untuk melakukan proses hand recognition. Setelah proses tersebut selesai, maka layar display akan memunculkan huruf atau kata dari perubahan posisi gerak tangan yang dilakukan orang tunawicara yang berada di depan kamera.},
author = {A, Muhammad Yunus and Purwanto, Djoko and Mardiyanto, Ronny},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/A, Purwanto, Mardiyanto - 2017 - Penerjemahan Bahasa Isyarat Indonesia Menggunakan Kamera pada Telepon Genggam Android.pdf:pdf},
journal = {Jurnal Teknik ITS},
number = {1},
pages = {180--183},
title = {{Penerjemahan Bahasa Isyarat Indonesia Menggunakan Kamera pada Telepon Genggam Android}},
volume = {6},
year = {2017}
}
@article{Aljundi2019a,
abstract = {Continual learning, the setting where a learning agent is faced with a never ending stream of data, continues to be a great challenge for modern machine learning systems. In particular the online or "single-pass through the data" setting has gained attention recently as a natural setting that is difficult to tackle. Methods based on replay, either generative or from a stored memory, have been shown to be effective approaches for continual learning, matching or exceeding the state of the art in a number of standard benchmarks. These approaches typically rely on randomly selecting samples from the replay memory or from a generative model, which is suboptimal. In this work, we consider a controlled sampling of memories for replay. We retrieve the samples which are most interfered, i.e. whose prediction will be most negatively impacted by the foreseen parameters update. We show a formulation for this sampling criterion in both the generative replay and the experience replay setting, producing consistent gains in performance and greatly reduced forgetting. We release an implementation of our method at https://github.com/optimass/Maximally_Interfered_Retrieval.},
archivePrefix = {arXiv},
arxivId = {1908.04742},
author = {Aljundi, Rahaf and Caccia, Lucas and Belilovsky, Eugene and Caccia, Massimo and Lin, Min and Charlin, Laurent and Tuytelaars, Tinne},
eprint = {1908.04742},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aljundi et al. - 2019 - Online Continual Learning with Maximally Interfered Retrieval.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
month = {aug},
number = {NeurIPS 2019},
title = {{Online Continual Learning with Maximally Interfered Retrieval}},
url = {http://arxiv.org/abs/1908.04742},
volume = {32},
year = {2019}
}
@article{Asklany2011,
abstract = {We are interested in rainfall events prediction by applying rule-based reasoning and fuzzy logic. Five parameters: relative humidity, total cloud cover, wind direction, temperature and surface pressure are the input variables for our model, each has three membership functions. The data used is twenty years METAR data for Cairo airport station (HECA) [1972-1992] 30° 3' 29″ N, 31° 13' 44″ E. and five years METAR data for Mersa Matruh station (HEMM) 31° 20' 0″ N, 27° 13' 0″ E. Different models for each station were constructed depending on the available data sets. Among the overall 243 possibilities we have based our models on one hundred eighteen fuzzy IF-THEN rules and fuzzy reasoning. The output variable which has four membership functions, takes values from zero to one hundred corresponding to the percentage for rainfall events given for every hourly data. We used two skill scores to verify our results, the Brier score and the Friction score. The results are in high agreements with the recorded data for the stations with increasing in output values towards the real time rain events. All implementation are done with MATLAB 7.9. {\textcopyright} 2011 Elsevier B.V.},
author = {Asklany, Somia A. and Elhelow, Khaled and Youssef, I. K. and {Abd El-wahab}, M.},
doi = {10.1016/j.atmosres.2011.02.015},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Asklany et al. - 2011 - Rainfall events prediction using rule-based fuzzy inference system.pdf:pdf},
issn = {01698095},
journal = {Atmospheric Research},
keywords = {Artificial intelligence,Fuzzy inference system,Fuzzy logic,Rain forecast},
number = {1-2},
pages = {228--236},
publisher = {Elsevier B.V.},
title = {{Rainfall events prediction using rule-based fuzzy inference system}},
url = {http://dx.doi.org/10.1016/j.atmosres.2011.02.015},
volume = {101},
year = {2011}
}
@article{Mahmoud2016,
abstract = {This paper investigates the problem of feedback fuzzy control design for networked systems involving both random measurement and actuation delays and subject to quantization and random packet dropout. It is assumed that system state or output signal is quantized before being communicated. The paper focuses initially on an observer-based output feedback fuzzy controller design and then derives a state feedback controller as special case. Sufficient conditions for the existence of an admissible fuzzy controller are established to ensure the exponential stability of the resulting closed-loop fuzzy system. Simulation experiments on a lab-scale four-tank system to demonstrate the applicability of the designed fuzzy control algorithm.},
author = {Mahmoud, Magdi S. and Almutairi, Naif B.},
doi = {10.1016/j.amc.2016.05.040},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mahmoud, Almutairi - 2016 - Feedback fuzzy control for quantized networked systems with random delays.pdf:pdf},
issn = {00963003},
journal = {Applied Mathematics and Computation},
keywords = {Networked control systems (NCS),Nonstationary dropouts,Observer-based fuzzy control,Random actuation delays,Random measurement delays},
pages = {80--97},
publisher = {Elsevier Inc.},
title = {{Feedback fuzzy control for quantized networked systems with random delays}},
url = {http://dx.doi.org/10.1016/j.amc.2016.05.040},
volume = {290},
year = {2016}
}
@book{Makhlouf2011,
abstract = {This chapter addresses the most common coating techniques currently in use. Recent developments and future trends in coating technology are discussed, taking into account the essential innovations in the development of industrial coatings. These are based on new findings resulting from basic and applied research in the fields of both physics and chemistry. {\textcopyright} 2011 Woodhead Publishing Limited. All rights reserved.},
author = {Makhlouf, A. S.H.},
booktitle = {Nanocoatings and Ultra-Thin Films: Technologies and Applications},
doi = {10.1016/B978-1-84569-812-6.50001-4},
isbn = {9781845698126},
keywords = {Coating processes,Coating techniques,Composite coatings,Nanocoatings,Trends in coatings},
pages = {3--23},
title = {{Current and advanced coating technologies for industrial applications}},
year = {2011}
}
@article{Tagliaferri2015,
abstract = {We propose two methods for short term forecasting of wind direction with the aim to provide input for tactic decisions during yacht races. The wind direction measured in the past minutes is used as input and the wind direction for the next two minutes constitutes the output. The two methods are based on artificial neural networks (ANN) and support vector machines (SVM), respectively. For both methods we optimise the length of the moving average that we use to pre-process the input data, the length of the input vector and, for the ANN only, the number of neurons of each layer. The forecast is evaluated by looking at the mean absolute error and at a mean effectiveness index, which assesses the percentage of times that the forecast is accurate enough to predict the correct tactical choice in a sailing yacht race. The ANN forecast based on the ensemble average of ten networks shows a larger mean absolute error and a similar mean effectiveness index than the SVM forecast. However, we showed that the ANN forecast accuracy increases significantly with the size of the ensemble. Therefore increasing the computational power, it can lead to a better forecast.},
author = {Tagliaferri, F. and Viola, I.M. and Flay, R.G.J.},
doi = {10.1016/j.oceaneng.2014.12.026},
isbn = {0029-8018},
issn = {00298018},
journal = {Ocean Engineering},
pages = {65--73},
title = {{Wind direction forecasting with artificial neural networks and support vector machines}},
volume = {97},
year = {2015}
}
@article{Ebbinghaus2004,
abstract = {My aim in this essay is to raise the question "Is there such a thing as mental illness?" and to argue that there is not. Since the notion of mental illness is extremely widely used nowadays, inquiry into the ways in which this term is employed would seem to be especially indicated. Mental illness, of course, is not literally a "thing" -- or physical object -- and hence it can "exist" only in the same sort of way in which other theoretical concepts exist. Yet, familiar theories are in the habit of posing, sooner or later -- at least to those who come to believe in them -- as "objective truths" (or "facts"). During certain historical periods, explanatory conceptions such as deities, witches, and microorganisms appeared not only as theories but as self-evident causes of a vast number of events. I submit that today mental illness is widely regarded in a somewhat similar fashion, that is, as the cause of innumerable diverse happenings. As an antidote to the complacent use of the notion of mental illness -- whether as a self-evident phenomenon, theory, or cause-- let us ask this question: What is meant when it is asserted that someone is mentally ill? In what follows I shall describe briefly the main uses to which the concept of mental illness has been put. I shall argue that this notion has outlived whatever usefulness it might have had and that it now functions merely as a convenient myth.},
author = {Ebbinghaus, Hermann},
doi = {10.1037/10011-000},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ebbinghaus - 2004 - Memory A contribution to experimental psychology.pdf:pdf},
journal = {Memory: A contribution to experimental psychology.},
number = {4},
pages = {155--156},
title = {{Memory: A contribution to experimental psychology.}},
volume = {20},
year = {2004}
}
@article{Trisnaningtyas2013,
author = {Trisnaningtyas, R. Y. and Legowo, A.M. and Kusrahayu},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Trisnaningtyas, Legowo, Kusrahayu - 2013 - Pengaruh Penambahan Susu Skim Pada Pembuatan Frozen Yogurt Dengan Bahan Dasar Whey Terhadap T.pdf:pdf},
journal = {Animal Agriculture Journal},
number = {1},
pages = {217--224},
title = {{Pengaruh Penambahan Susu Skim Pada Pembuatan Frozen Yogurt Dengan Bahan Dasar Whey Terhadap Total Bahan Padat , Waktu Pelelehan Dan Tekstur}},
volume = {2},
year = {2013}
}
@article{Bolaji2016,
abstract = {Krill Herd (KH) algorithm is a class of nature-inspired algorithm, which simulates the herding behavior of krill individuals. It has been successfully utilized to tackle many optimization problems in different domains and found to be very efficient. As a result, the studies has expanded significantly in the last 3 years. This paper presents the extensive (not exhaustive) review of KH algorithm in the area of applications, modifications, and hybridizations across these fields. The description of how KH algorithm was used in the approaches for solving these kinds of problems and further research directions are also discussed.},
author = {aro Bolaji, Asaju La and Al-Betar, Mohammed Azmi and Awadallah, Mohammed A. and Khader, Ahamad Tajudin and Abualigah, Laith Mohammad},
doi = {10.1016/j.asoc.2016.08.041},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bolaji et al. - 2016 - A comprehensive review Krill Herd algorithm (KH) and its applications.pdf:pdf},
isbn = {1568-4946},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {Krill Herd algorithm,Metaheuristics,Nature-inspired algorithms,Swarm intelligence algorithms},
pages = {437--446},
publisher = {Elsevier B.V.},
title = {{A comprehensive review: Krill Herd algorithm (KH) and its applications}},
url = {http://dx.doi.org/10.1016/j.asoc.2016.08.041},
volume = {49},
year = {2016}
}
@article{VanDenOord2018,
abstract = {While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artificial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.},
archivePrefix = {arXiv},
arxivId = {1807.03748},
author = {{Van Den Oord}, Aaron and Li, Yazhe and Vinyals, Oriol},
eprint = {1807.03748},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Van Den Oord, Li, Vinyals - 2018 - Representation learning with contrastive predictive coding.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {contrastive learning,predictive coding,representation learning,unsupervised learning},
mendeley-tags = {contrastive learning,predictive coding,representation learning,unsupervised learning},
title = {{Representation learning with contrastive predictive coding}},
year = {2018}
}
@inproceedings{Iccv2021,
abstract = {In order to robustly deploy object detectors across a wide range of scenarios, they should be adaptable to shifts in the input distribution without the need to constantly annotate new data. This has motivated research in Unsu-pervised Domain Adaptation (UDA) algorithms for detection. UDA methods learn to adapt from labeled source domains to unlabeled target domains, by inducing alignment between detector features from source and target domains. Yet, there is no consensus on what features to align and how to do the alignment. In our work, we propose a framework that generalizes the different components commonly used by UDA methods laying the ground for an in-depth analysis of the UDA design space. Specifically, we propose a novel UDA algorithm, ViSGA, a direct implementation of our framework, that leverages the best design choices and introduces a simple but effective method to aggregate features at instance-level based on visual similarity before inducing group alignment via adversarial training. We show that both similarity-based grouping and adversarial training allows our model to focus on coarsely aligning feature groups, without being forced to match all instances across loosely aligned domains. Finally, we examine the applicability of ViSGA to the setting where labeled data are gathered from different sources. Experiments show that not only our method outperforms previous single-source approaches on Sim2Real and Adverse Weather, but also generalizes well to the multi-source setting.},
author = {Iccv, Anonymous and Id, Paper},
booktitle = {International Conference on Computer Vision},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Iccv, Id - 2021 - Seeking Similarities over Differences Similarity-based Domain Alignment for Adaptive Object Detection - Rebuttal.pdf:pdf},
keywords = {domain adaptation,unsupervised learning},
mendeley-tags = {domain adaptation,unsupervised learning},
pages = {8560},
title = {{Seeking Similarities over Differences : Similarity-based Domain Alignment for Adaptive Object Detection - Rebuttal}},
year = {2021}
}
@article{Prasad2017,
abstract = {In this paper, a correlation between vibration amplitude and tool wear when in dry turning of AISI 4140 steel using uncoated carbide insert DNMA 432 is analyzed via experiments and finite element simulations. 3D Finite element simulations results are utilized to predict the evolution of cutting forces, vibration displacement amplitudes and tool wear in vibration induced turning. In the present paper, the primary concern is to find the relative vibration and tool wear with the variation of process parameters. These changes lead to accelerated tool wear and even breakage. The cutting forces in the feed direction are also predicted and compared with the experimental trends. A laser Doppler vibrometer is used to detect vibration amplitudes and the usage of Kistler 9272 dynamometer for recording the cutting forces during the cutting process is well demonstrated. A sincere effort is put to investigate the influence of spindle speed, feed rate, depth of cut on vibration amplitude and tool flank wear at different levels of workpiece hardness. Empirical models have been developed using second order polynomial equations for correlating the interaction and higher order influences of various process parameters. Analysis of variance (ANOVA) is carried out to identify the significant factors that are affecting the vibration amplitude and tool flank wear. Response surface methodology (RSM) is implemented to investigate the progression of flank wear and displacement amplitude based on experimental data. While measuring the displacement amplitude, R-square values for experimental and numerical methods are 98.6 and 97.8. Based on the R-square values of ANOVA it is found that the numerical values show good agreement with the experimental values and are helpful in estimating displacement amplitude. In the case of predicting the tool wear, R-square values were found to be 97.69 and 96.08, respectively for numerical and experimental measures while determining the tool wear. By taking R-square values into account, ANOVA confirms the close relation between experimental values and numerical values in evaluating the tool wear.},
author = {Prasad, Balla Srinivasa and Babu, M. Prakash},
doi = {10.1016/j.jestch.2016.06.011},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Prasad, Babu - 2017 - Correlation between vibration amplitude and tool wear in turning Numerical and experimental analysis.pdf:pdf},
issn = {22150986},
journal = {Engineering Science and Technology, an International Journal},
keywords = {Cutting tools,Finite element modeling,Steel,Turning process,Vibration amplitude,Wear modeling},
number = {1},
pages = {197--211},
publisher = {Karabuk University},
title = {{Correlation between vibration amplitude and tool wear in turning: Numerical and experimental analysis}},
url = {http://dx.doi.org/10.1016/j.jestch.2016.06.011},
volume = {20},
year = {2017}
}
@article{Pendinginan2012,
author = {Pendinginan, Perhitungan Beban and Dan, Pemilihan and Air, Pemasangan and Di, Conditioning and Autocad, Ruang and Akhir, Tugas},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pendinginan et al. - 2012 - Universitas diponegoro.pdf:pdf},
journal = {Engginering},
keywords = {class schedule optimization,parking space,parking space optimization,parking space unit,srp},
pages = {1--29},
title = {{Universitas diponegoro}},
year = {2012}
}
@article{Cybenko1989,
abstract = {In this paper we study the degree of approximation by superpositions of a sigmoidal function. We mainly consider the univariate case. If f is a continuous function, we prove that for any bounded sigmoidal function $\sigma$, {Mathematical expression}. For the Heaviside function H(x), we prove that {Mathematical expression}. If f is a continuous function of bounded variation, we prove that {Mathematical expression} and {Mathematical expression}. For he Heaviside function, the coefficient 1 and the approximation orders are the best possible. We compare these results with the classical Jackson and Bernstein theorems, and make some conjectures for further study. {\textcopyright} 1993 Springer.},
author = {Cybenko, G.},
doi = {10.1007/BF02551274},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cybenko - 1989 - Approximation by superpositions of a sigmoidal function.pdf:pdf},
issn = {0932-4194},
journal = {Mathematics of Control, Signals, and Systems},
keywords = {approximation,completeness,neural networks},
month = {dec},
number = {4},
pages = {303--314},
title = {{Approximation by superpositions of a sigmoidal function}},
url = {http://link.springer.com/10.1007/BF02551274},
volume = {2},
year = {1989}
}
@inproceedings{Phoo2020,
abstract = {All few-shot learning techniques must be pre-trained on a large, labeled “base dataset”. In problem domains where such large labeled datasets are not available for pre-training (e.g., X-ray images), one must resort to pre-training in a different “source” problem domain (e.g., ImageNet), which can be very different from the desired target task. Traditional few-shot and transfer learning techniques fail in the presence of such extreme differences between the source and target tasks. In this paper, we present a simple and effective solution to tackle this extreme domain gap: self-training a source domain representation on unlabeled data from the target domain. We show that this improves one-shot performance on the target domain by 2.9 points on average on a challenging benchmark with multiple domains.},
archivePrefix = {arXiv},
arxivId = {2010.07734},
author = {Phoo, Cheng Perng and Hariharan, Bharath},
booktitle = {Iclr 2021},
eprint = {2010.07734},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Phoo, Hariharan - 2020 - Self-training for few-shot transfer across extreme task differences.pdf:pdf},
issn = {23318422},
keywords = {domain adaptation,extreme domain,few-shot learning,transfer learning},
mendeley-tags = {domain adaptation,extreme domain,few-shot learning,transfer learning},
pages = {1--16},
title = {{Self-training for few-shot transfer across extreme task differences}},
year = {2020}
}
@article{Kamranzad2011,
abstract = {Forecasting of wave parameters is necessary for many marine and coastal operations. Different forecasting methodologies have been developed using the wind and wave characteristics. In this paper, artificial neural network (ANN) as a robust data learning method is used to forecast the wave height for the next 3, 6, 12 and 24 h in the Persian Gulf. To determine the effective parameters, different models with various combinations of input parameters were considered. Parameters such as wind speed, direction and wave height of the previous 3 h, were found to be the best inputs. Furthermore, using the difference between wave and wind directions showed better performance. The results also indicated that if only the wind parameters are used as model inputs the accuracy of the forecasting increases as the time horizon increases up to 6 h. This can be due to the lower influence of previous wave heights on larger lead time forecasting and the existing lag between the wind and wave growth. It was also found that in short lead times, the forecasted wave heights primarily depend on the previous wave heights, while in larger lead times there is a greater dependence on previous wind speeds. {\textcopyright} 2010 Elsevier Ltd. All rights reserved.},
author = {Kamranzad, B. and Etemad-Shahidi, A. and Kazeminezhad, M. H.},
doi = {10.1016/j.oceaneng.2010.10.004},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kamranzad, Etemad-Shahidi, Kazeminezhad - 2011 - Wave height forecasting in Dayyer, the Persian Gulf.pdf:pdf},
issn = {00298018},
journal = {Ocean Engineering},
keywords = {Artificial neural networks,Data learning methods,Persian Gulf,Wave forecasting},
number = {1},
pages = {248--255},
publisher = {Elsevier},
title = {{Wave height forecasting in Dayyer, the Persian Gulf}},
url = {http://dx.doi.org/10.1016/j.oceaneng.2010.10.004},
volume = {38},
year = {2011}
}
@article{Confidential2007,
author = {Confidential, Cisco},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Confidential - 2007 - Optical DWDM Fundamentals.pdf:pdf},
title = {{Optical DWDM Fundamentals}},
year = {2007}
}
@article{Amos2019,
abstract = {We study the cross-entropy method (CEM) for the non-convex optimization of a continuous and parameterized objective function and introduce a differentiable variant that enables us to differentiate the output of CEM with respect to the objective function's parameters. In the machine learning setting this brings CEM inside of the end-to-end learning pipeline where this has otherwise been impossible. We show applications in a synthetic energy-based structured prediction task and in non-convex continuous control. In the control setting we show how to embed optimal action sequences into a lower-dimensional space. DCEM enables us to fine-tune CEM-based controllers with policy optimization.},
archivePrefix = {arXiv},
arxivId = {1909.12830},
author = {Amos, Brandon and Yarats, Denis},
eprint = {1909.12830},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Amos, Yarats - 2019 - The Differentiable Cross-Entropy Method.pdf:pdf;:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Method - 1984 - B . More details Simple regression task C . More details Cartpole experiment.pdf:pdf},
journal = {arXiv},
month = {sep},
title = {{The Differentiable Cross-Entropy Method}},
url = {http://arxiv.org/abs/1909.12830},
year = {2019}
}
@article{Sutskever2013a,
abstract = {Deep and recurrent neural networks (DNNs and RNNs respectively) are powerful models that were considered to be almost impossible to train using stochastic gradient descent with momentum. In this paper, we show that when stochastic gradient descent with momentum uses a well-designed random initialization and a particular type of slowly increasing schedule for the momentum parameter, it can train both DNNs and RNNs (on datasets with long-term dependencies) to levels of performance that were previously achievable only with Hessian-Free optimization. We find that both the initialization and the momentum are crucial since poorly initialized networks cannot be trained with momentum and well-initialized networks perform markedly worse when the momentum is absent or poorly tuned. Our success training these models suggests that previous attempts to train deep and recurrent neural networks from random initializations have likely failed due to poor initialization schemes. Furthermore, carefully tuned momentum methods suffice for dealing with the curvature issues in deep and recurrent network training objectives without the need for sophisticated second-order methods. Copyright 2013 by the author(s).},
author = {Sutskever, Ilya and Martens, James and Dahl, George and Hinton, Geoffrey},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sutskever et al. - 2013 - On the importance of initialization and momentum in deep learning.pdf:pdf},
journal = {30th International Conference on Machine Learning, ICML 2013},
number = {PART 3},
pages = {2176--2184},
title = {{On the importance of initialization and momentum in deep learning}},
year = {2013}
}
@article{Osaba2021,
abstract = {In this work we consider multitasking in the context of solving multiple optimization problems simultaneously by conducting a single search process. The principal goal when dealing with this scenario is to dynamically exploit the existing complementarities among the problems (tasks) being optimized, helping each other through the exchange of valuable knowledge. Additionally, the emerging paradigm of Evolutionary Multitasking tackles multitask optimization scenarios by using as inspiration concepts drawn from Evolutionary Computation. The main purpose of this survey is to collect, organize and critically examine the abundant literature published so far in Evolutionary Multitasking, with an emphasis on the methodological patterns followed when designing new algorithmic proposals in this area (namely, multifactorial optimization and multipopulation-based multitasking). We complement our critical analysis with an identification of challenges that remain open to date, along with promising research directions that can stimulate future efforts in this topic. Our discussions held throughout this manuscript are offered to the audience as a reference of the general trajectory followed by the community working in this field in recent times, as well as a self-contained entry point for newcomers and researchers interested to join this exciting research avenue.},
archivePrefix = {arXiv},
arxivId = {2102.02558},
author = {Osaba, Eneko and Martinez, Aritz D. and {Del Ser}, Javier},
eprint = {2102.02558},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Osaba, Martinez, Del Ser - 2021 - Evolutionary Multitask Optimization a Methodological Overview, Challenges and Future Research Directio.pdf:pdf},
keywords = {evolutionary,evolutionary multitasking,multi-population multitasking,multi-task,multi-task learning,multifactorial evolutionary algorithm,multitasking optimization,review,survey,transfer optimization},
mendeley-tags = {evolutionary,multi-task,multi-task learning,review,survey},
title = {{Evolutionary Multitask Optimization: a Methodological Overview, Challenges and Future Research Directions}},
url = {http://arxiv.org/abs/2102.02558},
year = {2021}
}
@article{Du2009,
abstract = {In our previous research, we applied independent component analysis (ICA) for the restoration of image sequences degraded by atmospheric turbulence. The original high-resolution image and turbulent sources were considered independent sources from which the degraded image is composed of. Although the result was promising, the assumption of source independence may not be true in practice. In this paper, we propose to apply the concept of dependent component analysis (DCA), which can relax the independence assumption, to image restoration. In addition, the restored image can be further enhanced by employing a recently developed Gabor-filter-bank-based single channel blind image deconvolution algorithm. Both simulated and real data experiments demonstrate that DCA outperforms ICA, resulting in the flexibility in the use of adjacent image frames. The contribution of this research is to convert the original multi-frame blind deconvolution problem into blind source separation problem without the assumption on source independence; as a result, there is no a priori information, such as sensor bandwidth, point-spread-function, or statistics of source images, that is required. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
author = {Du, Qian and Kopriva, Ivica},
doi = {10.1016/j.neucom.2008.09.012},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Du, Kopriva - 2009 - Dependent component analysis for blind restoration of images degraded by turbulent atmosphere.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Atmospheric turbulence,Dependent component analysis,Image restoration,Independent component analysis},
number = {10-12},
pages = {2682--2692},
title = {{Dependent component analysis for blind restoration of images degraded by turbulent atmosphere}},
volume = {72},
year = {2009}
}
@inproceedings{Deng2020,
abstract = {Deep neural networks have been successfully deployed in various domains of artificial intelligence, including computer vision and natural language processing. We observe that the current standard procedure for training DNNs discards all the learned information in the past epochs except the current learned weights. An interesting question is: is this discarded information indeed useless? We argue that the discarded information can benefit the subsequent training. In this paper, we propose learning with retrospection (LWR) which makes use of the learned information in the past epochs to guide the subsequent training. LWR is a simple yet effective training framework to improve accuracies, calibration, and robustness of DNNs without introducing any additional network parameters or inference cost, only with a negligible training overhead. Extensive experiments on several benchmark datasets demonstrate the superiority of LWR for training DNNs.},
archivePrefix = {arXiv},
arxivId = {2012.13098},
author = {Deng, Xiang and Zhang, Zhongfei},
eprint = {2012.13098},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deng, Zhang - 2020 - Learning with Retrospection(4).pdf:pdf},
keywords = {retrospection,training regime},
mendeley-tags = {retrospection,training regime},
title = {{Learning with Retrospection}},
url = {http://arxiv.org/abs/2012.13098},
year = {2021}
}
@article{Yu2016,
abstract = {{\textcopyright} 2016 IEEE. In order to produce reliable weather forecasts, it is essential to discriminate non-meteorological targets from rain clouds in weather radar data. Identification of chaff echoes, which is one of the main noise sources, is uncertain and imprecise for skilled weather experts because characteristics of them are similar to those of precipitation echoes. This paper uses treeinitialized fuzzy classifier (FC) to identify chaff echoes. Fuzzy models have been widely applied to the domain of uncertainty and vagueness. Classification and regression tree is used to generate an initial crisp model (a set of crisp rules). The number of the rules, corresponding to complexity of the model, is systematically determined by performance criterion. Finally, after transforming the crisp model to the fuzzy one straightforwardly, parameters of the FCs are optimized by genetic algorithms. FCs have more flexible decision boundaries than binary decision trees with rectangular partitioning. In order to evaluate identification performance, the FCs, and comparison methods are applied to many cases where both chaff and nonchaff echoes occurred simultaneously. The results of experiments show that the FCs achieve the best identification performance.},
author = {Yu, Jungwon and Lee, Hansoo and Jeong, Yeongsang and Kim, Sungshin},
doi = {10.1109/FUZZ-IEEE.2016.7737982},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu et al. - 2016 - Identifying chaff echoes in weather radar data using tree-initialized fuzzy rule-based classifier.pdf:pdf},
isbn = {9781509006250},
journal = {2016 IEEE International Conference on Fuzzy Systems, FUZZ-IEEE 2016},
keywords = {Chaff echo,Classification and regression tree (CART),Fuzzy classifier (FC),Genetic algorithm (GA),Weather radar data},
pages = {2317--2324},
title = {{Identifying chaff echoes in weather radar data using tree-initialized fuzzy rule-based classifier}},
year = {2016}
}
@article{Garcia2017,
abstract = {We propose to study the problem of few-shot learning with the prism of inference on a partially observed graphical model, constructed from a collection of input images whose label can be either observed or not. By assimilating generic message-passing inference algorithms with their neural-network counterparts, we define a graph neural network architecture that generalizes several of the recently proposed few-shot learning models. Besides providing improved numerical performance, our framework is easily extended to variants of few-shot learning, such as semi-supervised or active learning, demonstrating the ability of graph-based models to operate well on 'relational' tasks.},
archivePrefix = {arXiv},
arxivId = {1711.04043},
author = {Garcia, Victor and Bruna, Joan},
eprint = {1711.04043},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garcia, Bruna - 2017 - Few-Shot Learning with Graph Neural Networks.pdf:pdf},
journal = {arXiv},
month = {nov},
pages = {1--13},
title = {{Few-Shot Learning with Graph Neural Networks}},
url = {http://arxiv.org/abs/1711.04043},
year = {2017}
}
@article{Garrett2016,
abstract = {Dishonesty is an integral part of our social world, influencing domains ranging from finance and politics to personal relationships. Anecdotally, digressions from a moral code are often described as a series of small breaches that grow over time. Here we provide empirical evidence for a gradual escalation of self-serving dishonesty and reveal a neural mechanism supporting it. Behaviorally, we show that the extent to which participants engage in self-serving dishonesty increases with repetition. Using functional MRI, we show that signal reduction in the amygdala is sensitive to the history of dishonest behavior, consistent with adaptation. Critically, the extent of reduced amygdala sensitivity to dishonesty on a present decision relative to the previous one predicts the magnitude of escalation of self-serving dishonesty on the next decision. The findings uncover a biological mechanism that supports a 'slippery slope': what begins as small acts of dishonesty can escalate into larger transgressions.},
author = {Garrett, Neil and Lazzaro, Stephanie C. and Ariely, Dan and Sharot, Tali},
doi = {10.1038/nn.4426},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garrett et al. - 2016 - The brain adapts to dishonesty.pdf:pdf},
isbn = {1546-1726 (Electronic) 1097-6256 (Linking)},
issn = {15461726},
journal = {Nature Neuroscience},
number = {12},
pages = {1727--1732},
pmid = {27775721},
title = {{The brain adapts to dishonesty}},
volume = {19},
year = {2016}
}
@inproceedings{Chen2020k,
abstract = {This paper presents SimCLR: a simple framework for contrastive learning of visual representations. We simplify recently proposed contrastive self-supervised learning algorithms without requiring specialized architectures or a memory bank. In order to understand what enables the contrastive prediction tasks to learn useful representations, we systematically study the major components of our framework. We show that (1) composition of data augmentations plays a critical role in defining effective predictive tasks, (2) introducing a learnable nonlinear transformation between the representation and the contrastive loss substantially improves the quality of the learned representations, and (3) contrastive learning benefits from larger batch sizes and more training steps compared to supervised learning. By combining these findings, we are able to considerably outperform previous methods for self-supervised and semi-supervised learning on ImageNet. A linear classifier trained on self-supervised representations learned by SimCLR achieves 76.5% top-1 accuracy, which is a 7% relative improvement over previous state-of-the-art, matching the performance of a supervised ResNet-50. When fine-tuned on only 1% of the labels, we achieve 85.8% top-5 accuracy, outperforming AlexNet with 100X fewer labels.},
archivePrefix = {arXiv},
arxivId = {2002.05709},
author = {Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
booktitle = {International Conference on Machine Learning},
eprint = {2002.05709},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2020 - A Simple Framework for Contrastive Learning of Visual Representations.pdf:pdf},
keywords = {contrastive learning,self-supervised learning},
mendeley-tags = {contrastive learning,self-supervised learning},
month = {feb},
title = {{A Simple Framework for Contrastive Learning of Visual Representations}},
url = {http://arxiv.org/abs/2002.05709},
year = {2020}
}
@article{Detection2003,
abstract = {Light Detection and Ranging (LIDAR) is being used by the North Carolina Floodplain Mapping Program to generate digital elevation data. These highly accurate topographic data are then used with other digital information and field data to analyze flood hazards and delineate floodplain boundaries, which are depicted on Flood Insurance Rate Maps. This fact sheet provides information on this new technology and the resulting products being created and distributed. For more information on LIDAR technologies and digital elevation data, the best overall reference is Digital Elevation Model Technologies and Applications: The DEM Users Manual, by the American Society for Photogrammetry and Remote Sensing,},
author = {Detection, Light and Technologies, Model and Sensing, Remote and Contents, Fact Sheet and Acquisition, Data and Control, Quality and Products, Available and Products, User Generated and Pg, Definitions},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Detection et al. - 2003 - LIDAR and Digital Elevation Data.pdf:pdf},
journal = {North Carolina Cooperating Technical State},
number = {January},
pages = {1--6},
title = {{LIDAR and Digital Elevation Data}},
url = {http://www.ncfloodmaps.com/pubdocs/lidar_final_jan03.pdf},
volume = {2009},
year = {2003}
}
@inproceedings{Loo2020,
abstract = {Continual learning deals with training models on new tasks and datasets in an online fashion. One strand of research has used probabilistic regularization for continual learning, with two of the main approaches in this vein being Online Elastic Weight Consolidation (Online EWC) and Variational Continual Learning (VCL). VCL employs variational inference, which in other settings has been improved empirically by applying likelihood-tempering. We show that applying this modification to VCL recovers Online EWC as a limiting case, allowing for interpolation between the two approaches. We term the general algorithm Generalized VCL (GVCL). In order to mitigate the observed overpruning effect of VI, we take inspiration from a common multi-task architecture, neural networks with task-specific FiLM layers, and find that this addition leads to significant performance gains, specifically for variational methods. In the small-data regime, GVCL strongly outperforms existing baselines. In larger datasets, GVCL with FiLM layers outperforms or is competitive with existing baselines in terms of accuracy, whilst also providing significantly better calibration.},
archivePrefix = {arXiv},
arxivId = {2011.12328},
author = {Loo, Noel and Swaroop, Siddharth and Turner, Richard E.},
booktitle = {Iclr 2021},
eprint = {2011.12328},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Loo, Swaroop, Turner - 2020 - Generalized variational continual learning.pdf:pdf},
issn = {23318422},
keywords = {continual learning,variational inference},
mendeley-tags = {continual learning,variational inference},
pages = {1--45},
title = {{Generalized variational continual learning}},
year = {2020}
}
@article{Luo2017a,
abstract = {Real-time parking occupancy information is valuable for guiding drivers' searching for parking spaces. Recently many parking detection systems using range-based on-vehicle sensors are invented, but they disregard the practical difficulty of obtaining access to raw sensory data which are required for any feature-based algorithm. In this paper, we focus on a system using short-range radars (SRR) embedded in Advanced Driver Assistance System (ADAS) to collect occupancy information, and broadcast it through a connected vehicle network. The challenge that the data transmitted through ADAS unit has been encoded to sparse points is overcome by a statistical method instead of feature extractions. We propose a two-step classification algorithm combining Mean-Shift clustering and Support Vector Machine to analyze SRR-GPS data, and evaluate it through field experiments. The results show that the average Type I error rate for off-street parking is $15.23 \%$ and for on-street parking is $32.62\%$. In both cased the Type II error rates are less than $20 \%$. Bayesian updating can recursively improve the mapping results. This paper can provide a comprehensive method to elevate automotive sensors for the parking detection function.},
archivePrefix = {arXiv},
arxivId = {1607.06708},
author = {Luo, Qi and Saigal, Romesh and Hampshire, Robert and Wu, Xinyi},
doi = {10.1109/VTCSpring.2017.8108418},
eprint = {1607.06708},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Luo et al. - 2017 - A Statistical Method for Parking Spaces Occupancy Detection via Automotive Radars.pdf:pdf},
isbn = {9781509059324},
issn = {15502252},
journal = {IEEE Vehicular Technology Conference},
keywords = {ADAS,Clustering Analysis,Intelligent Parking System,Short Range Radars,Support Vector Machine},
title = {{A Statistical Method for Parking Spaces Occupancy Detection via Automotive Radars}},
volume = {2017-June},
year = {2017}
}
@article{Rifkin2015,
author = {Rifkin, Jeremy},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rifkin - 2015 - A Smart Green Third Industrial Revolution 2015-2020 Digital Europe The Rise of the Internet of Things and the Economic T.pdf:pdf},
journal = {European Investment Bank},
pages = {1--14},
title = {{A Smart Green Third Industrial Revolution 2015-2020 Digital Europe: The Rise of the Internet of Things and the Economic Transformation of the EU}},
url = {http://www.eib.org/attachments/general/events/20150302_momentum_for_europe_rifkin_en.pdf},
year = {2015}
}
@book{Klee1992a,
abstract = {This chapter describes properties, production, and application of borides. Borides do not conform to the ordinary concepts of valency, either in stoichiometry or in structure. The stoichiometry of metal borides ranges from compounds with low boron content. The spatial distribution of boron atoms is characteristic for all these compounds, changing from isolated boron atoms to pairs, chains, and three-dimensional connected networks in the boron-rich borides, the number of boron-boron interactions increasing with increasing boron content. The covalent bonding of the boron atoms can be considered as a reason for the commonly observed high hardness and high melting points of the borides. The hardness and wear resistance of the metal borides are the most common properties utilized in technical applications. In the boronizing process, boride layers are formed on the surface of metal parts or hard metal-cutting tools during heat treatment, thus improving lifetime and service performance under wear conditions. Hexaborides of the alkaline-earth metals and rare earth metals are valuable cathode materials for electron emission. It is found that very high current densities can be achieved at rather low emission temperatures compared with metal electrodes.},
author = {Klee, Mareike},
booktitle = {Advanced Materials},
doi = {10.1002/adma.19920041217},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Klee - 1992 - Concise encyclopedia of advanced ceramic materials.pdf:pdf},
isbn = {0080347207},
issn = {0935-9648},
number = {12},
pages = {826--827},
title = {{Concise encyclopedia of advanced ceramic materials.}},
volume = {4},
year = {1992}
}
@article{Huang2017a,
author = {Huang, Chao-Ming and Huang, Yann-Chang and Huang, Kun-Yuan and Chen, Shin-Ju and Yang, Sung-Pei},
doi = {10.1109/ICIT.2017.7913264},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang et al. - 2017 - Deterministic and probabilistic wind power forecasting using a hybrid method.pdf:pdf},
isbn = {978-1-5090-5320-9},
journal = {2017 IEEE International Conference on Industrial Technology (ICIT)},
keywords = {quantile regression,support vector regression,uncertainty analysis,wind power forecasting},
pages = {400--405},
title = {{Deterministic and probabilistic wind power forecasting using a hybrid method}},
url = {http://ieeexplore.ieee.org/document/7913264/},
year = {2017}
}
@article{Zhang2020,
abstract = {Current attention or transform modules in Convolutional Neural Networks (CNNs) are designed pursuing lightweight and in-place. Generally, we need to decrease the channel dimension of input feature maps for reducing computation cost firstly. And then we do some transformation for extracting weight maps or converting to other feature space etc. Finally, we increase the channel dimension back for outputting feature maps with the same size as input. When we change the channel dimension, commonly we choose $1\times 1$ convolutional layers or fully connected layers. They are simple and effective, but need learning parameters and consuming more memory with other computation resources. We propose a novel parameter free method named Channel Transformer Network (CTN) to decrease or increase channels for these modules whilst keeping most information with lower computation complexity. We also introduce a Video Co-segment Attentive Network (VCAN) for person re-identification (ReID) to improve pedestrian's noticeable representation across multiple video frames. We embed CTN in Non-local, CBAM, COSAM and VCAN blocks to replace $1\times 1$ convolutional or fully connected layers. Experiments of VCAN and CTN embedding models on Mars dataset for person ReID show significant performance in computation efficiency and accuracy, especially VCAN reaches 90.05% in Rank-1. We believe CTN can also be used in other vision tasks like image classification and object detection etc.},
author = {Zhang, Fuping and Zhao, Pengcheng and Wei, Jianming},
doi = {10.1109/ACCESS.2020.3042644},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Zhao, Wei - 2020 - Channel Transformer Network.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Channel transform,co-segmentation,person re-identification,pyramid pooling},
mendeley-tags = {Channel transform,co-segmentation,person re-identification,pyramid pooling},
pages = {220762--220778},
title = {{Channel Transformer Network}},
volume = {8},
year = {2020}
}
@article{Hall2012a,
abstract = {An explanation of Pearson's correlation coefficient is given and its suitability for evaluating curve fits to data in the third year lab is discussed.},
author = {Hall, G},
doi = {10.1136/bmj.e4483},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hall - 2012 - Pearson's Correlation.pdf:pdf},
isbn = {9780761988540},
issn = {1756-1833},
journal = {Statistics},
pages = {1--4},
title = {{Pearson's Correlation}},
url = {http://www.statstutor.ac.uk/resources/uploaded/pearsons.pdf%0Ahttp://www.statisticshowto.com/what-is-the-pearson-correlation-coefficient/},
volume = {1},
year = {2012}
}
@article{Wahyuni2017,
abstract = {{\textcopyright} 2017 Published by ITB Journal Publisher. Countries with a tropical climate, such as Indonesia, are highly dependent on rainfall prediction for many sectors, such as agriculture, aviation, and shipping. Rainfall has now become increasingly unpredictable due to climate change and this phenomenon also affects Indonesia. Therefore, a robust approach is required for more accurate rainfall prediction. The Tsukamoto Fuzzy Inference System (FIS) is one of the algorithms that can be used for prediction problems, but if its membership functions are not specified properly, the prediction error is still high. To improve the results, the boundaries of the membership functions can be adjusted automatically by using a genetic algorithm. The proposed genetic algorithm employs two selection processes. The first one uses the Roulette wheel method to select parents, while the second one uses the elitism method to select chromosomes for the next generation. Based on this approach, a rainfall prediction experiment was conducted for Tengger, Indonesia using historical rainfall data for ten-year periods. The proposed method generated root mean square errors (RMSE) of 6.78 and 6.63 for the areas of Tosari and Tutur respectively. These results are better compared with the results using Tsukamoto FIS and the Generalized Space Time Autoregressive (GSTAR) model from previous studies.},
author = {Wahyuni, Ida and Mahmudy, Wayan Firdaus},
doi = {10.5614/itbj.ict.res.appl.2017.11.1.3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wahyuni, Mahmudy - 2017 - Rainfall Prediction in Tengger, Indonesia Using Hybrid Tsukamoto FIS and Genetic Algorithm Method.pdf:pdf},
issn = {23375787},
journal = {Journal of ICT Research and Applications},
keywords = {genetic algorithm,hybrid,prediction,rainfall,roulette wheel,tsukamoto},
number = {1},
pages = {38--55},
title = {{Rainfall Prediction in Tengger, Indonesia Using Hybrid Tsukamoto FIS and Genetic Algorithm Method}},
url = {http://journals.itb.ac.id/index.php/jictra/article/view/2577},
volume = {11},
year = {2017}
}
@article{Fiedler2018,
abstract = {Summary The properties of the global ocean that potentially affect the distribution and abundance of marine mammals are summarized. Spatial patterns and temporal variability of these properties affect the distribution and abundance of marine mammals; examples are presented. Global warming is changing the ocean environment.},
author = {Fiedler, Paul C},
doi = {https://doi.org/10.1016/B978-0-12-804327-1.00014-5},
isbn = {978-0-12-804327-1},
keywords = {Surface temperature,currents,habitat,ice,productivity,winds},
number = {3},
pages = {649--654},
title = {{Ocean Environments A2  - W{\"{u}}rsig, Bernd}},
url = {https://www.sciencedirect.com/science/article/pii/B9780128043271000145},
year = {2018}
}
@article{Ibm2012,
abstract = {About IBM Business Analytics IBM Business Analytics software delivers complete, consistent and accurate information that decision-makers trust to improve business performance. A comprehensive portfolio of business intelligence, predictive analytics, financial performance and strategy management, and analytic applications provides clear, immediate and actionable insights into current performance and the ability to predict future outcomes. Combined with rich industry solutions, proven practices and professional services, organizations of every size can drive the highest productivity, confidently automate decisions and deliver better results. As part of this portfolio, IBM SPSS Predictive Analytics software helps organizations predict future events and proactively act upon that insight to drive better business outcomes. Commercial, government and academic customers worldwide rely on IBM SPSS technology as a competitive advantage in attracting, retaining and growing customers, while reducing fraud and mitigating risk. By incorporating IBM SPSS software into their daily operations, organizations become predictive enterprises – able to direct and automate decisions to meet business goals and achieve measurable competitive advantage. For further information or to reach a representative visit},
author = {Ibm},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ibm - 2012 - IBM SPSS Forecasting 22.pdf:pdf},
pages = {48},
title = {{IBM SPSS Forecasting 22}},
year = {2012}
}
@article{Domingos2016,
abstract = {A quadcopter is a multirotor helicopter lifted and propelled by four rotors. Classic and fuzzy controllers have been used for stabilization and navigation control of quadcopters, but they require considerable effort to design and tune their parameters. Controller tuning can be a challenging task especially when random environment and load disturbances are of major concern. This paper addresses the design and evaluation of a parameter free self evolving quadcopter autonomous fuzzy system for stabilization and navigation control of quadcopters. Simulation results suggest that the autonomous fuzzy control system outperforms classic fuzzy control.},
author = {Domingos, Diego and Camargo, Guilherme and Gomide, Fernando},
doi = {10.1016/j.ifacol.2016.07.092},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Domingos, Camargo, Gomide - 2016 - Autonomous Fuzzy Control and Navigation of Quadcopters.pdf:pdf},
issn = {24058963},
journal = {IFAC-PapersOnLine},
keywords = {evolving fuzzy control,quadcopter control},
number = {5},
pages = {73--78},
publisher = {Elsevier B.V.},
title = {{Autonomous Fuzzy Control and Navigation of Quadcopters}},
url = {http://dx.doi.org/10.1016/j.ifacol.2016.07.092},
volume = {49},
year = {2016}
}
@article{Ali2018a,
abstract = {Long-term load forecasting provides vital information about future load and it helps the power industries to make decision regarding electrical energy generation and delivery. In this work, fuzzy – neuro model is developed to forecast a year ahead load in relation to weather parameter (temperature and humidity) in Mubi, Adamawa State. It is observed that: electrical load increased with increase in temperature and relative humidity does not show notable effect on electrical load. The accuracy of the prediction is obtained at 98.78% with the corresponding mean absolute percentage error (MAPE) of 1.22%. This confirms that fuzzy – neuro is a good tool for load forecasting.},
author = {Ali, Danladi and Yohanna, Michael and Ijasini, Puwu Markus and Garkida, Musa Bulus},
doi = {10.1016/j.aej.2016.12.008},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ali et al. - 2018 - Application of fuzzy – Neuro to model weather parameter variability impacts on electrical load based on long-te(2).pdf:pdf},
issn = {11100168},
journal = {Alexandria Engineering Journal},
keywords = {Back propagation,Electrical load,Fuzzy logic,Load forecasting,Neuro-fuzzy,Weather parameter},
number = {1},
pages = {121--130},
publisher = {Faculty of Engineering, Alexandria University},
title = {{Application of fuzzy – Neuro to model weather parameter variability impacts on electrical load based on long-term forecasting}},
url = {http://dx.doi.org/10.1016/j.aej.2016.12.008},
volume = {57},
year = {2018}
}
@article{Lee2019a,
abstract = {Despite the growing interest in continual learning, most of its contemporary works have been studied in a rather restricted setting where tasks are clearly distinguish-able, and task boundaries are known during training. However, if our goal is to develop an algorithm that learns as humans do, this setting is far from realistic, and it is essential to develop a methodology that works in a task-free manner. Meanwhile , among several branches of continual learning, expansion-based methods have the advantage of eliminating catastrophic forgetting by allocating new resources to learn new data. In this work, we propose an expansion-based approach for task-free continual learning. Our model, named Continual Neural Dirichlet Process Mixture (CN-DPM), consists of a set of neural network experts that are in charge of a subset of the data. CN-DPM expands the number of experts in a principled way under the Bayesian nonparametric framework. With extensive experiments, we show that our model successfully performs task-free continual learning for both discriminative and generative tasks such as image classification and image generation.},
archivePrefix = {arXiv},
arxivId = {2001.00689},
author = {Lee, Soochan and Ha, Junsoo and Zhang, Dongsu and Kim, Gunhee},
eprint = {2001.00689},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee et al. - 2019 - A Neural Dirichlet Process Mixture Model for Task-Free Continual Learning.pdf:pdf},
keywords = {Bayesian nonparametric,continual learning,task-free},
mendeley-tags = {Bayesian nonparametric,continual learning,task-free},
pages = {1--10},
title = {{A Neural Dirichlet Process Mixture Model for Task-Free Continual Learning}},
url = {http://vision.snu.ac.kr/projects/cn-dpm https://github.com/soochan-lee/CN-DPM},
year = {2019}
}
@article{Redmon2016,
abstract = {We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is far less likely to predict false detections where nothing exists. Finally, YOLO learns very general representations of objects. It outperforms all other detection methods, including DPM and R-CNN, by a wide margin when generalizing from natural images to artwork on both the Picasso Dataset and the People-Art Dataset.},
archivePrefix = {arXiv},
arxivId = {arXiv:1506.02640v5},
author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
doi = {10.1109/CVPR.2016.91},
eprint = {arXiv:1506.02640v5},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Redmon et al. - Unknown - You Only Look Once Unified, Real-Time Object Detection.pdf:pdf},
isbn = {9781467388504},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {779--788},
title = {{You only look once: Unified, real-time object detection}},
volume = {2016-Decem},
year = {2016}
}
@article{Maternini2017,
abstract = {In the last few years in large and medium-sized Italian cities, the motorization index experienced a small reduction compared to its continuous growth in the previous decades for the first time. Furthermore, at the same time, many cities (both Italian and foreign) have set the improvement of public spaces as one of the main objectives of their urban planning strategies, such as removing “on-street” parking to create larger space for pedestrians and social activities. Therefore, management of parking supply and demand has emerged as an important theme. The analysis of some European and American case studies (particularly London, UK, and San Francisco, CA) revealed the existence of innovative plans and actions in urban planning (i.e. the introduction of a maximum standard for parking spaces) and parking strategies (i.e. the implementation of variable parking pricing). Such innovative tools can be considered the starting point of a new parking management optimization process. In particular, the variability of parking pricing in relation to the occupancy index is considered a good method to ensure an “ideal” maximum percentage of occupied parking spaces (ranging between 60% and 80%) mainly in “off-street” parking. This paper firstly aims to provide some guidance for a future application of the performance-based pricing schemes in to the Italian context, based on the results of a recent experiment on variable pricing techniques in San Francisco, California (the “SFpark” programme). This paper wants to encourage the real experimentation in Italy showing with the simulation the potential of this method. Then, this paper describes an Italian case study; the feasibility of potential application of similar techniques was investigated for an off-street parking structure located close to the city centre of Brescia, a medium-sized Italian city, through simulation of the effects that a change in parking fees could have on the occupancy index.},
author = {Maternini, Giulio and Ferrari, Francesca and Guga, Amela},
doi = {10.1016/j.cstp.2017.03.010},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maternini, Ferrari, Guga - 2017 - Application of variable parking pricing techniques to innovate parking strategies. The case study of B.pdf:pdf},
issn = {22136258},
journal = {Case Studies on Transport Policy},
keywords = {Performance based parking pricing,Variable parking pricing schemes},
number = {2},
pages = {425--437},
publisher = {World Conference on Transport Research Society},
title = {{Application of variable parking pricing techniques to innovate parking strategies. The case study of Brescia}},
url = {http://dx.doi.org/10.1016/j.cstp.2017.03.010},
volume = {5},
year = {2017}
}
@article{Zeng2016,
abstract = {After the US subprime mortgage crisis in 2008, European and American developed countries have deepened “the third industrial revolution” characterized by intelligence, digitization and individualization in the global market, so as to promote their industry. This brand-new industrial revolution tide will deeply change the paradigm of traditional manufacturing industry. Through the extensive application of advanced manufacturing technology like 3D print technology, flexible production technology and reconfigurable production system, the importance of large-scale standardized production under the guidance of scale economy in modern market declines gradually, and more and more attention is paid to the scope economy idea that can adapt to the market rapidly and satisfy consumers' individualized needs. By analyzing the trend and essence of the third industrial revolution, this paper expounds the impacts that might be caused to Chinese traditional manufacturing industry, such as the reduction of labor cost advantage, localization and decentralization of production mode, gradual deepening of service degree in manufacturing industry, and suppression on the traditional industry upgrading path and industrialization process. Meanwhile, based on the analysis of scale economy and scope economy, the ideological transformation from scale economy to scope economy is further proposed; theoretical analysis is made for the applicability of these two under the environment of the third industrial revolution, and the theoretical basis and development direction for paradigm transformation of Chinese manufacturing industry in the future are pointed out.},
author = {Zeng, Xiaowen},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zeng - 2016 - Study on the Third Industrial Revolution and Paradigm Transformation of China ' s Manufacturing Industry — Based on Th.pdf:pdf},
journal = {American Journal of Industrial and Business Management},
keywords = {2016,Chinese Manufacturing Ind,Paradiam Transformation, Chinese Manufacturing Ind,american journal of indus-,based on theoretical analysis,chinese manufacturing industry,how to cite this,industrial revolution and paradigm,manufacturing industry,of scale economy and,paper,paradiam transformation,production mode,s,scope economy,study on the third,transformation of china,w,x,zeng},
number = {February},
pages = {73--82},
title = {{Study on the Third Industrial Revolution and Paradigm Transformation of China ' s Manufacturing Industry — Based on Theoretical Analysis of Scale Economy and Scope Economy}},
year = {2016}
}
@article{Jiang2018,
abstract = {{\textcopyright}2018. The Authors. Two algorithms based on machine learning neural networks are proposed—the shallow learning (S-L) and deep learning (D-L) algorithms—that can potentially be used in atmosphere-only typhoon forecast models to provide flow-dependent typhoon-induced sea surface temperature cooling (SSTC) for improving typhoon predictions. The major challenge of existing SSTC algorithms in forecast models is how to accurately predict SSTC induced by an upcoming typhoon, which requires information not only from historical data but more importantly also from the target typhoon itself. The S-L algorithm composes of a single layer of neurons with mixed atmospheric and oceanic factors. Such a structure is found to be unable to represent correctly the physical typhoon-ocean interaction. It tends to produce an unstable SSTC distribution, for which any perturbations may lead to changes in both SSTC pattern and strength. The D-L algorithm extends the neural network to a 4 × 5 neuron matrix with atmospheric and oceanic factors being separated in different layers of neurons, so that the machine learning can determine the roles of atmospheric and oceanic factors in shaping the SSTC. Therefore, it produces a stable crescent-shaped SSTC distribution, with its large-scale pattern determined mainly by atmospheric factors (e.g., winds) and small-scale features by oceanic factors (e.g., eddies). Sensitivity experiments reveal that the D-L algorithms improve maximum wind intensity errors by 60–70% for four case study simulations, compared to their atmosphere-only model runs.},
author = {Jiang, Guo Qing and Xu, Jing and Wei, Jun},
doi = {10.1002/2018GL077004},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jiang, Xu, Wei - 2018 - A Deep Learning Algorithm of Neural Network for the Parameterization of Typhoon-Ocean Feedback in Typhoon Foreca.pdf:pdf},
issn = {19448007},
journal = {Geophysical Research Letters},
keywords = {air-sea interaction,neural network,parameterization,tropical cyclone,typhoon},
number = {8},
pages = {3706--3716},
title = {{A Deep Learning Algorithm of Neural Network for the Parameterization of Typhoon-Ocean Feedback in Typhoon Forecast Models}},
volume = {45},
year = {2018}
}
@article{Okrenets2017,
author = {Okrenets, Serhii and Fefelov, Andrii and Lytvynenko, Volodymyr and Osypenko, Volodymyr and Korobchynskyi, Maksym and Voronenko, Maria},
doi = {10.1109/IDAACS.2017.8095253},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Okrenets et al. - 2017 - Synthesis and learning of fuzzy neural networks for solving forecasting problems.pdf:pdf},
isbn = {9781538606971},
journal = {Proceedings of the 2017 IEEE 9th International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications, IDAACS 2017},
keywords = {artificial immune network,forescating,fuzzy inference neural networks,neuro-fuzzy networks},
number = {1},
pages = {1088--1093},
title = {{Synthesis and learning of fuzzy neural networks for solving forecasting problems}},
volume = {2},
year = {2017}
}
@article{BulliniOrlandi2016,
abstract = {The digital era is changing consistently the previous marketing scenarios and actual issues have to be addressed in order to close the capabilities gap created by digital innovations. Different authors call for theoretical and empirical contributions that cope with the issues brought out by the digitalization of marketing channels and the consequent ever increasing volume of digital data. This study develops a theoretical framework and propositions through a reframing and reconceptualization of previous theoretical constructs from managerial and marketing literature. The resulting model offers insights about organizational processes and capabilities needed to cope with the actual fast changing, but at the same time, data-rich environment. La era digital cambia constantemente los escenarios de marketing y se deben abordar problemas reales para poder cubrir el vac{\'{i}}o en cuanto a habilidades creado por la innovaci{\'{o}}n tecnol{\'{o}}gica. Varios autores ponen de relieve la demanda de contribuciones emp{\'{i}}ricas y te{\'{o}}ricas que lidien con los problemas causados por la digitalizaci{\'{o}}n de los canales de marketing y el consecuente constante aumento de informaci{\'{o}}n digital. Este trabajo desarrolla un marco y proposiciones te{\'{o}}ricos a trav{\'{e}}s de la redefinici{\'{o}}n y reconceptualizaci{\'{o}}n de ideas previas de la literatura de marketing y de gesti{\'{o}}n. El modelo resultante identifica los procesos organizativos y habilidades necesarias para enfrentarse a este contexto tan cambiante y enriquecedor en cuanto a datos se refiere.},
author = {{Bullini Orlandi}, Ludovico},
doi = {10.1016/j.jik.2016.01.002},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bullini Orlandi - 2016 - Organizational capabilities in the digital era Reframing strategic orientation.pdf:pdf},
isbn = {2032-5355},
issn = {2444569X},
journal = {Journal of Innovation & Knowledge},
number = {3},
pages = {156--161},
publisher = {Journal of Innovation & Knowledge},
title = {{Organizational capabilities in the digital era: Reframing strategic orientation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2444569X16000044},
volume = {1},
year = {2016}
}
@article{Marzuki2012,
abstract = {Abstrak: Kantor gedung direksi PT. Perkebunan Nusantara XIII (PTPN XIII) berada di daerah perkantoran dan bisnis, jalan Sultan Abdurrachman No. 11 Pontianak, Kalimantan Barat. Kebutuhan energi listrik untuk operasional gedung disuplai dari PLN sebagai sumber utama dengan daya sebesar 240 kVA dan sumber listrik cadangan (genset) berkapasitas 250 kVA. Kualitas daya listrik yang disuplai oleh PLN melalui transformator distribusi pada gedung tersebut cukup baik, dari hasil pengukuran parameter tegangan, arus dan faktor daya (power factor) masih memenuhi standard mutu yang ditetapkan oleh IEC. Komposisi pengguna energi terbagi dalam tiga kelompok beban yaitu; beban penerangan 4,54%, air conditioner (AC) 57,36% dan peralatan kantor lainnya 38,10%. Berdasarkan standard konservasi energi yang digunakan oleh Departemen Pendidikan Nasional Republik Indonesia dan ASEAN – USAID, intensitas konsumsi energi (IKE) dalam gedung digolongkan dalam dua bagian yaitu ruangan ber-AC dan tanpa AC. Penggunaan energi listrik rata-rata dari rekening listrik selama 8 bulan dari bulan maret sampai dengan Oktober 2011 adalah sebesar 39,593 kWh/bulan, dengan tariff rata-rata sebesar Rp 966,10 /kWh. Potensi penghematan dari selisih penggunaan energi dari penggantian AC konvensional dengan AC inverter hemat energi untuk seluruh gedung kantor direksi PT. PN XIII (Persero) adalah sebesar Rp 13,083,536 /bulan atau Rp 157,002,429 /tahun. Penggantian lampu TL dengan lampu LED tidak terlalu signifikan dalam penurunan rekening listrik karena prosentasenya cukup kecil, namun dalam jangka panjang akan berdampak positip bagi lingkungan, juga panas yang dihasilkan oleh lampu LED jauh lebih rendah (lebih sejuk) dari lampu lain sehingga dapat menurunkan beban kerja AC, dan apabila teknologinya sudah lebih murah, lampu LED merupakan alternatif pilihan yang tepat untuk solusi hemat energi pada sistem penerangan. Keyword : IKE, AC Inverter, LED Energi merupakan kebutuhan dasar untuk menggerakkan hampir seluruh aktivitas ekonomi dan sosial masyarakat. Dari waktu ke waktu kebutuhan energi semakin meningkat, sedangkan cadangan energi global semikin langka. Penggunaan energi secara boros dan berlebihan akan berdampak pada kerusakan lingkungan, penurunan daya saing produk dan gejolak sosial ekonomi jangka panjang. Seiring dengan permasalahan energi yang semakin komplek, manajemen penggunaan energi pada sisi beban khususnya pada gedung perkantoran dan industri, sudah saatnya menjadi bagian penting dalam struktur manajemen perusahaan. Kegiatan audit energi merupakan top down initiative, yang keberhasilannya sangat bergantung kepada resources yang dialokasikan. Dalam banyak cara, audit energi sama halnya dengan laporan keuangan dan pemeriksaan. Audit energi ini merupakan dokumentasi spesifik},
author = {Marzuki, Achmad and Rusman, D A N},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Marzuki, Rusman - 2012 - Audit Energi pada Bangunan Gedung Direksi PT . Perkebunan Nusantara XIII ( Persero ).pdf:pdf},
isbn = {1693-9085},
journal = {Vokasi},
number = {3},
pages = {184--196},
title = {{Audit Energi pada Bangunan Gedung Direksi PT . Perkebunan Nusantara XIII ( Persero )}},
volume = {8},
year = {2012}
}
@article{Eseye2017,
abstract = {Wind generation power output estimation is always associated with some uncertainties as a result of wind speed and other weather parameters intermittency, and accurate short-term predictions are important for their efficient operation. This can greatly help transmission and distribution system operators and schedulers to improve the power network control and management. In this paper, a double stage hierarchical genetic algorithm based adaptive neuro-fuzzy inference system (double-stage hybrid GA-ANFIS) approach is proposed for short-term wind power forecast of a microgrid wind farm in Beijing, China. The approach has two hierarchical stages. The first GA-ANFIS stage utilizes numerical weather prediction (NWP) meteorological parameters to predict wind speed at the wind farm exact site and turbine hub height. The second stage maps the actual wind speed and power relationships. Then, the forecasted next day's wind speed by the first stage is applied to the second stage to predict next day's wind power. The presented approach has achieved considerable prediction accuracy enhancement. The accuracy of the proposed model is compared with other four forecasting methods and resulted in the best accuracy improvement of all.},
author = {Eseye, Abinet Tesfaye and Zhang, Jianhua and Zheng, Dehua and Li, Han and Jingfu, Gan},
doi = {10.1109/ICCCBDA.2017.7951965},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Eseye et al. - 2017 - Short-term wind power forecasting using a double-stage hierarchical hybrid GA-ANFIS approach.pdf:pdf},
isbn = {9781509044986},
journal = {2017 2nd IEEE International Conference on Cloud Computing and Big Data Analysis, ICCCBDA 2017},
keywords = {forecasting,fuzzy logic,genetic algorithm,neural network,numerical weather prediction,wind power},
pages = {499--503},
title = {{Short-term wind power forecasting using a double-stage hierarchical hybrid GA-ANFIS approach}},
year = {2017}
}
@inproceedings{OguzYazici2020,
abstract = {Recurrent neural networks (RNN) are popular for many computer vision tasks, including multi-label classification. Since RNNs produce sequential outputs, labels need to be ordered for the multi-label classification task. Current approaches sort labels according to their frequency, typically ordering them in either rare-first or frequent-first. These imposed orderings do not take into account that the natural order to generate the labels can change for each image, e.g. first the dominant object before summing up the smaller objects in the image. Therefore, we propose ways to dynamically order the ground truth labels with the predicted label sequence. This allows for faster training of more optimal LSTM models. Analysis evidences that our method does not suffer from duplicate generation, something which is common for other models. Furthermore, it outperforms other CNN-RNN models, and we show that a standard architecture of an image encoder and language decoder trained with our proposed loss obtains the state-of-the-art results on the challenging MS-COCO, WIDER Attribute and PA-100K and competitive results on NUS-WIDE.},
archivePrefix = {arXiv},
arxivId = {1911.09996},
author = {{Oguz Yazici}, Vacit and Gonzalez-Garcia, Abel and Ramisa, Arnau and Twardowski, Bartlomiej and van de Weijer, Joost},
booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/CVPR42600.2020.01345},
eprint = {1911.09996},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oguz Yazici et al. - 2020 - Orderless Recurrent Models for Multi-Label Classification.pdf:pdf},
isbn = {978-1-7281-7168-5},
issn = {10636919},
month = {jun},
pages = {13437--13446},
publisher = {IEEE},
title = {{Orderless Recurrent Models for Multi-Label Classification}},
url = {https://ieeexplore.ieee.org/document/9156739/},
year = {2020}
}
@article{Suseela2016,
author = {Suseela, G and Basha, S Ahmed and Babu, K Prasasd},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Suseela, Basha, Babu - 2016 - Image Restoration Using Lucy Richardson Algorithm For X-Ray Images.pdf:pdf},
journal = {IJISET - International Journal of Innovative Science, Engineering & Technology},
keywords = {lra,matlab,psf,x ray images},
number = {2},
pages = {280--285},
title = {{Image Restoration Using Lucy Richardson Algorithm For X-Ray Images}},
volume = {3},
year = {2016}
}
@article{Sidnev2019,
abstract = {The one-shot approach, DeepMark, for fast clothing detection as a modification of a multi-target network, CenterNet, is proposed in the paper. The state-of-the-art accuracy of 0.723 mAP for bounding box detection task and 0.532 mAP for landmark detection task on the DeepFashion2 Challenge dataset were achieved. The proposed architecture can be used effectively on the low-power devices.},
archivePrefix = {arXiv},
arxivId = {1910.01225},
author = {Sidnev, Alexey and Trushkov, Alexey and Kazakov, Maxim and Korolev, Ivan and Sorokin, Vladislav},
eprint = {1910.01225},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sidnev et al. - 2019 - DeepMark One-Shot Clothing Detection.pdf:pdf},
title = {{DeepMark: One-Shot Clothing Detection}},
url = {http://arxiv.org/abs/1910.01225},
year = {2019}
}
@article{Shaham2019,
abstract = {We introduce SinGAN, an unconditional generative model that can be learned from a single natural image. Our model is trained to capture the internal distribution of patches within the image, and is then able to generate high quality, diverse samples that carry the same visual content as the image. SinGAN contains a pyramid of fully convolutional GANs, each responsible for learning the patch distribution at a different scale of the image. This allows generating new samples of arbitrary size and aspect ratio, that have significant variability, yet maintain both the global structure and the fine textures of the training image. In contrast to previous single image GAN schemes, our approach is not limited to texture images, and is not conditional (i.e. it generates samples from noise). User studies confirm that the generated samples are commonly confused to be real images. We illustrate the utility of SinGAN in a wide range of image manipulation tasks.},
archivePrefix = {arXiv},
arxivId = {1905.01164},
author = {Shaham, Tamar Rott and Dekel, Tali and Michaeli, Tomer},
eprint = {1905.01164},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shaham, Dekel, Michaeli - 2019 - SinGAN Learning a Generative Model from a Single Natural Image.pdf:pdf},
title = {{SinGAN: Learning a Generative Model from a Single Natural Image}},
url = {http://arxiv.org/abs/1905.01164},
year = {2019}
}
@article{Abdalla2018,
abstract = {Nanotechnology is utilized well in the development and improvement of the performance in Solid Oxide Fuel Cells (SOFCs). The high operating temperature of SOFCs (700–900 °C) has resulted in serious demerits regarding their overall performance and durability. Therefore, the operating temperature has been reduced to an intermediate temperature range of approximately 400–700 °C which improved performance and, subsequently, commercialized SOFCs as portable power sources. However, at reduced temperature, challenges such as an increase in internal resistance of the fuel cell components arise. Although, this may not be as serious as problems encountered at high temperature, it still significantly affects the performance of SOFCs. This review paper addresses the work of researchers in the application of nanotechnology in fabricating SOFCs through distinct methods. These methods have successfully omitted or at least reduced the internal resistance and showed considerable improvement in power density of the SOFCs at reduced temperatures.},
author = {Abdalla, Abdalla M. and Hossain, Shahzad and Azad, Atia T. and Petra, Pg Mohammad I. and Begum, Feroza and Eriksson, Sten G. and Azad, Abul K.},
doi = {10.1016/j.rser.2017.09.046},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abdalla et al. - 2018 - Nanomaterials for solid oxide fuel cells A review.pdf:pdf},
issn = {18790690},
journal = {Renewable and Sustainable Energy Reviews},
keywords = {Fuel cell performance,Materials development,Nanomaterials,Solid oxide fuel cell},
number = {September 2016},
pages = {353--368},
publisher = {Elsevier Ltd},
title = {{Nanomaterials for solid oxide fuel cells: A review}},
url = {http://dx.doi.org/10.1016/j.rser.2017.09.046},
volume = {82},
year = {2018}
}
@article{Tan2019,
abstract = {Model efficiency has become increasingly important in computer vision. In this paper, we systematically study various neural network architecture design choices for object detection and propose several key optimizations to improve efficiency. First, we propose a weighted bi-directional feature pyramid network (BiFPN), which allows easy and fast multi-scale feature fusion; Second, we propose a compound scaling method that uniformly scales the resolution, depth, and width for all backbone, feature network, and box/class prediction networks at the same time. Based on these optimizations, we have developed a new family of object detectors, called EfficientDet, which consistently achieve an order-of-magnitude better efficiency than prior art across a wide spectrum of resource constraints. In particular, without bells and whistles, our EfficientDet-D7 achieves stateof-the-art 51.0 mAP on COCO dataset with 52M parameters and 326B FLOPS1 , being 4x smaller and using 9.3x fewer FLOPS yet still more accurate (+0.3% mAP) than the best previous detector.},
archivePrefix = {arXiv},
arxivId = {1911.09070},
author = {Tan, Mingxing and Pang, Ruoming and Le, Quoc V.},
eprint = {1911.09070},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tan, Pang, Le - 2019 - EfficientDet Scalable and Efficient Object Detection.pdf:pdf},
title = {{EfficientDet: Scalable and Efficient Object Detection}},
url = {http://arxiv.org/abs/1911.09070},
year = {2019}
}
@article{Zhang2011,
abstract = {INTRODUCTION: Near-infrared fluorescent (NIRF) imaging is a rapidly growing research field which has the potential to be an important imaging modality in cancer diagnosis. Various exogenous NIR fluorophores have been developed for the technique, including small molecule fluorophores and nanoparticles. NIRF imaging has been used in animal models for the detection of cancer overthe last twenty years and has in recent years been used in human clinical trials.\n\nAREAS COVERED: This article describes the types and characteristics of exogenous fluorophores available for in vivo fluorescent cancer imaging. The article also discusses the progression of NIRF cancer imaging over recent years and its future challenges, from both a biological and clinical perspective. in The review also looks at its application for lymph node mapping, tumor targeting and characterization, and tumor margin definition for surgical guidance.\n\nEXPERT OPINION: NIRF imaging is not in routine clinical cancer practice; yet, the authors predict that techniques using NIR fluorophores for tumor margin definition and lymph node mapping will enter clinical practice in the near future. The authors also anticipate that NIRF imaging research will lead to the development of flurophores with 'high brightness' that will overcome the limited penetration of this modality and be better suited for non invasive tumor targeting.},
author = {Zhang, Hua and Uselman, Ryan R and Yee, Douglas},
doi = {10.1517/17530059.2011.566858},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Uselman, Yee - 2011 - Exogenous near-infrared fluorophores and their applications in cancer diagnosis biological and clinical per.pdf:pdf},
issn = {1753-0059},
journal = {Expert Opinion on Medical Diagnostics},
number = {3},
pages = {241--251},
pmid = {21566703},
title = {{Exogenous near-infrared fluorophores and their applications in cancer diagnosis: biological and clinical perspectives}},
url = {http://www.tandfonline.com/doi/full/10.1517/17530059.2011.566858},
volume = {5},
year = {2011}
}
@article{Asniar2016,
abstract = {This study aimed to describe the profile of scientific reasoning and the argumentation skill of students from science and non-science. This research is a descriptive study in a state university at Bandung with samples from science and non-science students totaling 100 people and lecturer of the science course. The studies starts by visiting the universities, reviewing the literature related to the focus of the research, interviews with science faculty about how learning science is done, giving questionnaires to students, giving essay on scientific reasoning, and interviews with several students. The research instrument is a questionnaire (speaking and argumentation), interview, and questions about the essays. The results showed that the average student scientific reasoning ability of non-science (1.4) higher than students of science (1). The arguments, the students found the skills to argue required by students mainly by student teachers (SS = 43.3%, S = 50%), to be able to have the skills to argue we need a habituation or conditioning (SS = 23.3%, S = 50%), and the ability to argue must be procured in all the lectures (SS = 53.5%, S = 43.3%).},
archivePrefix = {arXiv},
arxivId = {2477-2038},
author = {Asniar},
eprint = {2477-2038},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Asniar - 2016 - Profil Penalaran Ilmiah Dan Kemampuan Berargumentasi.pdf:pdf},
journal = {Jurnal Penelitian dan Pembelajaran IPA},
keywords = {argument,non-science,science,scientific reasoning},
number = {1},
pages = {30--41},
title = {{Profil Penalaran Ilmiah Dan Kemampuan Berargumentasi}},
volume = {2},
year = {2016}
}
@article{Lecun1998,
abstract = {Recent reports have suggested that mesenchymal cells derived from bone marrow may differentiate into not only mesenchymal lineage cells but also other lineage cells. There is possibility for insulin-producing cells (IPCs) to be differentiated from mesenchymal cells. We used self-functional repair stimuli of stem cells by partial injury. Rat pancreatic extract (RPE) from the regenerating pancreas (2 days after 60% pancreatectomy) was treated to rat mesenchymal cells. After the treatment of RPE, they made clusters like islet of Langerhans within a week and expressed four pancreatic endocrine hormones; insulin, glucagon, pancreatic polypeptide, and somatostatin. Moreover, IPCs released insulin in response to normal glucose challenge. Here we demonstrate that the treatment of RPE can differentiate rat mesenchymal cells into IPCs which can be a potential source for the therapy of diabetes. {\textcopyright} 2005 Elsevier Inc. All rights reserved.},
author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
doi = {10.1109/5.726791},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lecun et al. - 1998 - Gradient-based learning applied to document recognition.pdf:pdf},
issn = {00189219},
journal = {Proceedings of the IEEE},
keywords = {Bone marrow stromal cell,Differentiation,Mesenchymal stem cell,Pancreatectomy},
number = {11},
pages = {2278--2324},
pmid = {15823584},
title = {{Gradient-based learning applied to document recognition}},
url = {http://ieeexplore.ieee.org/document/726791/},
volume = {86},
year = {1998}
}
@book{Hadiwiyoto1994,
address = {Jogjakarta},
author = {Hadiwiyoto, S},
publisher = {Liberty},
title = {{Teori dan Prosedur Pengujian Mutu Susu dan Hasil Olahannya}},
year = {1994}
}
@article{Chen2016,
abstract = {Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable endto-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.},
archivePrefix = {arXiv},
arxivId = {1603.02754},
author = {Chen, Tianqi and Guestrin, Carlos},
doi = {10.1145/2939672.2939785},
eprint = {1603.02754},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Guestrin - 2016 - XGBoost A scalable tree boosting system.pdf:pdf},
isbn = {9781450342322},
journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
keywords = {Large-scale Machine learning,tabular data,tree-based},
mendeley-tags = {tabular data,tree-based},
pages = {785--794},
title = {{XGBoost: A scalable tree boosting system}},
url = {https://arxiv.org/pdf/1603.02754.pdf https://github.com/dmlc/xgboost},
volume = {13-17-Augu},
year = {2016}
}
@article{Takase2016,
abstract = {Vector representation is a common approach for expressing the meaning of a relational pattern. Most previous work obtained a vector of a relational pattern based on the distribution of its context words (e.g., arguments of the relational pattern), regarding the pattern as a single 'word'. However, this approach suffers from the data sparseness problem, because relational patterns are productive, i.e., produced by combinations of words. To address this problem, we propose a novel method for computing the meaning of a relational pattern based on the semantic compositionality of constituent words. We extend the Skip-gram model (Mikolov et al., 2013) to handle semantic compositions of relational patterns using recursive neural networks. The experimental results show the superiority of the proposed method for modeling the meanings of relational patterns, and demonstrate the contribution of this work to the task of relation extraction.},
author = {Takase, Sho and Okazaki, Naoaki and Inui, Kentaro},
doi = {10.1016/j.engappai.2016.01.027},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Takase, Okazaki, Inui - 2016 - Modeling semantic compositionality of relational patterns.pdf:pdf},
issn = {09521976},
journal = {Engineering Applications of Artificial Intelligence},
keywords = {Knowledge acquisition,Natural language processing,Recursive neural network,Relation extraction,Semantic compositionality,Word embedding},
pages = {256--264},
publisher = {Elsevier},
title = {{Modeling semantic compositionality of relational patterns}},
url = {http://dx.doi.org/10.1016/j.engappai.2016.01.027},
volume = {50},
year = {2016}
}
@article{Roberts2009,
author = {Roberts, S C and Little, A C and Lyndon, A and Roberts, J and Havlicek, J and Wright, R L},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roberts et al. - 2009 - Manipulation of body odour alters men'sself-confidence and judgements of their visualattractiveness by women.pdf:pdf},
journal = {International journal of cosmetic science},
keywords = {deodorant, evolutionary psychology, olfaction, per},
pages = {47--54},
pmid = {6844},
title = {{Manipulation of body odour alters men'sself-confidence and judgements of their visualattractiveness by women}},
volume = {31},
year = {2009}
}
@article{Galloway2019,
abstract = {Batch normalization (batch norm) is often used in an attempt to stabilize and accelerate training in deep neural networks. In many cases it indeed decreases the number of parameter updates required to achieve low training error. However, it also reduces robustness to small adversarial input perturbations and noise by double-digit percentages, as we show on five standard datasets. Furthermore, substituting weight decay for batch norm is sufficient to nullify the relationship between adversarial vulnerability and the input dimension. Our work is consistent with a mean-field analysis that found that batch norm causes exploding gradients.},
archivePrefix = {arXiv},
arxivId = {1905.02161},
author = {Galloway, Angus and Golubeva, Anna and Tanay, Thomas and Moussa, Medhat and Taylor, Graham W.},
eprint = {1905.02161},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Galloway et al. - 2019 - Batch normalization is a cause of adversarial vulnerability.pdf:pdf},
journal = {arXiv},
pages = {1--17},
title = {{Batch normalization is a cause of adversarial vulnerability}},
year = {2019}
}
@article{Yang2019b,
abstract = {Modern object detectors rely heavily on rectangular bounding boxes, such as anchors, proposals and the final predictions, to represent objects at various recognition stages. The bounding box is convenient to use but provides only a coarse localization of objects and leads to a correspondingly coarse extraction of object features. In this paper, we present \textbf{RepPoints} (representative points), a new finer representation of objects as a set of sample points useful for both localization and recognition. Given ground truth localization and recognition targets for training, RepPoints learn to automatically arrange themselves in a manner that bounds the spatial extent of an object and indicates semantically significant local areas. They furthermore do not require the use of anchors to sample a space of bounding boxes. We show that an anchor-free object detector based on RepPoints can be as effective as the state-of-the-art anchor-based detection methods, with 46.5 AP and 67.4 $AP_{50}$ on the COCO test-dev detection benchmark, using ResNet-101 model. Code is available at https://github.com/microsoft/RepPoints.},
archivePrefix = {arXiv},
arxivId = {1904.11490},
author = {Yang, Ze and Liu, Shaohui and Hu, Han and Wang, Liwei and Lin, Stephen},
eprint = {1904.11490},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2019 - RepPoints Point Set Representation for Object Detection.pdf:pdf},
title = {{RepPoints: Point Set Representation for Object Detection}},
url = {http://arxiv.org/abs/1904.11490},
year = {2019}
}
@book{Lewandowski2015,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21% with default Glide SP settings to 58% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Lewandowski, Clare M. and Co-investigator, New and Lewandowski, Clare M.},
booktitle = {The effects of brief mindfulness intervention on acute pain experience: An examination of individual difference},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lewandowski, Co-investigator, Lewandowski - 2015 - Soft Computing for Control of Non-Linear Dynamical Systems.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {icle},
pages = {1689--1699},
pmid = {25246403},
title = {{Soft Computing for Control of Non-Linear Dynamical Systems}},
volume = {1},
year = {2015}
}
@article{Bates1969,
abstract = {Aggregating information by combining forecasts from two or more forecasting methods is an alternative to using just a single method. In this paper we provide extensive empirical results showing that combined forecasts obtained through weighted averages can be quite accurate. Five procedures for estimating weights are investigated, and two appear to be superior to the others. These two procedures provide forecasts that are more accurate overall than forecasts from individual methods. Furthermore, they are superior to forecasts found from a simple unweighted average of the same methods. CR - Copyright &#169; 1983 Royal Statistical Society},
author = {Bates, J. M. and Granger, C. W. J.},
doi = {10.2307/3008764},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bates, Granger - 1969 - The Combination of Forecasts(2).pdf:pdf},
isbn = {9780511753961},
issn = {14732858},
journal = {Operational Research Society},
number = {4},
pages = {451--468},
title = {{The Combination of Forecasts}},
url = {http://www.jstor.org/stable/3008764?origin=crossref},
volume = {20},
year = {1969}
}
@article{Koppula2021,
abstract = {Fine-grained estimation of galaxy merger stages from observations is a key problem useful for validation of our current theoretical understanding of galaxy formation. To this end, we demonstrate a CNN-based regression model that is able to predict, for the first time, using a single image, the merger stage relative to the first perigee passage with a median error of 38.3 million years (Myrs) over a period of 400 Myrs. This model uses no specific dynamical modeling and learns only from simulated merger events. We show that our model provides reasonable estimates on real observations, approximately matching prior estimates provided by detailed dynamical modeling. We provide a preliminary interpretability analysis of our models, and demonstrate first steps toward calibrated uncertainty estimation.},
archivePrefix = {arXiv},
arxivId = {2102.05182},
author = {Koppula, Skanda and Bapst, Victor and Huertas-Company, Marc and Blackwell, Sam and Grabska-Barwinska, Agnieszka and Dieleman, Sander and Huber, Andrea and Antropova, Natasha and Binkowski, Mikolaj and Openshaw, Hannah and Recasens, Adria and Caro, Fernando and Deke, Avishai and Dubois, Yohan and Ferrero, Jesus Vega and Koo, David C. and Primack, Joel R. and Back, Trevor},
eprint = {2102.05182},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Koppula et al. - 2021 - A Deep Learning Approach for Characterizing Major Galaxy Mergers.pdf:pdf},
keywords = {application,galaxy},
mendeley-tags = {application,galaxy},
number = {NeurIPS},
pages = {1--7},
title = {{A Deep Learning Approach for Characterizing Major Galaxy Mergers}},
url = {http://arxiv.org/abs/2102.05182},
year = {2021}
}
@article{Goswami2014,
author = {Goswami, Savita and Gaur, Abhishek Kumar},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goswami, Gaur - 2014 - Enhance the performance of weather parameters in Short-Term Weather forecasting using ANFIS.pdf:pdf},
keywords = {- adaptive neuro-fuzzy inference,anfis,coefficient,mse,rmase,rmse,systems,weather prediction},
number = {1},
pages = {290--296},
title = {{Enhance the performance of weather parameters in Short-Term Weather forecasting using ANFIS}},
volume = {5},
year = {2014}
}
@article{Alsayid2013,
abstract = {In a solar photovoltaic array, it is possible that shadow may fall over some of its cells. Under partial shading conditions the PV characteristic gets more complex with multiple peaks. The purpose of this paper is to illustrate, by analyzing different shading situations, the effects that partial shading can cause in a PV array. First this is done by simulation using Matlab/Simulink, then the impact of shading is illustrated experimentally by measurements on a two commercial 140 W PV panels series connected.},
author = {Alsayid, Basim a and Alsadi, Samer Y and Jallad, Ja S and Dradi, Muhammad H},
doi = {10.4236/sgre.2013.46049},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alsayid et al. - 2013 - Partial Shading of PV System Simulation with Experimental Results.pdf:pdf},
issn = {2151-481X},
journal = {Smart Grid and Renewable Energy},
keywords = {bypass diodes,modeling,partial shading,simulation},
number = {September},
pages = {429--435},
title = {{Partial Shading of PV System Simulation with Experimental Results}},
volume = {4},
year = {2013}
}
@inproceedings{Lopez-Paz2017a,
abstract = {One major obstacle towards AI is the poor ability of models to solve new problems quicker, and without forgetting previously acquired knowledge. To better understand this issue, we study the problem of continual learning, where the model observes, once and one by one, examples concerning a sequence of tasks. First, we propose a set of metrics to evaluate models learning over a continuum of data. These metrics characterize models not only by their test accuracy, but also in terms of their ability to transfer knowledge across tasks. Second, we propose a model for continual learning, called Gradient Episodic Memory (GEM) that alleviates forgetting, while allowing beneficial transfer of knowledge to previous tasks. Our experiments on variants of the MNIST and CIFAR-100 datasets demonstrate the strong performance of GEM when compared to the state-of-the-art.},
annote = {Comment: Published at NIPS 2017
arXiv: 1706.08840},
archivePrefix = {arXiv},
arxivId = {1706.08840},
author = {Lopez-Paz, David and Ranzato, Marc'Aurelio},
booktitle = {Advances in Neural Information Processing Systems},
eprint = {1706.08840},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lopez-Paz, Ranzato - 2017 - Gradient episodic memory for continual learning.pdf:pdf;:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lopez-Paz, Ranzato - 2017 - Gradient episodic memory for continual learning(2).pdf:pdf},
issn = {10495258},
keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,[cifar],[mnist],gem},
mendeley-tags = {[cifar],[mnist]},
pages = {6468--6477},
title = {{Gradient episodic memory for continual learning}},
url = {http://arxiv.org/abs/1706.08840},
volume = {2017-Decem},
year = {2017}
}
@article{Cermelli2020,
abstract = {Despite their effectiveness in a wide range of tasks, deep architectures suffer from some important limitations. In particular, they are vulnerable to catastrophic forgetting, i.e. they perform poorly when they are required to update their model as new classes are available but the original training set is not retained. This paper addresses this problem in the context of semantic segmentation. Current strategies fail on this task because they do not consider a peculiar aspect of semantic segmentation: since each training step provides annotation only for a subset of all possible classes, pixels of the background class (i.e. pixels that do not belong to any other classes) exhibit a semantic distribution shift. In this work we revisit classical incremental learning methods, proposing a new distillation-based framework which explicitly accounts for this shift. Furthermore, we introduce a novel strategy to initialize classifier's parameters, thus preventing biased predictions toward the background class. We demonstrate the effectiveness of our approach with an extensive evaluation on the Pascal-VOC 2012 and ADE20K datasets, significantly outperforming state of the art incremental learning methods.},
archivePrefix = {arXiv},
arxivId = {2002.00718},
author = {Cermelli, Fabio and Mancini, Massimiliano and Bulo, Samuel Rota and Ricci, Elisa and Caputo, Barbara},
doi = {10.1109/CVPR42600.2020.00925},
eprint = {2002.00718},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cermelli et al. - 2020 - Modeling the background for incremental learning in semantic segmentation.pdf:pdf},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
keywords = {continual learning,incremental learning,semantic segmentation},
mendeley-tags = {continual learning,incremental learning,semantic segmentation},
pages = {9230--9239},
title = {{Modeling the background for incremental learning in semantic segmentation}},
year = {2020}
}
@article{Wu2020a,
abstract = {We propose a greedy strategy to train a deep network for multi-class classification, where each layer is defined as a composition of a linear projection and a nonlinear mapping. This nonlinear mapping is defined as the feature map of a Gaussian kernel, and the linear projection is learned by maximizing the dependence between the layer output and the labels, using the Hilbert Schmidt Independence Criterion (HSIC) as the dependence measure. Since each layer is trained greedily in sequence, all learning is local, and neither backpropagation nor even gradient descent is needed. The depth and width of the network are determined via natural guidelines, and the procedure regularizes its weights in the linear layer. As the key theoretical result, the function class represented by the network is proved to be sufficiently rich to learn any dataset labeling using a finite number of layers, in the sense of reaching minimum mean-squared error or cross-entropy, as long as no two data points with different labels coincide. Experiments demonstrate good generalization performance of the greedy approach across multiple benchmarks while showing a significant computational advantage against a multilayer perceptron of the same complexity trained globally by backpropagation.},
archivePrefix = {arXiv},
arxivId = {2006.08539},
author = {Wu, Chieh and Masoomi, Aria and Gretton, Arthur and Dy, Jennifer},
eprint = {2006.08539},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu et al. - 2020 - Layer-wise Learning of Kernel Dependence Networks.pdf:pdf},
journal = {arXiv},
title = {{Layer-wise Learning of Kernel Dependence Networks}},
volume = {130},
year = {2020}
}
@article{Ioffe2015,
abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters.},
archivePrefix = {arXiv},
arxivId = {1502.03167},
author = {Ioffe, Sergey and Szegedy, Christian},
eprint = {1502.03167},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ioffe, Szegedy - 2015 - Batch normalization Accelerating deep network training by reducing internal covariate shift.pdf:pdf},
isbn = {9781510810587},
journal = {32nd International Conference on Machine Learning, ICML 2015},
pages = {448--456},
title = {{Batch normalization: Accelerating deep network training by reducing internal covariate shift}},
volume = {1},
year = {2015}
}
@article{Boey2011,
abstract = {The accelerating and frequently fluctuating price of conventional diesel, together with growing environmental concerns has sparked renewed attention on the search for an alternative fuel. The awareness of the toxic effects related to the tailpipe emissions of vehicles has driven many countries to look for a less-polluted transportation fuel. In this regard, biodiesel (alkyl esters) from vegetable oils or animal fats via transesterification is regarded as the most viable alternative as a green fuel for diesel engines. Transesterification is a catalyzed process and, traditionally, homogeneous catalysts are employed. However, this type of catalyst is not able to be reused and requires tedious washing and separating steps, hence, stimulating the conception of heterogeneous-catalyzed transesterification. Despite the success of various heterogeneous catalysts, many are not viable for wide industrial usage as most of the catalysts are expensive and need additional preparation effort. Among them, CaO seems to have a promising place and the increasing research on CaO is self-evidence of its capability in catalyzing the reaction. Therefore, in this paper, various issues regarding CaO-catalyzed transesterification are reviewed. The diverse performance of CaO in neat, loaded and mixed forms, as well as a support for other catalyst systems, CaO reaction mechanism, CaO tolerance to low to moderate oil qualities and reaction conditions, the conformance of CaO-catalyzed biodiesel to key specifications and the future outlook and the challenges of the catalyst are suitably addressed. {\textcopyright} 2011 Elsevier B.V.},
author = {Boey, Peng Lim and Maniam, Gaanty Pragas and Hamid, Shafida Abd},
doi = {10.1016/j.cej.2011.01.009},
isbn = {1385-8947},
issn = {13858947},
journal = {Chemical Engineering Journal},
keywords = {Biodiesel,Calcium oxide,Heterogeneous catalyst,Methyl ester,Transesterification},
number = {1},
pages = {15--22},
publisher = {Elsevier B.V.},
title = {{Performance of calcium oxide as a heterogeneous catalyst in biodiesel production: A review}},
url = {http://dx.doi.org/10.1016/j.cej.2011.01.009},
volume = {168},
year = {2011}
}
@article{Ghosh2021,
abstract = {Most of the existing artificial neural networks(ANNs) fail to learn continually due to catastrophic forgetting, while humans can do the same by maintaining previous tasks' performances. Although storing all the previous data can alleviate the problem, it takes a large memory, infeasible in real-world utilization. We propose a continual zero-shot learning model that is more suitable in real-case scenarios to address the issue that can learn sequentially and distinguish classes the model has not seen during training. We present a hybrid network that consists of a shared VAE module to hold information of all tasks and task-specific private VAE modules for each task. The model's size grows with each task to prevent catastrophic forgetting of task-specific skills, and it includes a replay approach to preserve shared skills. We demonstrate our hybrid model is effective on several datasets, i.e., CUB, AWA1, AWA2, and aPY. We show our method is superior on class sequentially learning with ZSL(Zero-Shot Learning) and GZSL(Generalized Zero-Shot Learning).},
archivePrefix = {arXiv},
arxivId = {2102.03778},
author = {Ghosh, Subhankar},
eprint = {2102.03778},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghosh - 2021 - Adversarial Training of Variational Auto-encoders for Continual Zero-shot Learning.pdf:pdf},
keywords = {adversarial learning,continual learning,zero-shot learning},
mendeley-tags = {adversarial learning,continual learning,zero-shot learning},
title = {{Adversarial Training of Variational Auto-encoders for Continual Zero-shot Learning}},
url = {http://arxiv.org/abs/2102.03778},
year = {2021}
}
@article{Cohen1992a,
abstract = {FERROELECTRIC materials are characterized by a switchable macroscopic polarization. Most technologically important ferroelectrics are oxides with a perovskite structure. The origin of their ferroelectric behaviour is unclear, however, and there is incomplete understanding of why similar, but chemically different, perovskites should display very different ferroelectric behaviour. The great sensitivity of ferroelectrics to chemistry, defects, electrical boundary conditions and pressure arises from a delicate balance between long-range Coulomb forces (which favour the ferroelectric state) and short-range repulsions (which favour the nonpolar cubic structure). To model the transition accurately, total-energy techniques are required which incorporate the effects of charge distortion and covalency. Here I report results of electronic-structure calculations on two classic examples of ferroelectric perovskites, BaTiO3 and PbTiO3, and demonstrate that hybridization between the titanium 3d states and the oxygen 2p states is essential for ferroelectricity. The different ferroelectric phase behaviour of the two materials is also clear: in PbTiO3, the lead and oxygen states hybridize, leading to a large strain that stabilizes the tetragonal phase, whereas in BaTiO3 the interaction between barium and oxygen is completely ionic, favouring a rhombohedral structure.},
archivePrefix = {arXiv},
arxivId = {1108.5819},
author = {Cohen, Ronald E.},
doi = {10.1038/358136a0},
eprint = {1108.5819},
isbn = {0028-0836},
issn = {0028-0836},
journal = {Nature},
number = {6382},
pages = {136--138},
title = {{Origin of ferroelectricity in perovskite oxides}},
url = {http://www.nature.com/doifinder/10.1038/358136a0},
volume = {358},
year = {1992}
}
@article{Zhang2021a,
abstract = {The explosive growth of image data facilitates the fast development of image processing and computer vision methods for emerging visual applications, meanwhile introducing novel distortions to the processed images. This poses a grand challenge to existing blind image quality assessment (BIQA) models, failing to continually adapt to such subpopulation shift. Recent work suggests training BIQA methods on the combination of all available human-rated IQA datasets. However, this type of approach is not scalable to a large number of datasets, and is cumbersome to incorporate a newly created dataset as well. In this paper, we formulate continual learning for BIQA, where a model learns continually from a stream of IQA datasets, building on what was learned from previously seen data. We first identify five desiderata in the new setting with a measure to quantify the plasticity-stability trade-off. We then propose a simple yet effective method for learning BIQA models continually. Specifically, based on a shared backbone network, we add a prediction head for a new dataset, and enforce a regularizer to allow all prediction heads to evolve with new data while being resistant to catastrophic forgetting of old data. We compute the quality score by an adaptive weighted summation of estimates from all prediction heads. Extensive experiments demonstrate the promise of the proposed continual learning method in comparison to standard training techniques for BIQA.},
archivePrefix = {arXiv},
arxivId = {2102.09717},
author = {Zhang, Weixia and Li, Dingquan and Ma, Chao and Zhai, Guangtao and Yang, Xiaokang and Ma, Kede},
eprint = {2102.09717},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2021 - Continual Learning for Blind Image Quality Assessment.pdf:pdf},
keywords = {blind quality assessment,continual learning,incremental learning},
mendeley-tags = {blind quality assessment,continual learning,incremental learning},
pages = {1--14},
title = {{Continual Learning for Blind Image Quality Assessment}},
url = {http://arxiv.org/abs/2102.09717},
year = {2021}
}
@article{Silver2018,
abstract = {The game of chess is the longest-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. By contrast, the AlphaGo Zero program recently achieved superhuman performance in the game of Go by reinforcement learning from self-play. In this paper, we generalize this approach into a single AlphaZero algorithm that can achieve superhuman performance in many challenging games. Starting from random play and given no domain knowledge except the game rules, AlphaZero convincingly defeated a world champion program in the games of chess and shogi (Japanese chess), as well as Go.},
author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
doi = {10.1126/science.aar6404},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Silver et al. - 2018 - A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play.pdf:pdf},
issn = {10959203},
journal = {Science},
number = {6419},
pages = {1140--1144},
pmid = {30523106},
title = {{A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play}},
volume = {362},
year = {2018}
}
@article{Asikin-Mijan2015,
abstract = {Biodiesel has gained interest of most researchers recently as an alternative for fossil diesel fuels in promoting environmentally sustainable fuels. With the presence of base catalyst, biodiesel can be easily produced via transesterification of triglyceride with alcohol under mild reaction conditions. Utilization of green catalysts from natural waste shells for biodiesel synthesis is capable of reducing the cost of catalyst which is beneficial to overall production cost. In this study, we have developed a modified CaO catalyst from natural waste clamshell (Meretrix meretrix) via hydration-dehydration treatment for transesterification process. The effects of hydration duration on clamshell were investigated to achieve the most optimum characteristic and catalytic activity. The surface area and the basicity of the treated catalyst increased extensively with prolonged hydration duration technique. By prolonging the water treatment process, it shall allow more formation of Ca(OH)<inf>2</inf> which then has promoted the formation of Bronsted base sites for higher basicity. The catalytic activity of hydration-dehydration treated catalysts were found increased in the following order CS-CaO<inf>12h</inf>>CS-CaO<inf>9h</inf>>CS-CaO<inf>6h</inf>>CS-CaO<inf>3h</inf>>CS-CaO<inf>1h</inf>. The triglyceride conversion was as high as 98% when utilizing CS-CaO<inf>12h</inf> under reflux conditions of methanol: oil molar ratio of 9:1, catalyst amount is 1 wt% and 2h of reaction time.},
author = {Asikin-Mijan, N. and Lee, H. V. and Taufiq-Yap, Y. H.},
doi = {10.1016/j.cherd.2015.07.002},
issn = {02638762},
journal = {Chemical Engineering Research and Design},
keywords = {Biodiesel,Calcium oxide,Clamshell,Green-catalyst,Hydration technique,Transesterification},
pages = {368--377},
publisher = {Institution of Chemical Engineers},
title = {{Synthesis and catalytic activity of hydration-dehydration treated clamshell derived CaO for biodiesel production}},
url = {http://dx.doi.org/10.1016/j.cherd.2015.07.002},
volume = {102},
year = {2015}
}
@article{Oktay2020,
abstract = {The successes of deep learning, variational inference, and many other fields have been aided by specialized implementations of reverse-mode automatic differentiation (AD) to compute gradients of mega-dimensional objectives. The AD techniques underlying these tools were designed to compute exact gradients to numerical precision, but modern machine learning models are almost always trained with stochastic gradient descent. Why spend computation and memory on exact (minibatch) gradients only to use them for stochastic optimization? We develop a general framework and approach for randomized automatic differentiation (RAD), which allows unbiased gradient estimates to be computed with reduced memory in return for variance. We examine limitations of the general approach, and argue that we must leverage problem specific structure to realize benefits. We develop RAD techniques for a variety of simple neural network architectures, and show that for a fixed memory budget, RAD converges in fewer iterations than using a small batch size for feedforward networks, and in a similar number for recurrent networks. We also show that RAD can be applied to scientific computing, and use it to develop a low-memory stochastic gradient method for optimizing the control parameters of a linear reaction-diffusion PDE representing a fission reactor.},
archivePrefix = {arXiv},
arxivId = {2007.10412},
author = {Oktay, Deniz and McGreivy, Nick and Aduol, Joshua and Beatson, Alex and Adams, Ryan P.},
eprint = {2007.10412},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oktay et al. - 2020 - Randomized Automatic Differentiation.pdf:pdf},
isbn = {0090-5364},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Folded concave penalties,Global optimization,High-dimensional statistical learning,MCP,Nonconvex quadratic programming,SCAD,Sparse recovery},
month = {jul},
number = {2},
pages = {629--659},
title = {{Randomized Automatic Differentiation}},
url = {http://arxiv.org/abs/2007.10412 https://github.com/PrincetonLIPS/RandomizedAutomaticDifferentiation},
volume = {44},
year = {2020}
}
@article{Liew2011,
abstract = {Microarray gene expression data generally suffers from missing value problem due to a variety of experimental reasons. Since the missing data points can adversely affect downstream analysis, many algorithms have been proposed to impute missing values. In this survey, we provide a comprehensive review of existing missing value imputation algorithms, focusing on their underlying algorithmic techniques and how they utilize local or global information from within the data, or their use of domain knowledge during imputation. In addition, we describe how the imputation results can be validated and the different ways to assess the performance of different imputation algorithms, as well as a discussion on some possible future research directions. It is hoped that this review will give the readers a good understanding of the current development in this field and inspire them to come up with the next generation of imputation algorithms.},
author = {Liew, AlanWee Chung and Law, Ngai Fong and Yan, Hong},
doi = {10.1093/bib/bbq080},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liew, Law, Yan - 2011 - Missing value imputation for gene expression data Computational techniques to recover missing data from availabl.pdf:pdf},
isbn = {1477-4054},
issn = {14675463},
journal = {Briefings in Bioinformatics},
keywords = {Gene expression analysis,Gene expression data,Information recovery,Missing value imputation},
number = {5},
pages = {498--513},
pmid = {21156727},
title = {{Missing value imputation for gene expression data: Computational techniques to recover missing data from available information}},
volume = {12},
year = {2011}
}
@article{Zouache2018,
abstract = {We propose a novel cooperative swarm intelligence algorithm to solve multi-objective discrete optimization problems (MODP). Our algorithm combines a firefly algorithm (FA) and a particle swarm optimization (PSO). Basically, we address three main points: the effect of FA and PSO cooperation on the exploration of the search space, the discretization of the two algorithms using a transfer function, and finally, the use of the epsilon dominance relation to manage the size of the external archive and to guarantee the convergence and the diversity of Pareto optimal solutions. We compared the results of our algorithm with the results of five well-known meta-heuristics on nine multi-objective knapsack problem benchmarks. The experiments show clearly the ability of our algorithm to provide a better spread of solutions with a better convergence behavior.},
author = {Zouache, Djaafar and Moussaoui, Abdelouahab and {Ben Abdelaziz}, Fouad},
doi = {10.1016/j.ejor.2017.06.058},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zouache, Moussaoui, Ben Abdelaziz - 2018 - A cooperative swarm intelligence algorithm for multi-objective discrete optimization with app.pdf:pdf},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Firefly algorithm,Knapsack problem,Multi-objective discrete optimization,Particle swarm optimization,Transfer function},
number = {1},
pages = {74--88},
publisher = {Elsevier B.V.},
title = {{A cooperative swarm intelligence algorithm for multi-objective discrete optimization with application to the knapsack problem}},
url = {http://dx.doi.org/10.1016/j.ejor.2017.06.058},
volume = {264},
year = {2018}
}
@article{Xi2013,
author = {Xi, Chao},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xi - 2013 - Title Artificial Neural Network and Fuzzy Logic in forecasting short-term Temperature.pdf:pdf},
journal = {Telemark University College Faculty of Technology TFver.0.8},
number = {120295},
pages = {20--27},
title = {{Title: Artificial Neural Network and Fuzzy Logic in forecasting short-term Temperature}},
volume = {x},
year = {2013}
}
@article{Martinez-Martinez2012a,
abstract = {This paper presents a system based on an Artificial Neural Network (ANN) for estimating and predicting environmental variables related to tobacco drying processes. This system has been validated with temperature and relative humidity data obtained from a real tobacco dryer with a Wireless Sensor Network (WSN). A fitting ANN was used to estimate temperature and relative humidity in different locations inside the tobacco dryer and to predict them with different time horizons. An error under 2% can be achieved when estimating temperature as a function of temperature and relative humidity in other locations. Moreover, an error around 1.5 times lower than that obtained with an interpolation method can be achieved when predicting the temperature inside the tobacco mass as a function of its present and past values with time horizons over 150 minutes. These results show that the tobacco drying process can be improved taking into account the predicted future value of the monitored variables and the estimated actual value of other variables using a fitting ANN as proposed.},
author = {Mart{\'{i}}nez-Mart{\'{i}}nez, V{\'{i}}ctor and Baladr{\'{o}}n, Carlos and Gomez-Gil, Jaime and Ruiz-Ruiz, Gonzalo and Navas-Gracia, Luis M. and Aguiar, Javier M. and Carro, Bel{\'{e}}n},
doi = {10.3390/s121014004},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mart{\'{i}}nez-Mart{\'{i}}nez et al. - 2012 - Temperature and Relative Humidity Estimation and Prediction in the Tobacco Drying Process Using Arti.pdf:pdf},
isbn = {3463679752},
issn = {1424-8220},
journal = {Sensors},
number = {12},
pages = {14004--14021},
title = {{Temperature and Relative Humidity Estimation and Prediction in the Tobacco Drying Process Using Artificial Neural Networks}},
url = {http://www.mdpi.com/1424-8220/12/10/14004/},
volume = {12},
year = {2012}
}
@article{Pfulb2019,
abstract = {We present a large-scale empirical study of catastrophic forgetting (CF) in modern Deep Neural Network (DNN) models that perform sequential (or: incremental) learning. A new experimental protocol is proposed that enforces typical constraints encountered in application scenarios. As the investigation is empirical, we evaluate CF behavior on the hitherto largest number of visual classification datasets, from each of which we construct a representative number of Sequential Learning Tasks (SLTs) in close alignment to previous works on CF. Our results clearly indicate that there is no model that avoids CF for all investigated datasets and SLTs under application conditions. We conclude with a discussion of potential solutions and workarounds to CF, notably for the EWC and IMM models.},
archivePrefix = {arXiv},
arxivId = {1905.08101},
author = {Pf{\"{u}}lb, B. and Gepperth, A.},
eprint = {1905.08101},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pf{\"{u}}lb, Gepperth - 2019 - A comprehensive, application-oriented study of catastrophic forgetting in dnns.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {continual learning,review,survey},
mendeley-tags = {continual learning,review,survey},
number = {c},
pages = {1--14},
title = {{A comprehensive, application-oriented study of catastrophic forgetting in dnns}},
volume = {1},
year = {2019}
}
@article{Askari2017,
abstract = {A data driven Fuzzy Inference System (FIS) employs Membership Functions (MFs) with adjustable parameters in its IF part to fuzzify the input data. The input space is partitioned simply by dividing universe of discourse of each input variable into some fuzzy subspaces. The MFs are then defined on the fuzzy subspaces of the input variables. Parameters of the MFs are tuned for maximum accuracy of the system (which demands high runtime) without considering the data structure which impairs interpretability of the FIS and degenerates the system into a black-box tool. Such a FIS does not represent actual structure of the data and its MFs are not necessarily in accord with the data distribution in the input space. In addition, the FIS suffers from exponential complexity of order O(Tr) where T is number of linguistic terms (number of subspaces on the universe of discourse of input variables) and r is number of input variables. This article presents a novel Multiple-Input and Multiple-Output Clustering based Fuzzy Inference System (MIMO CFIS) which is made directly from a class of fuzzy clustering algorithms to overcome these shortcomings. CFIS identifies dense regions of the input data using fuzzy clustering and then places a cluster on each of these regions. These fuzzy clusters represent actual structure of the data and serve as fuzzy rules in the rule base of CFIS and provide MFs that exactly fit the dense regions of the data that makes the system more interpretable and avoids redundant rules. These MFs are normal, convex, and continuous and have no parameter to be tuned (which makes CFIS much faster than other FISs) and fuzzify the input data according to their membership in the clusters. THEN part of CFIS is generalized form of THEN part of Takagi-Sugeno (TS) fuzzy system which accommodates any function of input variables. Despite less number of adjustable parameters, testing error of CFIS is less than that of TS system and its modified versions. Moreover, number of fuzzy rules in CFIS rule base is the same as the number of linguistic terms (or fuzzy clusters) and consequently its complexity is of orderO(T). Also, CFIS is a MIMO system and avoids inconsistent (contradictory) rules by generating well-separated fuzzy clusters whereas TS system is MISO and never guarantees generation of consistent rules. In addition, CFIS satisfies most of the interpretability criteria of FISs.},
author = {Askari, S.},
doi = {10.1016/j.eswa.2017.04.045},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Askari - 2017 - A novel and fast MIMO fuzzy inference system based on a class of fuzzy clustering algorithms with interpretability and c.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Classification,Complexity,Fuzzy clustering,Fuzzy systems,Interpretability,Regression,TS fuzzy system},
pages = {301--322},
publisher = {Elsevier Ltd},
title = {{A novel and fast MIMO fuzzy inference system based on a class of fuzzy clustering algorithms with interpretability and complexity analysis}},
url = {http://dx.doi.org/10.1016/j.eswa.2017.04.045},
volume = {84},
year = {2017}
}
@inproceedings{Xiao2020,
abstract = {Recent self-supervised contrastive methods have been able to produce impressive transferable visual representations by learning to be invariant to different data augmentations. However, these methods implicitly assume a particular set of representational invariances (e.g., invariance to color), and can perform poorly when a downstream task violates this assumption (e.g., distinguishing red vs. yellow cars). We introduce a contrastive learning framework which does not require prior knowledge of specific, task-dependent invariances. Our model learns to capture varying and invariant factors for visual representations by constructing separate embedding spaces, each of which is invariant to all but one augmentation. We use a multi-head network with a shared backbone which captures information across each augmentation and alone outperforms all baselines on downstream tasks. We further find that the concatenation of the invariant and varying spaces performs best across all tasks we investigate, including coarse-grained, fine-grained, and few-shot downstream classification tasks, and various data corruptions.},
archivePrefix = {arXiv},
arxivId = {2008.05659},
author = {Xiao, Tete and Wang, Xiaolong and Efros, Alexei A. and Darrell, Trevor},
booktitle = {Iclr 2021},
eprint = {2008.05659},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xiao et al. - 2020 - What should not be contrastive in contrastive learning.pdf:pdf},
issn = {23318422},
keywords = {contrastive learning,self-supervised learning},
mendeley-tags = {contrastive learning,self-supervised learning},
pages = {1--11},
title = {{What should not be contrastive in contrastive learning}},
year = {2020}
}
@article{Xiong2020,
abstract = {One fundamental problem in deep learning is understanding the outstanding performance of deep Neural Networks (NNs) in practice. One explanation for the superiority of NNs is that they can realize a large class of complicated functions, i.e., they have powerful expressivity. The expressivity of a ReLU NN can be quantified by the maximal number of linear regions it can separate its input space into. In this paper, we provide several mathematical results needed for studying the linear regions of CNNs, and use them to derive the maximal and average numbers of linear regions for one-layer ReLU CNNs. Furthermore, we obtain upper and lower bounds for the number of linear regions of multi-layer ReLU CNNs. Our results suggest that deeper CNNs have more powerful expressivity than their shallow counterparts, while CNNs have more expressivity than fully-connected NNs per parameter.},
archivePrefix = {arXiv},
arxivId = {2006.00978},
author = {Xiong, Huan and Huang, Lei and Yu, Mengyang and Liu, Li and Zhu, Fan and Shao, Ling},
eprint = {2006.00978},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xiong et al. - 2020 - On the Number of Linear Regions of Convolutional Neural Networks.pdf:pdf},
journal = {arXiv},
month = {jun},
title = {{On the Number of Linear Regions of Convolutional Neural Networks}},
url = {http://arxiv.org/abs/2006.00978},
year = {2020}
}
@inproceedings{The2021,
abstract = {The ability to learn continually without forgetting the past tasks is a desired attribute for artificial learning systems. Existing approaches to enable such learning in artificial neural networks usually rely on network growth, importance based weight update or replay of old data from the memory. In contrast, we propose a novel approach where a neural network learns new tasks by taking gradient steps in the orthogonal direction to the gradient subspaces deemed important for the past tasks. We find the bases of these subspaces by analyzing network representations (activations) after learning each task with Singular Value Decomposition (SVD) in a single shot manner and store them in the memory as Gradient Projection Memory (GPM). With qualitative and quantitative analyses, we show that such orthogonal gradient decent induces minimum to no interference with the past tasks, thereby mitigating forgetting. We evaluate our algorithm on diverse image classification datasets with short and long sequences of tasks and report better or on-par performance compared to the state-of-the-art approaches.},
author = {The, Bstract and Decomposition, Singular Value and Pro-, Gradient and Humans, Ntroduction and Networks, Neural and Learning, Continual and Forgetting, Catastrophic and Interference, Catastrophic},
booktitle = {Iclr},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/The et al. - 2021 - Gradient projection memory for contiunal learning.pdf:pdf},
keywords = {continual learning,optimization,orthogonal gradient descent,regularization},
mendeley-tags = {continual learning,optimization,orthogonal gradient descent,regularization},
number = {2020},
pages = {1--18},
title = {{Gradient projection memory for contiunal learning}},
year = {2021}
}
@article{Fionda2013,
abstract = {Mixed multi-unit combinatorial auctions (MMUCAs) are extensions of classical combinatorial auctions (CAs) where bidders trade transformations of goods rather than just sets of goods. Solving MMUCAs, i.e., determining the sequences of bids to be accepted by the auctioneer, is computationally intractable in general. However, differently from classical combinatorial auctions, little was known about whether polynomial-time solvable classes of MMUCAs can be singled out on the basis of their characteristics. The paper fills this gap, by studying the computational complexity of MMUCA instances under structural and qualitative restrictions, which characterize interactions among bidders and types of bids involved in the various transformations, respectively. {\textcopyright} 2013 Elsevier B.V.},
author = {Fionda, Valeria and Greco, Gianluigi},
doi = {10.1016/j.artint.2012.12.002},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fionda, Greco - 2013 - The complexity of mixed multi-unit combinatorial auctions Tractability under structural and qualitative restricti.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {Computational complexity,Mixed multi-unit combinatorial auctions,Structural decomposition methods},
pages = {1--25},
publisher = {Elsevier B.V.},
title = {{The complexity of mixed multi-unit combinatorial auctions: Tractability under structural and qualitative restrictions}},
url = {http://dx.doi.org/10.1016/j.artint.2012.12.002},
volume = {196},
year = {2013}
}
@article{Fixler2014,
abstract = {In this paper we report the optical properties of fluorescein-conjugated gold nanoparticles (GNPs) in solid phantoms using diffusion reflection (DR) and fluorescence lifetime imaging microscopy (FLIM). The GNPs attached with fluorescein in solution were studied by fluorescence correlation spectroscopy. The intensity decays were recorded to reveal the fluorescence lifetime of fluorescein while in the near-field vicinity of the GNPs. The DR method was used to explore the solid phantoms containing GNPs, indicating the light propagation from the surface of solid phantoms. The resulting DR slopes of the reflected intensity showed the higher the GNP concentration, the bigger the slope. Fluorescence intensity, lifetime, and anisotropy images of solid phantoms were investigated by FLIM. The exploration of optical properties and molecular imaging combined with DR and FLIM methods is a new approach that has not been established until now. The combined DR–FLIM technique is expected to provide discrimination based on...},
author = {Fixler, Dror and Nayhoz, Tsviya and Ray, Krishanu},
doi = {10.1021/ph500214m},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fixler, Nayhoz, Ray - 2014 - Diffusion Reflection and Fluorescence Lifetime Imaging Microscopy Study of Fluorophore-Conjugated Gold Nano.pdf:pdf},
issn = {23304022},
journal = {ACS Photonics},
keywords = {biomolecular imaging,diffusion reflection,fluorescence anisotropy,fluorescence lifetime imaging,gold nanoparticles,noninvasive detection},
number = {9},
pages = {900--905},
pmid = {25541621},
title = {{Diffusion Reflection and Fluorescence Lifetime Imaging Microscopy Study of Fluorophore-Conjugated Gold Nanoparticles or Nanorods in Solid Phantoms}},
volume = {1},
year = {2014}
}
@misc{Shirane1952d,
author = {Shirane, G. and Susuki, K},
booktitle = {J. Phys. Soc. Japan},
doi = {10.1143/JPSJ.7.333},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shirane, Susuki - 1952 - Crystal structure of PZT.pdf:pdf},
issn = {0031-9015},
pages = {333},
title = {{Crystal structure of PZT}},
volume = {7},
year = {1952}
}
@article{Al-Shedivat2021,
abstract = {Meta-learning has enabled learning statistical models that can be quickly adapted to new prediction tasks. Motivated by use-cases in personalized federated learning, we study the often overlooked aspect of the modern meta-learning algorithms -- their data efficiency. To shed more light on which methods are more efficient, we use techniques from algorithmic stability to derive bounds on the transfer risk that have important practical implications, indicating how much supervision is needed and how it must be allocated for each method to attain the desired level of generalization. Further, we introduce a new simple framework for evaluating meta-learning methods under a limit on the available supervision, conduct an empirical study of MAML, Reptile, and Protonets, and demonstrate the differences in the behavior of these methods on few-shot and federated learning benchmarks. Finally, we propose active meta-learning, which incorporates active data selection into learning-to-learn, leading to better performance of all methods in the limited supervision regime.},
archivePrefix = {arXiv},
arxivId = {2102.00127},
author = {Al-Shedivat, Maruan and Li, Liam and Xing, Eric and Talwalkar, Ameet},
eprint = {2102.00127},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Al-Shedivat et al. - 2021 - On Data Efficiency of Meta-learning.pdf:pdf},
keywords = {active learning,data efficiency,meta-learning},
mendeley-tags = {active learning,data efficiency,meta-learning},
title = {{On Data Efficiency of Meta-learning}},
url = {http://arxiv.org/abs/2102.00127},
year = {2021}
}
@article{Rolnick2019,
abstract = {Interacting with a complex world involves continual learning, in which tasks and data distributions change over time. A continual learning system should demonstrate both plasticity (acquisition of new knowledge) and stability (preservation of old knowledge). Catastrophic forgetting is the failure of stability, in which new experience overwrites previous experience. In the brain, replay of past experience is widely believed to reduce forgetting, yet it has been largely overlooked as a solution to forgetting in deep reinforcement learning. Here, we introduce CLEAR, a replay-based method that greatly reduces catastrophic forgetting in multi-task reinforcement learning. CLEAR leverages off-policy learning and behavioral cloning from replay to enhance stability, as well as on-policy learning to preserve plasticity. We show that CLEAR performs better than state-of-the-art deep learning techniques for mitigating forgetting, despite being significantly less complicated and not requiring any knowledge of the individual tasks being learned.},
archivePrefix = {arXiv},
arxivId = {1811.11682},
author = {Rolnick, David and Ahuja, Arun and Schwarz, Jonathan and Lillicrap, Timothy P. and Wayne, Greg},
eprint = {1811.11682},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rolnick et al. - 2019 - Experience replay for continual learning.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {NeurIPS},
title = {{Experience replay for continual learning}},
volume = {32},
year = {2019}
}
@article{Combustion2015,
abstract = {Complete Combustion • Complete combustion reacts oxygen with a fuel to produce carbon dioxide and water. Eg: 2C 8 H 18 + 25O 2  18CO 2 + 16H 2 0 • Because the air we breathe is only 21% oxygen, a large volume of air is required for complete combustion to take place.},
author = {Combustion, Complete},
doi = {10.1093/bjaceaccp/mkt021},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Combustion - 2015 - Complete vs . Incomplete Combustion.pdf:pdf},
pages = {1--7},
title = {{Complete vs . Incomplete Combustion}},
year = {2015}
}
@article{Lelis2013,
abstract = {Korf, Reid and Edelkamp initiated a line of research for developing methods (KRE and later CDP) that predict the number of nodes expanded by IDA* for a given start state and cost bound. Independently, Chen developed a method (SS) that can also be used to predict the number of nodes expanded by IDA*. In this paper we improve both of these prediction methods. First, we present {\"{I}}$\mu$-truncation, a method that acts as a preprocessing step and improves CDP{\^{E}}s prediction accuracy. Second and orthogonally to {\"{I}}$\mu$- truncation, we present a variant of CDP that can be orders of magnitude faster than CDP while producing exactly the same predictions. Third, we show how ideas developed in the KRE line of research can be used to improve the predictions produced by SS. Finally, we make an empirical comparison between our new enhanced versions of CDP and SS. Our experimental results suggest that CDP is suitable for applications that require less accurate but fast predictions, while SS is suitable for applications that require more accurate predictions but can afford more computation time. {\textcopyright} 2013 Elsevier B.V.},
author = {Lelis, Levi H.S. and Zilles, Sandra and Holte, Robert C.},
doi = {10.1016/j.artint.2013.01.001},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lelis, Zilles, Holte - 2013 - Predicting the size of IDA{\^{E}}s search tree.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {Heuristic search,Predicting search performance},
pages = {53--76},
publisher = {Elsevier B.V.},
title = {{Predicting the size of IDA*{\^{E}}s search tree}},
url = {http://dx.doi.org/10.1016/j.artint.2013.01.001},
volume = {196},
year = {2013}
}
@article{Engines,
author = {Engines, Heat},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Engines - Unknown - Department of energy engineering.pdf:pdf},
title = {{Department of energy engineering}}
}
@article{Gunawan2011a,
author = {Gunawan, Dodo and Linarka, Utoyo Ajie},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gunawan, Linarka - 2011 - Penentuan prediktor untuk prediksi curah hujan bulanan menggunakan metode statistical dynamical downscaling.pdf:pdf},
journal = {Jurnal Meteorologi dan Geofisika},
keywords = {dynamical downscaling,singular value decompisition,statistical downscaling},
number = {1},
pages = {93--102},
title = {{Penentuan prediktor untuk prediksi curah hujan bulanan menggunakan metode statistical dynamical downscaling}},
volume = {12},
year = {2011}
}
@article{Yao2014,
abstract = {Recently, antireflective coatings (ARCs) with self-cleaning properties have attracted significant attention for both their fundamental aspects and wide practical applications. In the current review, the basic principles of antireflection and self-cleaning are briefly discussed first. Then, fabrication strategies with particular emphasis on silicon and silica substrates are reviewed in detail. Meanwhile, ARCs and self-cleaning coatings on polymer and metal foil are also briefly described. Afterwards, progresses in antireflective self-cleaning coatings and some multifunctional ARCs in the latest five years are presented in detail. The applications of ARCs are discussed in terms of architectural glasses, solar collectors, photovoltaic modules, and display devices. Finally, current challenges faced in practical applications and the trend of future development are presented and discussed to facilitate a universal understanding of ARCs and self-cleaning coatings. {\textcopyright} 2013 Elsevier Ltd. All rights reserved.},
author = {Yao, Lin and He, Junhui},
doi = {10.1016/j.pmatsci.2013.12.003},
isbn = {0079-6425},
issn = {00796425},
journal = {Progress in Materials Science},
pages = {94--143},
publisher = {Elsevier Ltd},
title = {{Recent progress in antireflection and self-cleaning technology - From surface engineering to functional surfaces}},
url = {http://dx.doi.org/10.1016/j.pmatsci.2013.12.003},
volume = {61},
year = {2014}
}
@book{Aliev2014,
author = {Aliev, Aziz and Guirimov, Babek Ghalib},
isbn = {9783319090719},
pages = {203},
publisher = {Springer International Publishing Switzerland},
title = {{Type-2 Fuzzy Neural Networks and Their Applications}},
year = {2014}
}
@article{Shrivastava2016,
abstract = {A proton exchange membrane fuel cell (PEMFC) was segmented to measure local current density, electrochemical surface area, and high frequency resistance (HFR) distribution in the land-channel direction at resolution of 350 $\mu$m. An in-house catalyst coated membrane of 3 mm × 3 mm active area was prepared to represent a small area in a larger scale cell with 1 mm land and channel widths. This design was employed to measure current density and HFR distribution at 60°C with several different operating conditions. Local electrical resistance was also measured separately so that local protonic resistances can be discerned from local HFR. To analyze the effect of the land-channel geometry a method was developed to quantify the sources of current distribution, such as distributions of oxygen concentration at the electrode, oxygen transport resistance, cathode catalyst layer resistance, and membrane water content. Current density distribution is strongly correlated with the distribution of membrane water content and electrode resistance in dry condition, and oxygen concentration distribution in wet condition, while in moderate condition both oxygen concentration and water content in membrane are critical to the local current density distribution. The results imply the limitation of uniform condition assumption used in a differential cell study.},
author = {Shrivastava, Udit N. and Tajiri, Kazuya},
doi = {10.1149/2.0831609jes},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shrivastava, Tajiri - 2016 - Sources of Current Density Distribution in the Land-Channel Direction of a PEMFC.pdf:pdf},
issn = {0013-4651},
journal = {Journal of The Electrochemical Society},
number = {9},
pages = {F1072--F1083},
title = {{Sources of Current Density Distribution in the Land-Channel Direction of a PEMFC}},
url = {http://jes.ecsdl.org/lookup/doi/10.1149/2.0831609jes},
volume = {163},
year = {2016}
}
@article{StanleyRaj2017,
abstract = {Rainfall is one of the most complex phenomenons occurring on earth to study with extreme and advanced soft computing engine that can perform well with adaptive perception. Water table depth is more or less proportionate to the rainfall occurring on the study area. Some other factors involved in it are climate change, soil characteristics and human activities. Here in this research, an attempt has been made to study the behaviour of rainfall in Kanyakumari district, Tamil Nadu, India. The study region is one of the most agricultural favourable climatic districts with large area of cultivating lands. Unlike the other districts in Tamil Nadu, this district gets rainfall from both south west and north east monsoons. For this analysis, wavelet tool has been used. Apart from analysing it, short term forecasting has been attempted with efficient soft computing tool, Artificial Neural Networks (ANN). This method has been validated with the actual water table depth with respect to the rainfall. This approach applied to the data works well for short term forecasting. The performance of the model was evaluated using the regression coefficients and Mean Absolute Percent Error (MAPE) reveals the success of the working integrated model.},
author = {{Stanley Raj}, A. and {Hudson Oliver}, D. and Srinivas, Y. and Viswanath, J.},
doi = {10.1016/j.gsd.2017.06.009},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stanley Raj et al. - 2017 - Wavelet based analysis on rainfall and water table depth forecasting using Neural Networks in Kanyakumari di.pdf:pdf},
issn = {2352801X},
journal = {Groundwater for Sustainable Development},
keywords = {Neural Networks forecasting,Rainfall,Water table depth model,Wavelet analysis},
number = {April 2016},
pages = {178--186},
publisher = {Elsevier},
title = {{Wavelet based analysis on rainfall and water table depth forecasting using Neural Networks in Kanyakumari district, Tamil Nadu, India}},
url = {http://dx.doi.org/10.1016/j.gsd.2017.06.009},
volume = {5},
year = {2017}
}
@article{Sui2017,
abstract = {The strain-induced softening of thermoplastic polyurethane elastomers (TPUs), known as the Mullins effect, arises from their multi-phase structure. We used the combination of small-and wide-angle X-ray scattering (SAXS/WAXS) during in situ repeated tensile loading to elucidate the relationship between molecular architecture, nano-strain, and macro-scale mechanical properties. Insights obtained from our analysis highlight the importance of the 'fuzzy interface' between the hard and soft regions that governs the structure evolution at nanometre length scales and leads to macroscopic stiffness reduction. We propose a hierarchical Eshelby inclusion model of phase interaction mediated by the 'fuzzy interface' that accommodates the nano-strain gradient between hard and soft regions and undergoes tension-induced softening, causing the Mullins effect that becomes apparent in TPUs even at moderate tensile strains. Thermoplastic polyurethane (TPU) elastomers are versatile polymer materials that find numerous applications due to the outstanding combination of thermal and mechanical properties. TPUs are block co-polymers that have the morphology of nano-composites consisting of hard regions embedded within contiguous soft regions, with nano-scale gradient transitions between them that are structurally accommodated by the " fuzzy interface " regions 1, 2},
author = {Sui, T. and Salvati, E. and Ying, S. and Sun, G. and Dolbnya, I. P. and Dragnevski, K. and Prisacariu, C. and Korsunsky, A. M.},
doi = {10.1038/s41598-017-00904-3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sui et al. - 2017 - Strain softening of nano-scale fuzzy interfaces causes Mullins effect in thermoplastic polyurethane.pdf:pdf},
issn = {20452322},
journal = {Scientific Reports},
number = {1},
pages = {1--9},
publisher = {Springer US},
title = {{Strain softening of nano-scale fuzzy interfaces causes Mullins effect in thermoplastic polyurethane}},
url = {http://dx.doi.org/10.1038/s41598-017-00904-3},
volume = {7},
year = {2017}
}
@article{Vimala2014,
abstract = {Prediction of significant wave heights (Hs) is of immense importance in ocean and coastal engineering applications. The aim of this study is to predict significant wave height values at buoy locations with the lead time of 3,6,12 and 24 hours using past observations of wind and wave parameters applying Artificial Neural Network. Although there exists a number of wave height estimation models, they do not consider all causative factors without any approximation and consequently their results are more or less a general approximation of the overall dynamic behaviour. Since soft computing techniques are totally data driven, based on the duration of the data availability they can be used for prediction. In the National data buoy program of National institute of Ocean Technology, not all the buoys have wind sensors and wave sensors and so it is attempted to apply neural network algorithms for prediction of wave heights using wind speed only as the input and then using only wave height as the input. The measurement made by the data buoy at DS3 location in Bay of Bengal (12°11'21"N and 90°43'33"E) are considered, for the period 2003 - 2004. Out of this, the data of period Jan 2003-Dec 2003 was used for training and the data for the period July 2004- Nov 2004 is used for testing. Real time wave forecasting for 3,6,12 and 24 hours were carried out for a month at the location chosen and the results show that the ANN technique proves encouraging for wave forecasting. Performance of ANN for varying inputs have been analysed and the results are discussed.},
author = {Vimala, J. and Latha, G. and Venkatesan, R.},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vimala, Latha, Venkatesan - 2014 - Real Time wave forecasting using artificial neural network with varying input parameter.pdf:pdf},
issn = {03795136},
journal = {Indian Journal of Marine Sciences},
keywords = {ANN,Computational elements,Correlation coefficient,Neural network,Wave Forecasting},
number = {1},
pages = {82--87},
title = {{Real Time wave forecasting using artificial neural network with varying input parameter}},
volume = {43},
year = {2014}
}
@article{Keshav,
archivePrefix = {arXiv},
arxivId = {quant-ph/0703255},
author = {Keshav, S.},
eprint = {0703255},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Keshav - Unknown - How to Read a Paper S.pdf:pdf},
isbn = {978-1-7281-7539-3},
issn = {1364-0321},
pmid = {25246403},
primaryClass = {quant-ph},
title = {{How to Read a Paper S.}}
}
@book{Uchino2017b,
abstract = {Piezocomposites composed of a piezoelectric ceramic and a polymer are promising materials because of their excellent tailorable properties. The geometry for two-phase composites can be classified according to the connectivity of each phase (1-, 2-, or 3-dimensionally) into 10 structures. In particular, a 1-3 piezocomposite (PZT-rod/polymer-matrix composite) is considered most useful. The advantages of this composite are high coupling factors, low acoustic impedance, good matching to water or human tissue, mechanical flexibility, and broad bandwidth in combination with a low mechanical quality factor. Piezoelectric composite materials are especially useful for underwater sonar and medical diagnostic ultrasonic transducer applications. Other types of composites based on piezoelectric ceramics are also introduced in this chapter. Piezoelectric passive dampers comprise a piezoelectric ceramic particle, polymer, and a carbon black, which suppress the noise vibration more effectively than traditional rubbers. A composite with a magnetostrictive ceramic and a piezoelectric ceramic produces an intriguing product effect—the magnetoelectric effect in which an electric field is produced in the material in response to an applied magnetic field.},
author = {Uchino, K.},
booktitle = {Advanced Piezoelectric Materials},
doi = {10.1016/B978-0-08-102135-4.00009-6},
edition = {2},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Uchino - 2017 - Piezoelectric Composite Materials.pdf:pdf},
isbn = {9780081021354},
keywords = {Combination effect,Magnetoelectric composite.,PZT-polymer composite,Phase connectivity,Piezoelectric composite,Piezoelectric damper,Piezoelectric energy harvesting,Product effect,Sum effect,combination,effect,energy harvesting,magnetoelectric composite,phase connectivity,piezoelectric,piezoelectric composite,piezoelectric damper,product effect,pzt-polymer composite,sum effect},
pages = {353--382},
publisher = {Elsevier Ltd.},
title = {{Piezoelectric Composite Materials}},
url = {http://linkinghub.elsevier.com/retrieve/pii/B9780081021354000096},
year = {2017}
}
@book{Uchino2010c,
abstract = {Piezoelectric materials produce electric charges on their surfaces as a consequence of applying mechanical stress. They are used in the fabrication of a growing range of devices such as transducers (used, for example, in ultrasound scanning), actuators (deployed in such areas as vibration suppression in optical and microelectronic engineering), pressure sensor devices (such as gyroscopes) and increasingly as a way of producing energy. Their versatility has led to a wealth of research to broaden the range of piezoelectric materials and their potential uses. Advanced piezoelectric materials: science and technology provides a comprehensive review of these new materials, their properties, methods of manufacture and applications. After an introductory overview of the development of piezoelectric materials, Part one reviews the various types of piezoelectric material, ranging from lead zirconate titanate (PZT) piezo-ceramics, relaxor ferroelectric ceramics, lead-free piezo-ceramics, quartz-based piezoelectric materials, the use of lithium niobate and lithium in piezoelectrics, single crystal piezoelectric materials, electroactive polymers (EAP) and piezoelectric composite materials. Part two discusses how to design and fabricate piezo-materials with chapters on piezo-ceramics, single crystal preparation techniques, thin film technologies, aerosol techniques and manufacturing technologies for piezoelectric transducers. The final part of the book looks at applications such as high-power piezoelectric materials and actuators as well as the performance of piezoelectric materials under stress. With its distinguished editor and international team of expert contributors Advanced piezoelectric materials: science and technology is a standard reference for all those researching piezoelectric materials and using them to develop new devices in such areas as microelectronics, optical, sound, structural and biomedical engineering.},
author = {Uchino, K.},
booktitle = {Woodhead Publishing Series in Electronic and Optical Materials},
doi = {10.1533/9781845699758.frontmatter},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Uchino - 2010 - Advanced Piezoelectric Materials.pdf:pdf},
isbn = {978-1-84569-534-7},
issn = {00135127},
pages = {i--iii},
title = {{Advanced Piezoelectric Materials}},
url = {http://linkinghub.elsevier.com/retrieve/pii/B9781845695347500194},
volume = {9},
year = {2010}
}
@article{C2017,
author = {C, Manjunath Patel G and Shettigar, Arun Kumar and Krishna, Prasad and Parappagoudar, Mahesh B},
doi = {10.1016/j.asoc.2017.06.018},
issn = {1568-4946},
journal = {Applied Soft Computing Journal},
publisher = {Elsevier B.V.},
title = {{Back Propagation Genetic and Recurrent Neural Network Applications in Modelling and Analysis of Squeeze Casting Process}},
url = {http://dx.doi.org/10.1016/j.asoc.2017.06.018},
year = {2017}
}
@article{Misra2019a,
abstract = {The concept of non-linearity in a Neural Network is introduced by an activation function which serves an integral role in the training and performance evaluation of the network. Over the years of theoretical research, many activation functions have been proposed, however, only a few are widely used in mostly all applications which include ReLU (Rectified Linear Unit), TanH (Tan Hyperbolic), Sigmoid, Leaky ReLU and Swish. In this work, a novel neural activation function called as Mish is proposed. The experiments show that Mish tends to work better than both ReLU and Swish along with other standard activation functions in many deep networks across challenging datasets. For instance, in Squeeze Excite Net- 18 for CIFAR 100 classification, the network with Mish had an increase in Top-1 test accuracy by 0.494% and 1.671% as compared to the same network with Swish and ReLU respectively. The similarity to Swish along with providing a boost in performance and its simplicity in implementation makes it easier for researchers and developers to use Mish in their Neural Network Models.},
archivePrefix = {arXiv},
arxivId = {1908.08681},
author = {Misra, Diganta},
eprint = {1908.08681},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Misra - 2019 - Mish A Self Regularized Non-Monotonic Neural Activation Function.pdf:pdf},
number = {1},
title = {{Mish: A Self Regularized Non-Monotonic Neural Activation Function}},
url = {http://arxiv.org/abs/1908.08681},
year = {2019}
}
@article{Karpathy2017a,
abstract = {We present a model that generates natural language de- scriptions ofimages and their regions. Our approach lever- ages datasets of images and their sentence descriptions to learn about the inter-modal correspondences between lan- guage and visual data. Our alignment model is based on a novel combination ofConvolutional Neural Networks over image regions, bidirectional Recurrent Neural Networks over sentences, and a structured objective that aligns the two modalities through a multimodal embedding. We then describe a Multimodal Recurrent Neural Network architec- ture that uses the inferred alignments to learn to generate novel descriptions of image regions. We demonstrate that our alignment model produces state ofthe art results in re- trieval experiments on Flickr8K, Flickr30K and MSCOCO datasets. We then show that the generated descriptions sig- nificantly outperform retrieval baselines on both full images and on a new dataset ofregion-level annotations},
author = {Karpathy, Andrej and Fei-Fei, Li},
doi = {10.1109/TPAMI.2016.2598339},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Karpathy, Fei-Fei - 2017 - Deep Visual-Semantic Alignments for Generating Image Descriptions.pdf:pdf},
isbn = {9781316569290},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
month = {apr},
number = {4},
pages = {664--676},
publisher = {Cambridge University Press},
title = {{Deep Visual-Semantic Alignments for Generating Image Descriptions}},
url = {https://www.cambridge.org/core/product/identifier/9781316569290%23CN-bp-11/type/book_part http://ieeexplore.ieee.org/document/7534740/},
volume = {39},
year = {2017}
}
@article{Li2018b,
abstract = {In this paper, we propose a novel face detection network with three novel contributions that address three key aspects of face detection, including better feature learning, progressive loss design and anchor assign based data augmentation, respectively. First, we propose a Feature Enhance Module (FEM) for enhancing the original feature maps to extend the single shot detector to dual shot detector. Second, we adopt Progressive Anchor Loss (PAL) computed by two different sets of anchors to effectively facilitate the features. Third, we use an Improved Anchor Matching (IAM) by integrating novel anchor assign strategy into data augmentation to provide better initialization for the regressor. Since these techniques are all related to the two-stream design, we name the proposed network as Dual Shot Face Detector (DSFD). Extensive experiments on popular benchmarks, WIDER FACE and FDDB, demonstrate the superiority of DSFD over the state-of-the-art face detectors.},
archivePrefix = {arXiv},
arxivId = {1810.10220},
author = {Li, Jian and Wang, Yabiao and Wang, Changan and Tai, Ying and Qian, Jianjun and Yang, Jian and Wang, Chengjie and Li, Jilin and Huang, Feiyue},
eprint = {1810.10220},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2018 - DSFD Dual Shot Face Detector.pdf:pdf},
title = {{DSFD: Dual Shot Face Detector}},
url = {http://arxiv.org/abs/1810.10220},
year = {2018}
}
@article{Xiao2019,
abstract = {A fundamental goal in deep learning is the characterization of trainability and generalization of neural networks as a function of their architecture and hyperparameters. In this paper, we discuss these challenging issues in the context of wide neural networks at large depths where we will see that the situation simplifies considerably. To do this, we leverage recent advances that have separately shown: (1) that in the wide network limit, random networks before training are Gaussian Processes governed by a kernel known as the Neural Network Gaussian Process (NNGP) kernel, (2) that at large depths the spectrum of the NNGP kernel simplifies considerably and becomes "weakly data-dependent", and (3) that gradient descent training of wide neural networks is described by a kernel called the Neural Tangent Kernel (NTK) that is related to the NNGP. Here we show that in the large depth limit the spectrum of the NTK simplifies in much the same way as that of the NNGP kernel. By analyzing this spectrum, we arrive at a precise characterization of trainability and a necessary condition for generalization across a range of architectures including Fully Connected Networks (FCNs) and Convolutional Neural Networks (CNNs). In particular, we find that there are large regions of hyperparameter space where networks can only memorize the training set in the sense they reach perfect training accuracy but completely fail to generalize outside the training set, in contrast with several recent results. By comparing CNNs with-A nd without-global average pooling, we show that CNNs without average pooling have very nearly identical learning dynamics to FCNs while CNNs with pooling contain a correction that alters its generalization performance. We perform a thorough empirical investigation of these theoretical results and finding excellent agreement on real datasets.},
archivePrefix = {arXiv},
arxivId = {arXiv:1912.13053v2},
author = {Xiao, Lechao and Pennington, Jeffrey and Schoenholz, Samuel S.},
eprint = {arXiv:1912.13053v2},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xiao, Pennington, Schoenholz - 2019 - Disentangling trainability and generalization in deep learning.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {generalization,theory,trainability},
mendeley-tags = {generalization,theory,trainability},
title = {{Disentangling trainability and generalization in deep learning}},
year = {2019}
}
@article{Liu2007a,
abstract = {An analytical decoupling control method is proposed for multiple-input-multiple-output (MIMO) processes with multiple time delays. The desired diagonal system transfer matrix is proposed first in terms of the H2optimal performance specification, resulting in the ideal desired decoupling controller matrix derived within the framework of a unity feedback control structure. It is demonstrated that dead-time compensators must be enclosed in the decoupling controller matrix to realize absolute decoupling for MIMO processes with multiple time delays. To alleviate the difficulties associated with the implementation, the ideal desired decoupling controller matrix is transformed into a practical form using an analytical approximation approach. Correspondingly, the stability of the resultant control system is assessed, together with its robust stability in the presence of process uncertainties. An on-line tuning rule for the single adjustable parameter of each column controllers in the decoupling controller matrix is given to cope with the process unmodeled dynamics. Finally, illustrative examples are given to show the superiority of the proposed method over the recently improved decoupling control methods. {\textcopyright} 2006 Elsevier Ltd. All rights reserved.},
author = {Liu, Tao and Zhang, Weidong and Gao, Furong},
doi = {10.1016/j.jprocont.2006.08.010},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu, Zhang, Gao - 2007 - Analytical decoupling control strategy using a unity feedback control structure for MIMO processes with time de.pdf:pdf},
issn = {09591524},
journal = {Journal of Process Control},
keywords = {Analytical approximation,Decoupling,H2optimal performance specification,MIMO process,Robust stability,Time delay},
number = {2},
pages = {173--186},
title = {{Analytical decoupling control strategy using a unity feedback control structure for MIMO processes with time delays}},
volume = {17},
year = {2007}
}
@article{Alaoui-elfels2021,
author = {Alaoui-elfels, Omaima El and Gadi, Taoufiq},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alaoui-elfels, Gadi - 2021 - From Auto-encoders to Capsule Networks A Survey.pdf:pdf},
keywords = {Auto-encoders,Capsule Networks,Convolutional Neural Networks,Deep Learning.,EM Routing,Routing by Agreement Between Capsules,Stacked Capsule Network,a very powerful deep,auto-encoders,capsule networks,capsules,convolutional neural networks,convolutional neural networks are,deep learning,em routing,image processing,learning structure used in,neural networks,review,routing by agreement between,stacked capsule network,survey},
mendeley-tags = {capsule networks,deep learning,neural networks,review,survey},
title = {{From Auto-encoders to Capsule Networks : A Survey}},
volume = {01003},
year = {2021}
}
@article{Walid2012a,
author = {Walid, Problems and Atomi, Hasen},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Walid, Atomi - 2012 - the Effect of Data Preprocessing on the Performance of Artificial Neural Networks Techniques for Classification.pdf:pdf},
title = {{the Effect of Data Preprocessing on the Performance of Artificial Neural Networks Techniques for Classification}},
url = {http://eprints.uthm.edu.my/3635/1/WALID_HASEN_ATOMI.pdf},
year = {2012}
}
@article{Puchkin2020,
abstract = {Prediction for high dimensional time series is a challenging task due to the curse of dimensionality problem. Classical parametric models like ARIMA or VAR require strong modeling assumptions and time stationarity and are often overparametrized. This paper offers a new flexible approach using recent ideas of manifold learning. The considered model includes linear models such as the central subspace model and ARIMA as particular cases. The proposed procedure combines manifold denoising techniques with a simple nonparametric prediction by local averaging. The resulting procedure demonstrates a very reasonable performance for real-life econometric time series. We also provide a theoretical justification of the manifold estimation procedure.},
archivePrefix = {arXiv},
arxivId = {2012.08244},
author = {Puchkin, Nikita and Timofeev, Aleksandr and Spokoiny, Vladimir},
eprint = {2012.08244},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Puchkin, Timofeev, Spokoiny - 2020 - Manifold-based time series forecasting.pdf:pdf},
keywords = {chain,ergodic markov,fi-,manifold denoising,manifold learning,non-mixing markov chain,research program,the article was prepared,the hse university basic,time series,time series prediction,within the framework of},
mendeley-tags = {time series},
month = {dec},
number = {19},
title = {{Manifold-based time series forecasting}},
url = {http://arxiv.org/abs/2012.08244 https://github.com/TimofeevAlex/Manifold-based-time-series-forecasting},
year = {2020}
}
@article{Hassan2016a,
abstract = {Type-2 fuzzy logic systems have extensively been applied to various engineering problems, e.g. identification, prediction, control, pattern recognition, etc. in the past two decades, and the results were promising especially in the presence of significant uncertainties in the system. In the design of type-2 fuzzy logic systems, the early applications were realized in a way that both the antecedent and consequent parameters were chosen by the designer with perhaps some inputs from some experts. Since 2000s, a huge number of papers have been published which are based on the adaptation of the parameters of type-2 fuzzy logic systems using the training data either online or offline. Consequently, the major challenge was to design these systems in an optimal way in terms of their optimal structure and their corresponding optimal parameter update rules. In this review, the state of the art of the three major classes of optimization methods are investigated: derivative-based (computational approaches), derivative-free (heuristic methods) and hybrid methods which are the fusion of both the derivative-free and derivative-based methods.},
author = {Hassan, Saima and Khanesar, Mojtaba Ahmadieh and Kayacan, Erdal and Jaafar, Jafreezal and Khosravi, Abbas},
doi = {10.1016/j.asoc.2016.03.023},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hassan et al. - 2016 - Optimal design of adaptive type-2 neuro-fuzzy systems A review.pdf:pdf},
isbn = {1568-4946},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {Genetic algorithms,Hybrid learning,Interval type-2 fuzzy logic systems,Optimal learning algorithm,Parameter update rules,Particle swarm optimization},
pages = {134--143},
publisher = {Elsevier B.V.},
title = {{Optimal design of adaptive type-2 neuro-fuzzy systems: A review}},
url = {http://dx.doi.org/10.1016/j.asoc.2016.03.023},
volume = {44},
year = {2016}
}
@article{Peng2020,
abstract = {Incremental learning requires a model to continually learn new tasks from streaming data. However, traditional fine-tuning of a well-trained deep neural network on a new task will dramatically degrade performance on the old task -- a problem known as catastrophic forgetting. In this paper, we address this issue in the context of anchor-free object detection, which is a new trend in computer vision as it is simple, fast, and flexible. Simply adapting current incremental learning strategies fails on these anchor-free detectors due to lack of consideration of their specific model structures. To deal with the challenges of incremental learning on anchor-free object detectors, we propose a novel incremental learning paradigm called Selective and Inter-related Distillation (SID). In addition, a novel evaluation metric is proposed to better assess the performance of detectors under incremental learning conditions. By selective distilling at the proper locations and further transferring additional instance relation knowledge, our method demonstrates significant advantages on the benchmark datasets PASCAL VOC and COCO.},
archivePrefix = {arXiv},
arxivId = {2012.15439},
author = {Peng, Can and Zhao, Kun and Maksoud, Sam and Li, Meng and Lovell, Brian C.},
eprint = {2012.15439},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Peng et al. - 2020 - SID Incremental Learning for Anchor-Free Object Detection via Selective and Inter-Related Distillation.pdf:pdf},
keywords = {anchor-free,continual learning,incremental learning,object detection},
mendeley-tags = {anchor-free,continual learning,incremental learning,object detection},
title = {{SID: Incremental Learning for Anchor-Free Object Detection via Selective and Inter-Related Distillation}},
url = {http://arxiv.org/abs/2012.15439},
year = {2020}
}
@article{Skladal2016,
abstract = {Progress in the field of piezoelectric (quartz crystal microbalance-based) biosensors in the recent five years is reviewed. In addition to the traditional immunosensing assays, the combination with detection of nucleic acids is addressed, biosensing of microbes and novel applications in the field of cellular biology are highlighted. The signal enhancing strategies based on both biochemical cascades (often involving nanoparticles) and technological improvements of instrumentation are discussed.},
author = {Skl{\'{a}}dal, Petr},
doi = {10.1016/j.trac.2015.12.009},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Skl{\'{a}}dal - 2016 - Piezoelectric biosensors.pdf:pdf},
isbn = {0165-9936},
issn = {18793142},
journal = {TrAC - Trends in Analytical Chemistry},
keywords = {Eukaryotic cellular studies,Immunosensor,Instrumentation for piezosensors,Nucleic acid sensor,Quartz crystal microbalance},
pages = {127--133},
publisher = {Elsevier B.V.},
title = {{Piezoelectric biosensors}},
url = {http://dx.doi.org/10.1016/j.trac.2015.12.009},
volume = {79},
year = {2016}
}
@article{Lyu2020,
abstract = {Rehearsal, seeking to remind the model by storing old knowledge in lifelong learning, is one of the most effective ways to mitigate catastrophic forgetting, i.e., biased forgetting of previous knowledge when moving to new tasks. However, the old tasks of the most previous rehearsal-based methods suffer from the unpredictable domain shift when training the new task. This is because these methods always ignore two significant factors. First, the Data Imbalance between the new task and old tasks that makes the domain of old tasks prone to shift. Second, the Task Isolation among all tasks will make the domain shift toward unpredictable directions; To address the unpredictable domain shift, in this paper, we propose Multi-Domain Multi-Task (MDMT) rehearsal to train the old tasks and new task parallelly and equally to break the isolation among tasks. Specifically, a two-level angular margin loss is proposed to encourage the intra-class/task compactness and inter-class/task discrepancy, which keeps the model from domain chaos. In addition, to further address domain shift of the old tasks, we propose an optional episodic distillation loss on the memory to anchor the knowledge for each old task. Experiments on benchmark datasets validate the proposed approach can effectively mitigate the unpredictable domain shift.},
archivePrefix = {arXiv},
arxivId = {2012.07236},
author = {Lyu, Fan and Wang, Shuai and Feng, Wei and Ye, Zihan and Hu, Fuyuan and Wang, Song},
eprint = {2012.07236},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lyu et al. - 2020 - Multi-Domain Multi-Task Rehearsal for Lifelong Learning.pdf:pdf},
keywords = {continual learning,multi-domain,multi-task},
mendeley-tags = {continual learning,multi-domain,multi-task},
title = {{Multi-Domain Multi-Task Rehearsal for Lifelong Learning}},
url = {http://arxiv.org/abs/2012.07236},
year = {2020}
}
@article{Giordani2016,
abstract = {A fuzzy clustering method for random fuzzy sets is proposed. The starting point is a p-value matrix with elements obtained by comparing the expected values of random fuzzy sets by means of a bootstrap test. As such, the p-value matrix can be viewed as a relational data matrix since the p-values represent a kind of similarity between random fuzzy sets. For this reason, in order to cluster random fuzzy sets, fuzzy clustering techniques for relational data can be applied. In this context, the so-called NE-FRC algorithm is considered. One of the most important advantages of the NE-FRC is that the relational data could not be derived from Euclidean distances. Some simulations are presented to show the behavior of the proposed procedure and two applications to real-life situations are also included.},
author = {Giordani, Paolo and Ramos-Guajardo, Ana Bel{\'{e}}n},
doi = {10.1016/j.fss.2016.02.006},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Giordani, Ramos-Guajardo - 2016 - A fuzzy clustering procedure for random fuzzy sets.pdf:pdf},
isbn = {0165-0114},
issn = {01650114},
journal = {Fuzzy Sets and Systems},
keywords = {Fuzzy clustering,Random fuzzy sets,Relational data},
pages = {54--69},
publisher = {Elsevier B.V.},
title = {{A fuzzy clustering procedure for random fuzzy sets}},
url = {http://dx.doi.org/10.1016/j.fss.2016.02.006},
volume = {305},
year = {2016}
}
@article{Liu2007,
abstract = {In this study, transesterification of soybean oil to biodiesel using SrO as a solid base catalyst was studied. The reaction mechanism was proposed and the separate effects of reaction temperature, molar ratio of methanol to oil, mass ratio of catalyst to oil and repeated experiments were investigated. The results showed that the yield of biodiesel produced with SrO as a catalyst was in excess of 95% at temperatures below 70 °C within 30 min. SrO had a long catalyst lifetime and could maintain sustained activity even after being repeatedly used for 10 cycles. The results proved that transesterification of soybean oil to biodiesel using SrO as a catalyst is a commercially viable way to decrease the costs of biodiesel production. {\textcopyright} 2006 Elsevier B.V. All rights reserved.},
author = {Liu, Xuejun and He, Huayang and Wang, Yujun and Zhu, Shenlin},
doi = {10.1016/j.catcom.2006.10.026},
isbn = {1566-7367},
issn = {15667367},
journal = {Catalysis Communications},
keywords = {Biodiesel,Solid base catalyst,Strontium oxide,Transesterification},
number = {7},
pages = {1107--1111},
pmid = {24812574},
title = {{Transesterification of soybean oil to biodiesel using SrO as a solid base catalyst}},
volume = {8},
year = {2007}
}
@book{Figure,
author = {Figure, Supplementary},
doi = {10.15713/ins.mmj.3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Figure - Unknown - No Title No Title_2015(2).pdf:pdf},
isbn = {9789004310087},
number = {c},
pages = {1--4},
pmid = {29982528},
title = {{No Title No Title_2015}}
}
@article{Chaudhry2020,
abstract = {In continual learning, the learner faces a stream of data whose distribution changes over time. Modern neural networks are known to suffer under this setting, as they quickly forget previously acquired knowledge. To address such catastrophic forgetting, many continual learning methods implement different types of experience replay, re-learning on past data stored in a small buffer known as episodic memory. In this work, we complement experience replay with a new objective that we call “anchoring”, where the learner uses bilevel optimization to update its knowledge on the current task, while keeping intact the predictions on some anchor points of past tasks. These anchor points are learned using gradient-based optimization to maximize forgetting, which is approximated by fine-tuning the currently trained model on the episodic memory of past tasks. Experiments on several supervised learning benchmarks for continual learning demonstrate that our approach improves the standard experience replay in terms of both accuracy and forgetting metrics and for various sizes of episodic memories.},
archivePrefix = {arXiv},
arxivId = {2002.08165},
author = {Chaudhry, Arslan and Gordo, Albert and Dokania, Puneet K. and Torr, Philip and Lopez-Paz, David},
eprint = {2002.08165},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chaudhry et al. - 2020 - Using hindsight to anchor past knowledge in continual learning.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {anchor-based,continual learning},
mendeley-tags = {anchor-based,continual learning},
title = {{Using hindsight to anchor past knowledge in continual learning}},
year = {2020}
}
@article{Ayranci2016,
abstract = {There is a movement in engineering to shift from conventional materials to those that can adapt and morph to their environment as a result of external stimuli. This category of materials is called shape memory materials. Among these, shape memory polymers have great potential due to their light weight and ease of shaping. They can significantly alter the way engineers think of their design approach; however, a number of them have stiffness and strength disadvantages compared to conventional engineering materials. Through composite material-based approaches, shape memory polymers have improved to meet some engineering challenges. Herein, fundamental aspects of shape memory polymers and composites are discussed; furthermore, recent adaptations of shape memory composites to shape memory braided composites are explored.},
author = {Ayranci, C. and Ivey, M. and Carey, Jason P.},
doi = {10.1016/B978-0-08-100369-5.00011-8},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ayranci, Ivey, Carey - 2016 - Shape memory composites and braids.pdf:pdf},
isbn = {9780081003770},
journal = {Handbook of Advances in Braided Composite Materials: Theory, Production, Testing and Applications},
keywords = {Activation,Braids,Fundamental concepts,Manufacturing,Review,Shape memory polymer composites,Shape recovery properties},
pages = {397--408},
title = {{Shape memory composites and braids}},
volume = {1},
year = {2016}
}
@article{Nozawa2021,
abstract = {Instance discriminative self-supervised representation learning has been attracted attention thanks to its unsupervised nature and informative feature representation for downstream tasks. Self-supervised representation learning commonly uses more negative samples than the number of supervised classes in practice. However, there is an inconsistency in the existing analysis; theoretically, a large number of negative samples degrade supervised performance, while empirically, they improve the performance. We theoretically explain this empirical result regarding negative samples. We empirically confirm our analysis by conducting numerical experiments on CIFAR-10/100 datasets.},
archivePrefix = {arXiv},
arxivId = {2102.06866},
author = {Nozawa, Kento and Sato, Issei},
eprint = {2102.06866},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nozawa, Sato - 2021 - Understanding Negative Samples in Instance Discriminative Self-supervised Representation Learning.pdf:pdf},
keywords = {negative samples,self-supervised learning,theory},
mendeley-tags = {negative samples,self-supervised learning,theory},
pages = {1--21},
title = {{Understanding Negative Samples in Instance Discriminative Self-supervised Representation Learning}},
url = {http://arxiv.org/abs/2102.06866},
year = {2021}
}
@article{Xie2019,
abstract = {We present a simple self-training method that achieves 88.4% top-1 accuracy on ImageNet, which is 2.0% better than the state-of-the-art model that requires 3.5B weakly labeled Instagram images. On robustness test sets, it improves ImageNet-A top-1 accuracy from 61.0% to 83.7%, reduces ImageNet-C mean corruption error from 45.7 to 28.3, and reduces ImageNet-P mean flip rate from 27.8 to 12.2. To achieve this result, we first train an EfficientNet model on labeled ImageNet images and use it as a teacher to generate pseudo labels on 300M unlabeled images. We then train a larger EfficientNet as a student model on the combination of labeled and pseudo labeled images. We iterate this process by putting back the student as the teacher. During the generation of the pseudo labels, the teacher is not noised so that the pseudo labels are as accurate as possible. However, during the learning of the student, we inject noise such as dropout, stochastic depth and data augmentation via RandAugment to the student so that the student generalizes better than the teacher.},
archivePrefix = {arXiv},
arxivId = {1911.04252},
author = {Xie, Qizhe and Luong, Minh-Thang and Hovy, Eduard and Le, Quoc V.},
eprint = {1911.04252},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xie et al. - 2019 - Self-training with Noisy Student improves ImageNet classification(2).pdf:pdf},
title = {{Self-training with Noisy Student improves ImageNet classification}},
url = {http://arxiv.org/abs/1911.04252},
year = {2019}
}
@article{Farooq2015,
abstract = {Due to rapid depletion of the fossil fuel reserves and environmental concerns biodiesel has attracted a great deal of attention over the last few decades. In this study, heterogeneous catalysts derived from waste chicken bones were employed in the transesterification reaction of waste cooking oil for biodiesel production. The physicochemical properties of the synthesized catalysts were studied by various techniques such as differential thermal analysis/thermogravimetric analysis (DTA-TGA), BET surface area, X-ray diffraction (XRD), temperature programmed desorption of CO2(TPD-CO2), energy dispersive X-ray (EDX) spectroscopy. The experimental results showed that the heterogeneous catalyst calcined at 900°C exhibited good catalytic activity in the transesterification of WCO, providing maximum biodiesel yield of 89.33% at 5.0g of catalyst loading, 15:1 methanol to oil molar ratio at temperature of 65°C in reaction time of 4h. The better catalytic activity of the aforementioned catalyst in the biodiesel reaction could be attributed to the presence of optimal number of catalytically active basic site density on its surface. Moreover, the catalyst was successfully recycled for 4 times for biodiesel production.},
author = {Farooq, Muhammad and Ramli, Anita},
doi = {10.1016/j.renene.2014.11.042},
isbn = {0960-1481},
issn = {18790682},
journal = {Renewable Energy},
keywords = {Biodiesel,Chicken bones heterogeneous catalyst,Optimization},
pages = {362--368},
publisher = {Elsevier Ltd},
title = {{Biodiesel production from low FFA waste cooking oil using heterogeneous catalyst derived from chicken bones}},
url = {http://dx.doi.org/10.1016/j.renene.2014.11.042},
volume = {76},
year = {2015}
}
@article{LeCun1998,
author = {LeCun, Yann A. and Bottou, L{\'{e}}on and Orr, Genevieve B. and M{\"{u}}ller, Klaus-Robert},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/LeCun et al. - 1998 - Efficient BackProp.pdf:pdf},
title = {{Efficient BackProp}},
year = {1998}
}
@article{Montoya2020,
abstract = {Despite significant achievements and current interest in machine learning and artificial intelligence, the quest for a theory of intelligence, allowing general and efficient problem solving, has done little progress. This work tries to contribute in this direction by proposing a novel framework of intelligence based on three principles. First, the generative and mirroring nature of learned representations of inputs. Second, a grounded, intrinsically motivated and iterative process for learning, problem solving and imagination. Third, an ad hoc tuning of the reasoning mechanism over causal compositional representations using inhibition rules. Together, those principles create a systems approach offering interpretability, continuous learning, common sense and more. This framework is being developed from the following perspectives: as a general problem solving method, as a human oriented tool and finally, as model of information processing in the brain.},
archivePrefix = {arXiv},
arxivId = {2012.09477},
author = {Montoya, Abel Torres},
eprint = {2012.09477},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Montoya - 2020 - Computational principles of intelligence learning and reasoning with neural networks.pdf:pdf},
keywords = {reasoning},
mendeley-tags = {reasoning},
title = {{Computational principles of intelligence: learning and reasoning with neural networks}},
url = {http://arxiv.org/abs/2012.09477},
year = {2020}
}
@article{Kusdiana2004,
abstract = {In the conventional transesterification of fats/vegetable oils for biodiesel production, free fatty acids and water always produce negative effects, since the presence of free fatty acids and water causes soap formation, consumes catalyst and reduces catalyst effectiveness, all of which result in a low conversion. The objective of this study was, therefore, to investigate the effect of water on the yield of methyl esters in transesterification of triglycerides and methyl esterification of fatty acids as treated by catalyst-free supercritical methanol. The presence of water did not have a significant effect on the yield, as complete conversions were always achieved regardless of the content of water. In fact, the present of water at a certain amount could enhance the methyl esters formation. For the vegetable oil containing water, three types of reaction took place; transesterification and hydrolysis of triglycerides and methyl esterification of fatty acids proceeded simultaneously during the treatment to produce a high yield. These results were compared with those of methyl esters prepared by acid- and alkaline-catalyzed methods. The finding demonstrated that, by a supercritical methanol approach, crude vegetable oil as well as its wastes could be readily used for biodiesel fuel production in a simple preparation. {\textcopyright} 2003 Elsevier Ltd. All rights reserved.},
author = {Kusdiana, Dadan and Saka, Shiro},
doi = {10.1016/S0960-8524(03)00201-3},
isbn = {0960-8524},
issn = {09608524},
journal = {Bioresource Technology},
keywords = {Biodiesel,Methyl esterification,Methyl esters,Supercritical methanol,Transesterification},
number = {3},
pages = {289--295},
pmid = {14607489},
title = {{Effects of water on biodiesel fuel production by supercritical methanol treatment}},
volume = {91},
year = {2004}
}
@article{VanBavel2018a,
abstract = {Democracies assume accurate knowledge by the populace, but the human attraction to fake and untrustworthy news poses a serious problem for healthy democratic functioning. We articulate why and how identification with political parties – known as partisanship – can bias information processing in the human brain. There is extensive evidence that people engage in motivated political reasoning, but recent research suggests that partisanship can alter memory, implicit evaluation, and even perceptual judgments. We propose an identity-based model of belief for understanding the influence of partisanship on these cognitive processes. This framework helps to explain why people place party loyalty over policy, and even over truth. Finally, we discuss strategies for de-biasing information processing to help to create a shared reality across partisan divides.},
author = {{Van Bavel}, Jay J. and Pereira, Andrea},
doi = {10.1016/j.tics.2018.01.004},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Van Bavel, Pereira - 2018 - The Partisan Brain An Identity-Based Model of Political Belief.pdf:pdf},
issn = {1879307X},
journal = {Trends in Cognitive Sciences},
keywords = {attention,group identity,memory,partisanship,perception,reasoning},
number = {3},
pages = {213--224},
pmid = {29475636},
publisher = {Elsevier Ltd},
title = {{The Partisan Brain: An Identity-Based Model of Political Belief}},
url = {http://dx.doi.org/10.1016/j.tics.2018.01.004},
volume = {22},
year = {2018}
}
@article{Jaffal2011,
author = {Jaffal, Hussein and Tao, Cheng},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jaffal, Tao - 2011 - Multiple Attributes Group Decision Making by Type-2 Fuzzy Sets and Systems.pdf:pdf},
journal = {Fuzzy Sets and Systems},
title = {{Multiple Attributes Group Decision Making by Type-2 Fuzzy Sets and Systems}},
year = {2011}
}
@article{Loning2019,
abstract = {We present sktime - a new scikit-learn compatible Python library with a unified interface for machine learning with time series. Time series data gives rise to various distinct but closely related learning tasks, such as forecasting and time series classification, many of which can be solved by reducing them to related simpler tasks. We discuss the main rationale for creating a unified interface, including reduction, as well as the design of sktime's core API, supported by a clear overview of common time series tasks and reduction approaches.},
archivePrefix = {arXiv},
arxivId = {1909.07872},
author = {L{\"{o}}ning, Markus and Kazakov, Viktor and Bagnall, Anthony and Lines, Jason and Ganesh, Sajaysurya and Kir{\'{a}}ly, Franz J.},
eprint = {1909.07872},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/L{\"{o}}ning et al. - 2019 - Sktime A unified interface for machine learning with time series.pdf:pdf},
journal = {arXiv},
keywords = {time series},
mendeley-tags = {time series},
title = {{Sktime: A unified interface for machine learning with time series}},
url = {https://arxiv.org/pdf/1909.07872v1.pdf https://github.com/alan-turing-institute/sktime},
year = {2019}
}
@article{Beaumont2012,
author = {Beaumont, Robin},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Beaumont - 2012 - An Introduction to statistics Correlation.pdf:pdf},
journal = {Claire Nickerson},
number = {September},
pages = {1--28},
title = {{An Introduction to statistics Correlation}},
url = {http://www.robin-beaumont.co.uk/virtualclassroom/contents.html%5CnWho},
year = {2012}
}
@article{Tagliaferri2015c,
abstract = {We propose two methods for short term forecasting of wind direction with the aim to provide input for tactic decisions during yacht races. The wind direction measured in the past minutes is used as input and the wind direction for the next two minutes constitutes the output. The two methods are based on artificial neural networks (ANN) and support vector machines (SVM), respectively. For both methods we optimise the length of the moving average that we use to pre-process the input data, the length of the input vector and, for the ANN only, the number of neurons of each layer. The forecast is evaluated by looking at the mean absolute error and at a mean effectiveness index, which assesses the percentage of times that the forecast is accurate enough to predict the correct tactical choice in a sailing yacht race. The ANN forecast based on the ensemble average of ten networks shows a larger mean absolute error and a similar mean effectiveness index than the SVM forecast. However, we showed that the ANN forecast accuracy increases significantly with the size of the ensemble. Therefore increasing the computational power, it can lead to a better forecast.},
author = {Tagliaferri, F. and Viola, I. M. and Flay, R. G J},
doi = {10.1016/j.oceaneng.2014.12.026},
isbn = {0029-8018},
issn = {00298018},
journal = {Ocean Engineering},
keywords = {Artificial neural networks,Race,Sailing yacht,Support vector machines,Tactics,Wind forecast},
pages = {65--73},
publisher = {Elsevier},
title = {{Wind direction forecasting with artificial neural networks and support vector machines}},
url = {http://dx.doi.org/10.1016/j.oceaneng.2014.12.026},
volume = {97},
year = {2015}
}
@article{Kitaev2020,
abstract = {Large Transformer models routinely achieve state-of-the-art results on a number of tasks but training these models can be prohibitively costly, especially on long sequences. We introduce two techniques to improve the efficiency of Transformers. For one, we replace dot-product attention by one that uses locality-sensitive hashing, changing its complexity from O($L^2$) to O($L\log L$), where $L$ is the length of the sequence. Furthermore, we use reversible residual layers instead of the standard residuals, which allows storing activations only once in the training process instead of $N$ times, where $N$ is the number of layers. The resulting model, the Reformer, performs on par with Transformer models while being much more memory-efficient and much faster on long sequences.},
archivePrefix = {arXiv},
arxivId = {2001.04451},
author = {Kitaev, Nikita and Kaiser, {\L}ukasz and Levskaya, Anselm},
eprint = {2001.04451},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kitaev, Kaiser, Levskaya - 2020 - Reformer The Efficient Transformer.pdf:pdf},
journal = {arXiv},
keywords = {backbone,module,self-attention,transformer},
mendeley-tags = {backbone,module,self-attention,transformer},
month = {jan},
pages = {1--12},
title = {{Reformer: The Efficient Transformer}},
url = {http://arxiv.org/abs/2001.04451 https://github.com/google/trax/tree/master/trax/models/reformer},
year = {2020}
}
@inproceedings{Shen2020,
abstract = {The ability of intelligent agents to learn and remember mul- tiple tasks sequentially is crucial to achieving artificial gen- eral intelligence. Many continual learning (CL) methods have been proposed to overcome catastrophic forgetting which re- sults from non i.i.d data in the sequential learning of neural networks. In this paper we focus on class incremental learn- ing, a challenging CL scenario. For this scenario, generative replay is a promising strategy which generates and replays pseudo data for previous tasks to alleviate catastrophic forget- ting. However, it is hard to train a generative model continu- ally for relatively complex data. Based on recently proposed orthogonal weight modification (OWM) algorithm which can approximately keep previously learned feature invariant when learning new tasks, we propose to 1) replay penultimate layer feature with a generative model; 2) leverage a self-supervised auxiliary task to further enhance the stability of feature. Em- pirical results on several datasets show our method always achieves substantial improvement over powerful OWM while conventional generative replay always results in a negative effect. Meanwhile our method beats several strong baselines including one based on real data storage. In addition, we con- duct experiments to study why our method is effective. Introduction},
archivePrefix = {arXiv},
arxivId = {2005.03490},
author = {Shen, Gehui and Zhang, Song and Chen, Xiang and Deng, Zhi-hong},
eprint = {2005.03490},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shen et al. - 2020 - Generative Feature Replay with Orthogonal Weight Modification for Continual Learning.pdf:pdf},
keywords = {continual learning,generative replay,rehearsal,replay},
mendeley-tags = {continual learning,generative replay,rehearsal,replay},
title = {{Generative Feature Replay with Orthogonal Weight Modification for Continual Learning}},
year = {2020}
}
@inproceedings{kemker2018fearnet,
abstract = {Incremental class learning involves sequentially learning classes in bursts of examples from the same class. This violates the assumptions that underlie methods for training standard deep neural networks, and will cause them to suffer from catastrophic forgetting. Arguably, the best method for incremental class learning is iCaRL, but it requires storing training examples for each class, making it challenging to scale. Here, we propose FearNet for incremental class learning. FearNet is a generative model that does not store previous examples, making it memory efficient. FearNet uses a brain-inspired dual-memory system in which new memories are consolidated from a network for recent memories inspired by the mammalian hippocampal complex to a network for long-term storage inspired by medial prefrontal cortex. Memory consolidation is inspired by mechanisms that occur during sleep. FearNet also uses a module inspired by the basolateral amygdala for determining which memory system to use for recall. FearNet achieves state-of-the-art performance at incremental class learning on image \(CIFAR-100, CUB-200\) and audio classification \(AudioSet\) benchmarks.},
archivePrefix = {arXiv},
arxivId = {1711.10563},
author = {Kemker, Ronald and Kanan, Christopher},
booktitle = {International Conference on Learning Representations},
eprint = {1711.10563},
file = {:home/user/Downloads/1711.10563.pdf:pdf},
issn = {23318422},
keywords = {continual learning,generative replay,incremental learning,rehearsal,replay},
mendeley-tags = {continual learning,generative replay,incremental learning,rehearsal,replay},
title = {{FearNet: Brain-inspired model for incremental learning}},
year = {2018}
}
@inproceedings{Girshick2015,
abstract = {This paper proposes a Fast Region-based Convolutional Network method (Fast R-CNN) for object detection. Fast R-CNN builds on previous work to efficiently classify object proposals using deep convolutional networks. Compared to previous work, Fast R-CNN employs several innovations to improve training and testing speed while also increasing detection accuracy. Fast R-CNN trains the very deep VGG16 network 9x faster than R-CNN, is 213x faster at test-time, and achieves a higher mAP on PASCAL VOC 2012. Compared to SPPnet, Fast R-CNN trains VGG16 3x faster, tests 10x faster, and is more accurate. Fast R-CNN is implemented in Python and C++ (using Caffe) and is available under the open-source MIT License at https://github.com/rbgirshick/fast-rcnn.},
archivePrefix = {arXiv},
arxivId = {1504.08083},
author = {Girshick, Ross},
booktitle = {2015 IEEE International Conference on Computer Vision (ICCV)},
doi = {10.1109/ICCV.2015.169},
eprint = {1504.08083},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Girshick - 2015 - Fast R-CNN.pdf:pdf},
isbn = {978-1-4673-8391-2},
month = {dec},
pages = {1440--1448},
publisher = {IEEE},
title = {{Fast R-CNN}},
url = {http://arxiv.org/abs/1504.08083 http://ieeexplore.ieee.org/document/7410526/},
year = {2015}
}
@article{Tzimiropoulos2017,
abstract = {Fitting algorithms for Active Appearance Mod-els (AAMs) are usually considered to be robust but slow or fast but less able to generalize well to unseen variations. In this paper, we look into AAM fitting algorithms and make the following orthogonal contributions: We present a simple " project-out " optimization framework that unifies and revises the most well-known optimization problems and solutions in AAMs. Based on this framework, we describe robust simul-taneous AAM fitting algorithms the complexity of which is not prohibitive for current systems. We then go on one step further and propose a new approximate project-out AAM fit-ting algorithm which we coin Extended Project-Out Inverse Compositional (E-POIC). In contrast to current algorithms, E-POIC is both efficient and robust. Next, we describe a part-based AAM employing a translational motion model, which results in superior fitting and convergence proper-ties. We also show that the proposed AAMs, when trained " in-the-wild " using SIFT descriptors, perform surprisingly well even for the case of unseen unconstrained images. Via a number of experiments on unconstrained human and ani-mal face databases, we show that our combined contributions largely bridge the gap between exact and current approximate methods for AAM fitting and perform comparably with state-of-the-art face alignment systems.},
author = {Tzimiropoulos, Georgios and Pantic, Maja},
doi = {10.1007/s11263-016-0950-1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tzimiropoulos, Pantic - 2017 - Fast Algorithms for Fitting Active Appearance Models to Unconstrained Images.pdf:pdf},
issn = {15731405},
journal = {International Journal of Computer Vision},
keywords = {Active Appearance Models,Face alignment,In-the-wild},
number = {1},
pages = {17--33},
publisher = {Springer US},
title = {{Fast Algorithms for Fitting Active Appearance Models to Unconstrained Images}},
volume = {122},
year = {2017}
}
@article{Guo2013,
author = {Guo, Shu Juan and Guan, Sheng-Uei and Yang, Shang and Li, Wei Fan and Zhao, Lin Fan and Song, Jing Hao},
doi = {10.7763/JOCET.2013.V1.76},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guo et al. - 2013 - Input Partitioning Based on Correlation for Neural Network Learning.pdf:pdf},
issn = {1793821X},
journal = {Journal of Clean Energy Technologies},
number = {4},
pages = {335--338},
title = {{Input Partitioning Based on Correlation for Neural Network Learning}},
url = {http://www.jocet.org/index.php?m=content&c=index&a=show&catid=29&id=343},
volume = {1},
year = {2013}
}
@article{Kouhi2007,
author = {Kouhi, Y. and Adlgostar, R. and Nourzadeh, H.},
doi = {10.3182/20070927-4-RO-3905.00089},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kouhi, Adlgostar, Nourzadeh - 2007 - Robust and Fel Control Design for Mimo Flow-Level Control Plant.pdf:pdf},
isbn = {978-3-902661-31-9},
issn = {14746670},
journal = {IFAC Proceedings Volumes},
keywords = {Fuzzy control,H{\~{A}}¢{\"{E}}†{\AA}¾ control,Identification,MIMO system,Robust controller,Robust stability,control,fuzzy control,h,identification,mimo system,robust controller,robust stability},
number = {18},
pages = {535--540},
publisher = {IFAC},
title = {{Robust and Fel Control Design for Mimo Flow-Level Control Plant}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1474667015322205},
volume = {40},
year = {2007}
}
@article{Nakkiran2019,
abstract = {We show that a variety of modern deep learning tasks exhibit a “double-descent” phenomenon where, as we increase model size, performance first gets worse and then gets better. Moreover, we show that double descent occurs not just as a function of model size, but also as a function of the number of training epochs. We unify the above phenomena by defining a new complexity measure we call the effective model complexity and conjecture a generalized double descent with respect to this measure. Furthermore, our notion of model complexity allows us to identify certain regimes where increasing (even quadrupling) the number of train samples actually hurts test performance.},
archivePrefix = {arXiv},
arxivId = {1912.02292},
author = {Nakkiran, Preetum and Barak, Boaz and Kaplun, Gal and Sutskever, Ilya and Bansal, Yamini and Yang, Tristan},
eprint = {1912.02292},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nakkiran et al. - 2019 - Deep double descent Where bigger models and more data hurt.pdf:pdf},
journal = {arXiv},
pages = {1--24},
title = {{Deep double descent: Where bigger models and more data hurt}},
year = {2019}
}
@article{Schmidt2020,
abstract = {Future self-driving cars must be able to perceive and understand their surroundings. Deep learning based approaches promise to solve the perception problem but require a large amount of manually labeled training data. Active learning is a training procedure in which the model itself selects interesting samples for labeling based on their uncertainty, with substantially less data required for training. Recent research in active learning has mostly focused on the simple image classification task. In this paper, we propose novel methods to estimate sample uncertainties for 2D and 3D object detection using Ensembles. We moreover evaluate different training strategies including Continuous Training to alleviate increasing training times introduced by the active learning cycle. Finally, we investigate the effects of active learning on imbalanced datasets and possible interactions with class weighting. Experiment results show both increased time saving around 55% and data saving rates of around 30%. For the 3D object detection task, we show that our proposed uncertainty estimation method is valid, saving 35% of labeling efforts and thus is ready for application for automotive object detection use cases.},
author = {Schmidt, Sebastian and Rao, Qing and Tatsch, Julian and Knoll, Alois},
doi = {10.1109/IV47402.2020.9304565},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schmidt et al. - 2020 - Advanced Active Learning Strategies for Object Detection.pdf:pdf},
isbn = {9781728166735},
journal = {IEEE Intelligent Vehicles Symposium, Proceedings},
keywords = {active learning,object detection},
mendeley-tags = {active learning,object detection},
number = {Iv},
pages = {871--876},
title = {{Advanced Active Learning Strategies for Object Detection}},
year = {2020}
}
@article{Zhou2018,
abstract = {—Lots of learning tasks require dealing with graph data which contains rich relation information among elements. Modeling physics system, learning molecular fingerprints, predicting protein interface, and classifying diseases require a model to learn from graph inputs. In other domains such as learning from non-structural data like texts and images, reasoning on extracted structures, like the dependency tree of sentences and the scene graph of images, is an important research topic which also needs graph reasoning models. Graph neural networks (GNNs) are connectionist models that capture the dependence of graphs via message passing between the nodes of graphs. Unlike standard neural networks, graph neural networks retain a state that can represent information from its neighborhood with arbitrary depth. Although the primitive GNNs have been found difficult to train for a fixed point, recent advances in network architectures, optimization techniques, and parallel computation have enabled successful learning with them. In recent years, systems based on variants of graph neural networks such as graph convolutional network (GCN), graph attention network (GAT), gated graph neural network (GGNN) have demonstrated ground-breaking performance on many tasks mentioned above. In this survey, we provide a detailed review over existing graph neural network models, systematically categorize the applications, and propose four open problems for future research.},
archivePrefix = {arXiv},
arxivId = {1812.08434},
author = {Zhou, Jie and Cui, Ganqu and Zhang, Zhengyan and Yang, Cheng and Liu, Zhiyuan and Wang, Lifeng and Li, Changcheng and Sun, Maosong},
eprint = {1812.08434},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou et al. - 2018 - Graph Neural Networks A Review of Methods and Applications.pdf:pdf},
journal = {arXiv},
keywords = {Deep Learning,,Graph Neural Network},
pages = {1--22},
title = {{Graph Neural Networks: A Review of Methods and Applications}},
year = {2018}
}
@article{Yang2018,
abstract = {Person re-identification is a useful technique to automatically match observations of the same person cross different times and different camera views. It attracts extensive attention and researches in computer vision community because of its application and challenge. An effect way to tackle the problem is to learn a useful distance metric from training examples. Then the learned metric could be used for distance calculations between a probe image and images from the gallery. For a real application, the labeled training samples usually increase gradually along the time. To keep the performance of a system for re-identification tasks, the learned model needs to be updated according to the newly added training sets. Although the learned model can be retrained with the whole dataset, the procedure is usually time-consuming. In this paper, we propose an incremental metric learning method based on the widely used XQDA metric for person re-identification. The key idea is that the covariance matrices of similar and dissimilar example pairs can be effectively updated incrementally in the XQDA metric learning algorithm. Then the final metric could be deduced in an incremental way. The proposed approach method is validated on two public available datasets, and the experimental results indicate the effectiveness of our proposed approach.},
author = {Yang, Zhao and Wu, Yiqiang and Cheng, Jun and Peng, Shaohu and Wang, Li and Tao, Dapeng},
doi = {10.1109/ICInfA.2018.8812373},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2018 - Incremental XQDA metric learning for person reidentification.pdf:pdf},
isbn = {9781538680698},
journal = {2018 IEEE International Conference on Information and Automation, ICIA 2018},
keywords = {Incremental learning,Metric learning,Person re-identification,continual learning,incremental learning,person,person re-identification,re-identificiation},
mendeley-tags = {continual learning,incremental learning,person,person re-identification,re-identificiation},
number = {61501177},
pages = {433--438},
publisher = {IEEE},
title = {{Incremental XQDA metric learning for person reidentification}},
year = {2018}
}
@inproceedings{Xu2020,
abstract = {We study how neural networks trained by gradient descent extrapolate, i.e., what they learn outside the support of the training distribution. Previous works report mixed empirical results when extrapolating with neural networks: while multilayer perceptrons (MLPs) do not extrapolate well in certain simple tasks, Graph Neural Network (GNN), a structured network with MLP modules, has shown some success in more complex tasks. Working towards a theoretical explanation, we identify conditions under which MLPs and GNNs extrapolate well. First, we quantify the observation that ReLU MLPs quickly converge to linear functions along any direction from the origin, which implies that ReLU MLPs do not extrapolate most non-linear functions. But, they can provably learn a linear target function when the training distribution is sufficiently “diverse”. Second, in connection to analyzing successes and limitations of GNNs, these results suggest a hypothesis for which we provide theoretical and empirical evidence: the success of GNNs in extrapolating algorithmic tasks to new data (e.g., larger graphs or edge weights) relies on encoding task-specific non-linearities in the architecture or features.},
archivePrefix = {arXiv},
arxivId = {2009.11848},
author = {Xu, Keyulu and Li, Jingling and Zhang, Mozhi and Du, Simon S. and Kawarabayashi, Ken Ichi and Jegelka, Stefanie},
booktitle = {Iclr 2021},
eprint = {2009.11848},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu et al. - 2020 - How neural networks extrapolate From feedforward to graph neural networks.pdf:pdf},
issn = {23318422},
keywords = {empirical study,extrapolation,graph neural networks,neural networks,theory},
mendeley-tags = {empirical study,extrapolation,graph neural networks,neural networks,theory},
title = {{How neural networks extrapolate: From feedforward to graph neural networks}},
year = {2020}
}
@article{Pap2001,
abstract = {Peptides carrying different fluorophores can be designed to incorporate spontaneously into living cells when added to the medium. By incorporating the peroxisome-targeting sequence PTS1, the peptide is recognized by the protein-import machinery of peroxisomes and, as a result, can accumulate in these organelles. Depending on the cell type, an inhibitor of the multidrug-resistance protein might be required to ensure strong accumulation. In this update, we discuss the potential of these peptide-linked fluorophores in solving issues related to organelle function and dynamics.},
author = {Pap, E. H W and Dansen, T. B. and Wirtz, K. W A},
doi = {10.1016/S0962-8924(00)01829-8},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pap, Dansen, Wirtz - 2001 - Peptide-based targeting of fluorophores to peroxisomes in living cells.pdf:pdf},
issn = {09628924},
journal = {Trends in Cell Biology},
number = {1},
pages = {10--12},
pmid = {11146278},
title = {{Peptide-based targeting of fluorophores to peroxisomes in living cells}},
volume = {11},
year = {2001}
}
@article{Bjorck2020,
abstract = {Weight decay (WD) is a traditional regularization technique in deep learning, but despite its ubiquity, its behavior is still an area of active research. Golatkar et al. have recently shown that WD only matters at the start of the training in computer vision, upending traditional wisdom. Loshchilov et al. show that for adaptive optimizers, manually decaying weights can outperform adding an $l_2$ penalty to the loss. This technique has become increasingly popular and is referred to as decoupled WD. The goal of this paper is to investigate these two recent empirical observations. We demonstrate that by applying WD only at the start, the network norm stays small throughout training. This has a regularizing effect as the effective gradient updates become larger. However, traditional generalizations metrics fail to capture this effect of WD, and we show how a simple scale-invariant metric can. We also show how the growth of network weights is heavily influenced by the dataset and its generalization properties. For decoupled WD, we perform experiments in NLP and RL where adaptive optimizers are the norm. We demonstrate that the primary issue that decoupled WD alleviates is the mixing of gradients from the objective function and the $l_2$ penalty in the buffers of Adam (which stores the estimates of the first-order moment). Adaptivity itself is not problematic and decoupled WD ensures that the gradients from the $l_2$ term cannot "drown out" the true objective, facilitating easier hyperparameter tuning.},
archivePrefix = {arXiv},
arxivId = {2012.13841},
author = {Bjorck, Johan and Weinberger, Kilian and Gomes, Carla},
eprint = {2012.13841},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bjorck, Weinberger, Gomes - 2020 - Understanding Decoupled and Early Weight Decay.pdf:pdf},
keywords = {weight decay},
mendeley-tags = {weight decay},
title = {{Understanding Decoupled and Early Weight Decay}},
url = {http://arxiv.org/abs/2012.13841},
year = {2020}
}
@article{Lopes,
author = {Lopes, Noel and Ribeiro, Bernardete and Francisco, Av and Carneiro, S{\'{a}} and Guarda, P-},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lopes et al. - Unknown - A Data Pre-Processing Tool for Neural Networks ( DPTNN ) Use in A Moulding Injection Machine Institute Poly.pdf:pdf},
keywords = {can offer relatively,data analysis,fault diagnosis,injection moulding,neural networks,pattern recognition and,simple solutions to complex,the neural computing approach},
title = {{A Data Pre-Processing Tool for Neural Networks ( DPTNN ) Use in A Moulding Injection Machine Institute Polytechnic of Guarda – Department of Engineering Informatics CISUC – Department of Engineering Informatics}}
}
@article{Tian2021,
abstract = {Contrastive approaches to self-supervised learning (SSL) learn representations by minimizing the distance between two augmented views of the same data point (positive pairs) and maximizing the same from different data points (negative pairs). However, recent approaches like BYOL and SimSiam, show remarkable performance {\it without} negative pairs, raising a fundamental theoretical question: how can SSL with only positive pairs avoid representational collapse? We study the nonlinear learning dynamics of non-contrastive SSL in simple linear networks. Our analysis yields conceptual insights into how non-contrastive SSL methods learn, how they avoid representational collapse, and how multiple factors, like predictor networks, stop-gradients, exponential moving averages, and weight decay all come into play. Our simple theory recapitulates the results of real-world ablation studies in both STL-10 and ImageNet. Furthermore, motivated by our theory we propose a novel approach that \emph{directly} sets the predictor based on the statistics of its inputs. In the case of linear predictors, our approach outperforms gradient training of the predictor by $5\%$ and on ImageNet it performs comparably with more complex two-layer non-linear predictors that employ BatchNorm. Code is released in https://github.com/facebookresearch/luckmatters/tree/master/ssl.},
archivePrefix = {arXiv},
arxivId = {2102.06810},
author = {Tian, Yuandong and Chen, Xinlei and Ganguli, Surya},
eprint = {2102.06810},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tian, Chen, Ganguli - 2021 - Understanding self-supervised Learning Dynamics without Contrastive Pairs.pdf:pdf},
keywords = {contrastive learning,negative samples,self-supervised learning},
mendeley-tags = {contrastive learning,negative samples,self-supervised learning},
title = {{Understanding self-supervised Learning Dynamics without Contrastive Pairs}},
url = {http://arxiv.org/abs/2102.06810 https: //github.com/facebookresearch/ luckmatters/tree/master/ssl},
year = {2021}
}
@article{Misra2016,
abstract = {In this paper, we present an approach for learning a visual representation from the raw spatiotemporal signals in videos. Our representation is learned without supervision from semantic labels. We formulate our method as an unsupervised sequential verification task, i.e., we determine whether a sequence of frames from a video is in the correct temporal order. With this simple task and no semantic labels, we learn a powerful visual representation using a Convolutional Neural Network (CNN). The representation contains complementary information to that learned from supervised image datasets like ImageNet. Qualitative results show that our method captures information that is temporally varying, such as human pose.When used as pre-training for action recognition, our method gives significant gains over learning without external data on benchmark datasets like UCF101 and HMDB51. To demonstrate its sensitivity to human pose, we show results for pose estimation on the FLIC and MPII datasets that are competitive, or better than approaches using significantly more supervision. Our method can be combined with supervised representations to provide an additional boost in accuracy.},
archivePrefix = {arXiv},
arxivId = {1603.08561},
author = {Misra, Ishan and {Lawrence Zitnick}, C. and Hebert, Martial},
doi = {10.1007/978-3-319-46448-0_32},
eprint = {1603.08561},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Misra, Lawrence Zitnick, Hebert - 2016 - Shuffle and learn Unsupervised learning using temporal order verification.pdf:pdf},
isbn = {9783319464473},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Action recognition,Convolutional neural networks,Pose estimation,Sequence verification,Unsupervised learning,Videos},
pages = {527--544},
title = {{Shuffle and learn: Unsupervised learning using temporal order verification}},
volume = {9905 LNCS},
year = {2016}
}
@article{Sciancalepore2014a,
author = {Sciancalepore, Corrado and Manfredini, Tiziano and Bondioli, Federica},
doi = {10.4028/www.scientific.net/AST.92.90},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sciancalepore, Manfredini, Bondioli - 2014 - Antibacterial and Self-Cleaning Coatings for Silicate Ceramics A Review.pdf:pdf},
isbn = {3038353043},
issn = {1662-0356},
journal = {Advances in Science and Technology},
keywords = {abstract,antibacterial tiles,durability,in many,innovation is strongly felt,into materials and components,like textiles or ceramics,materials is increasingly leading,nanostructured coating,over the last twenty,self-cleaning tiles,the development of advanced,the so-called,this drive in technological,tio 2,to integration of functions,traditional,traditional fields,years},
pages = {90--99},
title = {{Antibacterial and Self-Cleaning Coatings for Silicate Ceramics: A Review}},
url = {http://www.scientific.net/AST.92.90},
volume = {92},
year = {2014}
}
@article{Ndiour2020,
abstract = {This paper presents a principled approach for detecting out-of-distribution (OOD) samples in deep neural networks (DNN). Modeling probability distributions on deep features has recently emerged as an effective, yet computationally cheap method to detect OOD samples in DNN. However, the features produced by a DNN at any given layer do not fully occupy the corresponding high-dimensional feature space. We apply linear statistical dimensionality reduction techniques and nonlinear manifold-learning techniques on the high-dimensional features in order to capture the true subspace spanned by the features. We hypothesize that such lower-dimensional feature embeddings can mitigate the curse of dimensionality, and enhance any feature-based method for more efficient and effective performance. In the context of uncertainty estimation and OOD, we show that the log-likelihood score obtained from the distributions learnt on this lower-dimensional subspace is more discriminative for OOD detection. We also show that the feature reconstruction error, which is the $L_2$-norm of the difference between the original feature and the pre-image of its embedding, is highly effective for OOD detection and in some cases superior to the log-likelihood scores. The benefits of our approach are demonstrated on image features by detecting OOD images, using popular DNN architectures on commonly used image datasets such as CIFAR10, CIFAR100, and SVHN.},
archivePrefix = {arXiv},
arxivId = {2012.04250},
author = {Ndiour, Ibrahima and Ahuja, Nilesh and Tickoo, Omesh},
eprint = {2012.04250},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ndiour, Ahuja, Tickoo - 2020 - Out-Of-Distribution Detection With Subspace Techniques And Probabilistic Modeling Of Features.pdf:pdf},
keywords = {out-of-distribution},
mendeley-tags = {out-of-distribution},
title = {{Out-Of-Distribution Detection With Subspace Techniques And Probabilistic Modeling Of Features}},
url = {http://arxiv.org/abs/2012.04250},
year = {2020}
}
@article{Dong2013,
abstract = {The impact of missing data on quantitative research can be serious, leading to biased estimates of parameters, loss of information, decreased statistical power, increased standard errors, and weakened generalizability of findings. In this paper, we discussed and demonstrated three principled missing data methods: multiple imputation, full information maximum likelihood, and expectation-maximization algorithm, applied to a real-world data set. Results were contrasted with those obtained from the complete data set and from the listwise deletion method. The relative merits of each method are noted, along with common features they share. The paper concludes with an emphasis on the importance of statistical assumptions, and recommendations for researchers. Quality of research will be enhanced if (a) researchers explicitly acknowledge missing data problems and the conditions under which they occurred, (b) principled methods are employed to handle missing data, and (c) the appropriate treatment of missing data is incorporated into review standards of manuscripts submitted for publication.},
archivePrefix = {arXiv},
arxivId = {arXiv:1501.0228},
author = {Dong, Yiran and Peng, Chao Ying Joanne},
doi = {10.1186/2193-1801-2-222},
eprint = {arXiv:1501.0228},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dong, Peng - 2013 - Principled missing data methods for researchers.pdf:pdf},
isbn = {2193-1801 (Electronic)},
issn = {21931801},
journal = {SpringerPlus},
keywords = {Em,Fiml,Listwise deletion,Mar,Mcar,Mi,Missing data,Mnar},
number = {1},
pages = {1--17},
pmid = {23853744},
title = {{Principled missing data methods for researchers}},
volume = {2},
year = {2013}
}
@article{Pezzelle2020,
abstract = {This work aims at modeling how the meaning of gradable adjectives of size ('big', 'small') can be learned from visually-grounded contexts. Inspired by cognitive and linguistic evidence showing that the use of these expressions relies on setting a threshold that is dependent on a specific context, we investigate the ability of multi-modal models in assessing whether an object is 'big' or 'small' in a given visual scene. In contrast with the standard computational approach that simplistically treats gradable adjectives as 'fixed' attributes, we pose the problem as relational: to be successful, a model has to consider the full visual context. By means of four main tasks, we show that state-of-the-art models (but not a relatively strong baseline) can learn the function subtending the meaning of size adjectives, though their performance is found to decrease while moving from simple to more complex tasks. Crucially, models fail in developing abstract representations of gradable adjectives that can be used compositionally.},
archivePrefix = {arXiv},
arxivId = {arXiv:1908.10285v1},
author = {Pezzelle, Sandro and Fern{\'{a}}ndez, Raquel},
eprint = {arXiv:1908.10285v1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pezzelle, Fern{\'{a}}ndez - 2020 - Is the Red square big Malevic Modeling adjectives leveraging visual contexts.pdf:pdf},
isbn = {9781950737901},
journal = {EMNLP-IJCNLP 2019 - 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing, Proceedings of the Conference},
pages = {2865--2876},
title = {{Is the Red square big? Malevic: Modeling adjectives leveraging visual contexts}},
year = {2020}
}
@inproceedings{Blaschko2017,
abstract = {This paper introduces a new lifelong learning solution where a single model is trained for a sequence of tasks. The main challenge that vision systems face in this context is catastrophic forgetting: as they tend to adapt to the most recently seen task, they lose performance on the tasks that were learned previously. Our method aims at preserving the knowledge of the previous tasks while learning a new one by using autoencoders. For each task, an under-complete autoencoder is learned, capturing the features that are crucial for its achievement. When a new task is presented to the system, we prevent the reconstructions of the features with these autoencoders from changing, which has the effect of preserving the information on which the previous tasks are mainly relying. At the same time, the features are given space to adjust to the most recent environment as only their projection into a low dimension submanifold is controlled. The proposed system is evaluated on image classification tasks and shows a reduction of forgetting over the state-of-the-art.},
archivePrefix = {arXiv},
arxivId = {arXiv:1704.01920v1},
author = {Blaschko, Mathew B and Tuytelaars, Tinne and Leuven, K U},
booktitle = {International Conference on Computer Vision},
eprint = {arXiv:1704.01920v1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Blaschko, Tuytelaars, Leuven - 2017 - Encoder Based Lifelong Learning.pdf:pdf},
number = {6},
pages = {1320--1328},
title = {{Encoder Based Lifelong Learning}},
url = {http://openaccess.thecvf.com/content_ICCV_2017/papers/Rannen_Encoder_Based_Lifelong_ICCV_2017_paper.pdf},
year = {2017}
}
@article{Han2020,
abstract = {Zero-shot object recognition or zero-shot learning aims to transfer the object recognition ability among the semantically related categories, such as fine-grained animal or bird species. However, the images of different fine-grained objects tend to merely exhibit subtle differences in appearance, which will severely deteriorate zero-shot object recognition. To reduce the superfluous information in the fine-grained objects, in this paper, we propose to learn the redundancy-free features for generalized zero-shot learning. We achieve our motivation by projecting the original visual features into a new (redundancy-free) feature space and then restricting the statistical dependence between these two feature spaces. Furthermore, we require the projected features to keep and even strengthen the category relationship in the redundancy-free feature space. In this way, we can remove the redundant information from the visual features without losing the discriminative information. We extensively evaluate the performance on four benchmark datasets. The results show that our redundancy-free feature based generalized zero-shot learning (RFF-GZSL) approach can outperform the state-of-the-arts often by a large margin. Our code is available.},
archivePrefix = {arXiv},
arxivId = {2006.08939},
author = {Han, Zongyan and Fu, Zhenyong and Yang, Jian},
eprint = {2006.08939},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Han, Fu, Yang - 2020 - Learning the Redundancy-free Features for Generalized Zero-Shot Object Recognition.pdf:pdf},
title = {{Learning the Redundancy-free Features for Generalized Zero-Shot Object Recognition}},
url = {http://arxiv.org/abs/2006.08939},
year = {2020}
}
@article{Freidus2018,
abstract = {Fluorescent molecular imaging has advanced drastically over the past decade. With the development of high-resolution microscopy techniques and the ability to visualize intracellular molecular events, there is a growing need for new fluorophores to accompany these fast-developing techniques. Therefore, there has been substantial development of alternative fluorophores for single-molecule detection and molecular imaging. These rationally designed fluorophores have infinite possibilities and novel fluorophores are constantly being produced for different applications. This review focuses on the recent developments in novel fluorophores designed for molecular imaging and single-molecule detection. Here, single-molecule imaging, smart fluorescent probes, two-photon microscopy, F{\"{o}}rster resonance energy transfer (FRET) and super-resolution microscopy are discussed in detail. A wide variety of alternative and novel fluorophores have been developed with wide-reaching applications in the fields of single molecule detection and molecular imaging.},
author = {Freidus, Lara G. and Pradeep, Priyamvada and Kumar, Pradeep and Choonara, Yahya E. and Pillay, Viness},
doi = {10.1016/j.drudis.2017.09.008},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Freidus et al. - 2018 - Alternative fluorophores designed for advanced molecular imaging.pdf:pdf},
issn = {18785832},
journal = {Drug Discovery Today},
number = {1},
pages = {115--133},
pmid = {29111179},
publisher = {Elsevier Ltd},
title = {{Alternative fluorophores designed for advanced molecular imaging}},
url = {https://doi.org/10.1016/j.drudis.2017.09.008},
volume = {23},
year = {2018}
}
@article{Wang2020c,
abstract = {The challenge of unsupervised person re-identification (ReID) lies in learning discriminative features without true labels. This paper formulates unsupervised person ReID as a multi-label classification task to progressively seek true labels. Our method starts by assigning each person image with a single-class label, then evolves to multi-label classification by leveraging the updated ReID model for label prediction. The label prediction comprises similarity computation and cycle consistency to ensure the quality of predicted labels. To boost the ReID model training efficiency in multi-label classification, we further propose the memory-based multi-label classification loss (MMCL). MMCL works with memory-based non-parametric classifier and integrates multi-label classification and single-label classification in a unified framework. Our label prediction and MMCL work iteratively and substantially boost the ReID performance. Experiments on several large-scale person ReID datasets demonstrate the superiority of our method in unsupervised person ReID. Our method also allows to use labeled person images in other domains. Under this transfer learning setting, our method also achieves state-of-the-art performance.},
author = {Wang, Dongkai and Zhang, Shiliang},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Zhang - 2020 - Unsupervised Person Re-identification via Multi-label Classification.pdf:pdf},
journal = {arXiv},
pages = {10981--10990},
title = {{Unsupervised Person Re-identification via Multi-label Classification}},
year = {2020}
}
@article{Finn2017,
abstract = {We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.},
author = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Finn, Abbeel, Levine - 2017 - Model-agnostic meta-learning for fast adaptation of deep networks.pdf:pdf},
journal = {arXiv},
title = {{Model-agnostic meta-learning for fast adaptation of deep networks}},
year = {2017}
}
@article{Long2019,
abstract = {We analyze the joint probability distribution on the lengths of the vectors of hidden variables in different layers of a fully connected deep network, when the weights and biases are chosen randomly according to gaussian distributions. We show that if the activation function $\phi$ satisfies a minimal set of assumptions, satisfied by all activation functions that we know that are used in practice, then, as the width of the network gets large, the “length process” converges in probability to a length map that is determined as a simple function of the variances of the random weights and biases and the activation function $\phi$. We also show that this convergence may fail for $\phi$ that violate our assumptions. We show how to use this analysis to choose the variance of weight initialization, depending on the activation function, so that hidden variables maintain a consistent scale throughout the network.},
archivePrefix = {arXiv},
arxivId = {1901.02104},
author = {Long, Philip M. and Sedghi, Hanie},
doi = {10.1162/neco_a_01235},
eprint = {1901.02104},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Long, Sedghi - 2019 - On the effect of the activation function on the distribution of hidden nodes in a deep network.pdf:pdf},
issn = {1530888X},
journal = {Neural Computation},
keywords = {activation function,theory},
mendeley-tags = {activation function,theory},
number = {12},
pages = {2562--2580},
pmid = {31614106},
title = {{On the effect of the activation function on the distribution of hidden nodes in a deep network}},
volume = {31},
year = {2019}
}
@article{Patra2020,
author = {Patra, Arijit and Chakraborti, Tapabrata},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Patra, Chakraborti - 2020 - Learn more , forget less Cues from human brain.pdf:pdf},
journal = {Accv},
keywords = {catastrophic forgetting,continual learning,pseudorehearsal},
title = {{Learn more , forget less : Cues from human brain}},
year = {2020}
}
@article{Zhang2008,
author = {Zhang, Youzhuan and Wang, Jingxia and Zhao, Yong and Zhai, Jin and Jiang, Lei and Song, Yanlin},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2008 - Photonic Crystal Concentrator for Efficient Output of Dye- sensitized Solar Cells.pdf:pdf},
journal = {Society},
pages = {1--7},
title = {{Photonic Crystal Concentrator for Efficient Output of Dye- sensitized Solar Cells}},
volume = {2},
year = {2008}
}
@article{Springer2021,
abstract = {Neural networks trained on visual data are well-known to be vulnerable to often imperceptible adversarial perturbations. The reasons for this vulnerability are still being debated in the literature. Recently Ilyas et al. (2019) showed that this vulnerability arises, in part, because neural network classifiers rely on highly predictive but brittle "non-robust" features. In this paper we extend the work of Ilyas et al. by investigating the nature of the input patterns that give rise to these features. In particular, we hypothesize that in a neural network trained in a standard way, non-robust features respond to small, "non-semantic" patterns that are typically entangled with larger, robust patterns, known to be more human-interpretable, as opposed to solely responding to statistical artifacts in a dataset. Thus, adversarial examples can be formed via minimal perturbations to these small, entangled patterns. In addition, we demonstrate a corollary of our hypothesis: robust classifiers are more effective than standard (non-robust) ones as a source for generating transferable adversarial examples in both the untargeted and targeted settings. The results we present in this paper provide new insight into the nature of the non-robust features responsible for adversarial vulnerability of neural network classifiers.},
archivePrefix = {arXiv},
arxivId = {2102.05110},
author = {Springer, Jacob M. and Mitchell, Melanie and Kenyon, Garrett T.},
eprint = {2102.05110},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Springer, Mitchell, Kenyon - 2021 - Adversarial Perturbations Are Not So Weird Entanglement of Robust and Non-Robust Features in Neural.pdf:pdf},
keywords = {adversarial learning,adversarial perturbation,robustness},
mendeley-tags = {adversarial learning,adversarial perturbation,robustness},
title = {{Adversarial Perturbations Are Not So Weird: Entanglement of Robust and Non-Robust Features in Neural Network Classifiers}},
url = {http://arxiv.org/abs/2102.05110},
year = {2021}
}
@article{Voyant2017,
abstract = {Forecasting the output power of solar systems is required for the good operation of the power grid or for the optimal management of the energy fluxes occurring into the solar system. Before forecasting the solar systems output, it is essential to focus the prediction on the solar irradiance. The global solar radiation forecasting can be performed by several methods; the two big categories are the cloud imagery combined with physical models, and the machine learning models. In this context, the objective of this paper is to give an overview of forecasting methods of solar irradiation using machine learning approaches. Although, a lot of papers describes methodologies like neural networks or support vector regression, it will be shown that other methods (regression tree, random forest, gradient boosting and many others) begin to be used in this context of prediction. The performance ranking of such methods is complicated due to the diversity of the data set, time step, forecasting horizon, set up and performance indicators. Overall, the error of prediction is quite equivalent. To improve the prediction performance some authors proposed the use of hybrid models or to use an ensemble forecast approach.},
author = {Voyant, Cyril and Notton, Gilles and Kalogirou, Soteris and Nivet, Marie Laure and Paoli, Christophe and Motte, Fabrice and Fouilloy, Alexis},
doi = {10.1016/j.renene.2016.12.095},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Voyant et al. - 2017 - Machine learning methods for solar radiation forecasting A review.pdf:pdf},
isbn = {9781538627150},
issn = {18790682},
journal = {Renewable Energy},
keywords = {Artificial neural networks,Machine learning,Regression,Solar radiation forecasting,Support vector machines},
pages = {569--582},
publisher = {Elsevier Ltd},
title = {{Machine learning methods for solar radiation forecasting: A review}},
url = {http://dx.doi.org/10.1016/j.renene.2016.12.095},
volume = {105},
year = {2017}
}
@article{Rizianiza2015,
author = {Rizianiza, Illa and Aisjah, Aulia Siti},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rizianiza, Aisjah - 2015 - Prediction of Significant Wave Height in The Java Sea Using Artificial Neural Network.pdf:pdf},
isbn = {9781479977116},
keywords = {backpropagation,significant wave height,speed,wind,wind direction},
pages = {5--10},
title = {{Prediction of Significant Wave Height in The Java Sea Using Artificial Neural Network}},
year = {2015}
}
@article{Yang2016a,
abstract = {A Fuzzy Permutation Method for False Discovery Rate Control},
author = {Yang, Ya Hui and Lin, Wan Yu and Lee, Wen Chung},
doi = {10.1038/srep28507},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang, Lin, Lee - 2016 - A Fuzzy Permutation Method for False Discovery Rate Control.pdf:pdf},
issn = {20452322},
journal = {Scientific Reports},
pages = {1--9},
pmid = {27328860},
publisher = {Nature Publishing Group},
title = {{A Fuzzy Permutation Method for False Discovery Rate Control}},
url = {http://dx.doi.org/10.1038/srep28507},
volume = {6},
year = {2016}
}
@article{Fiedler2018a,
abstract = {Highlights some of the key issues affecting our use of the oceans with an emphasis on moving away from seeing the sea as a separate unseen environment. An activity pack containing a Teachers' Handbook, cassette tape, activity sheets, song book and board game.},
author = {Fiedler, Paul C.},
doi = {10.1016/B978-0-12-804327-1.00014-5},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fiedler - 2018 - Ocean Environments.pdf:pdf},
isbn = {9780128043271},
journal = {Encyclopedia of Marine Mammals},
number = {3},
pages = {649--654},
title = {{Ocean Environments}},
url = {http://linkinghub.elsevier.com/retrieve/pii/B9780128043271000145},
year = {2018}
}
@article{Todaro2017a,
abstract = {Piezoelectric MEMS energy harvesters based on thin films are compact and cost-effective microgenerators for scavenging environmental vibrations. This technology is promising for the replacement of electrochemical batteries in low power autonomous sensors and microdevices capturing vibrations in the $\mu$W-mW range. Most of piezoelectric MEMS devices, reported in the last few years, exhibit low generated power/voltage and are not suitable for practical applications. This work reviews the current status of MEMS energy harvesters based on piezoelectric thin films, highlighting approaches/strategies to face the two main challenges to be addressed for high performance devices, namely generated power and frequency bandwidth. The paper introduces the theoretical principles and the main figures of merit of energy conversion in piezoelectric thin films and devices. After an overview on piezoelectric thin films for energy harvesting applications, highlighting their key properties, the manuscript reports a comprehensive survey on the state of the art for this device technology. The last section summarizes the review, highlighting key issues to be addressed and providing an insight into the future outlook to realize devices for practical applications.},
author = {Todaro, Maria Teresa and Guido, Francesco and Mastronardi, Vincenzo and Desmaele, Denis and Epifani, Gianmichele and Algieri, Luciana and {De Vittorio}, Massimo},
doi = {10.1016/j.mee.2017.10.005},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Todaro et al. - 2017 - Piezoelectric MEMS vibrational energy harvesters Advances and outlook.pdf:pdf},
issn = {01679317},
journal = {Microelectronic Engineering},
keywords = {Energy harvesting,MEMS,Piezoelectric thin films},
pages = {23--36},
publisher = {Elsevier B.V},
title = {{Piezoelectric MEMS vibrational energy harvesters: Advances and outlook}},
url = {http://dx.doi.org/10.1016/j.mee.2017.10.005},
volume = {183-184},
year = {2017}
}
@article{Leonard2015,
abstract = {An electrode-scale, transport model for a proton-exchange-membrane fuel cell (PEMFC) cathode is presented. The model describes the performance of non-precious metal catalysts for the oxygen reduction reaction in a fuel cell context. Because of its relatively high thickness, emphasis is placed on phenomena occurring in the cathode layer. Water flooding is studied in terms of its impact on gas-phase transport and on electrochemically accessible surface area (ECSA). Although cathode performance in both air and oxygen are susceptible to ECSA loss, gas diffusion limitations at high current density in air are more significant. In oxygen, catalyst utilization at high current density is primarily limited by conductivity. For this reason, air fuel cell data is recommended over oxygen data for characterizing catalyst performance. Due to both ohmic and mass transport limitations, increased loading of low-cost catalysts does not necessarily lead to higher performance. Therefore, careful optimization of catalyst layer thickness is required.},
author = {Leonard, Nathaniel D. and Artyushkova, Kateryna and Halevi, Barr and Serov, Alexey and Atanassov, Plamen and Barton, Scott Calabrese},
doi = {10.1149/2.0311510jes},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leonard et al. - 2015 - Modeling of Low-Temperature Fuel Cell Electrodes Using Non-Precious Metal Catalysts.pdf:pdf},
isbn = {10.1149/2.0311510jes},
issn = {0013-4651},
journal = {Journal of The Electrochemical Society},
number = {10},
pages = {F1253--F1261},
title = {{Modeling of Low-Temperature Fuel Cell Electrodes Using Non-Precious Metal Catalysts}},
url = {http://jes.ecsdl.org/lookup/doi/10.1149/2.0311510jes},
volume = {162},
year = {2015}
}
@article{Pratama2017a,
abstract = {--Most of the real world datasets suffer from the problem of missing data. It may lead data mining analysts to end with wrong inferences about data under study. Many researchers are working on this problem to introduce more sophisticated methods. Eventhough many methods are available, analysts are facing difficulty in searching a suitable method due to lack of knowledge about the methods and their applicability. To bridge this gap, this paper provides a brief overview of the review papers that have been published during last 10 years that deal with missing values. It discusses about the methods that are compared in the literatures and observations that the authors have made. Finally the techniques that are recommended in most of the literatures are implemented in real world datasets and the empirical results are studied.},
author = {Pratama, Irfan and Permanasari, Adhistya Erna and Ardiyanto, Igi and Indrayani, Rini},
doi = {10.1109/ICITSI.2016.7858189},
isbn = {9781509024490},
journal = {2016 International Conference on Information Technology Systems and Innovation, ICITSI 2016 - Proceedings},
keywords = {deletion,estimation technique,mean imputation,missing values,time series},
title = {{A review of missing values handling methods on time-series data}},
year = {2017}
}
@article{Noor2013a,
author = {Noor, M.N. and Yahaya, A.S. and Ramli, N.A. and {Al Bakri}, Abdullah Mohd Mustafa},
doi = {10.4028/www.scientific.net/KEM.594-595.889},
issn = {1662-9795},
journal = {Key Engineering Materials},
number = {May},
pages = {889--895},
title = {{Filling Missing Data Using Interpolation Methods: Study on the Effect of Fitting Distribution}},
url = {http://www.scientific.net/KEM.594-595.889},
volume = {594-595},
year = {2013}
}
@article{Gavin2017,
author = {Gavin, Henri P},
doi = {10.1080/10426914.2014.941480},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gavin - 2017 - The Levenberg-Marquardt method for nonlinear least squares curve-fitting problems.pdf:pdf},
isbn = {9780898713527},
issn = {1042-6914},
pages = {1--19},
pmid = {16721427},
title = {{The Levenberg-Marquardt method for nonlinear least squares curve-fitting problems}},
year = {2017}
}
@article{Pernici2020,
abstract = {In class-incremental learning, a learning agent faces a stream of data with the goal of learning new classes while not forgetting previous ones. Neural networks are known to suffer under this setting, as they forget previously acquired knowledge. To address this problem, effective methods exploit past data stored in an episodic memory while expanding the final classifier nodes to accommodate the new classes. In this work, we substitute the expanding classifier with a novel fixed classifier in which a number of pre-allocated output nodes are subject to the classification loss right from the beginning of the learning phase. Contrarily to the standard expanding classifier, this allows: (a) the output nodes of future unseen classes to firstly see negative samples since the beginning of learning together with the positive samples that incrementally arrive; (b) to learn features that do not change their geometric configuration as novel classes are incorporated in the learning model. Experiments with public datasets show that the proposed approach is as effective as the expanding classifier while exhibiting novel intriguing properties of the internal feature representation that are otherwise not-existent. Our ablation study on pre-allocating a large number of classes further validates the approach.},
archivePrefix = {arXiv},
arxivId = {2010.08657},
author = {Pernici, Federico and Bruni, Matteo and Baecchi, Claudio and Turchini, Francesco and {Del Bimbo}, Alberto},
eprint = {2010.08657},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pernici et al. - 2020 - Class-incremental Learning with Pre-allocated Fixed Classifiers.pdf:pdf},
keywords = {architectural,continual learning},
mendeley-tags = {architectural,continual learning},
title = {{Class-incremental Learning with Pre-allocated Fixed Classifiers}},
url = {http://arxiv.org/abs/2010.08657},
year = {2020}
}
@article{Chen2000,
abstract = {A drawback of traditional forecasting methods is that they can not deal with forecasting problems in which the historical data are represented by linguistic values. Using fuzzy time series to deal with forecasting problems can overcome this drawback. In this paper, we propose a new fuzzy time series model called the two-factors time-variant fuzzy time series model to deal with forecasting problems. Based on the proposed model, we develop two algorithms for temperature prediction. Both algorithms have the advantage of obtaining good forecasting results.},
author = {Chen, S M and Hwang, J R},
doi = {10.1109/3477.836375},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Hwang - 2000 - Temperature prediction using fuzzy time series.pdf:pdf},
issn = {1083-4419},
journal = {IEEE transactions on systems, man, and cybernetics. Part B, Cybernetics : a publication of the IEEE Systems, Man, and Cybernetics Society},
number = {2},
pages = {263--275},
pmid = {18244753},
title = {{Temperature prediction using fuzzy time series.}},
volume = {30},
year = {2000}
}
@article{Chiatti2020,
abstract = {Service robots can help with many of our daily tasks, especially in those cases where it is inconvenient or unsafe for us to intervene: e.g., under extreme weather conditions or when social distance needs to be maintained. However, before we can successfully delegate complex tasks to robots, we need to enhance their ability to make sense of dynamic, real world environments. In this context, the first prerequisite to improving the Visual Intelligence of a robot is building robust and reliable object recognition systems. While object recognition solutions are traditionally based on Machine Learning methods, augmenting them with knowledge based reasoners has been shown to improve their performance. In particular, based on our prior work on identifying the epistemic requirements of Visual Intelligence, we hypothesise that knowledge of the typical size of objects could significantly improve the accuracy of an object recognition system. To verify this hypothesis, in this paper we present an approach to integrating knowledge about object sizes in a ML based architecture. Our experiments in a real world robotic scenario show that this combined approach ensures a significant performance increase over state of the art Machine Learning methods.},
archivePrefix = {arXiv},
arxivId = {2010.14296},
author = {Chiatti, Agnese and Motta, Enrico and Daga, Enrico and Bardaro, Gianluca},
eprint = {2010.14296},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chiatti et al. - 2020 - Fit to Measure Reasoning about Sizes for Robust Object Recognition.pdf:pdf},
issn = {1613-0073},
keywords = {cognitive systems,hybrid ai,object recognition,reasoning about sizes,service robotics},
pages = {0--3},
title = {{Fit to Measure: Reasoning about Sizes for Robust Object Recognition}},
url = {http://arxiv.org/abs/2010.14296},
volume = {1592},
year = {2020}
}
@article{Chen2015a,
abstract = {In this paper, we propose a new fuzzy forecasting method based on two-factors second-order fuzzy-trend logical relationship groups (TSFTLRGs), particle swarm optimization (PSO) techniques and similarity measures between the subscripts of fuzzy sets (FSs) for forecasting the Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX) and the New Taiwan Dollar/US Dollar (NTD/USD) exchange rates. First, we propose a PSO-based optimal-intervals partition algorithm to get the optimal partition of the intervals in the universe of discourse (UOD) of the main factor TAIEX and to get the optimal partition of the intervals in the UOD of the secondary factor SF, where SF ∈ {Dow Jones, NASDAQ, M1B}. Based on the proposed PSO-based optimal-intervals partition algorithm, the constructed TSFTLRGs, and similarity measures between the subscripts of FSs, we propose a new method for forecasting the TAIEX and the NTD/USD exchange rates. The main contribution of this paper is that we propose a new fuzzy forecasting method based on TSFTLRGs, PSO techniques and similarity measures between the subscripts of FSs for forecasting the TAIEX and the NTD/USD exchange rates to get higher forecasting accuracy rates than the ones of the existing fuzzy forecasting methods.},
author = {Chen, Shyi Ming and Chen, Shen Wen},
doi = {10.1109/TCYB.2014.2326888},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Chen - 2015 - Fuzzy forecasting based on two-factors second-order fuzzy-trend logical relationship groups and the probabilities of.pdf:pdf},
isbn = {9781479942169},
issn = {21682267},
journal = {IEEE Transactions on Cybernetics},
keywords = {Fuzzy forecasting,fuzzy logical relationships,fuzzy time series,fuzzy-trend logical relationship groups,probabilities of trends.},
number = {3},
pages = {405--417},
pmid = {23193240},
publisher = {Elsevier Inc.},
title = {{Fuzzy forecasting based on two-factors second-order fuzzy-trend logical relationship groups and the probabilities of trends of fuzzy logical relationships}},
url = {http://dx.doi.org/10.1016/j.ins.2016.11.004},
volume = {45},
year = {2015}
}
@book{Figurea,
author = {Figure, Supplementary},
doi = {10.15713/ins.mmj.3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Figure - Unknown - No Title No Title_2015.pdf:pdf},
isbn = {9789004310087},
number = {c},
pages = {1--4},
pmid = {29982528},
title = {{No Title No Title_2015}}
}
@article{Setzler2015,
abstract = {A physics-based impedance model of a proton exchange membrane fuel cell is developed, incorporating a coupled oxide growth- oxygen reduction reaction kinetic model. The oxide layer is shown to produce a lowfrequency inductive loop that agrees quantitatively with the experimental inductive loop at current densities as high as 800 mA/cm2, even when kinetic and mass-transfer parameters are fit from polarization curves and cyclic voltammetry instead of electrochemical impedance spectroscopy. The importance of the inductive loop in explaining both AC and DC results is discussed.},
author = {Setzler, B. P. and Fuller, T. F.},
doi = {10.1149/2.0361506jes},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Setzler, Fuller - 2015 - A Physics-Based Impedance Model of Proton Exchange Membrane Fuel Cells Exhibiting Low-Frequency Inductive Loops.pdf:pdf},
isbn = {0013-4651},
issn = {0013-4651},
journal = {Journal of the Electrochemical Society},
number = {6},
pages = {F519--F530},
title = {{A Physics-Based Impedance Model of Proton Exchange Membrane Fuel Cells Exhibiting Low-Frequency Inductive Loops}},
url = {http://jes.ecsdl.org/cgi/doi/10.1149/2.0361506jes},
volume = {162},
year = {2015}
}
@article{Memari2016,
author = {Memari, Hamed and Rahimi, Shahram},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Memari, Rahimi - 2016 - Towards Patient Flow Optimization in Emergency Departments Using Genetic Algorithms.pdf:pdf},
isbn = {9781509028702},
keywords = {Advanced Methodology and Applications of Industria},
pages = {843--850},
title = {{Towards Patient Flow Optimization in Emergency Departments Using Genetic Algorithms}},
year = {2016}
}
@article{Huang2018,
abstract = {Deep convolutional neural networks have liberated its extraordinary power on various tasks. However, it is still very challenging to deploy state-of-the-art models into real-world applications due to their high computational complexity. How can we design a compact and effective network without massive experiments and expert knowledge? In this paper, we propose a simple and effective framework to learn and prune deep models in an end-to-end manner. In our framework, a new type of parameter – scaling factor is first introduced to scale the outputs of specific structures, such as neurons, groups or residual blocks. Then we add sparsity regularizations on these factors, and solve this optimization problem by a modified stochastic Accelerated Proximal Gradient (APG) method. By forcing some of the factors to zero, we can safely remove the corresponding structures, thus prune the unimportant parts of a CNN. Comparing with other structure selection methods that may need thousands of trials or iterative fine-tuning, our method is trained fully end-to-end in one training pass without bells and whistles. We evaluate our method, Sparse Structure Selection with several state-of-the-art CNNs, and demonstrate very promising results with adaptive depth and width selection. Code is available at: https://github.com/huangzehao/sparse-structure-selection.},
archivePrefix = {arXiv},
arxivId = {1707.01213},
author = {Huang, Zehao and Wang, Naiyan},
doi = {10.1007/978-3-030-01270-0_19},
eprint = {1707.01213},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang, Wang - 2018 - Data-Driven Sparse Structure Selection for Deep Neural Networks.pdf:pdf},
isbn = {9783030012694},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Deep network structure learning,Model acceleration,Sparse},
pages = {317--334},
title = {{Data-Driven Sparse Structure Selection for Deep Neural Networks}},
volume = {11220 LNCS},
year = {2018}
}
@techreport{Sudarsono2017,
address = {Surabaya},
author = {Sudarsono, Riszal},
institution = {Institut Teknologi Sepuluh Nopember Surabaya},
pages = {131},
title = {{Perancangan Prediktor Cuaca Maritim Menggunakan Fuzzy Tipe 2 Sebagai Pendukung Keselamatan Nelayan Dengan User Interface Android}},
year = {2017}
}
@article{Nguyen2017,
author = {Nguyen, Linh},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen - 2017 - Trend-cycle Forecasting Based on New Fuzzy Techniques.pdf:pdf},
isbn = {9781509060344},
pages = {0--5},
title = {{Trend-cycle Forecasting Based on New Fuzzy Techniques}},
year = {2017}
}
@article{Yang2019c,
abstract = {Are neural networks biased toward simple functions? Does depth always help learn more complex features? Is training the last layer of a network as good as training all layers? These questions seem unrelated at face value, but in this work we give all of them a common treatment from the spectral perspective. We will study the spectra of the Conjugate Kernel, CK, (also called the Neural Network-Gaussian Process Kernel), and the Neural Tangent Kernel, NTK. Roughly, the CK and the NTK tell us respectively “what a network looks like at initialization” and “what a network looks like during and after training.” Their spectra then encode valuable information about the initial distribution and the training and generalization properties of neural networks. By analyzing the eigenvalues, we lend novel insights into the questions put forth at the beginning, and we verify these insights by extensive experiments of neural networks. We believe the computational tools we develop here for analyzing the spectra of CK and NTK serve as a solid foundation for future studies of deep neural networks. We have open-sourced the code for it and for generating the plots in this paper at github.com/thegregyang/NNspectra.},
archivePrefix = {arXiv},
arxivId = {1907.10599},
author = {Yang, Greg and Salman, Hadi},
eprint = {1907.10599},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang, Salman - 2019 - A fine-grained spectral perspective on neural networks.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {network initialization,spectral perspective,theory},
mendeley-tags = {network initialization,spectral perspective,theory},
title = {{A fine-grained spectral perspective on neural networks}},
year = {2019}
}
@article{Onoro-Rubio2018,
abstract = {Hourglass networks such as the U-Net and V-Net are popular neural architectures for medical image segmentation and counting problems. Typical instances of hourglass networks contain shortcut connections between mirroring layers. These shortcut connections improve the performance and it is hypothesized that this is due to mitigating effects on the vanishing gradient problem and the ability of the model to combine feature maps from earlier and later layers. We propose a method for not only combining feature maps of mirroring layers but also feature maps of layers with different spatial dimensions. For instance, the method enables the integration of the bottleneck feature map with those of the reconstruction layers. The proposed approach is applicable to any hourglass architecture. We evaluated the contextual hourglass networks on image segmentation and object counting problems in the medical domain. We achieve competitive results outperforming popular hourglass networks by up to 17 percentage points.},
archivePrefix = {arXiv},
arxivId = {1806.04009},
author = {O{\~{n}}oro-Rubio, Daniel and Niepert, Mathias},
eprint = {1806.04009},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/O{\~{n}}oro-Rubio, Niepert - 2018 - Contextual Hourglass Networks for Segmentation and Density Estimation.pdf:pdf},
number = {Midl},
pages = {1--3},
title = {{Contextual Hourglass Networks for Segmentation and Density Estimation}},
url = {http://arxiv.org/abs/1806.04009},
year = {2018}
}
@article{Wong2009,
author = {Wong, Jennifer},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wong - 2009 - What is a Survey Paper A survey paper is {\ldots}.pdf:pdf},
title = {{What is a Survey Paper ?? A survey paper is {\ldots}}},
year = {2009}
}
@article{Shi2021,
archivePrefix = {arXiv},
arxivId = {arXiv:2101.09387v1},
author = {Shi, Changhao and Holtz, Chester and Mishne, Gal},
eprint = {arXiv:2101.09387v1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shi, Holtz, Mishne - 2021 - Online Adversarial Purification based on Self-supervised Learning.pdf:pdf},
journal = {International Conference on Learning Representations},
keywords = {adversarial learning,online learning,self-supervised learning},
mendeley-tags = {adversarial learning,online learning,self-supervised learning},
pages = {1--15},
title = {{Online Adversarial Purification based on Self-supervised Learning}},
url = {https://openreview.net/forum?id=_i3ASPp12WS},
year = {2021}
}
@article{Jaffres2018a,
abstract = {The quality and quantity of observed and reanalysed data influence the direction and accuracy of scientific research. This paper reviews the data available for the study of climate and weather patterns in Australia. A list of global reanalysis and satellite data is provided, along with a more detailed review of available in situ (weather station) data in Australia. Regularly updated climate indices are identified that have previously been linked to Australian climate and weather events. Observation of Australian weather is severely hampered by the continents' vastness and remoteness, as evidenced by heavy bias of in situ measurements that are generally clustered in the coastal high-population centres (mainly southeast of Australia), with central and northern regions often having to rely on remote sensing and reanalysis data. Data sparsity can introduce significant uncertainty in terms of extreme weather and climate change management, as variables such as rainfall exhibit high spatial and temporal variability. Several areas for future research are identified, including investigation into the impact of Australian aerosol levels, the connection between soil moisture and flooding potential, and teleconnection between Atlantic sea surface temperature and Australian climate. While this study focusses on data availability to investigate Australian climate patterns, findings are applicable at a global scale.},
author = {Jaffr{\'{e}}s, Jasmine B.D. and Cuff, Chris and Rasmussen, Cecily and Hesson, Aimee S.},
doi = {10.1016/j.earscirev.2017.08.010},
isbn = {0012-8252},
issn = {00128252},
journal = {Earth-Science Reviews},
keywords = {Australia,Climate indices,Data availability,Extreme weather events,Reanalysis,Satellites,Weather stations},
pages = {117--146},
publisher = {Elsevier B.V},
title = {{Teleconnection of atmospheric and oceanic climate anomalies with Australian weather patterns: a review of data availability}},
url = {http://dx.doi.org/10.1016/j.earscirev.2017.08.010},
volume = {176},
year = {2018}
}
@article{Guan2017,
author = {Guan, Xuefang and Xu, Qingxian and Zheng, Yi and Qian, Lei and Lin, Bin},
doi = {10.1016/j.bjm.2017.02.011},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guan et al. - 2017 - Screening and characterization of lactic acid bacterial strains that produce fermented milk and reduce cholesterol.pdf:pdf},
issn = {1517-8382},
journal = {Brazilian Journal of Microbiology},
number = {4},
pages = {730--739},
publisher = {Sociedade Brasileira de Microbiologia},
title = {{Screening and characterization of lactic acid bacterial strains that produce fermented milk and reduce cholesterol levels}},
url = {http://dx.doi.org/10.1016/j.bjm.2017.02.011},
volume = {48},
year = {2017}
}
@book{Lewandowski2015a,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21% with default Glide SP settings to 58% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Lewandowski, Clare M. and Co-investigator, New and Lewandowski, Clare M.},
booktitle = {The effects of brief mindfulness intervention on acute pain experience: An examination of individual difference},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {icle},
pages = {1689--1699},
pmid = {25246403},
title = {{Soft Computing for Control of Non-Linear Dynamical Systems}},
volume = {1},
year = {2015}
}
@article{Liu2009,
author = {Liu, Jing},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu - 2009 - Three Dimensional Diffuse Optical Spectroscopic Imaging (DOSI) use Opt ca Spect oscop c ag g ( OS ) of Breast Tumor in Refl.pdf:pdf},
journal = {Astronomy},
title = {{Three Dimensional Diffuse Optical Spectroscopic Imaging (DOSI) use Opt ca Spect oscop c ag g ( OS ) of Breast Tumor in Reflectance Geometry}},
year = {2009}
}
@article{Costain2021,
abstract = {Neural implicit representations have shown substantial improvements in efficiently storing 3D data, when compared to conventional formats. However, the focus of existing work has mainly been on storage and subsequent reconstruction. In this work, we argue that training neural representations for both reconstruction tasks, alongside conventional tasks, can produce more general encodings that admit equal quality reconstructions to single task training, whilst providing improved results on conventional tasks when compared to single task encodings. Through multi-task experiments on reconstruction, classification, and segmentation our approach learns feature rich encodings that produce high quality results for each task. We also reformulate the segmentation task, creating a more representative challenge for implicit representation contexts.},
archivePrefix = {arXiv},
arxivId = {2101.12690},
author = {Costain, Theo W. and Prisacariu, Victor Adrian},
eprint = {2101.12690},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Costain, Prisacariu - 2021 - Towards Generalising Neural Implicit Representations.pdf:pdf},
keywords = {neural implicit,representation learning,vision},
mendeley-tags = {neural implicit,representation learning,vision},
title = {{Towards Generalising Neural Implicit Representations}},
url = {http://arxiv.org/abs/2101.12690},
year = {2021}
}
@article{Pota1996,
abstract = {The authors present a very simple method, useful for classroom\nteaching, to obtain a minimal state-space representation (with the\nexception of systems where there is a pole-zero cancellation) from a\ntransfer function matrix. The method is direct and does not involve the\nintermediate step of obtaining nonminimal realization-which further\nrequires system reduction routines-and hence is suitable as a compact\nself-contained topic which has been hitherto neglected in undergraduate\nlinear control theory curriculum},
author = {Pota, H.R.},
doi = {10.1109/13.485241},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pota - 1996 - MIMO systems-transfer function to state-space.pdf:pdf},
issn = {0018-9359},
journal = {IEEE Transactions on Education},
number = {1},
pages = {97--99},
title = {{MIMO systems-transfer function to state-space}},
volume = {39},
year = {1996}
}
@article{Samart2009,
abstract = {Heterogeneous catalysis of transesterification using KI/mesoporous silica catalyst was utilized to produce biodiesel from soybean oil and methanol. The effects of reaction temperature, percentage of KI loading, reaction time, and amount of catalyst on the conversion to methyl ester were studied. The results showed that increasing reaction temperature, KI loading and reaction time can enhance the conversion. The optimum condition was the reaction temperature at 70 °C, 15 wt.% of KI, a reaction time of 8 h., and a catalyst amount of 5.0% by weight of the oil which yielded 90.09% of the conversion. The fuel properties of biodiesel from the optimum condition were tested and found that only viscosity showed over standard. However, the high viscosity can be reduced by separation of non-reacting soybean oil. Crown Copyright {\textcopyright} 2009.},
author = {Samart, C. and Sreetongkittikul, P. and Sookman, C.},
doi = {10.1016/j.fuproc.2009.03.017},
isbn = {0378-3820},
issn = {03783820},
journal = {Fuel Processing Technology},
keywords = {Biodiesel,Heterogeneous catalyst,Potassium iodide,Soybean oil},
number = {7-8},
pages = {922--925},
publisher = {Elsevier B.V.},
title = {{Heterogeneous catalysis of transesterification of soybean oil using KI/mesoporous silica}},
url = {http://dx.doi.org/10.1016/j.fuproc.2009.03.017},
volume = {90},
year = {2009}
}
@article{Aziz2013,
abstract = {The productivity of the construction industry worldwide has been declining over the past 40 years. One approach for improving the situation is using lean construction. Lean construction results from the application of a new form of production management to construction. Essential features of lean construction include a clear set of objectives for the delivery process, aimed at maximizing performance for the customer at the project level, concurrent design, construction, and the application of project control throughout the life cycle of the project from design to delivery. An increasing number of construction academics and professionals have been storming the ramparts of conventional construction management in an effort to deliver better value to owners while making real profits. As a result, lean-based tools have emerged and have been successfully applied to simple and complex construction projects. In general, lean construction projects are easier to manage, safer, completed sooner, and cost less and are of better quality. Significant research remains to complete the translation to construction of lean thinking in Egypt. This research will discuss principles, methods, and implementation phases of lean construction showing the waste in construction and how it could be minimized. The Last Planner System technique, which is an important application of the lean construction concepts and methodologies and is more prevalent, proved that it could enhance the construction management practices in various aspects. Also, it is intended to develop methodology for process evaluation and define areas for improvement based on lean approach principles. {\textcopyright} 2013 Production and hosting by Elsevier B.V.},
author = {Aziz, Remon Fayek and Hafez, Sherif Mohamed},
doi = {10.1016/j.aej.2013.04.008},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aziz, Hafez - 2013 - Applying lean thinking in construction and performance improvement.pdf:pdf},
isbn = {0000000000},
issn = {11100168},
journal = {Alexandria Engineering Journal},
keywords = {Construction industry,Improvement theories,Lean construction,Lean production,Lean thinking,Performance and},
number = {4},
pages = {679--695},
pmid = {1470408128},
publisher = {Faculty of Engineering, Alexandria University},
title = {{Applying lean thinking in construction and performance improvement}},
url = {http://dx.doi.org/10.1016/j.aej.2013.04.008},
volume = {52},
year = {2013}
}
@article{Bengio2011,
abstract = {Deep learning algorithms seek to exploit the unknown structure in the input distribution in order to discover good representations, often at multiple levels, with higher-level learned features defined in terms of lower-level features. The objective is to make these higher- level representations more abstract, with their individual features more invariant to most of the variations that are typically present in the training distribution, while collectively preserving as much as possible of the information in the input. Ideally, we would like these representations to disentangle the unknown factors of variation that underlie the training distribution. Such unsupervised learning of representations can be exploited usefully under the hypothesis that the input distribution P(x) is structurally related to some task of interest, say predicting P(y|x). This paper focusses on why unsupervised pre-training of representations can be useful, and how it can be exploited in the transfer learning scenario, where we care about predictions on examples that are not from the same distribution as the training distribution},
author = {Bengio, Yoshua},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bengio - 2011 - Deep Learning of Representations for Unsupervised and Transfer Learning.pdf:pdf},
isbn = {9780971977778},
journal = {JMLR: Workshop and Conference Proceedings},
keywords = {autoencoders,deep learning,domain adaptation,ing,multi-task learning,neural networks,re-,representation learning,self-taught learning,stricted boltzmann machines,transfer learn-,unsupervised learning},
pages = {1--20},
title = {{Deep Learning of Representations for Unsupervised and Transfer Learning}},
volume = {7},
year = {2011}
}
@article{Molchanov2019,
abstract = {We propose a new formulation for pruning convolutional kernels in neural networks to enable efficient inference. We interleave greedy criteria-based pruning with fine-tuning by backpropagation-a computationally efficient procedure that maintains good generalization in the pruned network. We propose a new criterion based on Taylor expansion that approximates the change in the cost function induced by pruning network parameters. We focus on transfer learning, where large pretrained networks are adapted to specialized tasks. The proposed criterion demonstrates superior performance compared to other criteria, e.g. the norm of kernel weights or feature map activation, for pruning large CNNs after adaptation to fine-grained classification tasks (Birds-200 and Flowers-102) relaying only on the first order gradient information. We also show that pruning can lead to more than 10× theoretical reduction in adapted 3D-convolutional filters with a small drop in accuracy in a recurrent gesture classifier. Finally, we show results for the large-scale ImageNet dataset to emphasize the flexibility of our approach.},
archivePrefix = {arXiv},
arxivId = {1611.06440},
author = {Molchanov, Pavlo and Tyree, Stephen and Karras, Tero and Aila, Timo and Kautz, Jan},
eprint = {1611.06440},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Molchanov et al. - 2019 - Pruning convolutional neural networks for resource efficient inference.pdf:pdf},
journal = {5th International Conference on Learning Representations, ICLR 2017 - Conference Track Proceedings},
number = {2015},
pages = {1--17},
title = {{Pruning convolutional neural networks for resource efficient inference}},
year = {2019}
}
@article{Chen2018,
abstract = {We have witnessed rapid evolution of deep neural network architecture design in the past years. These latest progresses greatly facilitate the developments in various areas such as computer vision and natural language processing. However, along with the extraordinary performance, these state-of-the-art models also bring in expensive computational cost. Directly deploying these models into applications with real-time requirement is still infeasible. Recently, Hinton et al. (?) have shown that the dark knowledge within a powerful teacher model can significantly help the training of a smaller and faster student network. These knowledge are vastly beneficial to improve the generalization ability of the student model. Inspired by their work, we introduce a new type of knowledge - cross sample similarities for model compression and acceleration. This knowledge can be naturally derived from deep metric learning model. To transfer them, we bring the “learning to rank” technique into deep metric learning formulation. We test our proposed DarkRank method on various metric learning tasks including pedestrian re-identification, image retrieval and image clustering. The results are quite encouraging. Our method can improve over the baseline method by a large margin. Moreover, it is fully compatible with other existing methods. When combined, the performance can be further boosted.},
archivePrefix = {arXiv},
arxivId = {1707.01220},
author = {Chen, Yuntao and Wang, Naiyan and Zhang, Zhaoxiang},
eprint = {1707.01220},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Wang, Zhang - 2018 - DarkRank Accelerating deep metric learning via cross sample similarities transfer.pdf:pdf},
isbn = {9781577358008},
journal = {32nd AAAI Conference on Artificial Intelligence, AAAI 2018},
pages = {2852--2859},
title = {{DarkRank: Accelerating deep metric learning via cross sample similarities transfer}},
year = {2018}
}
@article{Spielvogel2005,
abstract = {Originally published: Belmont, Calif. : Thomson Wadsworth, c2006. 6th ed. This book is part of the modular book, Western Civilization / Jackson J. Spielvogel. 6th ed. Belmont, Calif. : Thomson Wadsworth, c2006. Also published: v. A. To 1500--v. B. 1300-1815. Volume B concludes with Chapter 19, A revolution of politics, the era of the French Revolution and Napoleon. [This] narrative weaves the political, economic, social, religious, intellectual, cultural, and military aspects of history ... Each chapter offers a substantial introduction and conclusion, providing students a context for these disparate themes. [The author includes] excerpts of over 200 primary sources--including official documents, poems, and songs--that enliven the past while introducing students to source material that forms the basis of historical scholarship. -http://www.wadsworth.com. A revolution in politics, the era of the French Revolution and Napoleon -- The Industrial Revolution and its impact on European society -- Reaction, revolution, and romanticism, 1815-1850 -- An age of nationalism and realism, 1850-1871 -- Mass society in an "age of progress," 1871-1894 -- An age of modernity, anxiety, and imperialism, 1894-1914 -- The beginning of the twentieth-century crisis, war and revolution -- The futile search for stability, Europe between the wars, 1919-1939 -- The deepening of the European crisis, World War II -- Cold War and a new western world, 1945-1973 -- The contemporary Western world, since 1973 -- Glossary.},
author = {Spielvogel, Jackson J.},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Spielvogel - 2005 - The Industrial Revolution and Its Impact on European Society.pdf:pdf},
isbn = {0534646077},
journal = {Western civilization. Volume C, Since 1789},
pages = {583--608},
title = {{The Industrial Revolution and Its Impact on European Society}},
year = {2005}
}
@article{Guo2017,
abstract = {This paper proposes a method for de-blurring of images captured in the dynamic deformation of materials. De-blurring is achieved based on the dynamic-based approach, which is used to estimate the Point Spread Function (PSF) during the camera exposure window. The deconvolution process involving iterative matrix calculations of pixels, is then performed on the GPU to decrease the time cost. Compared to the Gauss method and the Lucy–Richardson method, it has the best result of the image restoration. The proposed method has been evaluated by using the Hopkinson bar loading system. In comparison to the blurry image, the proposed method has successfully restored the image. It is also demonstrated from image processing applications that the de-blurring method can improve the accuracy and the stability of the digital imaging correlation measurement.},
author = {Guo, X. and Li, Y. and Suo, T. and Liu, H. and Zhang, C.},
doi = {10.1016/j.optlaseng.2017.05.015},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guo et al. - 2017 - Dynamic deformation image de-blurring and image processing for digital imaging correlation measurement.pdf:pdf},
issn = {01438166},
journal = {Optics and Lasers in Engineering},
keywords = {Digital image correlation,Dynamic deformation,Hopkinson bar,PSF},
number = {December 2016},
pages = {1339--1351},
title = {{Dynamic deformation image de-blurring and image processing for digital imaging correlation measurement}},
volume = {98},
year = {2017}
}
@article{Parisi2018a,
abstract = {Artificial autonomous agents and robots interacting in complex environments are required to continually acquire and fine-tune knowledge over sustained periods of time. The ability to learn from continuous streams of information is referred to as lifelong learning and represents a long-standing challenge for neural network models due to catastrophic forgetting in which novel sensory experience interferes with existing representations and leads to abrupt decreases in the performance on previously acquired knowledge. Computational models of lifelong learning typically alleviate catastrophic forgetting in experimental scenarios with given datasets of static images and limited complexity, thereby differing significantly from the conditions artificial agents are exposed to. In more natural settings, sequential information may become progressively available over time and access to previous experience may be restricted. Therefore, specialized neural network mechanisms are required that adapt to novel sequential experience while preventing disruptive interference with existing representations. In this paper, we propose a dual-memory self-organizing architecture for lifelong learning scenarios. The architecture comprises two growing recurrent networks with the complementary tasks of learning object instances (episodic memory) and categories (semantic memory). Both growing networks can expand in response to novel sensory experience: the episodic memory learns fine-grained spatiotemporal representations of object instances in an unsupervised fashion while the semantic memory uses task-relevant signals to regulate structural plasticity levels and develop more compact representations from episodic experience. For the consolidation of knowledge in the absence of external sensory input, the episodic memory periodically replays trajectories of neural reactivations. We evaluate the proposed model on the CORe50 benchmark dataset for continuous object recognition, showing that we significantly outperform current methods of lifelong learning in three different incremental learning scenarios.},
author = {Parisi, German I and Tani, Jun and Weber, Cornelius and Wermter, Stefan},
doi = {10.3389/fnbot.2018.00078},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Parisi et al. - 2018 - Lifelong Learning of Spatiotemporal Representations With Dual-Memory Recurrent Self-Organization.pdf:pdf},
issn = {1662-5218},
journal = {Frontiers in Neurorobotics},
keywords = {CLS,Incremental Learning,Lifelong learning,Memory,Self-organizing Network,[core50],[dual],[som],object recognition systems},
language = {English},
mendeley-tags = {[core50],[dual],[som]},
title = {{Lifelong Learning of Spatiotemporal Representations With Dual-Memory Recurrent Self-Organization}},
url = {https://www.frontiersin.org/articles/10.3389/fnbot.2018.00078/full},
volume = {12},
year = {2018}
}
@article{Razavi2008,
abstract = {We describe a fuzzy-logic-based scheduling algorithm for synchronous optical packet switches that provides quality of service for delay-constrained traffic. The proposed method considers both packet importance as well as delay constraints. One of the advantages of a fuzzy controller is the fact that, regardless of the design complexity, it can be implemented as a simple look-up table. This makes it ideal for high-speed optical switches. We have used two fuzzy controllers: one to select a packet to be forwarded to an output port and another to decide which packet(s) should be buffered or dropped. In a simulation example, video traffic with three priority classes is considered. The results show up to 3 dBs of improvement in the quality of the received video, resulting from the packet loss differentiation achieved by employing the proposed fuzzy packet scheduling approach. {\textcopyright} 2008 Optical Society of America.},
author = {Razavi, R. and Hugues-Salas, E. and Quinlan, T. and Walker, S.D.},
doi = {10.1364/JON.7.000119},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Razavi et al. - 2008 - Fuzzy logic packet scheduling approach for QoS provision of delay-constrained traffic in synchronous optical pack.pdf:pdf},
issn = {15365379},
journal = {Journal of Optical Networking},
number = {2},
pages = {119--131},
title = {{Fuzzy logic packet scheduling approach for QoS provision of delay-constrained traffic in synchronous optical packet switched networks}},
volume = {7},
year = {2008}
}
@article{Regtien2012,
author = {Regtien, Paul P.L.},
doi = {10.1016/B978-0-12-391497-2.00008-X},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Regtien - 2012 - Piezoelectric Sensors.pdf:pdf},
isbn = {9780123914972},
journal = {Sensors for Mechatronics},
pages = {219--239},
title = {{Piezoelectric Sensors}},
url = {http://linkinghub.elsevier.com/retrieve/pii/B978012391497200008X},
year = {2012}
}
@article{Mokyr1998,
abstract = {Purpose – This paper aims to trace the history, application areas and users of Classical Analytics and Big Data Analytics. Design/methodology/approach – The paper discusses different types of Classical and Big Data Analytical techniques and application areas from the early days to present day. Findings – Businesses can benefit from a deeper understanding of Classical and Big Data Analytics to make better and more informed decisions. Originality/value – This is a historical perspective from the early days of analytics to present day use of analytics.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Mokyr, Joel},
doi = {10.1108/JCM-04-2015-1399},
eprint = {arXiv:1011.1669v3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mokyr - 1998 - The Second Industrial Revolution, 1870-1914.pdf:pdf},
isbn = {0920130437},
issn = {00224359},
journal = {In V. Castronono (Ed.), Storiadell'economia Mondiale. Rome: Laterza.},
keywords = {*Electronic Commerce,*Information,*Online Social Networks,*Privileged Communication,0,2310:Planning,3940:Marketing & Advertising,5220:Information technology management,5240:Software & systems,7000:Marketing,8301:Advertising agencies,8305:Professional services not elsewhere classifie,9130:Experiment/theoretical treatment,9130:Experimental/theoretical,9179:Asia & the Pacific,9520:Small business,Advertising agencies,Analytics,Automation,BIG data,BUSINESS enterprises,Behavioral Economics,Big Data,Big data,Big data analytics,Big data definition,Business,Business And Economics--Management,Business And Economics--Marketing And Purchasing,Business Intelligence,Business ecosystems,Business intelligence,Business intelligence software,Business transformation,Case studies,Clickstream,Complexity,Computers--Information Science And Information The,Consumer Behavior,Consumer analytics,Consumer behavior,Consumer insights,Continuous processing,Corporate culture,Customer Effort Score,Customer analytics,Customer feedback metrics,Customer journey,Customer retention,Customer satisfaction,DECISION making,Data analysis,Data practices,Decision support systems,Digitization,Disruptive innovation,Distributors,Ecosystems,Firm performance,Franchisors,Human,INFORMATION resources management,Ignorance,Impact analysis,Induction,Information industry,Information society,Information systems,Information technology,Innovations,Internet/e-commerce,Knowledge fusion,MARKETING,MICROSOFT Corp.,Management decisions,Marketing,Marketing analytics,Marketing channels,Marketing intelligence,Marketing mix,Multichannel,NPD,NPS,Net Promoter Score,OLAP,Online marketing,Performance implications of customer analytics,Predictive analytics,Product development,Purchase decision process,Qualitative Research,Resource-based theory,Retailers,Risk Assessment,SOCIAL interaction,SOCIETIES,SUPERCOMPUTERS,SWOT analysis,Small & medium sized enterprises-SME,Societal transformation,Strategic planning,Studies,Survey data,Survey versus log data,Systematic review,TRANSLATING & interpreting,Taiwan,Technological change,Traditional marketing analytics,Trends,Unstructured data analytics,Wholesalers,a revolution in how,affordances,analysis,and digital marketing,article,been,behavioral economics,benefits realisation,big data,big data analytics,boundaries,business intelligence and analytics,c550,c800,conditions for strategy-making has,consumer behavior,consumer panels,contemporary marketing,control,crm,customer data,data,data collection,data management,data mining,data warehouse,decision,decision support systems,decisions,digital marketing,direct,gossip,human consumer behavior,in the last few,information providers,information systems design,jel classification,literature review,m1,m150,market research,market segmentation,marketing,marketing data,model of network marketing,months,more than micro,new media,new media affordances,new technologies create new,of,paper type conceptual paper,performance improvement,predictive,purchase behavior,qualitative research industries,reverse use of customer,roi,service logic,service-based business model,small data,social media,socio-materiality,strategy as practice,system dynamics,technology,testing,text analysis,the idm,the institute of direct,the question of how,tourism,training,university management,we market,web 2},
number = {August 1998},
pages = {1--16},
pmid = {1650590391},
title = {{The Second Industrial Revolution, 1870-1914}},
url = {http://web.a.ebscohost.com/ehost/pdfviewer/pdfviewer?sid=c72752a6-fd0c-4184-ad0b-39ae0c9c16d8@sessionmgr4003&vid=1&hid=4209%0Ahttp://www.emeraldinsight.com/doi/10.1108/SL-04-2016-0018%0Ahttp://banques.enap.ca/Proxy.pl?adresse=http://search.proquest.com/do},
year = {1998}
}
@article{Chen2016c,
abstract = {We introduce techniques for rapidly transferring the information stored in one neural net into another neural net. The main purpose is to accelerate the training of a significantly larger neural net. During real-world workflows, one often trains very many different neural networks during the experimentation and design process. This is a wasteful process in which each new model is trained from scratch. Our Net2Net technique accelerates the experimentation process by instantaneously transferring the knowledge from a previous network to each new deeper or wider network. Our techniques are based on the concept of function-preserving transformations between neural network specifications. This differs from previous approaches to pre-training that altered the function represented by a neural net when adding layers to it. Using our knowledge transfer mechanism to add depth to Inception modules, we demonstrate a new state of the art accuracy rating on the ImageNet dataset.},
archivePrefix = {arXiv},
arxivId = {1511.05641},
author = {Chen, Tianqi and Goodfellow, Ian and Shlens, Jonathon},
eprint = {1511.05641},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Goodfellow, Shlens - 2016 - Net2Net Accelerating learning via knowledge transfer(3).pdf:pdf},
journal = {4th International Conference on Learning Representations, ICLR 2016 - Conference Track Proceedings},
pages = {1--12},
title = {{Net2Net: Accelerating learning via knowledge transfer}},
year = {2016}
}
@article{Eth2018,
author = {Eth, Z and Alistarh, Dan},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Eth, Alistarh - 2018 - MODEL COMPRESSION VIA DISTILLATION AND QUANTIZATION.pdf:pdf},
journal = {Iclr 2018},
number = {2015},
pages = {1--21},
title = {{MODEL COMPRESSION VIA DISTILLATION AND QUANTIZATION}},
year = {2018}
}
@article{Dosovitskiy2020a,
abstract = {While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.},
archivePrefix = {arXiv},
arxivId = {2010.11929},
author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
eprint = {2010.11929},
file = {:home/user/Downloads/2010.11929.pdf:pdf},
keywords = {transformer},
mendeley-tags = {transformer},
title = {{An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}},
url = {http://arxiv.org/abs/2010.11929},
year = {2020}
}
@article{Nayiroh2013,
abstract = {A. Pengertian Material Komposit (komposit) Komposit adalah suatu jenis bahan baru hasil rekayasa yang terdiri dari dua atau lebih bahan dimana sifat masing-masing bahan berbeda satu sama lainnya baik itu sifat kimia maupun fisikanya dan tetap terpisah dalam hasil akhir bahan tersebut (bahan komposit). Dengan adanya perbedaan dari material penyusunnya maka komposit antar material harus berikatan dengan kuat, sehingga perlu adanya penambahan wetting agent. Beberapa definisi komposit sebagai berikut • Tingkat dasar : pada molekul tunggal dan kisi kristal, bila material yang disusun dari dua atom atau lebih disebut komposit (contoh senyawa, paduan, polymer dan keramik) • Mikrostruktur : pada kristal, phase dan senyawa, bila material disusun dari dua phase atau senyawa atau lebih disebut komposit (contoh paduan Fe dan C) • Makrostruktur : material yang disusun dari campuran dua atau lebih penyusun makro yang berbeda dalam bentuk dan/atau komposisi dan tidak larut satu dengan yang lain disebut material komposit (definisi secara makro ini yang biasa dipakai) B. Tujuan pembuatan material komposit},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Nayiroh, Nurun},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nayiroh - 2013 - Teknologi Material Komposit.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
journal = {UIN Malang},
pages = {21},
pmid = {25246403},
title = {{Teknologi Material Komposit}},
year = {2013}
}
@inproceedings{Yuan2021a,
abstract = {A standard practice of deploying deep neural networks is to apply the same architecture to all the input instances. However, a fixed architecture may not be suitable for different data with high diversity. To boost the model capacity , existing methods usually employ larger convolutional kernels or deeper network layers, which incurs prohibitive computational costs. In this paper, we address this issue by proposing Differentiable Dynamic Wirings (DDW), which learns the instance-aware connectivity that creates different wiring patterns for different instances. 1) Specifically, the network is initialized as a complete directed acyclic graph, where the nodes represent convolutional blocks and the edges represent the connection paths. 2) We generate edge weights by a learnable module, Router, and select the edges whose weights are larger than a threshold, to adjust the connectivity of the neural network structure. 3) Instead of using the same path of the network, DDW aggregates features dynamically in each node, which allows the network to have more representation power. To facilitate effective training, we further represent the network connectivity of each sample as an adjacency matrix. The matrix is updated to aggregate features in the forward pass, cached in the memory, and used for gradient computing in the backward pass. We validate the effectiveness of our approach with several mainstream architectures, including MobileNetV2, ResNet, ResNeXt, and RegNet. Extensive experiments are performed on ImageNet classification and COCO object detection, which demonstrates the effectiveness and generalization ability of our approach.},
author = {Yuan, Kun and Li, Quanquan and Guo, Shaopeng and Chen, Dapeng and Zhou, Aojun and Yu, Fengwei and Liu, Ziwei},
booktitle = {International Conference on Computer Vision},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yuan et al. - 2021 - Differentiable Dynamic Wirings for Neural Networks.pdf:pdf},
keywords = {differentiable wirings,dynamic neural networks},
mendeley-tags = {differentiable wirings,dynamic neural networks},
pages = {327--336},
title = {{Differentiable Dynamic Wirings for Neural Networks}},
year = {2021}
}
@article{He,
archivePrefix = {arXiv},
arxivId = {arXiv:1512.03385v1},
author = {He, Kaiming},
eprint = {arXiv:1512.03385v1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/He - Unknown - Deep Residual Learning for Image Recognition.pdf:pdf},
title = {{Deep Residual Learning for Image Recognition}}
}
@book{Forbes2008a,
abstract = {For details of our global editorial offices, for customer services and for information about how to apply for permission to reuse the copyright material in this book please see our website at www.wiley.com. The publisher and the author make no representations or warranties with respect to the accuracy or completeness of the contents of this work and specifically disclaim all warranties, including without limitation any implied warranties of fitness for a particular purpose. This work is sold with the understanding that the publisher is not engaged in rendering professional services. The advice and strategies contained herein may not be suitable for every situation. In view of ongoing research, equipment modifications, changes in governmental regulations, and the constant flow of information relating to the use of experimental reagents, equipment, and devices, the reader is urged to review and evaluate the information provided in the package insert or instructions for each chemical, piece of equipment, reagent, or device for, among other things, any changes in the instructions or indication of usage and for added warnings and precautions.},
author = {Forbes, Peter},
booktitle = {Scientific American},
doi = {10.1038/scientificamerican0808-88},
isbn = {9781119991779},
issn = {0036-8733},
pages = {88--95},
pmid = {18666684},
title = {{Self-cleaning materials}},
volume = {299},
year = {2008}
}
@article{Farooqui2018,
abstract = {Graphene has captured the attention of many researchers due to its wide potential in energy-related applications; it possess high thermal and electrical conductivity, great mechanical strength, optical transparency, inherent flexibility, huge surface area, and unique two-dimensional structure. Graphene oxide and polymer composites are commonly blended for various purposes, especially in energy devices. The fuel cell technology has discovered as one of the best alternative for future energy source; however, an extensive research is still required for the further improvement of key components such as proton exchange membranes, anode and cathode. This review has highlighted the influence of graphene in membrane modification for various fuel cells. There are many reviews on polymer exchange membranes but this is the only review that specifically deals with the graphene based membranes for fuel cells. Also, the review has covered the substantial types of fuel cells; however, focus is given to the polymer electrolyte fuel cells (PEMFCs) and direct methanol fuel cells (DMFCs). The discussion will provide a better understanding of graphene features, its compatibility with different polymers and solvents, its working principle in polymer matrices, and future prospects of graphene-based membranes in fuel cells.},
author = {Farooqui, U. R. and Ahmad, A. L. and Hamid, N. A.},
doi = {10.1016/j.rser.2017.09.081},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Farooqui, Ahmad, Hamid - 2018 - Graphene oxide A promising membrane material for fuel cells.pdf:pdf},
issn = {18790690},
journal = {Renewable and Sustainable Energy Reviews},
keywords = {Energy,Fuel cells,Graphene,Membrane},
number = {August 2016},
pages = {714--733},
publisher = {Elsevier Ltd},
title = {{Graphene oxide: A promising membrane material for fuel cells}},
url = {http://dx.doi.org/10.1016/j.rser.2017.09.081},
volume = {82},
year = {2018}
}
@article{Bayu2013,
author = {Bayu, Bantara and Putra, Perrmana and Hatta, Agus M},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bayu, Putra, Hatta - 2013 - Perancangan Coupling Antara Solar Collector - Serat Optik Untuk Sistem Pencahayaan Alami.pdf:pdf},
number = {1},
pages = {1--5},
title = {{Perancangan Coupling Antara Solar Collector - Serat Optik Untuk Sistem Pencahayaan Alami}},
volume = {1},
year = {2013}
}
@article{Chen2020m,
abstract = {One paradigm for learning from few labeled examples while making best use of a large amount of unlabeled data is unsupervised pretraining followed by supervised fine-tuning. Although this paradigm uses unlabeled data in a task-agnostic way, in contrast to most previous approaches to semi-supervised learning for computer vision, we show that it is surprisingly effective for semi-supervised learning on ImageNet. A key ingredient of our approach is the use of a big (deep and wide) network during pretraining and fine-tuning. We find that, the fewer the labels, the more this approach (task-agnostic use of unlabeled data) benefits from a bigger network. After fine-tuning, the big network can be further improved and distilled into a much smaller one with little loss in classification accuracy by using the unlabeled examples for a second time, but in a task-specific way. The proposed semi-supervised learning algorithm can be summarized in three steps: unsupervised pretraining of a big ResNet model using SimCLRv2 (a modification of SimCLR [1]), supervised fine-tuning on a few labeled examples, and distillation with unlabeled examples for refining and transferring the task-specific knowledge. This procedure achieves 73.9% ImageNet top-1 accuracy with just 1% of the labels (≤13 labeled images per class) using ResNet-50, a 10× improvement in label efficiency over the previous state-of-the-art. With 10% of labels, ResNet-50 trained with our method achieves 77.5% top-1 accuracy, outperforming standard supervised training with all of the labels. 1},
archivePrefix = {arXiv},
arxivId = {2006.10029},
author = {Chen, Ting and Kornblith, Simon and Swersky, Kevin and Norouzi, Mohammad and Hinton, Geoffrey},
eprint = {2006.10029},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2020 - Big Self-Supervised Models are Strong Semi-Supervised Learners.pdf:pdf},
journal = {arXiv},
keywords = {self-supervised learning,semi-supervised learning},
mendeley-tags = {self-supervised learning,semi-supervised learning},
number = {NeurIPS},
pages = {1--18},
title = {{Big Self-Supervised Models are Strong Semi-Supervised Learners}},
url = {https://github.com/google-research/simclr https://arxiv.org/abs/2006.10029},
year = {2020}
}
@article{gupta2020a,
abstract = {The continual learning problem involves training models with limited capacity to perform well on a set of an unknown number of sequentially arriving tasks. While meta-learning shows great potential for reducing interference between old and new tasks, the current training procedures tend to be either slow or offline, and sensitive to many hyper-parameters. In this work, we propose Look-ahead MAML (La-MAML), a fast optimisation-based meta-learning algorithm for online-continual learning, aided by a small episodic memory. Our proposed modulation of per-parameter learning rates in our meta-learning update allows us to draw connections to prior work on hypergradients and meta-descent. This provides a more flexible and efficient way to mitigate catastrophic forgetting compared to conventional prior-based methods. La-MAML achieves performance superior to other replay-based, prior-based and meta-learning based approaches for continual learning on real-world visual classification benchmarks.},
archivePrefix = {arXiv},
arxivId = {2007.13904},
author = {Gupta, Gunshi and Yadav, Karmesh and Paull, Liam},
eprint = {2007.13904},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gupta, Yadav, Paull - 2020 - La-MAML Look-ahead Meta Learning for Continual Learning - Supplemental.pdf:pdf;:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gupta, Yadav, Paull - 2020 - La-MAML Look-ahead Meta Learning for Continual Learning - Supplemental(2).pdf:pdf},
journal = {arXiv},
pages = {12--20},
title = {{La-MAML: Look-ahead Meta Learning for Continual Learning - Supplemental}},
url = {https://arxiv.org/abs/2007.13904},
year = {2020}
}
@article{Farquhar2018,
abstract = {The experiments used in current continual learning research do not faithfully assess fundamental challenges of learning continually. We examine standard evaluations and show why these evaluations make some types of continual learning approaches look better than they are. In particular, current evaluations are biased towards continual learning approaches that treat previous models as a prior (e.g., EWC, VCL). We introduce desiderata for continual learning evaluations and explain why their absence creates misleading comparisons. Our analysis calls for a reprioritization of research effort by the community.},
archivePrefix = {arXiv},
arxivId = {1805.09733},
author = {Farquhar, Sebastian and Gal, Yarin},
eprint = {1805.09733},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Farquhar, Gal - 2018 - Towards robust evaluations of continual learning.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {continual learning,review,survey},
mendeley-tags = {continual learning,review,survey},
title = {{Towards robust evaluations of continual learning}},
year = {2018}
}
@article{Dohare2021,
abstract = {The Backprop algorithm for learning in neural networks utilizes two mechanisms: first, stochastic gradient descent and second, initialization with small random weights, where the latter is essential to the effectiveness of the former. We show that in continual learning setups, Backprop performs well initially, but over time its performance degrades. Stochastic gradient descent alone is insufficient to learn continually; the initial randomness enables only initial learning but not continual learning. To the best of our knowledge, ours is the first result showing this degradation in Backprop's ability to learn. To address this issue, we propose an algorithm that continually injects random features alongside gradient descent using a new generate-and-test process. We call this the Continual Backprop algorithm. We show that, unlike Backprop, Continual Backprop is able to continually adapt in both supervised and reinforcement learning problems. We expect that as continual learning becomes more common in future applications, a method like Continual Backprop will be essential where the advantages of random initialization are present throughout learning.},
archivePrefix = {arXiv},
arxivId = {2108.06325},
author = {Dohare, Shibhansh and Mahmood, A. Rupam and Sutton, Richard S.},
eprint = {2108.06325},
file = {:home/user/Downloads/2108.06325.pdf:pdf},
keywords = {continual learning},
mendeley-tags = {continual learning},
pages = {1--17},
title = {{Continual Backprop: Stochastic Gradient Descent with Persistent Randomness}},
url = {http://arxiv.org/abs/2108.06325},
year = {2021}
}
@article{Istiana2013,
abstract = {Salah satu bentuk pengakuan atas ide, pendapat orang lain dalam sebuah karya\ntulis adalah dengan menuliskan sumber rujukan yang secara nyata kita gunakan.\nHal ini merupukan kejujuran intelektual...},
author = {Istiana, Purwani},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Istiana - 2013 - Membuat Sitasi dan Daftar Pustaka.pdf:pdf},
journal = {ResearchGate},
number = {May 2013},
title = {{Membuat Sitasi dan Daftar Pustaka}},
url = {https://www.researchgate.net/publication/270050381_Membuat_Sitasi_dan_Daftar_Pustaka},
year = {2013}
}
@article{Silva2016,
author = {Silva, F and Teixeira, B and Teixeira, N and Pinto, T and Pra{\c{c}}a, I and Vale, Z and Abreu, S L},
doi = {10.1109/DEXA.2016.53},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Silva et al. - 2016 - Application of Hybrid Neural Fuzzy Inference System to Forecast Solar Intensity.pdf:pdf},
pages = {161--165},
title = {{Application of Hybrid Neural Fuzzy Inference System to Forecast Solar Intensity}},
year = {2016}
}
@article{Walid2012,
author = {Walid, Problems and Atomi, Hasen},
title = {{the Effect of Data Preprocessing on the Performance of Artificial Neural Networks Techniques for Classification}},
url = {http://eprints.uthm.edu.my/3635/1/WALID_HASEN_ATOMI.pdf},
year = {2012}
}
@article{Mermillod2013,
abstract = {... OK Please enter the date in dd/mm/yyyy format or use the calendar icon to the left of the date field. Opinion ARTICLE. ... Send. Cancel. Your message has been sent to the Frontiers Administration Office and will be deal with as soon as possible.\n},
author = {Mermillod, Martial and Bugaiska, Aur{\'{e}}lia and Bonin, Patrick},
doi = {10.3389/fpsyg.2013.00504},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mermillod, Bugaiska, Bonin - 2013 - The stability-plasticity dilemma investigating the continuum from catastrophic forgetting to age-lim.pdf:pdf},
issn = {1664-1078},
journal = {Frontiers in Psychology},
number = {August},
pages = {1--3},
pmid = {23935590},
title = {{The stability-plasticity dilemma: investigating the continuum from catastrophic forgetting to age-limited learning effects}},
volume = {4},
year = {2013}
}
@article{Cao2020,
abstract = {The Non-Local Network (NLNet) presents a pioneering approach for capturing long-range dependencies within an image, via aggregating query-specific global context to each query position. However, through a rigorous empirical analysis, we have found that the global contexts modeled by the non-local network are almost the same for different query positions. In this paper, we take advantage of this finding to create a simplified network based on a query-independent formulation, which maintains the accuracy of NLNet but with significantly less computation. We further replace the one-layer transformation function of the non-local block by a two-layer bottleneck, which further reduces the parameter number considerably. The resulting network element, called the global context (GC) block, effectively models global context in a lightweight manner, allowing it to be applied at multiple layers of a backbone network to form a global context network (GCNet). Experiments show that GCNet generally outperforms NLNet on major benchmarks for various recognition tasks. The code and network configurations are available at https://github.com/xvjiarui/GCNet.},
archivePrefix = {arXiv},
arxivId = {2012.13375},
author = {Cao, Yue and Xu, Jiarui and Lin, Stephen and Wei, Fangyun and Hu, Han},
eprint = {2012.13375},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cao et al. - 2020 - Global Context Networks.pdf:pdf},
keywords = {neural networks},
mendeley-tags = {neural networks},
pages = {1--14},
title = {{Global Context Networks}},
url = {http://arxiv.org/abs/2012.13375 https://github.com/xvjiarui/GCNet},
year = {2020}
}
@article{Chen2020l,
abstract = {Contrastive learning is an effective method for learning visual representations. In most cases, this involves adding an explicit loss function to encourage similar images to have similar representations, and different images to have different representations. Inspired by contrastive learning, we introduce a clever input construction for Implicit Contrastive Learning (ImCLR), primarily in the supervised setting: there, the network can implicitly learn to differentiate between similar and dissimilar images. Each input is presented as a concatenation of two images, and the label is the mean of the two one-hot labels. Furthermore, this requires almost no change to existing pipelines, which allows for easy integration and for fair demonstration of effectiveness on a wide range of well-accepted benchmarks. Namely, there is no change to loss, no change to hyperparameters, and no change to general network architecture. We show that ImCLR improves the test error in the supervised setting across a variety of settings, including 3.24% on Tiny ImageNet, 1.30% on CIFAR-100, 0.14% on CIFAR-10, and 2.28% on STL-10. We show that this holds across different number of labeled samples, maintaining approximately a 2% gap in test accuracy down to using only 5% of the whole dataset. We further show that gains hold for robustness to common input corruptions and perturbations at varying severities with a 0.72% improvement on CIFAR-100-C, and in the semi-supervised setting with a 2.16% improvement with the standard benchmark $\Pi$-model. We demonstrate that ImCLR is complementary to existing data augmentation techniques, achieving over 1% improvement on CIFAR-100 and 2% improvement on Tiny ImageNet by combining ImCLR with CutMix over either baseline, and 2% by combining ImCLR with AutoAugment over either baseline.},
archivePrefix = {arXiv},
arxivId = {2011.12618},
author = {Chen, John and Sinha, Samarth and Kyrillidis, Anastasios},
eprint = {2011.12618},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Sinha, Kyrillidis - 2020 - ImCLR Implicit Contrastive Learning for Image Classification.pdf:pdf},
title = {{ImCLR: Implicit Contrastive Learning for Image Classification}},
url = {http://arxiv.org/abs/2011.12618},
year = {2020}
}
@article{Liua,
author = {Liu, Yang},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu - Unknown - Latent Topic-aware Multi-Label Classification.pdf:pdf},
keywords = {feature-,label correlation,multi-label learning,sample and feature extraction,topic},
pages = {1--16},
title = {{Latent Topic-aware Multi-Label Classification}}
}
@article{May2011,
abstract = {Artificial neural networks may probably be the single most successful technology in the last two decades which has been widely used in a large variety of applications in various areas. The purpose of this book is to provide recent advances of artificial neural networks in biomedical applications. The book begins with fundamentals of artificial neural networks, which cover an introduction, design, and optimization. Advanced architectures for biomedical applications, which offer improved performance and desirable properties, follow. Parts continue with biological applications such as gene, plant biology, and stem cell, medical applications such as skin diseases, sclerosis, anesthesia, and physiotherapy, and clinical and other applications such as clinical outcome, telecare, and pre-med student failure prediction. Thus, this book will be a fundamental source of recent advances and applications of artificial neural networks in biomedical areas. The target audience includes professors and students in engineering and medical schools, researchers and engineers in biomedical industries, medical doctors, and healthcare professionals.},
author = {May, Robert and Dandy, Graeme and Maier, Holger},
doi = {10.5772/16004},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/May, Dandy, Maier - 2011 - Review of Input Variable Selection Methods for Artificial Neural Networks.pdf:pdf},
isbn = {978-953-307-243-2},
issn = {978-953-307-243-2},
journal = {Artificial Neural Networks - Methodological Advances and Biomedical Applications},
title = {{Review of Input Variable Selection Methods for Artificial Neural Networks}},
url = {http://www.intechopen.com/books/artificial-neural-networks-methodological-advances-and-biomedical-applications/review-of-input-variable-selection-methods-for-artificial-neural-networks},
year = {2011}
}
@article{Pokutta2020,
abstract = {This paper studies the empirical efficacy and benefits of using projection-free first-order methods in the form of Conditional Gradients, a.k.a. Frank-Wolfe methods, for training Neural Networks with constrained parameters. We draw comparisons both to current state-of-the-art stochastic Gradient Descent methods as well as across different variants of stochastic Conditional Gradients. In particular, we show the general feasibility of training Neural Networks whose parameters are constrained by a convex feasible region using Frank-Wolfe algorithms and compare different stochastic variants. We then show that, by choosing an appropriate region, one can achieve performance exceeding that of unconstrained stochastic Gradient Descent and matching state-of-the-art results relying on $L^2$-regularization. Lastly, we also demonstrate that, besides impacting performance, the particular choice of constraints can have a drastic impact on the learned representations.},
archivePrefix = {arXiv},
arxivId = {2010.07243},
author = {Pokutta, Sebastian and Spiegel, Christoph and Zimmer, Max},
eprint = {2010.07243},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pokutta, Spiegel, Zimmer - 2020 - Deep Neural Network Training with Frank-Wolfe.pdf:pdf},
number = {NeurIPS},
pages = {0--5},
title = {{Deep Neural Network Training with Frank-Wolfe}},
url = {http://arxiv.org/abs/2010.07243},
year = {2020}
}
@article{Keller2020,
abstract = {Efficient gradient computation of the Jacobian determinant term is a core problem of the normalizing flow framework. Thus, most proposed flow models either restrict to a function class with easy evaluation of the Jacobian determinant, or an efficient estimator thereof. However, these restrictions limit the performance of such density models, frequently requiring significant depth to reach desired performance levels. In this work, we propose Self Normalizing Flows, a flexible framework for training normalizing flows by replacing expensive terms in the gradient by learned approximate inverses at each layer. This reduces the computational complexity of each layer's exact update from $\mathcal{O}(D^3)$ to $\mathcal{O}(D^2)$, allowing for the training of flow architectures which were otherwise computationally infeasible, while also providing efficient sampling. We show experimentally that such models are remarkably stable and optimize to similar data likelihood values as their exact gradient counterparts, while surpassing the performance of their functionally constrained counterparts.},
archivePrefix = {arXiv},
arxivId = {2011.07248},
author = {Keller, T. Anderson and Peters, Jorn W. T. and Jaini, Priyank and Hoogeboom, Emiel and Forr{\'{e}}, Patrick and Welling, Max},
eprint = {2011.07248},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Keller et al. - 2020 - Self Normalizing Flows.pdf:pdf},
pages = {1--11},
title = {{Self Normalizing Flows}},
url = {http://arxiv.org/abs/2011.07248 https://github.com/akandykeller/SelfNormalizingFlows},
year = {2020}
}
@article{Zhao2020,
abstract = {As a challenging problem in machine learning, few-shot class-incremental learning asynchronously learns a sequence of tasks, acquiring the new knowledge from new tasks (with limited new samples) while keeping the learned knowledge from previous tasks (with old samples discarded). In general, existing approaches resort to one unified feature space for balancing old-knowledge preserving and new-knowledge adaptation. With a limited embedding capacity of feature representation, the unified feature space often makes the learner suffer from semantic drift or overfitting as the number of tasks increases. With this motivation, we propose a novel few-shot class-incremental learning pipeline based on a composite representation space, which makes old-knowledge preserving and new-knowledge adaptation mutually compatible by feature space composition (enlarging the embedding capacity). The composite representation space is generated by integrating two space components (i.e. stable base knowledge space and dynamic lifelong-learning knowledge space) in terms of distance metric construction. With the composite feature space, our method performs remarkably well on the CUB200 and CIFAR100 datasets, outperforming the state-of-the-art algorithms by 10.58% and 14.65% respectively.},
archivePrefix = {arXiv},
arxivId = {arXiv:2006.15524v2},
author = {Zhao, Hanbin and Fu, Yongjian and Li, Xuewei and Li, Songyuan and Omar, Bourahla and Li, Xi},
eprint = {arXiv:2006.15524v2},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao et al. - 2020 - Few-shot class-incremental learning via feature space composition.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {continual learning,few-shot learning,incremental learning},
mendeley-tags = {continual learning,few-shot learning,incremental learning},
title = {{Few-shot class-incremental learning via feature space composition}},
year = {2020}
}
@article{Kaya2017,
abstract = {The detection of changes in a process within shortest time provides significant benefits in terms of cost and quality. When considering the cost which would show up because of delays in identifying variability, detecting the deviation in the process accurately and quickly has a great importance for investors. In this paper, return volatility in the Borsa Istanbul-30 index (BIST-30) has been analyzed and a fuzzy control chart for individual measurements (FCCIM) has been proposed for use in determining and controlling in the variables of the BIST-30 index. For this purpose, firstly exponential smoothing method is used to forecast the variability of stock price of BIST-30 index by using MINITAB statistical software, and then a fuzzy control chart for individual measurements (FCCIM) which are fuzzy individual control chart (FICC) and fuzzy moving range control chart (FMRCC) with fuzzy control rules have been developed to be used in determining the variability of the process. For this aim, some fuzzy rules have been defined by using Ms EXCEL in fuzzy control chart for individual measurements. A real case application from Istanbul Stock Exchange for BIST-30 has been managed to check the effectiveness of suggested fuzzy control charts.},
author = {Kaya, İhsan and Erdoğan, Melike and Yıldız, Cansın},
doi = {10.1016/j.asoc.2016.11.048},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kaya, Erdoğan, Yıldız - 2017 - Analysis and control of variability by using fuzzy individual control charts.pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {BIST-30 Index,Control charts,Forecasting,Fuzzy logic,Statistical process control,Variability},
pages = {370--381},
title = {{Analysis and control of variability by using fuzzy individual control charts}},
volume = {51},
year = {2017}
}
@article{Wei2018,
abstract = {Deep learning software demands reliability and performance. However, many of the existing deep learning frameworks are software libraries that act as an unsafe DSL in Python and a computation graph interpreter. We present DLVM, a design and implementation of a compiler infrastructure with a linear algebra intermediate representation, algorithmic differentiation by adjoint code generation, domain-specific optimizations and a code generator targeting GPU via LLVM. Designed as a modern compiler infrastructure inspired by LLVM, DLVM is more modular and more generic than existing deep learning compiler frameworks, and supports tensor DSLs with high expressivity. With our prototypical staged DSL embedded in Swift, we argue that the DLVM system enables a form of modular, safe and performant frameworks for deep learning.},
archivePrefix = {arXiv},
arxivId = {1711.03016},
author = {Wei, Richard and Schwartz, Lane and Adve, Vikram},
eprint = {1711.03016},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wei, Schwartz, Adve - 2018 - DLVM A modern compiler infrastructure for deep learning systems.pdf:pdf},
journal = {6th International Conference on Learning Representations, ICLR 2018 - Workshop Track Proceedings},
pages = {1--10},
title = {{DLVM: A modern compiler infrastructure for deep learning systems}},
year = {2018}
}
@article{Shao1996,
abstract = {Intrinsically fuzzy morphological erosion and dilation are extended to a total of eight operations that have been formulated in terms of a single morphological operation-biased dilation. Based on the spatial coding of a fuzzy variable, a bidirectional projection concept is proposed. Thus, fuzzy logic operations, arithmetic operations, gray-scale dilation, and erosion for the extended intrinsically fuzzy morphological operations can be included in a unified algorithm with only biased dilation and fuzzy logic operations. To execute this image algebra approach we present a cellular two-layer processing architecture that consists of a biased dilation processor and a fuzzy logic processor.},
author = {Shao, L and Liu, L and Li, G},
doi = {10.1364/AO.35.003109},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shao, Liu, Li - 1996 - Optical intrinsically fuzzy mathematical morphology for gray-scale image processing.pdf:pdf},
issn = {21553165},
journal = {Applied Optics},
keywords = {cellular logic,fuzzy sets,mathematical morphology,of america,r 1996 optical society},
number = {17},
pages = {3109--3116},
pmid = {21102688},
title = {{Optical intrinsically fuzzy mathematical morphology for gray-scale image processing.}},
volume = {35},
year = {1996}
}
@article{Prade1993,
author = {Prade, Didier Dubois and Henri},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Prade - 1993 - Fuzzy Sets for Intelligent Systems.pdf:pdf},
title = {{Fuzzy Sets for Intelligent Systems}},
year = {1993}
}
@article{CHUNG2011,
author = {CHUNG, SO HYUN and MEHTA, RITA and TROMBERG, BRUCE J. and YODH, A. G.},
doi = {10.1142/S1793545811001708},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/CHUNG et al. - 2011 - Non-Invasive Measurement of Deep Tissue Temperature Changes Caused By Apoptosis During Breast Cancer Neoadjuvant C.pdf:pdf},
issn = {1793-5458},
journal = {Journal of Innovative Optical Health Sciences},
number = {04},
pages = {361--372},
title = {{Non-Invasive Measurement of Deep Tissue Temperature Changes Caused By Apoptosis During Breast Cancer Neoadjuvant Chemotherapy: a Case Study}},
url = {http://www.worldscientific.com/doi/abs/10.1142/S1793545811001708},
volume = {04},
year = {2011}
}
@article{Bruland2013,
abstract = {This article considers the historiographical and theoretical significance of Nicholas von Tunzelmann's first book, Steam Power and British Industrialization to 1860. Von Tunzelmann assessed the quantitative impact of the Watt steam engine and its pirate copies on the British economy using the social savings method pioneered by R.W. Fogel, showing that the impact was smaller and later than many historians had supposed. These results are of more than quantitative significance because they call into question a dominant line in the history of industrialization that focuses on the steam engine as a key determinant of the dynamics of industrial growth in Britain from the late eighteenth century. This article discusses the origin of this line in the work of Arnold Toynbee and outlines its long-term influence on economic history, including contemporary debates on the question of why Europe outpaced China and India from the seventeenth century. These issues are important also for innovation studies, which often describes the relation between innovation and growth in terms of such 'critical technologies' as steam power; these accounts are subject to the same weaknesses as technicist histories of industrialization. Von Tunzelmann's early work is therefore of continuing theoretical and empirical significance as we seek an adequate theory of the links between innovation and growth. {\textcopyright} 2013 Elsevier B.V.},
author = {Bruland, Kristine and Smith, Keith},
doi = {10.1016/j.respol.2012.12.008},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bruland, Smith - 2013 - Assessing the role of steam power in the first industrial revolution The early work of Nick von Tunzelmann.pdf:pdf},
isbn = {0048-7333},
issn = {00487333},
journal = {Research Policy},
keywords = {Energy innovation,Industrialisation,Steam power,Technology dynamics},
number = {10},
pages = {1716--1723},
publisher = {Elsevier B.V.},
title = {{Assessing the role of steam power in the first industrial revolution: The early work of Nick von Tunzelmann}},
url = {http://dx.doi.org/10.1016/j.respol.2012.12.008},
volume = {42},
year = {2013}
}
@article{Elaziz2017,
abstract = {{\textcopyright} 2017 The Author(s). The current economics of the fish protein industry demand rapid, accurate and expressive prediction algorithms at every step of protein production especially with the challenge of global climate change. This help to predict and analyze functional and nutritional quality then consequently control food allergies in hyper allergic patients. As, it is quite expensive and time-consuming to know these concentrations by the lab experimental tests, especially to conduct large-scale projects. Therefore, this paper introduced a new intelligent algorithm using adaptive neuro-fuzzy inference system based on whale optimization algorithm. This algorithm is used to predict the concentration levels of bioactive amino acids in fish protein hydrolysates at different times during the year. The whale optimization algorithm is used to determine the optimal parameters in adaptive neuro-fuzzy inference system. The results of proposed algorithm are compared with others an d it is indicated the higher performance of the proposed algorithm.},
author = {Elaziz, Mohamed Abd and Hemdan, Ahmed Monem and Hassanien, Aboul Ella and Oliva, Diego and Xiong, Shengwu},
doi = {10.1038/s41598-017-10890-1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elaziz et al. - 2017 - Analysis of Bioactive Amino Acids from Fish Hydrolysates with a New Bioinformatic Intelligent System Approach.pdf:pdf},
issn = {20452322},
journal = {Scientific Reports},
number = {1},
pages = {1--9},
publisher = {Springer US},
title = {{Analysis of Bioactive Amino Acids from Fish Hydrolysates with a New Bioinformatic Intelligent System Approach}},
url = {http://dx.doi.org/10.1038/s41598-017-10890-1},
volume = {7},
year = {2017}
}
@inproceedings{Madan2021,
abstract = {Decomposing knowledge into interchangeable pieces promises a generalization advantage when there are changes in distribution. A learning agent interacting with its environment is likely to be faced with situations requiring novel combinations of existing pieces of knowledge. We hypothesize that such a decomposition of knowledge is particularly relevant for being able to generalize in a systematic way to out-of-distribution changes. To study these ideas, we propose a particular training framework in which we assume that the pieces of knowledge an agent needs, as well as its reward function are stationary and can be re-used across tasks. An attention mechanism dynamically selects which modules can be adapted to the current task, and the parameters of the selected modules are allowed to change quickly as the learner is confronted with variations in what it experiences, while the parameters of the attention mechanisms act as stable, slowly changing, meta-parameters. We focus on pieces of knowledge captured by an ensemble of modules sparsely communicating with each other via a bottleneck of attention. We find that meta-learning the modular aspects of the proposed system greatly helps in achieving faster adaptation in experiments with a reinforcement learning setup involving navigation in a partially observed grid world with image-level input. We also find that reversing the role of parameters and meta-parameters does not work nearly as well, suggesting a particular role for fast adaptation of the dynamically selected modules.},
author = {Madan, Kanika and Ke, Nan Rosemary and Goyal, Anirudh and Sch{\"{o}}lkopf, Bernhard and Bengio, Yoshua},
booktitle = {Iclr 2021},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Madan et al. - 2021 - Meta Attention Networks Meta-learning Attention To Modulate Information Between Recurrent Independent Mechanisms.pdf:pdf},
keywords = {attention networks,meta-learning},
mendeley-tags = {attention networks,meta-learning},
number = {2021},
pages = {1--12},
title = {{Meta Attention Networks: Meta-learning Attention To Modulate Information Between Recurrent Independent Mechanisms}},
year = {2021}
}
@inproceedings{Univesity2016,
abstract = {Most current NLP systems have little knowl- edge about quantitative attributes of objects and events. We propose an unsupervised method for collecting quantitative information from large amounts of web data, and use it to create a new, very large resource consisting of distributions over physical quantities associ- ated with objects, adjectives, and verbs which we call Distribution over Quantities (DOQ)1. This contrasts with recent work in this area which has focused on making only relative comparisons such as “Is a lion bigger than a wolf?”. Our evaluation shows that DOQ com- pares favorably with state of the art results on existing datasets for relative comparisons of nouns and adjectives, and on a new dataset we introduce.},
archivePrefix = {arXiv},
arxivId = {arXiv:1906.01327v1},
author = {Univesity, Bar Ilan and Bedrax-weiss, Tania and Roth, Dan},
eprint = {arXiv:1906.01327v1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Univesity, Bedrax-weiss, Roth - 2016 - How Large Are Lions Inducing Distributions over Quantitative Attributes.pdf:pdf},
title = {{How Large Are Lions? Inducing Distributions over Quantitative Attributes}},
year = {2016}
}
@inproceedings{Socher2013,
abstract = {This work introduces a model that can recognize objects in images even if no training data is available for the objects. The only necessary knowledge about the unseen categories comes from unsupervised large text corpora. In our zero-shot framework distributional information in language can be seen as spanning a semantic basis for understanding what objects look like. Most previous zero-shot learning models can only differentiate between unseen classes. In contrast, our model can both obtain state of the art performance on classes that have thousands of training images and obtain reasonable performance on unseen classes. This is achieved by first using outlier detection in the semantic space and then two separate recognition models. Furthermore, our model does not require any manually defined semantic features for either words or images.},
archivePrefix = {arXiv},
arxivId = {1301.3666},
author = {Socher, Richard and Ganjoo, Milind and Sridhar, Hamsa and Bastani, Osbert and Manning, Christopher D. and Ng, Andrew Y.},
booktitle = {1st International Conference on Learning Representations, ICLR 2013 - Workshop Track Proceedings},
eprint = {1301.3666},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Socher et al. - 2013 - Zero-Shot Learning Through Cross-Modal Transfer.pdf:pdf},
month = {jan},
title = {{Zero-Shot Learning Through Cross-Modal Transfer}},
url = {http://arxiv.org/abs/1301.3666},
year = {2013}
}
@article{Rao2019,
abstract = {Continual learning aims to improve the ability of modern learning systems to deal with non-stationary distributions, typically by attempting to learn a series of tasks sequentially. Prior art in the field has largely considered supervised or reinforcement learning tasks, and often assumes full knowledge of task labels and boundaries. In this work, we propose an approach (CURL) to tackle a more general problem that we will refer to as unsupervised continual learning. The focus is on learning representations without any knowledge about task identity, and we explore scenarios when there are abrupt changes between tasks, smooth transitions from one task to another, or even when the data is shuffled. The proposed approach performs task inference directly within the model, is able to dynamically expand to capture new concepts over its lifetime, and incorporates additional rehearsal-based techniques to deal with catastrophic forgetting. We demonstrate the efficacy of CURL in an unsupervised learning setting with MNIST and Omniglot, where the lack of labels ensures no information is leaked about the task. Further, we demonstrate strong performance compared to prior art in an i.i.d setting, or when adapting the technique to supervised tasks such as incremental class learning.},
archivePrefix = {arXiv},
arxivId = {1910.14481},
author = {Rao, Dushyant and Visin, Francesco and Rusu, Andrei A. and Teh, Yee Whye and Pascanu, Razvan and Hadsell, Raia},
eprint = {1910.14481},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rao et al. - 2019 - Continual unsupervised representation learning.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
keywords = {continual learning,unsupervised learning},
mendeley-tags = {continual learning,unsupervised learning},
title = {{Continual unsupervised representation learning}},
volume = {32},
year = {2019}
}
@article{Zeiler2014,
abstract = {Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets. {\textcopyright} 2014 Springer International Publishing.},
archivePrefix = {arXiv},
arxivId = {1311.2901},
author = {Zeiler, Matthew D. and Fergus, Rob},
doi = {10.1007/978-3-319-10590-1_53},
eprint = {1311.2901},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zeiler, Fergus - 2014 - Visualizing and understanding convolutional networks.pdf:pdf},
isbn = {9783319105895},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
number = {PART 1},
pages = {818--833},
title = {{Visualizing and understanding convolutional networks}},
volume = {8689 LNCS},
year = {2014}
}
@article{Prince2004,
abstract = {This study examines the evidence for the effectiveness of active learning. It defines the common forms of active learning most relevant for engineering faculty and critically examines the core element of each method. It is found that there is broad but uneven support for the core elements of active, collaborative, cooperative and problem-based learning.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Prince, M},
doi = {10.1002/j.2168-9830.2004.tb00809.x},
eprint = {arXiv:1011.1669v3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Prince - 2004 - Does active learning work A review of the research.pdf:pdf},
isbn = {10694730},
issn = {1069-4730},
journal = {Journal of Engineering Education},
number = {3},
pages = {223--232},
pmid = {48056773},
title = {{Does active learning work? A review of the research}},
volume = {93},
year = {2004}
}
@article{Pretty2005a,
abstract = {Both physical activity and exposure to nature are known separately to have positive effects on physical and mental health. We have investigated whether there is a synergistic benefit in adopting physical activities whilst being directly exposed to nature ('green exercise'). Five groups of 20 subjects were exposed to a sequence of 30 scenes projected on a wall whilst exercising on a treadmill. Four categories of scenes were tested: rural pleasant, rural unpleasant, urban pleasant and urban unpleasant. The control was running without exposure to images. Blood pressure and two psychological measures (self-esteem and mood) were measured before and after the intervention. There was a clear effect of both exercise and different scenes on blood pressure, self-esteem and mood. Exercise alone significantly reduced blood pressure, increased self-esteem, and had a positive significant effect on 4 of 6 mood measures. Both rural and urban pleasant scenes produced a significantly greater positive effect on self-esteem than the exercise-only control. This shows the synergistic effect of green exercise in both rural and urban environments. By contrast, both rural and urban unpleasant scenes reduced the positive effects of exercise on self-esteem. The rural unpleasant scenes had the most dramatic effect, depressing the beneficial effects of exercise on three different measures of mood. It appears that threats to the countryside depicted in rural unpleasant scenes have a greater negative effect on mood than already urban unpleasant scenes. We conclude that green exercise has important public and environmental health consequences.},
author = {Pretty, Jules and Peacock, Jo and Sellens, Martin and Griffin, Murray},
doi = {10.1080/09603120500155963},
isbn = {0960-3123 (Print)},
issn = {09603123},
journal = {International Journal of Environmental Health Research},
keywords = {Environmental health,Green exercise,Mental health,Mood,Physical activity,Self-esteem},
number = {5},
pages = {319--337},
pmid = {16416750},
title = {{The mental and physical health outcomes of green exercise}},
volume = {15},
year = {2005}
}
@book{Brownlee2011,
abstract = {Welcome to Clever Algorithms! This is a handbook of recipes for com- putational problem solving techniques from the fields of Computational Intelligence, Biologically Inspired Computation, and Metaheuristics. Clever Algorithms are interesting, practical, and fun to learn about and implement. Research scientists may be interested in browsing algorithm inspirations in search of an interesting system or process analogs to investigate. Developers and software engineers may compare various problem solving algorithms and technique-specific guidelines. Practitioners, students, and interested amateurs may implement state-of-the-art algorithms to address business or scientific needs, or simply play with the fascinating systems they represent. This introductory chapter provides relevant background information on Artificial Intelligence and Algorithms. The core of the book provides a large corpus of algorithms presented in a complete and consistent manner. The final chapter covers some advanced topics to consider once a number of algorithms have been mastered. This book has been designed as a reference text, where specific techniques are looked up, or where the algorithms across whole fields of study can be browsed, rather than being read cover-to-cover. This book is an algorithm handbook and a technique guidebook, and I hope you find something useful.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Brownlee, Jason},
booktitle = {Search},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brownlee - 2011 - Clever Algorithms.pdf:pdf},
isbn = {9781446785065},
issn = {0269-2821},
pages = {436},
pmid = {25246403},
title = {{Clever Algorithms}},
url = {http://www.cleveralgorithms.com},
year = {2011}
}
@article{Khater2017,
abstract = {This paper presents a fault diagnostics system for a three-phase voltage source inverter. The system is developed as a rule-based fuzzy logic system for fault cases of the inverter power semiconductor switches. Based on a time domain simulation model, the inverter different fault conditions are simulated with the resulting voltage spectrum providing the database for the fuzzy logic system. The developed fault diagnostics system is capable of identifying the type and location of the inverter fault.},
author = {Khater, Faeka and {Abu El-Sebah}, Mohamed I. and Osama, Mohamed},
doi = {10.1016/j.jesit.2016.10.005},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khater, Abu El-Sebah, Osama - 2017 - Fault diagnostics in an inverter feeding an induction motor using fuzzy logic.pdf:pdf},
issn = {23147172},
journal = {Journal of Electrical Systems and Information Technology},
keywords = {Fault diagnostics,Fuzzy logic,Voltage source inverter,fault diagnostics,fuzzy logic,voltage source inverter},
number = {1},
pages = {10--17},
publisher = {Electronics Research Institute (ERI)},
title = {{Fault diagnostics in an inverter feeding an induction motor using fuzzy logic}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S231471721630085X},
volume = {4},
year = {2017}
}
@article{Liu2021c,
abstract = {Existing blind image quality assessment (BIQA) methods are mostly designed in a disposable way and cannot evolve with unseen distortions adaptively, which greatly limits the deployment and application of BIQA models in real-world scenarios. To address this problem, we propose a novel Lifelong blind Image Quality Assessment (LIQA) approach, targeting to achieve the lifelong learning of BIQA. Without accessing to previous training data, our proposed LIQA can not only learn new distortions, but also mitigate the catastrophic forgetting of seen distortions. Specifically, we adopt the Split-and-Merge distillation strategy to train a single-head network that makes task-agnostic predictions. In the split stage, we first employ a distortion-specific generator to obtain the pseudo features of each seen distortion. Then, we use an auxiliary multi-head regression network to generate the predicted quality of each seen distortion. In the merge stage, we replay the pseudo features paired with pseudo labels to distill the knowledge of multiple heads, which can build the final regressed single head. Experimental results demonstrate that the proposed LIQA method can handle the continuous shifts of different distortion types and even datasets. More importantly, our LIQA model can achieve stable performance even if the task sequence is long.},
archivePrefix = {arXiv},
arxivId = {2104.14115},
author = {Liu, Jianzhao and Zhou, Wei and Xu, Jiahua and Li, Xin and An, Shukun and Chen, Zhibo},
eprint = {2104.14115},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2021 - LIQA Lifelong Blind Image Quality Assessment.pdf:pdf},
keywords = {blind quality assessment,continual learning,incremental learning},
mendeley-tags = {blind quality assessment,continual learning,incremental learning},
number = {8},
pages = {1--13},
title = {{LIQA: Lifelong Blind Image Quality Assessment}},
url = {http://arxiv.org/abs/2104.14115},
volume = {14},
year = {2021}
}
@article{Hornik1991,
abstract = {We show that standard multilayer feedforward networks with as few as a single hidden layer and arbitrary bounded and nonconstant activation function are universal approximators with respect to Lp($\mu$) performance criteria, for arbitrary finite input environment measures $\mu$, provided only that sufficiently many hidden units are available. If the activation function is continuous, bounded and nonconstant, then continuous mappings can be learned uniformly over compact input sets. We also give very general conditions ensuring that networks with sufficiently smooth activation functions are capable of arbitrarily accurate approximation to a function and its derivatives. {\textcopyright} 1991.},
author = {Hornik, Kurt},
doi = {10.1016/0893-6080(91)90009-T},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hornik - 1991 - Approximation capabilities of multilayer feedforward networks.pdf:pdf},
issn = {08936080},
journal = {Neural Networks},
keywords = {Activation function,Input environment measure,Lp($\mu$) approximation,Multilayer feedforward networks,Smooth approximation,Sobolev spaces,Uniform approximation,Universal approximation capabilities},
number = {2},
pages = {251--257},
title = {{Approximation capabilities of multilayer feedforward networks}},
volume = {4},
year = {1991}
}
@article{Xu2013a,
abstract = {Some climate datasets are incomplete at certain places and times. A novel technique called the point estimation model of Biased Sentinel Hospitals-based Area Disease Estimation(P-BSHADE)is introduced to interpolate missing data in temperature datasets. Effectiveness of the technique was empirically evaluated in terms of an annual temperature dataset from 1950 to 2000 in China. The P-BSHADE technique uses a weighted summation of observed stations to derive unbiased and minimum error variance estimates of missing data. Both the ratio and covariance between stations were used in calculation of these weights. In this way, interpolation of missing data in the temperature dataset was improved, and best linear unbiased esti- mates (BLUE) were obtained. Using the same dataset, performance of P-BSHADE was compared against three estimators: kriging, inverse distance weighting (IDW), and spatial regression test (SRT). Kriging and IDW assume a homogeneous stochastic field, which may not be the case. SRT employs spatiotemporal data and has the potential to consider temperature nonhomogeneity caused by topographic differences, but has no objective function for the BLUE. Instead, P-BSHADEtakes into account geographic spatial autocorrelation and nonhomogeneity, and maximizes an objective function for the BLUE of the target station. In addition to the theoretical advantages of P-BSHADE over the three other methods, case studies for an annual Chinese temperature dataset demonstrate its empirical superiority, except for the SRT from 1950 to 1970.},
author = {Xu, Cheng Dong and Wang, Jin Feng and Hu, Mao Gui and Li, Qing Xiang},
doi = {10.1175/JCLI-D-12-00633.1},
isbn = {0894-8755},
issn = {08948755},
journal = {Journal of Climate},
keywords = {Interpolation schemes},
number = {19},
pages = {7452--7463},
title = {{Interpolation of missing temperature data at meteorological stations using P-BSHADE}},
volume = {26},
year = {2013}
}
@article{Yang2020,
abstract = {Current methods for training robust networks lead to a drop in test accuracy, which has led prior works to posit that a robustness-accuracy tradeoff may be inevitable in deep learning. We take a closer look at this phenomenon and first show that real image datasets are actually separated. With this property in mind, we then prove that robustness and accuracy should both be achievable for benchmark datasets through locally Lipschitz functions, and hence, there should be no inherent tradeoff between robustness and accuracy. Through extensive experiments with robustness methods, we argue that the gap between theory and practice arises from two limitations of current methods: either they fail to impose local Lipschitzness or they are insufficiently generalized. We explore combining dropout with robust training methods and obtain better generalization. We conclude that achieving robustness and accuracy in practice may require using methods that impose local Lipschitzness and augmenting them with deep learning generalization techniques. Code available at https://github.com/yangarbiter/robust-local-lipschitz},
archivePrefix = {arXiv},
arxivId = {2003.02460},
author = {Yang, Yao-Yuan and Rashtchian, Cyrus and Zhang, Hongyang and Salakhutdinov, Ruslan and Chaudhuri, Kamalika},
eprint = {2003.02460},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2020 - A Closer Look at Accuracy vs. Robustness(2).pdf:pdf},
number = {NeurIPS},
pages = {1--22},
title = {{A Closer Look at Accuracy vs. Robustness}},
url = {http://arxiv.org/abs/2003.02460},
year = {2020}
}
@article{Fulman2017,
abstract = {Urban parking prices do not reflect spatially heterogeneous parking supply and demand. We present an agent-based algorithm for establishing on-and off-street parking prices in a heterogeneous urban space that guarantee a predetermined uniform level of occupation.},
author = {Fulman, Nir and Benenson, Itzhak},
doi = {10.1016/j.procs.2017.05.420},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fulman, Benenson - 2017 - Simulating parking for establishing parking prices.pdf:pdf},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {Agent-Based Modeling,Spatially Exlicit Modeling,Transportation,Urban Parking},
pages = {911--916},
publisher = {Elsevier B.V.},
title = {{Simulating parking for establishing parking prices}},
url = {http://dx.doi.org/10.1016/j.procs.2017.05.420},
volume = {109},
year = {2017}
}
@article{Hc-sr,
author = {Hc-sr, Mikrokontroler Menggunakan Sensor},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hc-sr - Unknown - depan, samping dan belakang mobil. Mikrokontroler diperlukan untuk mengolah data dan menampilkan data jarak obyek ke b.pdf:pdf},
title = {{depan, samping dan belakang mobil. Mikrokontroler diperlukan untuk mengolah data dan menampilkan data jarak obyek ke bodi mobil melalui LCD, bunyi}}
}
@article{Topologies,
abstract = {Dense wavelength division multiplexing (DWDM) networks are classified into four major topological configurations: DWDM point-to-point with or without add-drop multiplexing network, fully connected mesh network, star network, and DWDM ring network with OADM nodes and a hub. Each topology has its own requirements and, based on the application, different optical components may be involved in the re-spective designs. In addition, there are hybrid network topologies that may consist of stars and/or rings that are interconnected with point-to-point links. For example, the Metropolitan Optical Network project (MONET) is a WDM network developed for and funded by a number of private companies and by U.S. government agencies. It consists of two sub-networks, one located in New Jersey and one in the Washington, D.C./Maryland area; the two are interconnected with a long-distance point-to-point optical link. 16.2 POINT-TO-POINT TOPOLOGY Point-to-point topology is predominantly for long-haul transport that requires ultrahigh speed (10-40 Gb/s), ultrahigh aggregate bandwidth (in the order of several ter-abits per second), high signal integrity, great reliability, and fast path restoration capa-bility. The distance between transmitter and receiver may be several hundred kilome-ters, and the number of amplifiers between the two end points is typically less than 10 (as determined by power loss and signal distortion). Point-to-point with add-drop mul-tiplexing enables the system to drop and add channels along its path. Number of chan-nels, channel spacing, type of fiber, signal modulation method, and component type se-lection are all important parameters in the calculation of the power budget.},
author = {Topologies, Dwdm},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Topologies - Unknown - Dwdm topologies 16.1.pdf:pdf},
pages = {197--207},
title = {{Dwdm topologies 16.1}},
volume = {10}
}
@article{Grujic2017,
abstract = {Estimation of fuzzy quantities is a topic that often appears in decision making. Some of the well-known approaches are based on the integration done with respect to the probability measure and, later on, on the possibility measure and the necessity measure. The approach considered here is focused on a fuzzy measure in general as a base of integration.},
author = {Gruji{\'{c}}, Gabrijela and Lozanov-Crvenkovi{\'{c}}, Zagorka and {\v{S}}tajner-Papuga, Ivana},
doi = {10.1016/j.fss.2017.05.026},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gruji{\'{c}}, Lozanov-Crvenkovi{\'{c}}, {\v{S}}tajner-Papuga - 2017 - General fuzzy integral as a base for estimation of fuzzy quantities.pdf:pdf},
issn = {01650114},
journal = {Fuzzy Sets and Systems},
keywords = {Distribution function,Fuzzy measure,Fuzzy set,General fuzzy integral,Mean value},
pages = {69--80},
title = {{General fuzzy integral as a base for estimation of fuzzy quantities}},
volume = {326},
year = {2017}
}
@article{Kahali2017,
abstract = {Segmentation of Magnetic Resonance Imaging (MRI) brain image data has a significant impact on the computer guided medical image diagnosis and analysis. However, due to limitation of image acquisition devices and other related factors, MRI images are severely affected by the noise and inhomogeneity artefacts which lead to blurry edges in the intersection of the intra-organ soft tissue regions, making the segmentation process more difficult and challenging. This paper presents a novel two-stage fuzzy multi-objective framework (2sFMoF) for segmenting 3D MRI brain image data. In the first stage, a 3D spatial fuzzy c-means (3DSpFCM) algorithm is introduced by incorporating the 3D spatial neighbourhood information of the volume data to define a new local membership function along with the global membership function for each voxel. In particular, the membership functions actually define the underlying relationship between the voxels of a close cubic neighbourhood and image data in 3D image space. The cluster prototypes thus obtained are fed into a 3D modified fuzzy c-means (3DMFCM) algorithm, which further incorporates local voxel information to generate the final prototypes. The proposed framework addresses the shortcomings of the traditional FCM algorithm, which is highly sensitive to noise and may stuck into a local minima. The method is validated on a synthetic image volume and several simulated and in-vivo 3D MRI brain image volumes and found to be effective even in noisy data. The empirical results show the supremacy of the proposed method over the other FCM based algorithms and other related methods devised in the recent past.},
author = {Kahali, Sayan and Adhikari, Sudip Kumar and Sing, Jamuna Kanta},
doi = {10.1016/j.asoc.2017.07.001},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kahali, Adhikari, Sing - 2017 - A two-stage fuzzy multi-objective framework for segmentation of 3D MRI brain image data.pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {3D image segmentation,Fuzzy clustering,MRI brain image volume,Multi-objective framework,Spatial fuzzy C-means},
pages = {312--327},
publisher = {Elsevier B.V.},
title = {{A two-stage fuzzy multi-objective framework for segmentation of 3D MRI brain image data}},
url = {http://dx.doi.org/10.1016/j.asoc.2017.07.001},
volume = {60},
year = {2017}
}
@article{Caron2020b,
abstract = {Unsupervised image representations have significantly reduced the gap with supervised pretraining, notably with the recent achievements of contrastive learning methods. These contrastive methods typically work online and rely on a large number of explicit pairwise feature comparisons, which is computationally challenging. In this paper, we propose an online algorithm, SwAV, that takes advantage of contrastive methods without requiring to compute pairwise comparisons. Specifically, our method simultaneously clusters the data while enforcing consistency between cluster assignments produced for different augmentations (or “views”) of the same image, instead of comparing features directly as in contrastive learning. Simply put, we use a “swapped” prediction mechanism where we predict the cluster assignment of a view from the representation of another view. Our method can be trained with large and small batches and can scale to unlimited amounts of data. Compared to previous contrastive methods, our method is more memory efficient since it does not require a large memory bank or a special momentum network. In addition, we also propose a new data augmentation strategy, multi-crop, that uses a mix of views with different resolutions in place of two full-resolution views, without increasing the memory or compute requirements much. We validate our findings by achieving 75.3% top-1 accuracy on ImageNet with ResNet-50, as well as surpassing supervised pretraining on all the considered transfer tasks.},
archivePrefix = {arXiv},
arxivId = {2006.09882},
author = {Caron, Mathilde and Goyal, Priya and Misra, Ishan and Bojanowski, Piotr and Mairal, Julien and Joulin, Armand},
eprint = {2006.09882},
issn = {23318422},
journal = {arXiv},
number = {NeurIPS},
pages = {1--23},
title = {{Unsupervised Learning of Visual Features by Contrasting Cluster Assignments}},
year = {2020}
}
@book{Karlin,
author = {Karlin, Samuel},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Karlin - Unknown - Probability , Statistics , and Papers in Honor of.pdf:pdf},
isbn = {0120584700},
title = {{Probability , Statistics , and Papers in Honor of}}
}
@article{Wolf2019,
abstract = {Recent advances in modern Natural Language Processing (NLP) research have been dominated by the combination of Transfer Learning methods with large-scale Transformer language models. With them came a paradigm shift in NLP with the starting point for training a model on a downstream task moving from a blank specific model to a general-purpose pretrained architecture. Still, creating these general-purpose models remains an expensive and time-consuming process restricting the use of these methods to a small sub-set of the wider NLP community. In this paper, we present Transformers, a library for state-of-the-art NLP, making these developments available to the community by gathering state-of-the-art general-purpose pretrained models under a unified API together with an ecosystem of libraries, examples, tutorials and scripts targeting many downstream NLP tasks. Transformers features carefully crafted model implementations and high-performance pretrained weights for two main deep learning frameworks, PyTorch and TensorFlow, while supporting all the necessary tools to analyze, evaluate and use these models in downstream tasks such as text/token classification, questions answering and language generation among others. Transformers has gained significant organic traction and adoption among both the researcher and practitioner communities. We are committed at Hugging Face to pursue the efforts to develop Transformers with the ambition of creating the standard library for building NLP systems.},
archivePrefix = {arXiv},
arxivId = {1910.03771},
author = {Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'{e}}mi and Funtowicz, Morgan and Brew, Jamie},
eprint = {1910.03771},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wolf et al. - 2019 - Transformers State-of-the-art Natural Language Processing.pdf:pdf},
title = {{Transformers: State-of-the-art Natural Language Processing}},
url = {http://arxiv.org/abs/1910.03771},
year = {2019}
}
@article{Trofimov2020,
abstract = {MOTIVATION: The recent development of sequencing technologies revolutionized our understanding of the inner workings of the cell as well as the way disease is treated. A single RNA sequencing (RNA-Seq) experiment, however, measures tens of thousands of parameters simultaneously. While the results are information rich, data analysis provides a challenge. Dimensionality reduction methods help with this task by extracting patterns from the data by compressing it into compact vector representations. RESULTS: We present the factorized embeddings (FE) model, a self-supervised deep learning algorithm that learns simultaneously, by tensor factorization, gene and sample representation spaces. We ran the model on RNA-Seq data from two large-scale cohorts and observed that the sample representation captures information on single gene and global gene expression patterns. Moreover, we found that the gene representation space was organized such that tissue-specific genes, highly correlated genes as well as genes participating in the same GO terms were grouped. Finally, we compared the vector representation of samples learned by the FE model to other similar models on 49 regression tasks. We report that the representations trained with FE rank first or second in all of the tasks, surpassing, sometimes by a considerable margin, other representations. AVAILABILITY AND IMPLEMENTATION: A toy example in the form of a Jupyter Notebook as well as the code and trained embeddings for this project can be found at: https://github.com/TrofimovAssya/FactorizedEmbeddings. SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.},
author = {Trofimov, Assya and Cohen, Joseph Paul and Bengio, Yoshua and Perreault, Claude and Lemieux, S{\'{e}}bastien},
doi = {10.1093/bioinformatics/btaa488},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Trofimov et al. - 2020 - Factorized embeddings learns rich and biologically meaningful embedding spaces using factorized tensor decompos.pdf:pdf},
issn = {1367-4803},
journal = {Bioinformatics},
month = {jul},
number = {Supplement_1},
pages = {i417--i426},
pmid = {32657403},
title = {{Factorized embeddings learns rich and biologically meaningful embedding spaces using factorized tensor decomposition}},
url = {https://academic.oup.com/bioinformatics/article/36/Supplement_1/i417/5870511},
volume = {36},
year = {2020}
}
@article{Liu2018,
abstract = {We propose an attention-injective deformable convolutional network called ADCrowdNet for crowd understanding that can address the accuracy degradation problem of highly congested noisy scenes. ADCrowdNet contains two concatenated networks. An attention-aware network called Attention Map Generator (AMG) first detects crowd regions in images and computes the congestion degree of these regions. Based on detected crowd regions and congestion priors, a multi-scale deformable network called Density Map Estimator (DME) then generates high-quality density maps. With the attention-aware training scheme and multi-scale deformable convolutional scheme, the proposed ADCrowdNet achieves the capability of being more effective to capture the crowd features and more resistant to various noises. We have evaluated our method on four popular crowd counting datasets (ShanghaiTech, UCF_CC_50, WorldEXPO'10, and UCSD) and an extra vehicle counting dataset TRANCOS, and our approach beats existing state-of-the-art approaches on all of these datasets.},
archivePrefix = {arXiv},
arxivId = {1811.11968},
author = {Liu, Ning and Long, Yongchao and Zou, Changqing and Niu, Qun and Pan, Li and Wu, Hefeng},
eprint = {1811.11968},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2018 - ADCrowdNet An Attention-injective Deformable Convolutional Network for Crowd Understanding.pdf:pdf},
title = {{ADCrowdNet: An Attention-injective Deformable Convolutional Network for Crowd Understanding}},
url = {http://arxiv.org/abs/1811.11968},
year = {2018}
}
@inproceedings{Tao2020a,
abstract = {The ability to incrementally learn new classes is crucial to the development of real-world artificial intelligence systems. In this paper, we focus on a challenging but practical few-shot class-incremental learning (FSCIL) problem. FSCIL requires CNN models to incrementally learn new classes from very few labelled samples, without forgetting the previously learned ones. To address this problem, we represent the knowledge using a neural gas (NG) network, which can learn and preserve the topology of the feature manifold formed by different classes. On this basis, we propose the TOpology-Preserving knowledge InCrementer (TOPIC) framework. TOPIC mitigates the forgetting of the old classes by stabilizing NG's topology and improves the representation learning for few-shot new classes by growing and adapting NG to new training samples. Comprehensive experimental results demonstrate that our proposed method significantly outperforms other state-of-the-art class-incremental learning methods on CIFAR100, mini-ImageNet, and CUB200 datasets.},
author = {Tao, Xiaoyu and Xiaopeng, Hong and Chang, Xinyuan and Dong, Songlin and Wei, Xing and Gong, Yihong},
booktitle = {Computer Vision and Pattern Recognition (CVPR)},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tao et al. - 2020 - Few-Shot Class-Incremental Learning.pdf:pdf},
title = {{Few-Shot Class-Incremental Learning}},
url = {https://github.com/xyutao/fscil},
year = {2020}
}
@article{Nunes2016,
abstract = {The concept of solar parking lots aims at coupling the development of clean solar electricity and electric mobility. Solar panels provide shade and generate electricity to charge parked electric vehicles. In a vehicle-to-grid approach, the vehicles may also feed the grid and support it with ancillary services. In this paper, we explore the potential of this solution, starting with a concise overview discussing the technical, environmental and financial issues constraining the development of solar parking lots. A comprehensive review of the literature follows, and finally open issues and prospects for future work are identified. It is intended that this paper may serve as a standalone summary of the most important work on this topic to date.},
author = {Nunes, Pedro and Figueiredo, Raquel and Brito, Miguel C.},
doi = {10.1016/j.rser.2016.08.015},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nunes, Figueiredo, Brito - 2016 - The use of parking lots to solar-charge electric vehicles.pdf:pdf},
issn = {18790690},
journal = {Renewable and Sustainable Energy Reviews},
keywords = {Car parking lots,Electric vehicles,Photovoltaics,Smart charging,Solar energy,Sustainable mobility},
pages = {679--693},
publisher = {Elsevier},
title = {{The use of parking lots to solar-charge electric vehicles}},
url = {http://dx.doi.org/10.1016/j.rser.2016.08.015},
volume = {66},
year = {2016}
}
@article{Pupeza2015,
abstract = {Powerful coherent light with a spectrum spanning the mid-infrared (MIR) spectral range is crucial for a number of applications in natural as well as life sciences, but so far has only been available from large-scale synchrotron sources1. Here we present a compact apparatus that generates pulses with a sub-two-cycle duration and with an average power of 0.1W and a spectral coverage of 6.8–16.4 $\mu$m(at −30 dB). The demonstrated source combines, for the first time in this spectral region, a high power, a high repetition rate and phase coherence. The MIR pulses emerge via difference-fre- quency generation (DFG) driven by the nonlinearly compressed pulses of a Kerr-lens mode-locked ytterbium-doped yttrium– aluminium–garnet (Yb:YAG) thin-disc oscillator. The resultant 100 MHz MIR pulse train is hundreds to thousands of times more powerful than state-of-the-art frequency combs that emit in this range2–4, and offers a high dynamic range for spectroscopy in the molecular fingerprint region4–7 and an ideal prerequisite for hyperspectral imaging8 as well as for the time-domain coherent control of vibrational dynamics9–11.},
author = {Pupeza, I. and Sanchez, D. and Zhang, J. and Lilienfein, N. and Seidel, M. and Karpowicz, N. and Paasch-Colberg, T. and Znakovskaya, I. and Pescher, M. and Schweinberger, W. and Pervak, V. and Fill, E. and Pronin, O. and Wei, Z. and Krausz, F. and Apolonski, A. and Biegert, J.},
doi = {10.1038/nphoton.2015.179},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pupeza et al. - 2015 - High-power sub-two-cycle mid-infrared pulses at 100 MHz repetition rate.pdf:pdf},
issn = {17494893},
journal = {Nature Photonics},
number = {11},
pages = {721--724},
publisher = {Nature Publishing Group},
title = {{High-power sub-two-cycle mid-infrared pulses at 100 MHz repetition rate}},
url = {http://dx.doi.org/10.1038/nphoton.2015.179},
volume = {9},
year = {2015}
}
@book{Safranski2017b,
author = {Safranski, David L. and Griffis, Jack C.},
isbn = {9780323377973},
title = {{Shape-memory polymer device design}},
year = {2017}
}
@article{Ashley2021,
abstract = {Catastrophic forgetting remains a severe hindrance to the broad application of artificial neural networks (ANNs), however, it continues to be a poorly understood phenomenon. Despite the extensive amount of work on catastrophic forgetting, we argue that it is still unclear how exactly the phenomenon should be quantified, and, moreover, to what degree all of the choices we make when designing learning systems affect the amount of catastrophic forgetting. We use various testbeds from the reinforcement learning and supervised learning literature to (1) provide evidence that the choice of which modern gradient-based optimization algorithm is used to train an ANN has a significant impact on the amount of catastrophic forgetting and show that--surprisingly--in many instances classical algorithms such as vanilla SGD experience less catastrophic forgetting than the more modern algorithms such as Adam. We empirically compare four different existing metrics for quantifying catastrophic forgetting and (2) show that the degree to which the learning systems experience catastrophic forgetting is sufficiently sensitive to the metric used that a change from one principled metric to another is enough to change the conclusions of a study dramatically. Our results suggest that a much more rigorous experimental methodology is required when looking at catastrophic forgetting. Based on our results, we recommend inter-task forgetting in supervised learning must be measured with both retention and relearning metrics concurrently, and intra-task forgetting in reinforcement learning must--at the very least--be measured with pairwise interference.},
archivePrefix = {arXiv},
arxivId = {2102.07686},
author = {Ashley, Dylan R. and Ghiassian, Sina and Sutton, Richard S.},
eprint = {2102.07686},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ashley, Ghiassian, Sutton - 2021 - Does Standard Backpropagation Forget Less Catastrophically Than Adam.pdf:pdf},
keywords = {adam,backpropagation,continual learning,empirical study,optimization,sgd,survey,theory},
mendeley-tags = {adam,backpropagation,continual learning,empirical study,optimization,sgd,survey,theory},
title = {{Does Standard Backpropagation Forget Less Catastrophically Than Adam?}},
url = {http://arxiv.org/abs/2102.07686},
year = {2021}
}
@article{Ren2017b,
abstract = {Extracting entities and relations for types of interest from text is important for understanding massive text corpora. Traditionally, systems of entity relation extraction have relied on human-annotated corpora for training and adopted an incremental pipeline. Such systems require additional human expertise to be ported to a new domain, and are vulnerable to errors cascading down the pipeline. In this paper, we investigate joint extraction of typed entities and relations with labeled data heuristically obtained from knowledge bases (i.e., distant supervision). As our algorithm for type labeling via distant supervision is context-agnostic, noisy training data poses unique challenges for the task. We propose a novel domain-independent framework, called COTYPE, that runs a data-driven text segmentation algorithm to extract entity mentions, and jointly embeds entity mentions, relation mentions, text features and type labels into two low-dimensional spaces (for entity and relation mentions respectively), where, in each space, objects whose types are close will also have similar representations. COTYPE, then using these learned embeddings, estimates the types of test (unlinkable) mentions. We formulate a joint optimization problem to learn embeddings from text corpora and knowledge bases, adopting a novel partial-label loss function for noisy labeled data and introducing an object "translation" function to capture the cross-constraints of entities and relations on each other. Experiments on three public datasets demonstrate the effectiveness of COTYPE across different domains (e.g., news, biomedical), with an average of 25% improvement in F1 score compared to the next best method.},
archivePrefix = {arXiv},
arxivId = {1610.08763},
author = {Ren, Xiang and Wu, Zeqiu and He, Wenqi and Qu, Meng and Voss, Clare R. and Ji, Heng and Abdelzaher, Tarek F. and Han, Jiawei},
doi = {10.1145/3038912.3052708},
eprint = {1610.08763},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ren et al. - 2017 - CoType Joint extraction of typed entities and relations with knowledge bases.pdf:pdf},
isbn = {9781450349130},
journal = {26th International World Wide Web Conference, WWW 2017},
keywords = {information extraction,joint entity and relation extraction,natural language processing},
mendeley-tags = {information extraction,joint entity and relation extraction,natural language processing},
pages = {1015--1024},
title = {{CoType: Joint extraction of typed entities and relations with knowledge bases}},
year = {2017}
}
@inproceedings{Yang2021,
abstract = {Learning from a limited number of samples is challenging since the learned model can easily become overfitted based on the biased distribution formed by only a few training examples. In this paper, we calibrate the distribution of these few-sample classes by transferring statistics from the classes with sufficient examples, then an adequate number of examples can be sampled from the calibrated distribution to expand the inputs to the classifier. We assume every dimension in the feature representation follows a Gaussian distribution so that the mean and the variance of the distribution can borrow from that of similar classes whose statistics are better estimated with an adequate number of samples. Our method can be built on top of off-the-shelf pretrained feature extractors and classification models without extra parameters. We show that a simple logistic regression classifier trained using the features sampled from our calibrated distribution can outperform the state-of-the-art accuracy on two datasets ($\sim$5% improvement on miniImageNet compared to the next best). The visualization of these generated features demonstrates that our calibrated distribution is an accurate estimation.},
archivePrefix = {arXiv},
arxivId = {2101.06395},
author = {Yang, Shuo and Liu, Lu and Xu, Min},
booktitle = {Iclr 2021},
eprint = {2101.06395},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang, Liu, Xu - 2021 - Free Lunch for Few-shot Learning Distribution Calibration(2).pdf:pdf},
keywords = {distribution calibration,few-shot learning},
mendeley-tags = {distribution calibration,few-shot learning},
pages = {1--13},
title = {{Free Lunch for Few-shot Learning: Distribution Calibration}},
url = {http://arxiv.org/abs/2101.06395},
year = {2021}
}
@article{Roschat2012,
abstract = {We present an environmentally friendly, efficient, simple heterogeneous transesterification process combining palm oil, soybean oil, rice bran oil, and waste cooking oil with methanol to make a biodiesel and glycerol by-product using calcined waste coral fragments in solid form as a catalyst. Under optimum reaction conditions, the coral fragments calcined at 700°C for 1 h; catalyst/oil ratio of 100 wt.%; methanol/oil molar ratio of 15:1; reaction temperature of 65°C with a constant stirring are able to transesterify oils to a biodiesel product with a FAME yield over 98% in 2 h. The catalyst can be easily separated from the reaction mixture by pouring off the reaction solution and can be reused several times with consistent results. Biodiesel and glycerol products without any treatment and cleansing show a high quality product in which fuel properties of the biodiesel meet all EN 14214 standards for bio-auto fuels. {\textcopyright} 2012 Elsevier Ltd. All rights reserved.},
author = {Roschat, Wuttichai and Kacha, Mattana and Yoosuk, Boonyawan and Sudyoadsuk, Taweesak and Promarak, Vinich},
doi = {10.1016/j.fuel.2012.04.009},
isbn = {0016-2361},
issn = {00162361},
journal = {Fuel},
keywords = {Biodiesel,Coral fragment,Glycerol,Heterogeneous process,Solid catalyst},
pages = {194--202},
publisher = {Elsevier Ltd},
title = {{Biodiesel production based on heterogeneous process catalyzed by solid waste coral fragment}},
url = {http://dx.doi.org/10.1016/j.fuel.2012.04.009},
volume = {98},
year = {2012}
}
@article{Armstrong1989,
abstract = {Research from over 200 studies demonstrates that combining forecasts produces consistent but modest gains in accuracy. However, this research does not define well the conditions under which combining is most effective nor how methods should be combined in each situation. Rule-based forecasting can be used to define these conditions and to specify more effective combinations. {\textcopyright} 1990.},
author = {Armstrong, J. Scott},
doi = {10.1016/0169-2070(89)90013-7},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Combining forecasts,Meta-analysis,Realistic simulations,Rule-based forecasting},
number = {4},
pages = {585--588},
title = {{Combining forecasts: The end of the beginning or the beginning of the end?}},
volume = {5},
year = {1989}
}
@article{Zhou2020b,
abstract = {Recent advances in object detection have benefited significantly from rapid developments in deep neural networks. However, neural networks suffer from the well-known issue of catastrophic forgetting, which makes continual or lifelong learning problematic. In this paper, we leverage the fact that new training classes arrive in a sequential manner and incrementally refine the model so that it additionally detects new object classes in the absence of previous training data. Specifically, we consider the representative object detector, Faster R-CNN, for both accurate and efficient prediction. To prevent abrupt performance degradation due to catastrophic forgetting, we propose to apply knowledge distillation on both the region proposal network and the region classification network, to retain the detection of previously trained classes. A pseudo-positive-aware sampling strategy is also introduced for distillation sample selection. We evaluate the proposed method on PASCAL VOC 2007 and MS COCO benchmarks and show competitive mAP and 6x inference speed improvement, which makes the approach more suitable for real-time applications. Our implementation will be publicly available.},
archivePrefix = {arXiv},
arxivId = {2009.01129},
author = {Zhou, Wang and Chang, Shiyu and Sosa, Norma and Hamann, Hendrik and Cox, David},
eprint = {2009.01129},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou et al. - 2020 - Lifelong object detection.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {continual learning,incremental learning,object detection},
mendeley-tags = {continual learning,incremental learning,object detection},
title = {{Lifelong object detection}},
year = {2020}
}
@inproceedings{Li2019b,
abstract = {Object detection models shipped with camera-equipped edge devices cannot cover the objects of interest for every user. Therefore, the incremental learning capability is a critical feature for a robust and personalized object detection system that many applications would rely on. In this paper, we present an efficient yet practical system, RILOD, to incrementally train an existing object detection model such that it can detect new object classes without losing its capability to detect old classes. The key component of RILOD is a novel incremental learning algorithm that trains end-to-end for one-stage deep object detection models only using training data of new object classes. Specifically to avoid catastrophic forgetting, the algorithm distills three types of knowledge from the old model to mimic the old model's behavior on object classification, bounding box regression and feature extraction. In addition, since the training data for the new classes may not be available, a real-time dataset construction pipeline is designed to collect training images on-the-fly and automatically label the images with both category and bounding box annotations. We have implemented RILOD under both edge-cloud and edge-only setups. Experiment results show that the proposed system can learn to detect a new object class in just a few minutes, including both dataset construction and model training. In comparison, traditional fine-tuning based method may take a few hours for training, and in most cases would also need a tedious and costly manual dataset labeling step.},
address = {New York, NY, USA},
author = {Li, Dawei and Tasci, Serafettin and Ghosh, Shalini and Zhu, Jingwen and Zhang, Junting and Heck, Larry},
booktitle = {Proceedings of the 4th ACM/IEEE Symposium on Edge Computing},
doi = {10.1145/3318216.3363317},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2019 - RILOD Near Real-Time Incremental Learning for Object Detection at the Edge.pdf:pdf},
isbn = {9781450367332},
issn = {23318422},
keywords = {Deep neural networks,Edge computing,Incremental learning,Object detection,continual learning,incremental learning,object detection},
mendeley-tags = {continual learning,incremental learning,object detection},
month = {nov},
pages = {113--126},
publisher = {ACM},
title = {{RILOD: Near Real-Time Incremental Learning for Object Detection at the Edge}},
url = {https://dl.acm.org/doi/10.1145/3318216.3363317},
year = {2019}
}
@article{Liu2015,
abstract = {Restoration of images degraded by blurring and impulse noise has received considerable attention recently. Guo et al. (2009) proposed a fast <sup>l1</sup>-total variation algorithm for grayscale image restoration with impulse noise. In this paper, we extend their idea for deblurring color images with impulse noise. An alternating iteration scheme is adopted for solving the corresponding problem. More importantly, we employ the five-point property to analyze the convergence of the proposed alternating algorithm. Numerical experiments demonstrate that the proposed method could deblur color images with good quality.},
author = {Liu, Jun and Huang, Ting Zhu and Lv, Xiao Guang and Huang, Jie},
doi = {10.1016/j.camwa.2015.06.029},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2015 - Restoration of blurred color images with impulse noise.pdf:pdf},
issn = {08981221},
journal = {Computers and Mathematics with Applications},
keywords = {Color image,Five-point property,Impulse noise,Restoration},
number = {6},
pages = {1255--1265},
publisher = {Elsevier Ltd},
title = {{Restoration of blurred color images with impulse noise}},
url = {http://dx.doi.org/10.1016/j.camwa.2015.06.029},
volume = {70},
year = {2015}
}
@article{Wu2020b,
abstract = {Current deep learning architectures suffer from catastrophic forgetting, a failure to retain knowledge of previously learned classes when incrementally trained on new classes. The fundamental roadblock faced by deep learning methods is that deep learning models are optimized as "black boxes," making it difficult to properly adjust the model parameters to preserve knowledge about previously seen data. To overcome the problem of catastrophic forgetting, we propose utilizing an alternative "white box" architecture derived from the principle of rate reduction, where each layer of the network is explicitly computed without back propagation. Under this paradigm, we demonstrate that, given a pre-trained network and new data classes, our approach can provably construct a new network that emulates joint training with all past and new classes. Finally, our experiments show that our proposed learning algorithm observes significantly less decay in classification performance, outperforming state of the art methods on MNIST and CIFAR-10 by a large margin and justifying the use of "white box" algorithms for incremental learning even for sufficiently complex image data.},
archivePrefix = {arXiv},
arxivId = {2011.14593},
author = {Wu, Ziyang and Baek, Christina and You, Chong and Ma, Yi},
eprint = {2011.14593},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu et al. - 2020 - Incremental Learning via Rate Reduction.pdf:pdf},
keywords = {continual learning,rate reduction},
mendeley-tags = {continual learning,rate reduction},
title = {{Incremental Learning via Rate Reduction}},
url = {http://arxiv.org/abs/2011.14593},
year = {2020}
}
@article{Cheraghian2021,
abstract = {Few-shot class incremental learning (FSCIL) portrays the problem of learning new concepts gradually, where only a few examples per concept are available to the learner. Due to the limited number of examples for training, the techniques developed for standard incremental learning cannot be applied verbatim to FSCIL. In this work, we introduce a distillation algorithm to address the problem of FSCIL and propose to make use of semantic information during training. To this end, we make use of word embeddings as semantic information which is cheap to obtain and which facilitate the distillation process. Furthermore, we propose a method based on an attention mechanism on multiple parallel embeddings of visual data to align visual and semantic vectors, which reduces issues related to catastrophic forgetting. Via experiments on MiniImageNet, CUB200, and CIFAR100 dataset, we establish new state-of-the-art results by outperforming existing approaches.},
archivePrefix = {arXiv},
arxivId = {2103.04059},
author = {Cheraghian, Ali and Rahman, Shafin and Fang, Pengfei and Roy, Soumava Kumar and Petersson, Lars and Harandi, Mehrtash},
doi = {10.1109/CVPR46437.2021.00256},
eprint = {2103.04059},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cheraghian et al. - 2021 - Semantic-aware Knowledge Distillation for Few-Shot Class-Incremental Learning.pdf:pdf},
isbn = {9781665445092},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
keywords = {continual learning},
mendeley-tags = {continual learning},
pages = {2534--2543},
title = {{Semantic-aware Knowledge Distillation for Few-Shot Class-Incremental Learning}},
year = {2021}
}
@article{Domanska2012,
abstract = {In the paper a model to predict the concentrations of particulate matter PM10, PM2.5, SO2, NO, CO and O3for a chosen number of hours forward is proposed. The method requires historical data for a large number of points in time, particularly weather forecast data, actual weather data and pollution data. The idea is that by matching forecast data with similar forecast data in the historical data set it is possible then to obtain actual weather data and through this pollution data. To aggregate time points with similar forecast data determined by a distance function, fuzzy numbers are generated from the forecast data, covering forecast data and actual data. Again using a distance function, actual data is compared with the fuzzy number to determine how the grade of membership is. The model was prepared in such a way that all the data which is usually imprecise, chaotic, uncertain can be used. The model is used in Poland by the Institute of Meteorology and by Water Management, and by the Voivodship Inspector for Environmental Protection. It forecast selected pollution concentrations for all areas of Poland. {\textcopyright} 2012 Elsevier Ltd. All rights reserved.},
author = {Doma{\'{n}}ska, D. and Wojtylak, M.},
doi = {10.1016/j.eswa.2012.01.023},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Doma{\'{n}}ska, Wojtylak - 2012 - Application of fuzzy time series models for forecasting pollution concentrations.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Air pollution forecasting,Data mining,Expert system,Fuzzy numbers,Fuzzy weather forecast,PM10,Prediction},
number = {9},
pages = {7673--7679},
title = {{Application of fuzzy time series models for forecasting pollution concentrations}},
volume = {39},
year = {2012}
}
@inproceedings{Frankle2020,
abstract = {Recent work has explored the possibility of pruning neural networks at initialization. We assess proposals for doing so: SNIP (Lee et al., 2019), GraSP (Wang et al., 2020), SynFlow (Tanaka et al., 2020), and magnitude pruning. Although these methods surpass the trivial baseline of random pruning, they remain below the accuracy of magnitude pruning after training, and we endeavor to understand why. We show that, unlike pruning after training, accuracy is the same or higher when randomly shuffling which weights these methods prune within each layer or sampling new initial values. As such, the per-weight pruning decisions made by these methods can be replaced by a per-layer choice of the fraction of weights to prune. This property undermines the claimed justifications for these methods and suggests broader challenges with the underlying pruning heuristics, the desire to prune at initialization, or both.},
archivePrefix = {arXiv},
arxivId = {2009.08576},
author = {Frankle, Jonathan and Dziugaite, Gintare Karolina and Roy, Daniel M. and Carbin, Michael},
booktitle = {Iclr 2021},
eprint = {2009.08576},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Frankle et al. - 2020 - Pruning neural networks at initialization Why are we Missing the Mark.pdf:pdf},
issn = {23318422},
keywords = {initialization,pruning},
mendeley-tags = {initialization,pruning},
pages = {1--29},
title = {{Pruning neural networks at initialization: Why are we Missing the Mark?}},
year = {2020}
}
@article{Wang2018c,
abstract = {Model distillation aims to distill the knowledge of a complex model into a simpler one. In this paper, we consider an alternative formulation called dataset distillation: we keep the model fixed and instead attempt to distill the knowledge from a large training dataset into a small one. The idea is to synthesize a small number of data points that do not need to come from the correct data distribution, but will, when given to the learning algorithm as training data, approximate the model trained on the original data. For example, we show that it is possible to compress 60,000 MNIST training images into just 10 synthetic distilled images (one per class) and achieve close to original performance with only a few gradient descent steps, given a fixed network initialization. We evaluate our method in various initialization settings and with different learning objectives. Experiments on multiple datasets show the advantage of our approach compared to alternative methods.},
archivePrefix = {arXiv},
arxivId = {1811.10959},
author = {Wang, Tongzhou and Zhu, Jun-Yan and Torralba, Antonio and Efros, Alexei A.},
eprint = {1811.10959},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2018 - Dataset Distillation.pdf:pdf},
keywords = {dataset,dataset distillation,distillation},
mendeley-tags = {dataset,dataset distillation,distillation},
pages = {1--14},
title = {{Dataset Distillation}},
url = {http://arxiv.org/abs/1811.10959},
year = {2018}
}
@article{Londhe2006,
abstract = {Abstract Sophisticated wave models like the Wave Model (WAM) and Simulating Waves Nearshore (SWAN)/WAVEWATCH are used nowadays along with atmospheric models to produce forecasts of ocean wave conditions. These models are generally run operationally on large ocean-scale domains. In many coastal areas, on the other hand, operational forecasting is not performed for a variety of reasons, yet the need for wave forecasts remains. To address such cases, the production of forecasts through the use of artificial neural networks and buoy measurements is explored. A modeling strategy that predicts wave heights up to 24 h on the basis of judiciously selected measurements over the previous 7 days was examined. A detailed investigation of this strategy using data from six National Data Buoy Center (NDBC) buoys with diverse geographical and statistical properties demonstrates that 6-h forecasts can be obtained with a high level of fidelity, and forecasts up to 12 h showed a correlation of 67% or better relative to a fu...},
author = {Londhe, S. N. and Panchang, Vijay},
doi = {10.1175/JTECH1932.1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Londhe, Panchang - 2006 - One-day wave forecasts based on artificial neural networks.pdf:pdf},
issn = {07390572},
journal = {Journal of Atmospheric and Oceanic Technology},
number = {11},
pages = {1593--1603},
title = {{One-day wave forecasts based on artificial neural networks}},
volume = {23},
year = {2006}
}
@article{Wang2018b,
author = {Wang, James Z and Lu, Xin and Lin, Zhe},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Lu, Lin - 2018 - I Nformative a Ssumption in C Hannel P Runing.pdf:pdf},
number = {2017},
pages = {1--11},
title = {{I Nformative a Ssumption in C Hannel P Runing}},
year = {2018}
}
@article{Chen2020c,
abstract = {In this paper, we consider the problem of fine-grained image retrieval in an incremental setting, when new categories are added over time. On the one hand, repeatedly training the representation on the extended dataset is time-consuming. On the other hand, fine-tuning the learned representation only with the new classes leads to catastrophic forgetting. To this end, we propose an incremental learning method to mitigate retrieval performance degradation caused by the forgetting issue. Without accessing any samples of the original classes, the classifier of the original network provides soft “labels” to transfer knowledge to train the adaptive network, so as to preserve the previous capability for classification. More importantly, a regularization function based on Maximum Mean Discrepancy is devised to minimize the discrepancy of new classes features from the original network and the adaptive network, respectively. Extensive experiments on two datasets show that our method effectively mitigates the catastrophic forgetting on the original classes while achieving high performance on the new classes.},
archivePrefix = {arXiv},
arxivId = {2010.08020},
author = {Chen, Wei and Liu, Yu and Wang, Weiping and Tuytelaars, Tinne and Bakker, Erwin M. and Lew, Michael},
eprint = {2010.08020},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2020 - On the exploration of incremental learning for fine-grained image retrieval(2).pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {continual learning,fine-grained,image retrieval,incremental learning},
mendeley-tags = {continual learning,fine-grained,image retrieval,incremental learning},
title = {{On the exploration of incremental learning for fine-grained image retrieval}},
year = {2020}
}
@article{Javedani2017,
author = {Javedani, Hossein and Gadelha, Frederico and Jos{\'{e}}, Cidiney and Hisyam, Muhammad and Eslami, Tayyebeh},
doi = {10.1016/j.ijar.2017.01.006},
issn = {0888-613X},
journal = {International Journal of Approximate Reasoning},
keywords = {short term load forecasting,stlf},
pages = {196--217},
publisher = {Elsevier Inc.},
title = {{Short-term load forecasting method based on fuzzy time series , seasonality and long memory process}},
url = {http://dx.doi.org/10.1016/j.ijar.2017.01.006},
volume = {83},
year = {2017}
}
@inproceedings{Caccia2022,
abstract = {In the online continual learning paradigm, agents must learn from a changing distribution while respecting memory and compute constraints. Experience Replay (ER), where a small subset of past data is stored and replayed alongside new data, has emerged as a simple and effective learning strategy. In this work, we focus on the change in representations of observed data that arises when previously unobserved classes appear in the incoming data stream, and new classes must be distinguished from previous ones. We shed new light on this question by showing that applying ER causes the newly added classes' representations to overlap significantly with the previous classes, leading to highly disruptive parameter updates. Based on this empirical analysis, we propose a new method which mitigates this issue by shielding the learned representations from drastic adaptation to accommodate new classes. We show that using an asymmetric update rule pushes new classes to adapt to the older ones (rather than the reverse), which is more effective especially at task boundaries, where much of the forgetting typically occurs. Empirical results show significant gains over strong baselines on standard continual learning benchmarks},
archivePrefix = {arXiv},
arxivId = {2203.03798},
author = {Caccia, Lucas and Aljundi, Rahaf and Asadi, Nader and Tuytelaars, Tinne and Pineau, Joelle and Belilovsky, Eugene},
booktitle = {International Conference on Learning Representations},
eprint = {2203.03798},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Caccia et al. - 2022 - New Insights on Reducing Abrupt Representation Change in Online Continual Learning.pdf:pdf},
month = {mar},
pages = {1--16},
title = {{New Insights on Reducing Abrupt Representation Change in Online Continual Learning}},
url = {http://arxiv.org/abs/2203.03798},
volume = {1},
year = {2022}
}
@article{Xu2013,
abstract = {Some climate datasets are incomplete at certain places and times. A novel technique called the point estimation model of Biased Sentinel Hospitals-based Area Disease Estimation(P-BSHADE)is introduced to interpolate missing data in temperature datasets. Effectiveness of the technique was empirically evaluated in terms of an annual temperature dataset from 1950 to 2000 in China. The P-BSHADE technique uses a weighted summation of observed stations to derive unbiased and minimum error variance estimates of missing data. Both the ratio and covariance between stations were used in calculation of these weights. In this way, interpolation of missing data in the temperature dataset was improved, and best linear unbiased esti- mates (BLUE) were obtained. Using the same dataset, performance of P-BSHADE was compared against three estimators: kriging, inverse distance weighting (IDW), and spatial regression test (SRT). Kriging and IDW assume a homogeneous stochastic field, which may not be the case. SRT employs spatiotemporal data and has the potential to consider temperature nonhomogeneity caused by topographic differences, but has no objective function for the BLUE. Instead, P-BSHADEtakes into account geographic spatial autocorrelation and nonhomogeneity, and maximizes an objective function for the BLUE of the target station. In addition to the theoretical advantages of P-BSHADE over the three other methods, case studies for an annual Chinese temperature dataset demonstrate its empirical superiority, except for the SRT from 1950 to 1970.},
author = {Xu, Cheng Dong and Wang, Jin Feng and Hu, Mao Gui and Li, Qing Xiang},
doi = {10.1175/JCLI-D-12-00633.1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu et al. - 2013 - Interpolation of missing temperature data at meteorological stations using P-BSHADE.pdf:pdf},
isbn = {0894-8755},
issn = {08948755},
journal = {Journal of Climate},
keywords = {Interpolation schemes},
number = {19},
pages = {7452--7463},
title = {{Interpolation of missing temperature data at meteorological stations using P-BSHADE}},
volume = {26},
year = {2013}
}
@article{Duan2019,
abstract = {In object detection, keypoint-based approaches often suffer a large number of incorrect object bounding boxes, arguably due to the lack of an additional look into the cropped regions. This paper presents an efficient solution which explores the visual patterns within each cropped region with minimal costs. We build our framework upon a representative one-stage keypoint-based detector named CornerNet. Our approach, named CenterNet, detects each object as a triplet, rather than a pair, of keypoints, which improves both precision and recall. Accordingly, we design two customized modules named cascade corner pooling and center pooling, which play the roles of enriching information collected by both top-left and bottom-right corners and providing more recognizable information at the central regions, respectively. On the MS-COCO dataset, CenterNet achieves an AP of 47.0%, which outperforms all existing one-stage detectors by at least 4.9%. Meanwhile, with a faster inference speed, CenterNet demonstrates quite comparable performance to the top-ranked two-stage detectors. Code is available at https://github.com/Duankaiwen/CenterNet.},
archivePrefix = {arXiv},
arxivId = {1904.08189},
author = {Duan, Kaiwen and Bai, Song and Xie, Lingxi and Qi, Honggang and Huang, Qingming and Tian, Qi},
eprint = {1904.08189},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Duan et al. - 2019 - CenterNet Keypoint Triplets for Object Detection.pdf:pdf},
pages = {1--10},
title = {{CenterNet: Keypoint Triplets for Object Detection}},
url = {http://arxiv.org/abs/1904.08189},
year = {2019}
}
@inproceedings{Zhao2020b,
abstract = {Unsupervised visual pretraining based on the instance discrimination pretext task has shown significant progress. Notably, in the recent work of MoCo, unsupervised pretraining1 has shown to surpass the supervised counterpart for finetuning downstream applications such as object detection on PASCAL VOC. It comes as a surprise that image annotations would be better left unused for transfer learning. In this work, we investigate the following problems: What makes instance discrimination pretraining good for transfer learning? What knowledge is actually learned and transferred from unsupervised pretraining? From this understanding of unsupervised pretraining, can we make supervised pretraining great again? Our findings are threefold. First, what truly matters for this detection transfer is low-level and mid-level representations, not high-level representations. Second, the intra-category invariance enforced by the traditional supervised model weakens transferability by increasing task misalignment. Finally, supervised pretraining can be strengthened by following an exemplar-based approach without explicit constraints among the instances within the same category.},
archivePrefix = {arXiv},
arxivId = {2006.06606},
author = {Zhao, Nanxuan and Wu, Zhirong and Lau, Rynson W.H. and Lin, Stephen},
booktitle = {Iclr 2021},
eprint = {2006.06606},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao et al. - 2020 - What makes instance discrimination good for transfer learning.pdf:pdf},
issn = {23318422},
keywords = {transfer learning},
mendeley-tags = {transfer learning},
pages = {1--17},
title = {{What makes instance discrimination good for transfer learning?}},
year = {2020}
}
@article{MFSWG2013,
author = {(MFSWG), Mobile Financial Services Working Group},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/(MFSWG) - 2013 - Mobile Financial Services Basic Terminology.pdf:pdf},
number = {2},
title = {{Mobile Financial Services Basic Terminology}},
year = {2013}
}
@book{Teixeira2012a,
abstract = {The use of natural ventilation systems may contribute considerably to the reduction of the energy consumption, while providing adequate comfort levels and hygiene standards for the occupants. Computational Fluid Dynamics (CFD) techniques are becoming increasingly attractive in the design of ventilation systems. In this work, tests on a validated CFD model, which simulates the air flow inside a standard building, were carried out in order to obtain a suitable tool to predict ventilation performance and therefore optimize the building ventilation design. The model solves the mass, momentum and energy for the air flow, coupled with the k-$\epsilon$ turbulence model. The equations are solved by a FV discretization technique in a structured grid. Appropriated boundary conditions and the dimension of the domain were studied for more accuracy in numeric simulation. The influence of the free stream velocity profile and wind direction upon the efficiency of a natural ventilation system under isothermal conditions has been tested. The results obtained so far confirm the validity of the implemented model and its possible use for the optimal design of natural ventilation systems.},
author = {Teixeira, Jos{\'{e}} Carlos and Lomba, Ricardo and Teixeira, Senhorinha F.C.F. and Lobarinhas, Pedro},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-31137-6_15},
isbn = {9783642311369},
issn = {03029743},
keywords = {Computational Fluid Dynamics (CFD),Natural ventilation,Sustainable systems},
number = {PART 3},
pages = {202--216},
title = {{Application of CFD tools to optimize natural building ventilation design}},
volume = {7335 LNCS},
year = {2012}
}
@article{DeMaio2017,
abstract = {Understanding situations occurring within the physical world by analyzing streams of sensor data is a complex task for both human and software agents. In the area of situation awareness, the observer is typically overwhelmed by information overload and by intrinsic difficulties of making sense of spatially distributed and temporal-ordered sensor observations. Thus, it is desirable to design effective decision-support systems and develop efficient methods to handle sensor data streams. The proposed work is for the comprehension of the situations evolving along the timeline and the projection of recognized situations in the near future. The system analyzes semantic sensor streams, it extracts temporal pattern describing events flow and provides useful insights with respect to the operators' goals. We implement a hybrid solution for situation comprehension and projection that combines data-driven approach, by using temporal extension of Fuzzy Formal Concept Analysis, and goal-driven approach, by using Fuzzy Cognitive Maps. The cloud-based architecture integrates a distributed algorithm to perform Fuzzy Formal Concept Analysis enabling to deal with deluge of sensor data stream acquired through a sensor-cloud architecture. We discuss the results in terms of prediction accuracy by simulating sensor data stream to early recognize daily life activities inside an apartment.},
author = {{De Maio}, Carmen and Fenza, Giuseppe and Loia, Vincenzo and Orciuoli, Francesco},
doi = {10.1016/j.neucom.2016.06.090},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Maio et al. - 2017 - Making sense of cloud-sensor data streams via Fuzzy Cognitive Maps and Temporal Fuzzy Concept Analysis.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Cloud computing,Fuzzy cognitive maps,Fuzzy formal concept analysis,Sensor cloud},
number = {2017},
pages = {35--48},
publisher = {Elsevier B.V.},
title = {{Making sense of cloud-sensor data streams via Fuzzy Cognitive Maps and Temporal Fuzzy Concept Analysis}},
url = {http://dx.doi.org/10.1016/j.neucom.2016.06.090},
volume = {256},
year = {2017}
}
@article{Ui1974,
author = {Ui, F T},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ui - 1974 - Wetting agent.pdf:pdf},
pages = {5--16},
title = {{Wetting agent}},
year = {1974}
}
@article{Cermelli2020a,
abstract = {Reducing the amount of supervision required by neural networks is especially important in the context of semantic segmentation, where collecting dense pixel-level annotations is particularly expensive. In this paper, we address this problem from a new perspective: Incremental Few-Shot Segmentation. In particular, given a pretrained segmentation model and few images containing novel classes, our goal is to learn to segment novel classes while retaining the ability to segment previously seen ones. In this context, we discover, against all beliefs, that fine-tuning the whole architecture with these few images is not only meaningful, but also very effective. We show how the main problems of end-to-end training in this scenario are i) the drift of the batch-normalization statistics toward novel classes that we can fix with batch renormalization and ii) the forgetting of old classes, that we can fix with regularization strategies. We summarize our findings with five guidelines that together consistently lead to the state of the art on the COCO and Pascal-VOC 2012 datasets, with different number of images per class and even with multiple learning episodes.},
archivePrefix = {arXiv},
arxivId = {2012.01415},
author = {Cermelli, Fabio and Mancini, Massimiliano and Xian, Yongqin and Akata, Zeynep and Caputo, Barbara},
eprint = {2012.01415},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cermelli et al. - 2020 - A few guidelines for incremental few-shot segmentation.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {continual learning,few-shot learning,incremental learning,semantic segmentation},
mendeley-tags = {continual learning,few-shot learning,incremental learning,semantic segmentation},
title = {{A few guidelines for incremental few-shot segmentation}},
year = {2020}
}
@article{Aghdam2019,
abstract = {The cost of drawing object bounding boxes (i.e. labeling) for millions of images is prohibitively high. For instance, labeling pedestrians in a regular urban image could take 35 seconds on average. Active learning aims to reduce the cost of labeling by selecting only those images that are informative to improve the detection network accuracy. In this paper, we propose a method to perform active learning of object detectors based on convolutional neural networks. We propose a new image-level scoring process to rank unlabeled images for their automatic selection, which clearly outperforms classical scores. The proposed method can be applied to videos and sets of still images. In the former case, temporal selection rules can complement our scoring process. As a relevant use case, we extensively study the performance of our method on the task of pedestrian detection. Overall, the experiments show that the proposed method performs better than random selection.},
archivePrefix = {arXiv},
arxivId = {1911.09168},
author = {Aghdam, Hamed H. and Gonzalez-Garcia, Abel and Lopez, Antonio and Weijer, Joost},
doi = {10.1109/ICCV.2019.00377},
eprint = {1911.09168},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aghdam et al. - 2019 - Active learning for deep detection neural networks.pdf:pdf},
isbn = {9781728148038},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
keywords = {active learning,object detection},
mendeley-tags = {active learning,object detection},
number = {Cvc},
pages = {3671--3679},
title = {{Active learning for deep detection neural networks}},
volume = {2019-Octob},
year = {2019}
}
@article{Gontier2020a,
abstract = {We are interested in understanding how well Transformer language models (TLMs) can perform reasoning tasks when trained on knowledge encoded in the form of natural language. We investigate their systematic generalization abilities on a logical reasoning task in natural language, which involves reasoning over relationships between entities grounded in first-order logical proofs. Specifically, we perform soft theorem-proving by leveraging TLMs to generate natural language proofs. We test the generated proofs for logical consistency, along with the accuracy of the final inference. We observe length-generalization issues when evaluated on longer-than-trained sequences. However, we observe TLMs improve their generalization performance after being exposed to longer, exhaustive proofs. In addition, we discover that TLMs are able to generalize better using backward-chaining proofs compared to their forward-chaining counterparts, while they find it easier to generate forward chaining proofs. We observe that models that are not trained to generate proofs are better at generalizing to problems based on longer proofs. This suggests that Transformers have efficient internal reasoning strategies that are harder to interpret. These results highlight the systematic generalization behavior of TLMs in the context of logical reasoning, and we believe this work motivates deeper inspection of their underlying reasoning strategies.},
archivePrefix = {arXiv},
arxivId = {2009.14786},
author = {Gontier, Nicolas and Sinha, Koustuv and Reddy, Siva and Pal, Christopher},
eprint = {2009.14786},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gontier et al. - 2020 - Measuring Systematic Generalization in Neural Proof Generation with Transformers.pdf:pdf},
number = {NeurIPS},
title = {{Measuring Systematic Generalization in Neural Proof Generation with Transformers}},
url = {http://arxiv.org/abs/2009.14786},
year = {2020}
}
@article{You2017,
author = {You, Won Suk and Seo, Joon Kyue and Kang, Gitae and Oh, Hyun Seok and Choi, Hyouk Ryeol},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/You et al. - 2017 - Kinematic design optimization of improved branched tendon mechanism using genetic algorithm.pdf:pdf},
isbn = {9781509030569},
journal = {Ubiquitous Robots and Ambient Intelligence (URAI), 2017 14th International Conference on},
keywords = {design op-,genetic algorithm,kinematic,tendon driven actuation,timization},
pages = {771--776},
title = {{Kinematic design optimization of improved branched tendon mechanism using genetic algorithm}},
volume = {1},
year = {2017}
}
@article{Cerussi,
author = {Cerussi, Albert and Tanamai, Wendy and Hsiang, David and Chung, Sophie and Kukreti, Shwayta and Mehta, Rita and Gratton, Enrico and Tromberg, Bruce},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cerussi et al. - Unknown - Breast Cancer Applications of Optical Imaging Biomarkers measured with Diffuse Optical Spectroscopic Imaging.pdf:pdf},
title = {{Breast Cancer Applications of Optical Imaging Biomarkers measured with Diffuse Optical Spectroscopic Imaging Current Research Team}}
}
@article{Blum1997,
abstract = {In this survey, we review work in machine learning on\nmethods for handling data sets containing large amounts\nof irrelevant information. We focus on two key issues:\nthe problem of selecting relevant features, and the\nproblem of selecting relevant examples. We describe the\nadvances that have been made on these topics in both\nempirical and theoretical work in machine learning, and\nwe present a general framework that we use to compare\ndifferent methods. We close with some challenges for\nfuture work in this area.},
author = {Blum, Avrim L. and Langley, Pat},
doi = {10.1016/S0004-3702(97)00063-5},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Blum, Langley - 1997 - Selection of relevant features and examples in machine learning.pdf:pdf},
isbn = {0004-3702},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {machine learning,relevant examples,relevant features},
number = {1-2},
pages = {245--271},
title = {{Selection of relevant features and examples in machine learning}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0004370297000635},
volume = {97},
year = {1997}
}
@article{Tian,
author = {Tian, Jimin and Huang, Jingwei and Zhao-, Chunjun},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tian, Huang, Zhao- - Unknown - Hybrid Systems Optimization Using Genetic Algoirithms.pdf:pdf},
pages = {579--583},
title = {{Hybrid Systems Optimization Using Genetic Algoirithms}}
}
@article{Ren2017,
abstract = {A microbial fuel cell (MFC) is a bioinspired energy converter which directly converts biomass into electricity through the catalytic activity of a specific species of bacteria. The effect of temperature on a miniaturized microbial fuel cell with Geobacter sulfurreducens dominated mixed inoculum is investigated in this paper for the first time. The miniaturized MFC warrants investigation due to its small thermal mass, and a customized setup is built for the temperature effect characterization. The experiment demonstrates that the optimal temperature for the miniaturized MFC is 322–326 K (49–53 °C). When the temperature is increased from 294 to 322 K, a remarkable current density improvement of 282% is observed, from 2.2 to 6.2 Am−2. Furthermore, we perform in depth analysis on the effect of temperature on the miniaturized MFC, and found that the activation energy for the current limiting mechanism of the MFC is approximately between 0.132 and 0.146 eV, and the result suggest that the electron transfer between cytochrome c is the limiting process for the miniaturized MFC.},
author = {Ren, Hao and Jiang, Chenming and Chae, Junseok},
doi = {10.1186/s40486-017-0048-8},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ren, Jiang, Chae - 2017 - Effect of temperature on a miniaturized microbial fuel cell (MFC).pdf:pdf},
issn = {2213-9621},
journal = {Micro and Nano Systems Letters},
keywords = {Microbial fuel cell (MFC),Micro-electro-mechanical,activation,cytochrome c,eet,energy,extracellular electron transfer,mems,mfc,micro-electro-mechanical systems,microbial fuel cell,rate limiting step,temperature effect},
number = {1},
pages = {13},
publisher = {Springer Berlin Heidelberg},
title = {{Effect of temperature on a miniaturized microbial fuel cell (MFC)}},
url = {http://mnsl-journal.springeropen.com/articles/10.1186/s40486-017-0048-8},
volume = {5},
year = {2017}
}
@book{Simha2017,
abstract = {Materials for smart applications are finding their utility in wide variety of actuators. Shape-memory alloys are a class of materials that undergo deformation upon heating above a critical temperature. The crucial property of actuators is to possess negligible recoverable strain after millions of fatigue cycles. With the increasing applications of shape-memory alloys, the fatigue and crack propagation behavior, failure mechanisms, using phenomelogical curves are very crutial and hence the mechanisms are discussed in detail. Although, several metals exhibit shape-memory effect, Ni–Ti and Cu based alloys are widely used. The present chapter discusses fatigue properties and related theories, crack initiation, phase transformation and the dependent properties, superlasticity, mechanical properties such as stress–strain curves, phase deformation and work hardening of single crystal, polycrystalline shape-memory alloys are presented with evidence from literature on both theoritical and experimental models.},
author = {Simha, N.K. and {Rama Sreekanth}, P.S. and {Venkata Siva}, S.B.},
booktitle = {Reference Module in Materials Science and Materials Engineering},
doi = {10.1016/B978-0-12-803581-8.00874-2},
isbn = {9780128035818},
keywords = {SHS,combustion,composition,titanium},
pages = {270--271},
publisher = {Elsevier Inc.},
title = {{Shape-Memory Alloys}},
url = {http://linkinghub.elsevier.com/retrieve/pii/B9780128035818008742},
year = {2017}
}
@article{Buzzega2020a,
abstract = {Neural networks struggle to learn continuously, as they forget the old knowledge catastrophically whenever the data distribution changes over time. Recently, Continual Learning has inspired a plethora of approaches and evaluation settings; however, the majority of them overlooks the properties of a practical scenario, where the data stream cannot be shaped as a sequence of tasks and offline training is not viable. We work towards General Continual Learning (GCL), where task boundaries blur and the domain and class distributions shift either gradually or suddenly. We address it through Dark Experience Replay, namely matching the network's logits sampled throughout the optimization trajectory, thus promoting consistency with its past. By conducting an extensive analysis on top of standard benchmarks, we show that such a seemingly simple baseline outperforms consolidated approaches and leverages limited resources. To provide a better understanding, we further introduce MNIST-360, a novel GCL evaluation setting.},
archivePrefix = {arXiv},
arxivId = {2004.07211},
author = {Buzzega, Pietro and Boschini, Matteo and Porrello, Angelo and Abati, Davide and Calderara, Simone},
eprint = {2004.07211},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Buzzega et al. - 2020 - Dark experience for general continual learning A strong, simple baseline.pdf:pdf},
journal = {arXiv},
keywords = {continual learning,experience replay,replay},
mendeley-tags = {continual learning,experience replay,replay},
number = {NeurIPS},
title = {{Dark experience for general continual learning: A strong, simple baseline}},
url = {https://arxiv.org/abs/2004.07211 https://github.com/aimagelab/mammoth},
year = {2020}
}
@article{Granados2007,
abstract = {This work studies the activity of activated CaO as a catalyst in the production of biodiesel by transesterification of triglycerides with methanol. Three basic aspects were investigated: the role of H2O and CO2in the deterioration of the catalytic performance by contact with room air, the stability of the catalyst by reutilization in successive runs and the heterogeneous character of the catalytic reaction. The characterization by X-ray diffraction (XRD), evolved gas analysis by mass spectrometry (EGA-MS) during heating the sample under programmed temperature, X-ray photoelectron (XPS) and Fourier transform-infrared (FT-IR) spectroscopies allowed to concluding that CaO is rapidly hydrated and carbonated by contact with room air. Few minutes are enough to chemisorb significant amount of H2O and CO2. It is demonstrated that the CO2is the main deactivating agent whereas the negative effect water is less important. As a matter of fact the surface of the activated catalyst is better described as an inner core of CaO particles covered by very few layers of Ca(OH)2. The activation by outgassing at temperatures ≥973 K are required to revert the CO2poisoning. The catalyst can be reused for several runs without significant deactivation. The catalytic reaction is the result of the heterogeneous and homogeneous contributions. Part of the reaction takes place on basic sites at the surface of the catalyst, the rest is due to the dissolution of the activated CaO in methanol that creates homogeneous leached active species. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Granados, M. L{\'{o}}pez and Poves, M. D.Zafra and Alonso, D. Mart{\'{i}}n and Mariscal, R. and Galisteo, F. Cabello and Moreno-Tost, R. and Santamar{\'{i}}a, J. and Fierro, J. L.G.},
doi = {10.1016/j.apcatb.2006.12.017},
issn = {09263373},
journal = {Applied Catalysis B: Environmental},
keywords = {Ca(OH)2,CaCO3,CaO,Fatty acid methyl esters (FAME),Heterogeneous basic catalyst,Lime,Transesterification},
number = {3},
pages = {317--326},
title = {{Biodiesel from sunflower oil by using activated calcium oxide}},
volume = {73},
year = {2007}
}
@article{Maschler2020,
author = {Maschler, Benjamin and Pham, Thi Thu Huong and Weyrich, Michael},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maschler, Pham, Weyrich - 2020 - Regularization-based Continual Learning for Anomaly Detection in Discrete Manufacturing.pdf:pdf},
journal = {arXiv preprint arXiv:2101.00509},
keywords = {anomaly detection,application,continual learning,deep learning,discrete manufacturing,elastic weight consolidation,industrial transfer learning,learning without forgetting,regularization,regularization strategies,synaptic intelligence},
mendeley-tags = {application,continual learning,regularization},
pages = {1--6},
title = {{Regularization-based Continual Learning for Anomaly Detection in Discrete Manufacturing}},
volume = {00},
year = {2020}
}
@article{Bengtsson2005,
abstract = {PURPOSE: To compare the performance of neural networks for perimetric glaucoma diagnosis when using different types of data inputs: numerical threshold sensitivities, Statpac Total Deviation and Pattern Deviation, and probability scores based on Total and Pattern Deviation probability maps (Carl Zeiss Meditec, Inc., Dublin, CA). METHODS: The results of SITA Standard visual field tests in 213 healthy subjects, 127 patients with glaucoma, 68 patients with concomitant glaucoma and cataract, and 41 patients with cataract only were included. The five different types of input data were entered into five identically designed artificial neural networks. Network thresholds were adjusted for each network. Receiver operating characteristic (ROC) curves were constructed to display the combinations of sensitivity and specificity. RESULTS: Input data in the form of Pattern Deviation probability scores gave the best results, with an area of 0.988 under the ROC curve, and were significantly better (P < 0.001) than threshold sensitivities and numerical Total Deviations and Total Deviation probability scores. The second best result was obtained with numerical Pattern Deviations with an area of 0.980. CONCLUSIONS: The choice of type of data input had important effects on the performance of the neural networks in glaucoma diagnosis. Refined input data, based on Pattern Deviations, resulted in higher sensitivity and specificity than did raw threshold values. Neural networks may have high potential in the production of useful clinical tools for the classification of visual field tests.},
author = {Bengtsson, Boel and Bizios, Dimitrios and Heijl, Anders},
doi = {10.1167/iovs.05-0175},
isbn = {0146-0404 (Print)},
issn = {01460404},
journal = {Investigative Ophthalmology and Visual Science},
number = {10},
pages = {3730--3736},
pmid = {16186356},
title = {{Effects of input data on the performance of a neural network in distinguishing normal and glaucomatous visual fields}},
volume = {46},
year = {2005}
}
@article{Raval2016,
abstract = {The clustering techniques are the most important part of the data analysis and k-means is the oldest and popular clustering technique used. The paper discusses the traditional K-means algorithm with advantages and disadvantages of it. It also includes researched on enhanced k-means proposed by various authors and it also includes the techniques to improve traditional K-means for better accuracy and efficiency. There are two area of concern for improving K-means; 1) is to select initial centroids and 2) by assigning data points to nearest cluster by using equations for calculating mean and distance between two data points. The time complexity of the proposed K-means technique will be lesser that then the traditional one with increase in accuracy and efficiency. The main purpose of the article is to proposed techniques to enhance the techniques for deriving initial centroids and the assigning of the data points to its nearest clusters. The clustering technique proposed in this paper is enhancing the accuracy and time complexity but it still needs some further improvements and in future it is also viable to include efficient techniques for selecting value for initial clusters(k). Experimental results show that the improved method can effectively improve the speed of clustering and accuracy, reducing the computational complexity of the k-means.},
author = {Raval, Unnati R and Jani, Chaita},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Raval, Jani - 2016 - Implementing &amp Improvisation of K-means Clustering Algorithm.pdf:pdf},
journal = {International Journal of Computer Science and Mobile Computing},
number = {5},
pages = {191--203},
title = {{Implementing & Improvisation of K-means Clustering Algorithm}},
url = {http://www.ijcsmc.com/docs/papers/May2016/V5I5201647.pdf},
volume = {55},
year = {2016}
}
@article{Shin2017a,
abstract = {Attempts to train a comprehensive artificial intelligence capable of solving multiple tasks have been impeded by a chronic problem called catastrophic forgetting. Although simply replaying all previous data alleviates the problem, it requires large memory and even worse, often infeasible in real world applications where the access to past data is limited. Inspired by the generative nature of the hippocampus as a short-term memory system in primate brain, we propose the Deep Generative Replay, a novel framework with a cooperative dual model architecture consisting of a deep generative model ("generator") and a task solving model ("solver"). With only these two models, training data for previous tasks can easily be sampled and interleaved with those for a new task. We test our methods in several sequential learning settings involving image classification tasks.},
archivePrefix = {arXiv},
arxivId = {1705.08690},
author = {Shin, Hanul and Lee, Jung Kwon and Kim, Jaehong and Kim, Jiwon},
eprint = {1705.08690},
file = {:home/user/Downloads/1705.08690.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
keywords = {continual learning,generative replay,incremental learning,rehearsal,replay},
mendeley-tags = {continual learning,generative replay,incremental learning,rehearsal,replay},
number = {Nips},
pages = {2991--3000},
title = {{Continual learning with deep generative replay}},
volume = {2017-Decem},
year = {2017}
}
@article{Kim2020,
abstract = {A split-transform-merge strategy has been broadly used as an architectural constraint in convolutional neural networks for visual recognition tasks. It approximates sparsely connected networks by explicitly defining multiple branches to simultaneously learn representations with different visual concepts or properties. Dependencies or interactions between these representations are typically defined by dense and local operations, however, without any adaptiveness or high-level reasoning. In this work, we propose to exploit this strategy and combine it with our Visual Concept Reasoning Networks (VCRNet) to enable reasoning between high-level visual concepts. We associate each branch with a visual concept and derive a compact concept state by selecting a few local descriptors through an attention module. These concept states are then updated by graph-based interaction and used to adaptively modulate the local descriptors. We describe our proposed model by split-transform-attend-interact-modulate-merge stages, which are implemented by opting for a highly modularized architecture. Extensive experiments on visual recognition tasks such as image classification, semantic segmentation, object detection, scene recognition, and action recognition show that our proposed model, VCRNet, consistently improves the performance by increasing the number of parameters by less than 1%.},
archivePrefix = {arXiv},
arxivId = {2008.11783},
author = {Kim, Taesup and Kim, Sungwoong and Bengio, Yoshua},
eprint = {2008.11783},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim, Kim, Bengio - 2020 - Visual concept reasoning networks.pdf:pdf},
journal = {arXiv},
pages = {1--13},
title = {{Visual concept reasoning networks}},
year = {2020}
}
@article{Ghiasi2018,
abstract = {Deep neural networks often work well when they are over-parameterized and trained with a massive amount of noise and regularization, such as weight decay and dropout. Although dropout is widely used as a regularization technique for fully connected layers, it is often less effective for convolutional layers. This lack of success of dropout for convolutional layers is perhaps due to the fact that activation units in convolutional layers are spatially correlated so information can still flow through convolutional networks despite dropout. Thus a structured form of dropout is needed to regularize convolutional networks. In this paper, we introduce DropBlock, a form of structured dropout, where units in a contiguous region of a feature map are dropped together. We found that applying DropbBlock in skip connections in addition to the convolution layers increases the accuracy. Also, gradually increasing number of dropped units during training leads to better accuracy and more robust to hyperparameter choices. Extensive experiments show that DropBlock works better than dropout in regularizing convolutional networks. On ImageNet classification, ResNet-50 architecture with DropBlock achieves 78.13% accuracy, which is more than 1.6% improvement on the baseline. On COCO detection, DropBlock improves Average Precision of RetinaNet from 36.8% to 38.4%.},
archivePrefix = {arXiv},
arxivId = {1810.12890},
author = {Ghiasi, Golnaz and Lin, Tsung Yi and Le, Quoc V.},
eprint = {1810.12890},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghiasi, Lin, Le - 2018 - Dropblock A regularization method for convolutional networks.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {10727--10737},
title = {{Dropblock: A regularization method for convolutional networks}},
volume = {2018-Decem},
year = {2018}
}
@article{Li2019,
abstract = {Population Based Training (PBT) is a recent approach that jointly optimizes neural network weights and hyperparameters which periodically copies weights of the best performers and mutates hyperparameters during training. Previous PBT implementations have been synchronized glass-box systems. We propose a general, black-box PBT framework that distributes many asynchronous "trials" (a small number of training steps with warm-starting) across a cluster, coordinated by the PBT controller. The black-box design does not make assumptions on model architectures, loss functions or training procedures. Our system supports dynamic hyperparameter schedules to optimize both differentiable and non-differentiable metrics. We apply our system to train a state-of-the-art WaveNet generative model for human voice synthesis. We show that our PBT system achieves better accuracy, less sensitivity and faster convergence compared to existing methods, given the same computational resource.},
archivePrefix = {arXiv},
arxivId = {arXiv:1902.01894v1},
author = {Li, Ang and Spyra, Ola and Perel, Sagi and Dalibard, Valentin and Jaderberg, Max and Gu, Chenjie and Budden, David and Harley, Tim and Gupta, Pramod},
doi = {10.1145/3292500.3330649},
eprint = {arXiv:1902.01894v1},
keywords = {based training,black-box optimization,black-box service for population,evolutionary algorithms,figure 1,neural networks,population based training,speech synthesis,wavenet},
pages = {1791--1799},
title = {{A Generalized Framework for Population Based Training}},
year = {2019}
}
@article{Wang2017b,
author = {Wang, Jing and Chen, Qing-hui and Zhang, Hong-yu and Chen, Xiao-hong and Wang, Jian-qiang},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2017 - Multi-Criteria Decision-Making Method Based on Type-2 Fuzzy Sets.pdf:pdf},
keywords = {fuzzy ranking method,generalized fuzzy number,interval type-2,multi-criteria decision-making,type-2 fuzzy set},
number = {November 2014},
pages = {431--450},
title = {{Multi-Criteria Decision-Making Method Based on Type-2 Fuzzy Sets}},
volume = {2},
year = {2017}
}
@article{Kim2021,
author = {Kim, Joonyoung and Seo, Hyowoon and Choi, Wan and Jung, Kyomin},
doi = {10.1109/access.2021.3050176},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim et al. - 2021 - Homeostasis-Inspired Continual Learning Learning to Control Structural Regularization.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {continual learning,regularization},
mendeley-tags = {continual learning,regularization},
pages = {1--1},
title = {{Homeostasis-Inspired Continual Learning: Learning to Control Structural Regularization}},
volume = {9},
year = {2021}
}
@article{Wagner2020,
abstract = {Super-Selfish is an easy to use PyTorch framework for image-based self-supervised learning. Features can be learned with 13 algorithms that span from simple classification to more complex state of theart contrastive pretext tasks. The framework is easy to use and allows for pretraining any PyTorch neural network with only two lines of code. Simultaneously, full flexibility is maintained through modular design choices. The code can be found at https://github.com/MECLabTUDA/Super_Selfish and installed using pip install super-selfish.},
archivePrefix = {arXiv},
arxivId = {2012.02706},
author = {Wagner, Nicolas and Mukhopadhyay, Anirban},
eprint = {2012.02706},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wagner, Mukhopadhyay - 2020 - Super-Selfish Self-Supervised Learning on Images with PyTorch.pdf:pdf},
keywords = {pre-training,self-supervised learning,self-supervision,transfer learning},
mendeley-tags = {pre-training,self-supervised learning,transfer learning},
pages = {1--6},
title = {{Super-Selfish: Self-Supervised Learning on Images with PyTorch}},
url = {http://arxiv.org/abs/2012.02706},
year = {2020}
}
@article{Rajasegaran2019,
abstract = {Incremental life-long learning is a main challenge towards the long-standing goal of Artificial General Intelligence. In real-life settings, learning tasks arrive in a sequence and machine learning models must continually learn to increment already acquired knowledge. Existing incremental learning approaches, fall well below the state-of-the-art cumulative models that use all training classes at once. In this paper, we propose a random path selection algorithm, called RPS-Net, that progressively chooses optimal paths for the new tasks while encouraging parameter sharing. Since the reuse of previous paths enables forward knowledge transfer, our approach requires a considerably lower computational overhead. As an added novelty, the proposed model integrates knowledge distillation and retrospection along with the path selection strategy to overcome catastrophic forgetting. In order to maintain an equilibrium between previous and newly acquired knowledge, we propose a simple controller to dynamically balance the model plasticity. Through extensive experiments, we demonstrate that the proposed method surpasses the state-of-the-art performance on incremental learning and by utilizing parallel computation this method can run in constant time with nearly the same efficiency as a conventional deep convolutional neural network.},
author = {Rajasegaran, Jathushan and Hayat, Munawar and Khan, Salman and Khan, Fahad Shahbaz and Shao, Ling},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rajasegaran et al. - 2019 - Random path selection for incremental learning.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
keywords = {architectural,continual learning},
mendeley-tags = {architectural,continual learning},
number = {c},
title = {{Random path selection for incremental learning}},
url = {https://github.com/brjathu/RPSnet},
volume = {32},
year = {2019}
}
@article{Birla2012,
abstract = {Waste frying oil was used to produce biodiesel using calcined snail shell as a heterogeneous base catalyst. Trans esterification reactions were carried out and the yield and conversion of the product were optimized by varying the methanol to oil molar ratio, catalyst amount, reaction temperature, and time. A biodiesel conversion of 99.58% was obtained with a yield of 87.28%. The reaction followed first order kinetics. The activation energy (EA) was 79kJ/mol and the frequency factor (A) was 2.98×1010min-1. The fuel properties of the biodiesel were measured according to ASTM D 6751 and found to be within the specifications. Snail shell is a novel source for the production of heterogeneous base catalyst that can be successfully utilized for synthesis of biodiesel of high purity. {\textcopyright} 2011 Elsevier Ltd.},
author = {Birla, Ashish and Singh, Bhaskar and Upadhyay, S. N. and Sharma, Y. C.},
doi = {10.1016/j.biortech.2011.11.065},
isbn = {0960-8524},
issn = {09608524},
journal = {Bioresource Technology},
keywords = {Activation energy,Biodiesel,Heterogeneous catalyst,Kinetics,Snail shell},
pages = {95--100},
pmid = {22206916},
publisher = {Elsevier Ltd},
title = {{Kinetics studies of synthesis of biodiesel from waste frying oil using a heterogeneous catalyst derived from snail shell}},
url = {http://dx.doi.org/10.1016/j.biortech.2011.11.065},
volume = {106},
year = {2012}
}
@article{Giorgi2013,
abstract = {A deep analysis of the Fuel Cells technologies state of the art has been done in this article. After a general de- scription of the fuel cell base structure the six most important fuel cell technologies Polymeric Electrolyte Membrane Fuel Cells (PEMFC), Direct Methanol Fuel Cells (DMFC), Alkaline Fuel Cells (AFC), Phosphoric Acid Fuel Cell (PAFC), Molten Carbonate Fuel Cell (MCFC), Solid Oxide Fuel Cell (SOFC) are explained, describing advantages and disadvan- tages of each one and pointing out their principal use. The future development are also shown.},
author = {Giorgi, Leonardo and Leccese, Fabio},
doi = {1875-9327/13},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Giorgi, Leccese - 2013 - Fuel Cells Technologies and Applications.pdf:pdf},
journal = {The Open Fuel Cells Journal},
keywords = {afc,dmfc,fuel cell,mcfc,pafc,pemfc,sofc},
pages = {1--20},
title = {{Fuel Cells: Technologies and Applications}},
volume = {6},
year = {2013}
}
@book{Uchino2010a,
abstract = {Piezoelectric materials produce electric charges on their surfaces as a consequence of applying mechanical stress. They are used in the fabrication of a growing range of devices such as transducers (used, for example, in ultrasound scanning), actuators (deployed in such areas as vibration suppression in optical and microelectronic engineering), pressure sensor devices (such as gyroscopes) and increasingly as a way of producing energy. Their versatility has led to a wealth of research to broaden the range of piezoelectric materials and their potential uses. Advanced piezoelectric materials: science and technology provides a comprehensive review of these new materials, their properties, methods of manufacture and applications. After an introductory overview of the development of piezoelectric materials, Part one reviews the various types of piezoelectric material, ranging from lead zirconate titanate (PZT) piezo-ceramics, relaxor ferroelectric ceramics, lead-free piezo-ceramics, quartz-based piezoelectric materials, the use of lithium niobate and lithium in piezoelectrics, single crystal piezoelectric materials, electroactive polymers (EAP) and piezoelectric composite materials. Part two discusses how to design and fabricate piezo-materials with chapters on piezo-ceramics, single crystal preparation techniques, thin film technologies, aerosol techniques and manufacturing technologies for piezoelectric transducers. The final part of the book looks at applications such as high-power piezoelectric materials and actuators as well as the performance of piezoelectric materials under stress. With its distinguished editor and international team of expert contributors Advanced piezoelectric materials: science and technology is a standard reference for all those researching piezoelectric materials and using them to develop new devices in such areas as microelectronics, optical, sound, structural and biomedical engineering.},
author = {Uchino, K.},
booktitle = {Woodhead Publishing Series in Electronic and Optical Materials},
doi = {10.1533/9781845699758.frontmatter},
isbn = {978-1-84569-534-7},
issn = {00135127},
pages = {i--iii},
title = {{Advanced Piezoelectric Materials}},
url = {http://linkinghub.elsevier.com/retrieve/pii/B9781845695347500194},
volume = {9},
year = {2010}
}
@article{Bradley2015,
abstract = {Digital disruption has the potential to overturn incumbents and reshape markets faster than perhaps any force in history. • The Global Center for Digital Business Transformation (DBT Center), an IMD and Cisco initiative, is dedicated to original research and to creating opportunities for executives to innovate new business models for the digital age. To learn more about the current state of digital disruption and the outlook for industries, the Center surveyed 941 business leaders around the world in 12 industries. • The results of our survey surfaced several troubling findings about the potential for disruption, and incumbents' readiness to adapt. Survey respondents believe an average of roughly four of today's top 10 incumbents (in terms of market share) in each industry will be displaced by digital disruption in the next five years. • Despite these dire ramifications, digital disruption is not seen as worthy of board-level attention in about 45 percent of companies (on average across industries). In addition, 43 percent of companies either do not acknowledge the risk of digital disruption, or have not addressed it sufficiently. Nearly a third are taking a “wait and see” approach, in hopes of emulating successful competitors. Only 25 percent describe their approach to digital disruption as proactive—willing to disrupt themselves in order to compete. • The impact of digital disruption can best be understood through the construct of a vortex. A vortex exerts a rotational force that draws everything that surrounds it into its center. The Digital Vortex is the inevitable movement of industries toward a “digital center” in which business models, offerings, and value chains are digitized to the maximum extent possible. • As industries move toward the center of the Digital Vortex, physical components that inhibit competitive advantage (such as manual, paper-based processes) are shed. Whatever can be digitized is digitized. The components of digital value can then be readily combined as disruptive business models. These models knit together different types of capabilities and deliver customer value in new ways. The most successful disruptors employ “combinatorial disruption,” in which multiple sources of value—cost, experience, and platform—are fused to create disruptive new business models and exponential gains. • We asked executives in each of the 12 industries we studied to estimate the likelihood of disruption based upon four variables: 1) investment in d{\ldots}},
author = {Bradley, Joseph and Loucks, Jeff and Macaulay, James and Noronha, Andy and Wade, Michael},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bradley et al. - 2015 - Digital Vortex How Digital Disruption is Redifining Industries.pdf:pdf},
isbn = {9781945010019},
journal = {Global Center for Digital Business Transformation},
number = {June},
pages = {1--24},
title = {{Digital Vortex: How Digital Disruption is Redifining Industries}},
year = {2015}
}
@article{Kong2017,
abstract = {During settlement, many methods will provide valuable information. When different methods combined properly, valuable information is variously used. Based on the principle of artificial intelligence and method of fuzzy mathematics, the fuzzy combination forecasting method of self-adaptively variable weight is proposed. According to matching degree, the weights can be revised, and then forecasting results can be accurate. The fuzzy combination forecasting method is used to the subgrade settlement in Changzhang expressway, which can provide the accuracy and applicability},
author = {Kong, Xiangxing},
doi = {10.1109/ISCID.2016.1041},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kong - 2017 - Prediction of Subgrade Settlement Based Fuzzy Self Adaptable Method of Artificial Intelligence.pdf:pdf},
isbn = {9781509035588},
journal = {Proceedings - 2016 9th International Symposium on Computational Intelligence and Design, ISCID 2016},
keywords = {artificial intelligence,fuzzy method,prediction,subgrade settlement},
number = {7},
pages = {144--147},
title = {{Prediction of Subgrade Settlement Based Fuzzy Self Adaptable Method of Artificial Intelligence}},
volume = {1},
year = {2017}
}
@article{Sun2018,
abstract = {Aerosol deposition is highly concerned recently due to its significant impact on surface glass cleaning, glass transmittance and energy conversion of building-integrated photovoltaics (BIPV). Thus, this paper reviewed direct transmittance degradation works of PV module surface glasses, and employed several integrated and improved experiment and model methods to investigate the correlation effects of PM2.5 deposition dynamics, tilt angles, surface conditions and self-cleaning TiO2nanocoating on glasses. Series of physical models from ambient aerosol concentration to deposition density and transmittance reduction were extended or newly developed. Measured and modeled data could inter-validate with each other and literature results. The usage condition of Al-Hasan model was discovered as 0<ap<0.10 for particle projected-area fraction under clustering particle projected-area fraction apcp≤5%. Ranging from 0 to 18.7 $\mu$g/cm2, deposition densities with the most reductions (50–91%) were found under the combination of wet and nanocoating conditions due to effects of water film and low adhesive force. Generally, the average deposition densities decreased 19–47% with the increase of each 30° tilt angle for different surface properties. Finally, six linear empirical models were obtained with decreasing slopes of 0.001544–0.001841 between fine aerosol deposition density and transmittance ratio. These observed phenomena and derived models would be useful for solar energy, building illumination or heat-transfer, and BIPV industries.},
author = {Sun, Ke and Lu, Lin and Jiang, Yu and Wang, Yuanhao and Zhou, Kun and He, Zhu},
doi = {10.1016/j.rser.2017.10.062},
issn = {18790690},
journal = {Renewable and Sustainable Energy Reviews},
keywords = {Aerosol dynamics,Deposition density,Mathematic modeling,TiO2nanocoating,Transmittance reduction},
number = {October},
pages = {4107--4120},
publisher = {Elsevier Ltd},
title = {{Integrated effects of PM2.5 deposition, module surface conditions and nanocoatings on solar PV surface glass transmittance}},
url = {http://dx.doi.org/10.1016/j.rser.2017.10.062},
volume = {82},
year = {2018}
}
@article{Deveci2017,
abstract = {Multiple-input multiple-output (MIMO) modeling and simulation techniques are utilized to boost the usefulness of a common DC-output photovoltaic (PV) system. Vast studies in the literature are mostly based on single-input single-output (SISO) methods. As a result they suffer numerous unpredicted features should they be exposed to particular temperature, irradiation and load changes. These features stem from parameter errors and unmodelled dynamics of actual circuit components. Another issue is that common linearization may fail due to substantial nonlinear behavior. These are caused by switching converters run by means of pulse width modulation (PWM). As a remedy a different method relying on simulated input/output data is put to use to compute a working condition and then obtaining a linear model of the entire system around it. Multiple SISO compensators are replaced with a single MIMO robust controller based on the MIMO model, after which the controlled system is tested in simulations with varying irradiation, temperature and load resistance values. Evaluating the outcomes unveils the fact that newly designed autonomous system can run the PV panel at the maximum power point over a wide envelope of atmospheric and load combinations. Moreover the voltage value fed to a sensitive load is constant and the extra power obtained from the PV panel is used to charge the battery.},
author = {Deveci, Onur and Kasnakoğlu, Coşku},
doi = {10.1016/j.ijhydene.2017.04.033},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deveci, Kasnakoğlu - 2017 - MIMO nonlinear modeling and robust control of standalone dc photovoltaic systems.pdf:pdf},
issn = {03603199},
journal = {International Journal of Hydrogen Energy},
keywords = {Hammerstein-Wiener,MIMO robust control,MPPT,PV,Photovoltaic,Voltage regulation},
number = {28},
pages = {18064--18080},
title = {{MIMO nonlinear modeling and robust control of standalone dc photovoltaic systems}},
volume = {42},
year = {2017}
}
@article{Jebaraj2017,
abstract = {Economic Load Dispatch (ELD) is an imperative assignment in contemporary aggressive power demand market. Dearth of power generation in all dimensions of energy resources will result escalating in generation cost wants the optimal power dispatch at minimum fuel cost. Owing to the confined optimum convergence, the predictable optimization methods are not proficient to crack such problems. Evolutionary optimization techniques are proved to be superior to the conventional techniques to solve ELD problems. Differential Evolution Algorithm (DEA) is one of the foremost and recent evolutionary techniques in modern optimization state of affairs. The application of DEA in multi directional ELD problem has been technologically summarized in this paper.},
author = {Jebaraj, Luke and Venkatesan, Chakkaravarthy and Soubache, Irisappane and Rajan, Charles Christober Asir},
doi = {10.1016/j.rser.2017.03.097},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jebaraj et al. - 2017 - Application of differential evolution algorithm in static and dynamic economic or emission dispatch problem A re.pdf:pdf},
issn = {18790690},
journal = {Renewable and Sustainable Energy Reviews},
keywords = {Differential evolution,Emission constraints,Power dispatch,Ramp limits,Valve point effect},
number = {October 2015},
pages = {1206--1220},
publisher = {Elsevier Ltd},
title = {{Application of differential evolution algorithm in static and dynamic economic or emission dispatch problem: A review}},
url = {http://dx.doi.org/10.1016/j.rser.2017.03.097},
volume = {77},
year = {2017}
}
@article{Hamilton2017,
abstract = {Machine learning on graphs is an important and ubiquitous task with applications ranging from drug design to friendship recommendation in social networks. The primary challenge in this domain is finding a way to represent, or encode, graph structure so that it can be easily exploited by machine learning models. Traditionally, machine learning approaches relied on user-defined heuristics to extract features encoding structural information about a graph (e.g., degree statistics or kernel functions). However, recent years have seen a surge in approaches that automatically learn to encode graph structure into low-dimensional embeddings, using techniques based on deep learning and nonlinear dimensionality reduction. Here we provide a conceptual review of key advancements in this area of representation learning on graphs, including matrix factorization-based methods, random-walk based algorithms, and graph neural networks. We review methods to embed individual nodes as well as approaches to embed entire (sub)graphs. In doing so, we develop a unified framework to describe these recent approaches, and we highlight a number of important applications and directions for future work.},
archivePrefix = {arXiv},
arxivId = {1709.05584},
author = {Hamilton, William L. and Ying, Rex and Leskovec, Jure},
eprint = {1709.05584},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hamilton, Ying, Leskovec - 2017 - Representation Learning on Graphs Methods and Applications.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {graph,representation learning},
mendeley-tags = {graph,representation learning},
pages = {1--23},
title = {{Representation Learning on Graphs: Methods and Applications}},
year = {2017}
}
@article{Guerado2017,
author = {Guerado, Enrique},
doi = {10.1016/S0020-1383(17)30788-X},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guerado - 2017 - Scientific societies and the third industrial revolution – The future role of the OTC.pdf:pdf},
issn = {18790267},
journal = {Injury},
pages = {ix--x},
pmid = {29162236},
title = {{Scientific societies and the third industrial revolution – The future role of the OTC}},
volume = {48},
year = {2017}
}
@article{Cai,
author = {Cai, Shaofeng and Shu, Yao and Wang, Wei},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cai, Shu, Wang - Unknown - Dynamic Routing Networks.pdf:pdf},
keywords = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning,Statistics - Machine Learning,efficient models,model compression,neural networks},
mendeley-tags = {efficient models,model compression,neural networks},
pages = {3588--3597},
title = {{Dynamic Routing Networks}}
}
@article{Patel2012,
author = {Patel, Dipi A. and Christian, R. A.},
doi = {10.5829/idosi.wasj.2012.20.11.1517},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Patel, Christian - 2012 - Ambient atmospheric temperature prediction using fuzzy knowledge-rule base for inland cities in India.pdf:pdf},
issn = {18184952},
journal = {World Applied Sciences Journal},
keywords = {Fuzzy knowledge-rule base,Membership function,Seasonal variation,Temperature prediction},
number = {11},
pages = {1448--1452},
title = {{Ambient atmospheric temperature prediction using fuzzy knowledge-rule base for inland cities in India}},
volume = {20},
year = {2012}
}
@article{Yang2019d,
abstract = {Incremental learning has become a new research hotspot in the field of machine learning. Compared with traditional machine learning, incremental learning can continuously learn new knowledge from new samples and preserve most of the knowledge that has been learned before. This paper is an overview of the existing incremental learning, and introduces the current popular incremental learning methods from incremental supervisory learning and incremental unsupervised learning, and shows the potential in application. Finally, online incremental research is prospected in this paper.},
author = {Yang, Qing and Gu, Yudi and Wu, Dongsheng},
doi = {10.1109/CCDC.2019.8832774},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang, Gu, Wu - 2019 - Survey of incremental learning.pdf:pdf},
isbn = {9781728101057},
journal = {Proceedings of the 31st Chinese Control and Decision Conference, CCDC 2019},
keywords = {Adaptive classification,Incremental learning,Machine learning,Supervised learning,Unsupervised learning,continual learning,incremental learning,review,survey},
mendeley-tags = {continual learning,incremental learning,review,survey},
pages = {399--404},
publisher = {IEEE},
title = {{Survey of incremental learning}},
year = {2019}
}
@article{Withrow2017,
abstract = {This book has been written with the purpose of covering all aspects about Infrared Spectroscopy.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Withrow, Janeth},
doi = {10.1021/acsreagents.2008.20160601},
eprint = {arXiv:1011.1669v3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Withrow - 2017 - Infrared Spectroscopy.pdf:pdf},
isbn = {9788132333142},
issn = {0003-2700},
journal = {ACS Reagent Chemicals},
pages = {1. Chady T, Gratkowski S, Takagi T. Electromagneti},
pmid = {25246403},
title = {{Infrared Spectroscopy}},
url = {http://pubs.acs.org/doi/abs/10.1021/acsreagents.2008.20160601},
volume = {5},
year = {2017}
}
@article{Szegedy,
archivePrefix = {arXiv},
arxivId = {arXiv:1409.4842v1},
author = {Szegedy, Christian and Reed, Scott and Sermanet, Pierre and Vanhoucke, Vincent and Rabinovich, Andrew},
eprint = {arXiv:1409.4842v1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Szegedy et al. - Unknown - Going deeper with convolutions.pdf:pdf},
pages = {1--12},
title = {{Going deeper with convolutions}}
}
@article{Oradee2013,
abstract = {وكانت أغراض هذا البحث: 1) لدراسة ومقارنة مهارات الصف 11 طالبا باستخدام ثلاثة الأنشطة التواصلية التحدث، و2) لدراسة موقف الطلاب تجاه تعليم المهارات الناطقة باللغة الإنجليزية باستخدام الأنشطة التواصلية الثلاثة. تكونت عينة الدراسة من 49 طالبا في مدرسة ثانوية في أودون ثاني، تايلاند، مصنفة حسب العالي والمتوسط، و متدن وفقا لمن قدرات من يتحدث الانجليزية مستوى الكفاءة. تصميم كانت الأبحاث مختلط تصميم الأسلوب. وجاءت البيانات الكمية من اختبار التحدث وموقف الطلاب تجاه تعليم التحدث باللغة الانجليزية. وقد وضعت البيانات النوعية من سجل التعلم، مقابلة منظم شبه ومجلة المعلم. كان يعمل أيضا تصميم مجموعة واحدة تظاهرة-الاختبار البعدي. كانت أدوات البحث 8 خطط الدروس، وهو يتحدث الانجليزية اختبار القدرة، واستبيان الموقف. تم توظيف المئوية والمتوسط ​​والانحراف المعياري واختبار (ت) للعينات التي تعتمد على تحليل البيانات الكمية. وكانت نتائج البحوث على النحو التالي: 1. اللغة الإنجليزية للطلاب قدرات يتحدث بعد باستخدام ثلاثة صريح وكانت أنشطة أعلى بكثير من ذي قبل استخدامها. (تظاهرة = 60.80؛ البعدي = 85.63). 2. موقف الطلاب نحو تعليم المهارات الناطقة باللغة الإنجليزية باستخدام الأنشطة التواصلية الثلاثة تصنف على أنها جيدة},
author = {Oradee, Thanyalak},
doi = {10.7763/IJSSH.2012.V2.164},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oradee - 2013 - Developing Speaking Skills Using Three Communicative Activities (Discussion, Problem-Solving, andRole-Playing).pdf:pdf},
isbn = {2010-3646},
issn = {20103646},
journal = {International Journal of Social Science and Humanity},
number = {6},
pages = {533--535},
title = {{Developing Speaking Skills Using Three Communicative Activities (Discussion, Problem-Solving, andRole-Playing)}},
url = {http://www.ijssh.org/show-33-391-1.html},
volume = {2},
year = {2013}
}
@article{Miller2020,
abstract = {Existing open set classifiers distinguish between known and unknown inputs by measuring distance in a network's logit space, assuming that known inputs cluster closer to the training data than unknown inputs. However, this approach is typically applied post-hoc to networks trained with cross-entropy loss, which neither guarantees nor encourages the hoped-for clustering behaviour. To overcome this limitation, we introduce Class Anchor Clustering (CAC) loss. CAC is an entirely distance-based loss that explicitly encourages training data to form tight clusters around class-dependent anchor points in the logit space. We show that an open set classifier trained with CAC loss outperforms all state-of-the-art techniques on the challenging TinyImageNet dataset, achieving a 2.4% performance increase in AUROC. In addition, our approach outperforms other state-of-the-art distance-based approaches on a number of further relevant datasets. We will make the code for CAC publicly available.},
archivePrefix = {arXiv},
arxivId = {2004.02434},
author = {Miller, Dimity and S{\"{u}}nderhauf, Niko and Milford, Michael and Dayoub, Feras},
eprint = {2004.02434},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Miller et al. - 2020 - Class Anchor Clustering a Distance-based Loss for Training Open Set Classifiers.pdf:pdf},
journal = {arXiv},
keywords = {Distance-based loss,Open set classification,Open set recognition,open-set recognition},
mendeley-tags = {open-set recognition},
pages = {3570--3578},
title = {{Class Anchor Clustering: a Distance-based Loss for Training Open Set Classifiers}},
year = {2020}
}
@article{Hussain2006,
abstract = {This review is designed to be a comprehensive source for polymer nanocomposite research, including fundamental structure/property relationships, manufacturing techniques, and applications of polymer nanocomposite materials. In addition to presenting the scientific framework for the advances in polymer nanocomposite research, this review focuses on the scientific principles and mechanisms in relation to the methods of processing and manufacturing with a discussion on commercial applications and health/safety concerns (a critical issue for production and scale-up). Hence, this review offers a comprehensive discussion on technology, modeling, characterization, processing, manufacturing, applications, and health/safety concerns for polymer nanocomposites.},
archivePrefix = {arXiv},
arxivId = {cond-mat/0406218},
author = {Hussain, Farzana and Hojjati, Mehdi and Okamoto, Masami and Gorga, Russell E.},
doi = {10.1177/0021998306067321},
eprint = {0406218},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hussain et al. - 2006 - Review article Polymer-matrix nanocomposites, processing, manufacturing, and application An overview.pdf:pdf},
isbn = {0021-9983},
issn = {00219983},
journal = {Journal of Composite Materials},
keywords = {Carbon nanotubes,Graphite nanoplatelets,Layered silicates,Nanofiber,Nanoparticles},
number = {17},
pages = {1511--1575},
pmid = {16834563},
primaryClass = {cond-mat},
title = {{Review article: Polymer-matrix nanocomposites, processing, manufacturing, and application: An overview}},
volume = {40},
year = {2006}
}
@article{Ren2017a,
abstract = {We describe a novel probabilistic framework for real-time tracking of multiple objects from combined depth-colour imagery. Object shape is represented implicitly using 3D signed distance functions. Probabilistic generative mod-els based on these functions are developed to account for the observed RGB-D imagery, and tracking is posed as a maxi-mum a posteriori problem. We present first a method suited to tracking a single rigid 3D object, and then generalise this to multiple objects by combining distance functions into a shape union in the frame of the camera. This second model accounts for similarity and proximity between objects, and leads to robust real-time tracking without recourse to bolt-on or ad-hoc collision detection.},
author = {Ren, C. Y. and Prisacariu, V. A. and K{\"{a}}hler, O. and Reid, I. D. and Murray, D. W.},
doi = {10.1007/s11263-016-0978-2},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ren et al. - 2017 - Real-Time Tracking of Single and Multiple Objects from Depth-Colour Imagery Using 3D Signed Distance Functions.pdf:pdf},
issn = {15731405},
journal = {International Journal of Computer Vision},
keywords = {Depth tracking,Multi-object tracking,RGB-D imagery,Real-time,Signed distance functions},
number = {1},
pages = {80--95},
publisher = {Springer US},
title = {{Real-Time Tracking of Single and Multiple Objects from Depth-Colour Imagery Using 3D Signed Distance Functions}},
volume = {124},
year = {2017}
}
@article{Hayes2020,
abstract = {People learn throughout life. However, incrementally updating conventional neural networks leads to catastrophic forgetting. A common remedy is replay, which is inspired by how the brain consolidates memory. Replay involves fine-tuning a network on a mixture of new and old instances. While there is neuroscientific evidence that the brain replays compressed memories, existing methods for convolutional networks replay raw images. Here, we propose REMIND, a brain-inspired approach that enables efficient replay with compressed representations. REMIND is trained in an online manner, meaning it learns one example at a time, which is closer to how humans learn. Under the same constraints, REMIND outperforms other methods for incremental class learning on the ImageNet ILSVRC-2012 dataset. We probe REMIND's robustness to data ordering schemes known to induce catastrophic forgetting. We demonstrate REMIND's generality by pioneering online learning for Visual Question Answering (VQA) (https://github.com/tyler-hayes/REMIND).},
archivePrefix = {arXiv},
arxivId = {1910.02509},
author = {Hayes, Tyler L. and Kafle, Kushal and Shrestha, Robik and Acharya, Manoj and Kanan, Christopher},
doi = {10.1007/978-3-030-58598-3_28},
eprint = {1910.02509},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hayes et al. - 2020 - REMIND Your Neural Network to Prevent Catastrophic Forgetting.pdf:pdf},
isbn = {9783030585976},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Brain-inspired,Deep learning,Online learning,continual learning,rehearsal},
mendeley-tags = {continual learning,rehearsal},
pages = {466--483},
title = {{REMIND Your Neural Network to Prevent Catastrophic Forgetting}},
volume = {12353 LNCS},
year = {2020}
}
@article{Yang2019g,
abstract = {Face recognition sees remarkable progress in recent years, and its performance has reached a very high level. Taking it to a next level requires substantially larger data, which would involve prohibitive annotation cost. Hence, exploiting unlabeled data becomes an appealing alternative. Recent works have shown that clustering unlabeled faces is a promising approach, often leading to notable performance gains. Yet, how to effectively cluster, especially on a large-scale (i.e. million-level or above) dataset, remains an open question. A key challenge lies in the complex variations of cluster patterns, which make it difficult for conventional clustering methods to meet the needed accuracy. This work explores a novel approach, namely, learning to cluster instead of relying on hand-crafted criteria. Specifically, we propose a framework based on graph convolutional network, which combines a detection and a segmentation module to pinpoint face clusters. Experiments show that our method yields significantly more accurate face clusters, which, as a result, also lead to further performance gain in face recognition.},
archivePrefix = {arXiv},
arxivId = {1904.02749},
author = {Yang, Lei and Zhan, Xiaohang and Chen, Dapeng and Yan, Junjie and Loy, Chen Change and Lin, Dahua},
eprint = {1904.02749},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2019 - keku.pdf:pdf},
title = {keku},
url = {http://arxiv.org/abs/1904.02749},
year = {2019}
}
@article{Stock2019,
abstract = {In this paper, we address the problem of reducing the memory footprint of convolutional network architectures. We introduce a vector quantization method that aims at preserving the quality of the reconstruction of the network outputs rather than its weights. The principle of our approach is that it minimizes the loss reconstruction error for in-domain inputs. Our method only requires a set of unlabelled data at quantization time and allows for efficient inference on CPU by using byte-aligned codebooks to store the compressed weights. We validate our approach by quantizing a high performing ResNet-50 model to a memory size of 5MB (20x compression factor) while preserving a top-1 accuracy of 76.1% on ImageNet object classification and by compressing a Mask R-CNN with a 26x factor.},
archivePrefix = {arXiv},
arxivId = {1907.05686},
author = {Stock, Pierre and Joulin, Armand and Gribonval, R{\'{e}}mi and Graham, Benjamin and J{\'{e}}gou, Herv{\'{e}}},
eprint = {1907.05686},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stock et al. - 2019 - And the Bit Goes Down Revisiting the Quantization of Neural Networks.pdf:pdf},
number = {2017},
pages = {1--11},
title = {{And the Bit Goes Down: Revisiting the Quantization of Neural Networks}},
url = {http://arxiv.org/abs/1907.05686},
year = {2019}
}
@article{Zezulka2016,
abstract = {The goal of the paper is to introduce specialists from industry into the important phenomenon of the recent technology and to explain cyber – physical and informatics background of the platform Industry 4.0 and basic steps in any design and implementation of the Industry 4.0 systems. Authors introduce readers in both the RAMI 4.0 as well as the Industry 4.0 Components models which represent necessary initial background of any Industry 4.0 application. The main stress is given to the Industry 4.0 components model, which enables designers from firms to understand already existing Industry 4.0 case studies and to develop their first Industry 4.0 case studies applications.},
author = {Zezulka, F. and Marcon, P. and Vesely, I. and Sajdl, O.},
doi = {10.1016/j.ifacol.2016.12.002},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zezulka et al. - 2016 - Industry 4.0 – An Introduction in the phenomenon.pdf:pdf},
isbn = {22128271 (ISSN)},
issn = {24058963},
journal = {IFAC-PapersOnLine},
keywords = {Industry 4.0 component,RAMI 4.0,administrative shell,communication,virtual},
number = {25},
pages = {8--12},
publisher = {Elsevier B.V.},
title = {{Industry 4.0 – An Introduction in the phenomenon}},
url = {http://dx.doi.org/10.1016/j.ifacol.2016.12.002},
volume = {49},
year = {2016}
}
@article{Arora2021,
abstract = {Images captured under low-light conditions manifest poor visibility, lack contrast and color vividness. Compared to conventional approaches, deep convolutional neural networks (CNNs) perform well in enhancing images. However, being solely reliant on confined fixed primitives to model dependencies, existing data-driven deep models do not exploit the contexts at various spatial scales to address low-light image enhancement. These contexts can be crucial towards inferring several image enhancement tasks, e.g., local and global contrast, brightness and color corrections; which requires cues from both local and global spatial extent. To this end, we introduce a context-aware deep network for low-light image enhancement. First, it features a global context module that models spatial correlations to find complementary cues over full spatial domain. Second, it introduces a dense residual block that captures local context with a relatively large receptive field. We evaluate the proposed approach using three challenging datasets: MIT-Adobe FiveK, LoL, and SID. On all these datasets, our method performs favorably against the state-of-the-arts in terms of standard image fidelity metrics. In particular, compared to the best performing method on the MIT-Adobe FiveK dataset, our algorithm improves PSNR from 23.04 dB to 24.45 dB.},
archivePrefix = {arXiv},
arxivId = {2101.00850},
author = {Arora, Aditya and Haris, Muhammad and Zamir, Syed Waqas and Hayat, Munawar and Khan, Fahad Shahbaz and Shao, Ling and Yang, Ming-Hsuan},
eprint = {2101.00850},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arora et al. - 2021 - Low Light Image Enhancement via Global and Local Context Modeling.pdf:pdf},
keywords = {image enhancment,image processing},
mendeley-tags = {image enhancment,image processing},
title = {{Low Light Image Enhancement via Global and Local Context Modeling}},
url = {http://arxiv.org/abs/2101.00850},
year = {2021}
}
@article{Tielens2010,
abstract = {The thermal-infrared wavelength region contains the spectral signatures of solidstate compounds as well as a variety of lines emitted by atoms and molecules in the gaseous state. Together, these signatures provide unique diagnostic probes of the physical and chemical conditions of the cool and dusty Universe. This article summarizes the contribution of space-based observations in the thermal infrared to our understanding of the Universe. In particular the formation of stars and planets, the characteristics of interstellar dust and of polycyclic aromatic hydrocarbons as well as the interstellar media of galaxies are discussed.},
author = {Tielens,  A. G. G. M. and Tielens, M},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tielens, Tielens - 2010 - The mid- and far-infrared range radiation emission processes from interstellar dust and gas.pdf:pdf},
journal = {In: Observing Photons in Space / M.C.E. Huber},
pages = {131--148},
title = {{The mid- and far-infrared range: radiation emission processes from interstellar dust and gas}},
url = {http://adsabs.harvard.edu/abs/2010ISSIR...9..131T},
year = {2010}
}
@article{Nguyen2004,
abstract = { This paper presents a comparison of the different data preprocessing strategies for developing neural network models for prediction of oil production rate. Data processing is an important step in developing a neural network application, which could affect model accuracy and results. We considered the following three ways to preprocess monthly oil production data: (1) the sequential approach in which condition-decision records from all the wells in a reservoir are placed sequentially to form a data set, (2) the averaging approach in which a data set is formed by averaging data values from individual wells in a reservoir, and (3) the individual approach in which data for individual wells are used separately to build models tailored for individual wells. Some advantages and disadvantages, as well as results of each approach are discussed.},
author = {Nguyen, H.H. and Chan, C.W.},
doi = {10.1109/COGINF.2004.1327476},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen, Chan - 2004 - A comparison of data preprocessing strategies for neural network modeling of oil production prediction.pdf:pdf},
isbn = {0-7695-2190-8},
journal = {Proceedings of the Third IEEE International Conference on Cognitive Informatics, 2004.},
keywords = {data preprocessing,neural networks,oil,production prediction},
title = {{A comparison of data preprocessing strategies for neural network modeling of oil production prediction}},
year = {2004}
}
@article{Shen2017,
abstract = {Photocatalysis is an emerging technology that enables a wide variety of applications, including degradation of organics and dyes, antibacterial action, and fuel generation through water splitting and carbon dioxide reduction. Numerous inorganic semiconducting materials have been explored as photocatalysts, and the versatility of these materials and reactions has been expanded in recent years [1,2]. Understanding the relationship between the physicochemical properties of photocatalytic materials and their performances as well as the fundamentals in catalytic processes is important to design and synthesis of photocatalytic materials [3,4]. To present the state of the art of photocatalytic materials and their applications, as well as explore the fundamentals of photo-catalytic processes, we compiled this special issue on photocatalytic materials, which includes metal oxides (TiO 2), metal-organic frameworks (MOF), plasmonics and hybrids for applications in water splitting, CO 2 reduction, and removal of environmental pol-lutants. The aspects of this special issue cover strategies of nano-structure and heterostructure design, surface defects and modifications, and the first-principles calculations, etc. We believe that these advances will be interesting to the broad readers of Journal of Materiomics. TiO 2 has been widely investigated for photocatalysis in removal of environmental pollutants, H 2 evolution and CO 2 reduction since 1972. It is generally accepted that the photocatalytic activity is affected by the light absorption, charge creation/recombination rate and surface reactivity. In this special issue, Binas et al. focused on modified TiO 2 as catalyst in heterogeneous photocatalytic processes and addressed the efficiency of TiO 2 -based building and construction materials on the removal of environmental pollutants indoors and outdoors [5]. Recent results on the disinfection per-formance of these materials and the inactivation of severe patho-gens contained in water and indoor air environments were then summarized. Blackening TiO 2 has been proposed as an effective strategy to enhance its solar absorption and thus the photocatalytic activities. Zhao et al. examined the major influences of TiO 2 point defects on CO 2 photoreduction with H 2 O, by changing the catalysts' gas adsorption capabilities, optical properties, and electronic structures [6]. In addition, the performances of various defective TiO 2 toward CO 2 photoreduction were summarized and compared in terms of productivity, selectivity, and stability. The use of plasmon excitations to increase the performance of visible light-driven water splitting systems has been investigated intensely in recent years. The literature on this subject shows that multiple mechanisms are possible to explain increases in water splitting efficiency. Zhang et al. discuss the recent literature on this subject, and present an informative description and summary of the mechanisms by which excitation of plasmons can improve photocatalytic performance [7]. These include mechanisms based on light scattering, near-field effects, as well as hot electron transfer. This review article provides a timely and useful analysis of the design parameters for plasmonic-metal/semiconductor photo-catalysts as well as a welcome perspective on the future of this technology. Graphene in the form of graphene oxide (GO) has been frequently composited with TiO 2 to improve the photocatalytic properties. Tan et al. studied the impacts of addition of RGO to P25 TiO 2 on photocatalytic oxidation of various organic substances [8]. They found that RGO is not a universal promoter for photocatalytic activities of TiO 2 , but the photocatalytic activity enhancement is strongly affected by the various functional groups appeared in the organic substances. It is realized that the length of alkyl chain in alcohols and carboxylic acids have the minimum influence on the overall activity while the number of hydroxyl groups can promote the further activity enhancement in the presence of RGO. MOFs have emerged as potential promising candidates for photocatalytic H 2 production. However, the reported MOFs are lack of active sites for H 2 evolution and suffer from the low light harvest,},
author = {Shen, Shaohua and Kronawitter, Coleman and Kiriakidis, George},
doi = {10.1016/j.jmat.2016.12.004},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shen, Kronawitter, Kiriakidis - 2017 - An overview of photocatalytic materials.pdf:pdf},
issn = {23528486},
journal = {Journal of Materiomics},
number = {1},
pages = {1--2},
publisher = {The Chinese Ceramic Society},
title = {{An overview of photocatalytic materials}},
url = {http://dx.doi.org/10.1016/j.jmat.2016.12.004},
volume = {3},
year = {2017}
}
@article{Huang2020d,
abstract = {Weakly Supervised Object Detection (WSOD) has emerged as an effective tool to train object detectors using only the image-level category labels. However, without object-level labels, WSOD detectors are prone to detect bounding boxes on salient objects, clustered objects and discriminative object parts. Moreover, the image-level category labels do not enforce consistent object detection across different transformations of the same images. To address the above issues, we propose a Comprehensive Attention Self-Distillation (CASD) training approach for WSOD. To balance feature learning among all object instances, CASD computes the comprehensive attention aggregated from multiple transformations and feature layers of the same images. To enforce consistent spatial supervision on objects, CASD conducts self-distillation on the WSOD networks, such that the comprehensive attention is approximated simultaneously by multiple transformations and feature layers of the same images. CASD produces new state-of-the-art WSOD results on standard benchmarks such as PASCAL VOC 2007/2012 and MS-COCO.},
archivePrefix = {arXiv},
arxivId = {2010.12023},
author = {Huang, Zeyi and Zou, Yang and Bhagavatula, Vijayakumar and Huang, Dong},
eprint = {2010.12023},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang et al. - 2020 - Comprehensive Attention Self-Distillation for Weakly-Supervised Object Detection.pdf:pdf},
number = {NeurIPS},
pages = {1--11},
title = {{Comprehensive Attention Self-Distillation for Weakly-Supervised Object Detection}},
url = {http://arxiv.org/abs/2010.12023},
volume = {1},
year = {2020}
}
@article{Hall2015,
abstract = {An explanation of Pearson's correlation coefficient is given and its suitability for evaluating curve fits to data in the third year lab is discussed},
author = {Hall, G},
doi = {10.1136/bmj.e4483},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hall - 2015 - Pearson ' s correlation coefficient.pdf:pdf},
isbn = {9780761988540},
pages = {1--4},
title = {{Pearson ' s correlation coefficient}},
volume = {1},
year = {2015}
}
@article{Naghibi2017,
abstract = {This paper presents control of underactuated robot manipulators in task space utilizing novel algorithm called fuzzy modified transpose effective Jacobian (MTEJ) with integrator term which ensures tracking trajectory in task space with high-quality performance. Although non-model base MTEJ have been introduced before and evaluated for underactuated robots, this method has poor operation against non-linear factors in actuators and joints observed in practical tests like deadband, backlash or Coulomb damping. The contributions of this paper are in twofold. First, to introduce improved MTEJ algorithm with additional integrator term that is efficient to eliminate effects of mentioned factors or other source of steady state error (SSE). Second, using new fuzzy rules to manage its terms to stabilize system with better control properties, the controller is used to make the endeffector to both track a predefined trajectory or set on an exact point. Global stabilization of this control method is proved. Simulation and experimental results are offered which compared tracking performance of the improved fuzzy MTEJ with integrator to other methods for both tracking and point to point (P.T.P) control. Outcomes of these experiments reveal privileges of using fuzzy improved MTEJ in various areas like removing SSE with better control characteristics and low computational efforts.},
author = {Naghibi, S. Reza and Pirmohamadi, Ali A. and Moosavian, S. Ali A.},
doi = {10.1016/j.rcim.2017.03.006},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Naghibi, Pirmohamadi, Moosavian - 2017 - Fuzzy MTEJ controller with integrator for control of underactuated manipulators.pdf:pdf},
issn = {07365845},
journal = {Robotics and Computer-Integrated Manufacturing},
keywords = {Deadband in actuators,Fuzzy control,MTEJ control,Underactuated manipulator},
number = {March},
pages = {93--101},
publisher = {Elsevier Ltd},
title = {{Fuzzy MTEJ controller with integrator for control of underactuated manipulators}},
url = {http://dx.doi.org/10.1016/j.rcim.2017.03.006},
volume = {48},
year = {2017}
}
@techreport{BSN1992,
author = {BSN, Badan Standarisasi Nasional},
title = {{Yogurt}},
year = {1992}
}
@article{Chen2015b,
abstract = {Black phosphorus (BP), an emerging narrow direct band-gap two-dimensional (2D) layered material that can fill the gap between the semi-metallic graphene and the wide-bandgap transition metal dichalcogenides (TMDs), had been experimentally found to exhibit the saturation of optical absorption if under strong light illumination. By taking advantage of this saturable absorption property, we could fabricate a new type of optical saturable absorber (SA) based on mechanically exfoliated BPs, and further demonstrate the applications for ultra-fast laser photonics. Based on the balanced synchronous twin-detector measurement method, we have characterized the saturable absorption property of the fabricated BP-SAs at the telecommunication band. By incorporating the BP-based SAs device into the all-fiber Erbium-doped fiber laser cavities, we are able to obtain either the passive Q-switching (with maximum pulse energy of 94.3 nJ) or the passive mode-locking operation (with pulse duration down to 946 fs). Our results show that BP could also be developed as an effective SA for pulsed fiber or solid-state lasers.},
archivePrefix = {arXiv},
arxivId = {1504.07341},
author = {Chen, Yu and Jiang, Guobao and Chen, Shuqing and Guo, Zhinan and Yu, Xuefeng and Zhao, Chujun and Zhang, Han and Bao, Qiaoliang and Wen, Shuangchun and Tang, Dingyuan and Fan, Dianyuan},
doi = {10.1364/OE.23.012823},
eprint = {1504.07341},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2015 - Mechanically exfoliated black phosphorus as a new saturable absorber for both Q-switching and Mode-locking laser op.pdf:pdf},
isbn = {2040-3372 (Electronic)\r2040-3364 (Linking)},
issn = {1094-4087},
journal = {Optics Express},
number = {10},
pages = {12823},
pmid = {26074536},
title = {{Mechanically exfoliated black phosphorus as a new saturable absorber for both Q-switching and Mode-locking laser operation}},
url = {https://www.osapublishing.org/abstract.cfm?URI=oe-23-10-12823},
volume = {23},
year = {2015}
}
@article{Jozi2017,
abstract = {One of the most challenging tasks for energy domain stakeholders is to have a better preview of the electricity consumption. Having a more trustable expectation of electricity consumption can help minimizing the cost of electricity and also enable a better control on the electricity tariff. This paper presents a study using a Methodology to Obtain Genetic fuzzy rule-based systems Under the iterative rule Learning approach (MOGUL) methodology in order to have a better profile of the electricity consumption of the following hours. The proposed approach uses the electricity consumption of the past hours to forecast the consumption value for the following hours. Results from this study are compared to those of previous approaches, namely two fuzzy based systems: and several different approaches based on artificial neural networks. The comparison of the achieved results with those achieved by the previous approaches shows that this approach can calculate a more reliable value for the electricity consumption in the following hours, as it is able to achieve lower forecasting errors, and a less standard deviation of the forecasting error results.},
author = {Jozi, Aria and Pinto, Tiago and Praca, Isabel and Silva, Francisco and Teixeira, Brigida and Vale, Zita},
doi = {10.1109/PTC.2017.7981219},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jozi et al. - 2017 - Energy consumption forecasting using genetic fuzzy rule-based systems based on MOGUL learning methodology.pdf:pdf},
isbn = {978-1-5090-4237-1},
journal = {2017 IEEE Manchester PowerTech},
keywords = {based methods,electricity consumption,forecasting,fuzzy rule,mogul},
number = {703689},
pages = {1--5},
title = {{Energy consumption forecasting using genetic fuzzy rule-based systems based on MOGUL learning methodology}},
volume = {703689},
year = {2017}
}
@article{Shen2017a,
abstract = {Epistemic negation not along with default negation ¬ plays a key role in knowledge representation and nonmonotonic reasoning. However, the existing epistemic approaches such as those by Gelfond [13,15,14], Truszczynski [33] and Kahl et al. [18] behave not satisfactorily in that they suffer from the problems of unintended world views due to recursion through the epistemic modal operator K or M (KF and MF are shorthands for ¬notF and not¬F, respectively). In this paper we present a new approach to handling epistemic negation which is free of unintended world views and thus offers a solution to the long-standing problem of epistemic specifications which were introduced by Gelfond [13] over two decades ago. We consider general logic programs consisting of rules of the form H→B, where H and B are arbitrary first-order formulas possibly containing epistemic negation, and define a general epistemic answer set semantics for general logic programs by introducing a novel program transformation and a new definition of world views in which we apply epistemic negation to minimize the knowledge in world views. The general epistemic semantics is applicable to extend any existing answer set semantics, such as those defined in [26,27,32,1,8,12,29], with epistemic negation. For illustration, we extend FLP answer set semantics of Faber et al. [8] for general logic programs with epistemic negation, leading to epistemic FLP semantics. We also extend the more restrictive well-justified FLP semantics of Shen et al. [29], which is free of circularity for default negation, to an epistemic well-justified semantics. We consider the computational complexity of epistemic FLP semantics and show that for a propositional program $\Pi$ with epistemic negation, deciding whether $\Pi$ has epistemic FLP answer sets is $\Sigma$3p-complete and deciding whether a propositional formula F is true in $\Pi$ under epistemic FLP semantics is $\Sigma$4p-complete in general, but has lower complexity for logic programs that match normal epistemic specifications, where the complexity of world view existence and query evaluation drops by one level in the polynomial hierarchy.},
author = {Shen, Yi Dong and Eiter, Thomas},
doi = {10.1016/j.artint.2016.04.004},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shen, Eiter - 2017 - Evaluating epistemic negation in answer set programming.pdf:pdf},
isbn = {9780999241103},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
keywords = {answer set programming},
pages = {5060--5064},
publisher = {Elsevier B.V.},
title = {{Evaluating epistemic negation in answer set programming}},
url = {http://dx.doi.org/10.1016/j.artint.2016.04.004},
volume = {237},
year = {2017}
}
@article{Ng2017,
abstract = {Fugitive emissions are one of the most notable contributors to atmospheric releases in chemical process industries affecting not only the economy but also both the environment and workers' health. In order to reduce fugitive emissions released in this process, the assessment of fugitive emissions should be conducted at the early stage of chemical process design when the cost of making changes is the lowest. This is however impeded by the limited knowledge on the leak sources, since the process is still under design. The paper presents a hybrid approach for estimating fugitive emission rates early in the design phase. The method combines a pre-calculated emission database of standard process module based approach with estimation by using generic piping and instrumentation diagrams if a suitable module is not available from the database. Also, both working and breathing emissions are included in the assessment. The emissions' assessment from a case study of hydrodealkylation distillation and storage systems is presented to demonstrate the proposed approach.},
author = {Ng, Rex T.L. and Hassim, Mimi H. and Hurme, Markku},
doi = {10.1016/j.psep.2017.04.003},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ng, Hassim, Hurme - 2017 - A hybrid approach for estimating fugitive emission rates in process development and design under incomplete k.pdf:pdf},
issn = {09575820},
journal = {Process Safety and Environmental Protection},
keywords = {Fugitive emission,Greenhouse gases,Health risk,Process design,Process development,Volatile organic compounds},
pages = {365--373},
publisher = {Institution of Chemical Engineers},
title = {{A hybrid approach for estimating fugitive emission rates in process development and design under incomplete knowledge}},
url = {http://dx.doi.org/10.1016/j.psep.2017.04.003},
volume = {109},
year = {2017}
}
@article{Kiguchi2004,
abstract = { We have been developing robotic exoskeletons to assist motion of physically weak persons such as elderly, disabled, and injured persons. The robotic exoskeleton is controlled basically based on the electromyogram (EMG) signals, since the EMG signals of human muscles are important signals to understand how the user intends to move. Even though the EMG signals contain very important information, however, it is not very easy to predict the user's upper-limb motion (elbow and shoulder motion) based on the EMG signals in real-time because of the difficulty in using the EMG signals as the controller input signals. In this paper, we propose a robotic exoskeleton for human upper-limb motion assist, a hierarchical neuro-fuzzy controller for the robotic exoskeleton, and its adaptation method.},
author = {Kiguchi, Kazuo and Tanaka, Takakazu and Fukuda, Toshio},
doi = {10.1109/TFUZZ.2004.832525},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kiguchi, Tanaka, Fukuda - 2004 - Neuro-fuzzy control of a robotic exoskeleton with EMG signals.pdf:pdf},
isbn = {1063-6706},
issn = {10636706},
journal = {IEEE Transactions on Fuzzy Systems},
number = {4},
pages = {481--490},
title = {{Neuro-fuzzy control of a robotic exoskeleton with EMG signals}},
volume = {12},
year = {2004}
}
@article{Baykasoglu2017,
abstract = {Most of the existing methods for solving fully fuzzy mathematical programs are based on the standard fuzzy arithmetic operations and/or Zadeh's extension principle. These methods may produce questionable results for many real-life applications. Due to this fact, this paper presents a novel method based on the constrained fuzzy arithmetic concept to solve fully fuzzy balanced/unbalanced transportation problems in which all of the parameters (source capacities, demands of destinations, transportation costs etc.) as well as the decision variables (transportation quantities) are considered as fuzzy numbers. In the proposed method, the requisite crisp and/or fuzzy constraints between the base variables of the fuzzy components are provided from the decision maker according to his/her exact or vague judgments. Thereafter, fuzzy arithmetic operations are performed under these requisite constraints by taking into account the additional information while transforming the fuzzy transportation model into crisp equivalent form. Therefore, various fuzzy efficient solutions can be generated by making use of the proposed method according to the decision maker's risk attitude. In order to present the efficiency/applicability of the proposed method, different types of fully fuzzy transportation problems are generated and solved as illustrative examples. A detailed comparative study is also performed with other methods available in the literature. The computational analysis have shown that relatively more precise solutions are obtained from the proposed method for “risk-averse” and “partially risk-averse” decision makers. The proposed method also successfully provided fuzzy acceptable solutions for “risk seekers” with high degree of uncertainty similar to the other existing methods in the literature.},
author = {Baykasoğlu, Adil and Subulan, Kemal},
doi = {10.1016/j.eswa.2017.03.040},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baykasoğlu, Subulan - 2017 - Constrained fuzzy arithmetic approach to fuzzy transportation problems with fuzzy decision variables.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Constrained fuzzy arithmetic,Fuzzy decision variables,Fuzzy linear programming,Fuzzy transportation problem,Risk attitude},
pages = {193--222},
title = {{Constrained fuzzy arithmetic approach to fuzzy transportation problems with fuzzy decision variables}},
volume = {81},
year = {2017}
}
@article{Kumar2020,
abstract = {In this paper, we propose NU-GAN, a new method for resampling audio from lower to higher sampling rates (upsampling). Audio upsampling is an important problem since productionizing generative speech technology requires operating at high sampling rates. Such applications use audio at a resolution of 44.1 kHz or 48 kHz, whereas current speech synthesis methods are equipped to handle a maximum of 24 kHz resolution. NU-GAN takes a leap towards solving audio upsampling as a separate component in the text-to-speech (TTS) pipeline by leveraging techniques for audio generation using GANs. ABX preference tests indicate that our NU-GAN resampler is capable of resampling 22 kHz to 44.1 kHz audio that is distinguishable from original audio only 7.4% higher than random chance for single speaker dataset, and 10.8% higher than chance for multi-speaker dataset.},
archivePrefix = {arXiv},
arxivId = {2010.11362},
author = {Kumar, Rithesh and Kumar, Kundan and Anand, Vicki and Bengio, Yoshua and Courville, Aaron},
eprint = {2010.11362},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kumar et al. - 2020 - NU-GAN High resolution neural upsampling with GAN.pdf:pdf},
pages = {0--4},
title = {{NU-GAN: High resolution neural upsampling with GAN}},
url = {http://arxiv.org/abs/2010.11362},
year = {2020}
}
@article{Yang2019f,
abstract = {Modern object detectors rely heavily on rectangular bounding boxes, such as anchors, proposals and the final predictions, to represent objects at various recognition stages. The bounding box is convenient to use but provides only a coarse localization of objects and leads to a correspondingly coarse extraction of object features. In this paper, we present \textbf{RepPoints} (representative points), a new finer representation of objects as a set of sample points useful for both localization and recognition. Given ground truth localization and recognition targets for training, RepPoints learn to automatically arrange themselves in a manner that bounds the spatial extent of an object and indicates semantically significant local areas. They furthermore do not require the use of anchors to sample a space of bounding boxes. We show that an anchor-free object detector based on RepPoints can be as effective as the state-of-the-art anchor-based detection methods, with 46.5 AP and 67.4 $AP_{50}$ on the COCO test-dev detection benchmark, using ResNet-101 model. Code is available at https://github.com/microsoft/RepPoints.},
archivePrefix = {arXiv},
arxivId = {1904.11490},
author = {Yang, Ze and Liu, Shaohui and Hu, Han and Wang, Liwei and Lin, Stephen},
eprint = {1904.11490},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2019 - RepPoints Point Set Representation for Object Detection.pdf:pdf},
title = {{RepPoints: Point Set Representation for Object Detection}},
url = {http://arxiv.org/abs/1904.11490},
year = {2019}
}
@article{Ke2020,
abstract = {Existing research on continual learning of a sequence of tasks focused on dealing with catastrophic forgetting, where the tasks are assumed to be dissimilar and have little shared knowledge. Some work has also been done to transfer previously learned knowledge to the new task when the tasks are similar and have shared knowledge. To the best of our knowledge, no technique has been proposed to learn a sequence of mixed similar and dissimilar tasks that can deal with forgetting and also transfer knowledge forward and backward. This paper proposes such a technique to learn both types of tasks in the same network. For dissimilar tasks, the algorithm focuses on dealing with forgetting, and for similar tasks, the algorithm focuses on selectively transferring the knowledge learned from some similar previous tasks to improve the new task learning. Additionally, the algorithm automatically detects whether a new task is similar to any previous tasks. Empirical evaluation using sequences of mixed tasks demonstrates the effectiveness of the proposed model. 2},
author = {Ke, Zixuan and Liu, Bing and Huang, Xingchang},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ke, Liu, Huang - 2020 - Continual Learning of a Mixed Sequence of Similar and Dissimilar Tasks.pdf:pdf},
journal = {NeurIPS},
keywords = {continual learning,transfer learning},
mendeley-tags = {continual learning,transfer learning},
number = {NeurIPS},
pages = {1--12},
title = {{Continual Learning of a Mixed Sequence of Similar and Dissimilar Tasks}},
url = {https://github.com/ZixuanKe/CAT},
year = {2020}
}
@inproceedings{Doshi2020AnyShotSA,
abstract = {Anomaly detection in surveillance videos has been recently gaining attention. Even though the performance of state-of-the-art methods on publicly available data sets has been competitive, they demand a massive amount of training data. Also, they lack a concrete approach for continuously updating the trained model once new data is available. Furthermore, online decision making is an important but mostly neglected factor in this domain. Motivated by these research gaps, we propose an online anomaly detection method for surveillance videos using transfer learning and any-shot learning, which in turn significantly reduces the training complexity and provides a mechanism which can detect anomalies using only a few labeled nominal examples. Our proposed algorithm leverages the feature extraction power of neural network-based models for transfer learning, and the any-shot learning capability of statistical detection methods.},
author = {Doshi, Keval and Yilmaz, Yasin},
booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Doshi, Yilmaz - 2020 - Any-shot sequential anomaly detection in surveillance videos.pdf:pdf},
issn = {23318422},
keywords = {anomaly detection,continual learning,incremental learning},
mendeley-tags = {anomaly detection,continual learning,incremental learning},
pages = {4037--4042},
title = {{Any-shot sequential anomaly detection in surveillance videos}},
year = {2020}
}
@article{Armstrong1989a,
author = {Armstrong, J Scott},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Armstrong - 1989 - Combining Forecasts The End of the Beginning or the Beginning of the End Combining Forecasts The End of the Beginn.pdf:pdf},
journal = {International Journal of Forecasting},
number = {4},
pages = {585--588},
title = {{Combining Forecasts : The End of the Beginning or the Beginning of the End ? Combining Forecasts : The End of the Beginning or the Beginning of the}},
volume = {5},
year = {1989}
}
@article{Bhatti2017,
abstract = {In this article, the influence of magnetohydrodynamics (MHD) on cilia motion of particle–fluid suspension through a porous planar channel has been investigated. The governing equations of Casson fluid model for fluid phase and particulate phase are solved by taking the assumption of long wavelength and neglecting the inertial forces due to laminar flow. The solutions for the resulting differential equations have been obtained analytically and a close form of solutions is presented. The expression for pressure rise along the whole length of the channel is evaluated numerically. The influences of all the physical parameters are demonstrated graphically. Trapping mechanism has also been discussed with the help of streamlines. It is observed that due to the influence of magnetohydrodynamics and particle volume fraction, velocity of the fluid decreases. It is also found that pressure rise shows similar behaviour for particle volume fraction and Casson fluid parameter.},
author = {Bhatti, M. M. and Zeeshan, A. and Rashidi, M. M.},
doi = {10.1016/j.jestch.2016.03.001},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bhatti, Zeeshan, Rashidi - 2017 - Influence of magnetohydrodynamics on metachronal wave of particle-fluid suspension due to cilia motion.pdf:pdf},
issn = {22150986},
journal = {Engineering Science and Technology, an International Journal},
keywords = {Cilia motion,Magnetohydrodynamics,Metachronal wave,Particle fluid},
number = {1},
pages = {265--271},
publisher = {Karabuk University},
title = {{Influence of magnetohydrodynamics on metachronal wave of particle-fluid suspension due to cilia motion}},
url = {http://dx.doi.org/10.1016/j.jestch.2016.03.001},
volume = {20},
year = {2017}
}
@article{Lin2019,
abstract = {Catastrophic forgetting of connectionist neural networks is caused by the global sharing of parameters among all training examples. In this study, we analyze parameter sharing under the conditional computation framework where the parameters of a neural network are conditioned on each input example. At one extreme, if each input example uses a disjoint set of parameters, there is no sharing of parameters thus no catastrophic forgetting. At the other extreme, if the parameters are the same for every example, it reduces to the conventional neural network. We then introduce a clipped version of maxout networks which lies in the middle, i.e. parameters are shared partially among examples. Based on the parameter sharing analysis, we can locate a limited set of examples that are interfered when learning a new example. We propose to perform rehearsal on this set to prevent forgetting, which is termed as conditional rehearsal. Finally, we demonstrate the effectiveness of the proposed method in an online non-stationary setup, where updates are made after each new example and the distribution of the received example shifts over time.},
archivePrefix = {arXiv},
arxivId = {1906.06635},
author = {Lin, Min and Fu, Jie and Bengio, Yoshua},
eprint = {1906.06635},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin, Fu, Bengio - 2019 - Conditional Computation for Continual Learning.pdf:pdf},
journal = {NeurIPS Workshop on Continual Learning},
month = {jun},
title = {{Conditional Computation for Continual Learning}},
url = {http://arxiv.org/abs/1906.06635},
year = {2019}
}
@article{Olabi2007a,
abstract = {Magneto-rheological fluid (MRF) technology is an old "newcomers" coming to the market at high speed. Various industries including the automotive industry are full of potential MRF applications. Magneto-rheological fluid technology has been successfully employed already in various low and high volume applications. A structure based on MRF might be the next generation in design for products where power density, accuracy and dynamic performance are the key features. Additionally, for products where is a need to control fluid motion by varying the viscosity, a structure based on MRF might be an improvement in functionality and costs. Two aspects of this technology, direct shear mode (used in brakes and clutches) and valve mode (used in dampers) have been studied thoroughly and several applications are already present on the market. Excellent features like fast response, simple interface between electrical power input and mechanical power output, and precise controllability make MRF technology attractive for many applications. This paper presents the state of the art of an actuator with a control arrangement based on MRF technology. The study shows that excellent features like fast response, simple interface between electrical power input and the mechanical power output, and controllability make MRF the next technology of choice for many applications. {\textcopyright} 2006 Elsevier Ltd. All rights reserved.},
author = {Olabi, A. G. and Grunwald, A.},
doi = {10.1016/j.matdes.2006.10.009},
issn = {18734197},
journal = {Materials and Design},
number = {10},
pages = {2658--2664},
title = {{Design and application of magneto-rheological fluid}},
volume = {28},
year = {2007}
}
@misc{Shirane1952b,
author = {Shirane, G. and Susuki, K},
booktitle = {J. Phys. Soc. Japan},
doi = {10.1143/JPSJ.7.333},
issn = {0031-9015},
pages = {333},
title = {{Crystal structure of PZT}},
volume = {7},
year = {1952}
}
@article{Martinez-Martinez2012,
abstract = {This paper presents a system based on an Artificial Neural Network (ANN) for estimating and predicting environmental variables related to tobacco drying processes. This system has been validated with temperature and relative humidity data obtained from a real tobacco dryer with a Wireless Sensor Network (WSN). A fitting ANN was used to estimate temperature and relative humidity in different locations inside the tobacco dryer and to predict them with different time horizons. An error under 2% can be achieved when estimating temperature as a function of temperature and relative humidity in other locations. Moreover, an error around 1.5 times lower than that obtained with an interpolation method can be achieved when predicting the temperature inside the tobacco mass as a function of its present and past values with time horizons over 150 minutes. These results show that the tobacco drying process can be improved taking into account the predicted future value of the monitored variables and the estimated actual value of other variables using a fitting ANN as proposed.},
author = {Mart{\'{i}}nez-Mart{\'{i}}nez, V{\'{i}}ctor and Baladr{\'{o}}n, Carlos and Gomez-Gil, Jaime and Ruiz-Ruiz, Gonzalo and Navas-Gracia, Luis M. and Aguiar, Javier M. and Carro, Bel{\'{e}}n},
doi = {10.3390/s121014004},
isbn = {3463679752},
issn = {1424-8220},
journal = {Sensors},
number = {12},
pages = {14004--14021},
title = {{Temperature and Relative Humidity Estimation and Prediction in the Tobacco Drying Process Using Artificial Neural Networks}},
url = {http://www.mdpi.com/1424-8220/12/10/14004/},
volume = {12},
year = {2012}
}
@article{Kang2019,
abstract = {The long-tail distribution of the visual world poses great challenges for deep learning based classification models on how to handle the class imbalance problem. Existing solutions usually involve class-balancing strategies, e.g. by loss re-weighting, data re-sampling, or transfer learning from head- to tail-classes, but most of them adhere to the scheme of jointly learning representations and classifiers. In this work, we decouple the learning procedure into representation learning and classification, and systematically explore how different balancing strategies affect them for long-tailed recognition. The findings are surprising: (1) data imbalance might not be an issue in learning high-quality representations; (2) with representations learned with the simplest instance-balanced (natural) sampling, it is also possible to achieve strong long-tailed recognition ability at little cost by adjusting only the classifier. We conduct extensive experiments and set new state-of-the-art performance on common long-tailed benchmarks like ImageNet-LT, Places-LT and iNaturalist, showing that it is possible to outperform carefully designed losses, sampling strategies, even complex modules with memory, by using a straightforward approach that decouples representation and classification.},
archivePrefix = {arXiv},
arxivId = {1910.09217},
author = {Kang, Bingyi and Xie, Saining and Rohrbach, Marcus and Yan, Zhicheng and Gordo, Albert and Feng, Jiashi and Kalantidis, Yannis},
eprint = {1910.09217},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kang et al. - 2019 - Decoupling representation and classifier for long-tailed recognition.pdf:pdf},
journal = {arXiv},
keywords = {imbalanced dataset,long-tailed recognition},
mendeley-tags = {imbalanced dataset,long-tailed recognition},
pages = {1--16},
title = {{Decoupling representation and classifier for long-tailed recognition}},
url = {https://github.com/facebookresearch/classifier-balancing https://arxiv.org/abs/1910.09217},
year = {2019}
}
@article{Pretty2005,
abstract = {Both physical activity and exposure to nature are known separately to have positive effects on physical and mental health. We have investigated whether there is a synergistic benefit in adopting physical activities whilst being directly exposed to nature ('green exercise'). Five groups of 20 subjects were exposed to a sequence of 30 scenes projected on a wall whilst exercising on a treadmill. Four categories of scenes were tested: rural pleasant, rural unpleasant, urban pleasant and urban unpleasant. The control was running without exposure to images. Blood pressure and two psychological measures (self-esteem and mood) were measured before and after the intervention. There was a clear effect of both exercise and different scenes on blood pressure, self-esteem and mood. Exercise alone significantly reduced blood pressure, increased self-esteem, and had a positive significant effect on 4 of 6 mood measures. Both rural and urban pleasant scenes produced a significantly greater positive effect on self-esteem than the exercise-only control. This shows the synergistic effect of green exercise in both rural and urban environments. By contrast, both rural and urban unpleasant scenes reduced the positive effects of exercise on self-esteem. The rural unpleasant scenes had the most dramatic effect, depressing the beneficial effects of exercise on three different measures of mood. It appears that threats to the countryside depicted in rural unpleasant scenes have a greater negative effect on mood than already urban unpleasant scenes. We conclude that green exercise has important public and environmental health consequences.},
author = {Pretty, Jules and Peacock, Jo and Sellens, Martin and Griffin, Murray},
doi = {10.1080/09603120500155963},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pretty et al. - 2005 - The mental and physical health outcomes of green exercise.pdf:pdf},
isbn = {0960-3123 (Print)},
issn = {09603123},
journal = {International Journal of Environmental Health Research},
keywords = {Environmental health,Green exercise,Mental health,Mood,Physical activity,Self-esteem},
number = {5},
pages = {319--337},
pmid = {16416750},
title = {{The mental and physical health outcomes of green exercise}},
volume = {15},
year = {2005}
}
@article{Herrick2000,
abstract = {Kartalopoulos, Stamatios V},
author = {Herrick, Robert J},
doi = {10.1109/9780470544990},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Herrick - 2000 - Introduction To Dwdm Technology(2).pdf:pdf},
isbn = {0780347455},
journal = {Introduction To Dwdm Technology},
number = {6387},
pages = {288},
title = {{Introduction To Dwdm Technology}},
year = {2000}
}
@book{Victorino2006,
author = {Victorino, Igor R de S. and Filho, R Maciel},
booktitle = {IFAC Proceedings Volumes},
doi = {10.3182/20060402-4-BR-2902.00857},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Victorino, Filho - 2006 - Application of Genetic Algorithms To the Optimization of an Industrial Reactor.pdf:pdf},
issn = {14746670},
keywords = {Chemical process,Genetic algorithms,Global optimization,genetic algorithms,global optimization},
number = {2},
pages = {857--862},
publisher = {IFAC},
title = {{Application of Genetic Algorithms To the Optimization of an Industrial Reactor}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1474667016354386},
volume = {39},
year = {2006}
}
@article{Where,
author = {Where, Engines},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Where - Unknown - Combust1a.ppp 1.pdf:pdf},
pages = {1--11},
title = {{Combust1a.ppp 1}}
}
@article{Bayas2017,
author = {Bayas, Antonio and {\v{S}}krjanc, Igor and S{\'{a}}ez, Doris},
doi = {10.1016/j.asoc.2017.10.003},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bayas, {\v{S}}krjanc, S{\'{a}}ez - 2017 - Design of fuzzy robust control strategies for a distributed solar collector field.pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing},
title = {{Design of fuzzy robust control strategies for a distributed solar collector field}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1568494617306063},
year = {2017}
}
@article{Sirignano1986,
abstract = {Summary This chapter is intended as introductory text in the fundamentals of combustion for engineering graduate students, as well as a basis for the next four chapters. Combustion is defined as a rapid exothermic reaction that liberates substantial energy as heat and flames as combustion reactions with the ability to propagate through a suitable medium. This propagation results from the strong coupling of the reaction with the molecular transport process. The chemistry and physics of combustion, i.e. destruction and rearrangement of certain molecules, rapidly release energy within a few millionths of second. Currently, combustion is a mature discipline and an integral element of diverse research and development programs from fundamental studies of the physics of flames and high-temperature molecular chemistry to applied engineering projects involved with developments such as advanced coal-burning equipment and improved combustion furnaces, boilers, and engines. These developments are important in controlling the pollutant emissions. Therefore, it is appropriate in this chapter to present two very important practical considerations relative to the combustion reaction systems, which are the mass and energy balance used to describe such systems.},
author = {Sirignano, William A.},
doi = {10.1016/0010-2180(86)90132-X},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sirignano - 1986 - Combustion fundamentals.pdf:pdf},
isbn = {978-0-08-044106-1},
issn = {00102180},
journal = {Combustion and Flame},
number = {1-2},
pages = {309},
title = {{Combustion fundamentals}},
url = {http://linkinghub.elsevier.com/retrieve/pii/001021808690132X},
volume = {63},
year = {1986}
}
@incollection{Yu2011b,
abstract = {This paper reports the first development of the Levenberg-Marquardt algorithm for neural networks. It describes the theory and application of the algorithm, which trains neural networks at a rate 10 to 100 times faster than the usual gradient descent backpropagation method.},
author = {Yu, Hao and Wilamowski, Bogdan},
doi = {10.1201/b10604-15},
isbn = {978-1-4398-0283-0},
pages = {1--16},
title = {{Levenberg–Marquardt Training}},
url = {http://www.crcnetbase.com/doi/abs/10.1201/b10604-15},
year = {2011}
}
@article{Pagani2017,
abstract = {The impact of extreme events (such as prolonged droughts, heat waves, cold shocks and frost) is poorly represented by most of the existing yield forecasting systems. Two new model-based approaches that account for the impact of extreme weather events on crop production are presented as a way to improve yield forecasts, both based on the Crop Growth Monitoring System (CGMS) of the European Commission. A first approach includes simple relations – consistent with the degree of complexity of the most generic crop simulators – to explicitly model the impact of these events on leaf development and yield formation. A second approach is a hybrid system which adds selected agro-climatic indicators (accounting for drought and cold/heat stress) to the previous one. The new proposed methods, together with the CGMS-standard approach and a system exclusively based on selected agro-climatic indicators, were evaluated in a comparative fashion for their forecasting reliability. The four systems were assessed for the main micro- and macro-thermal cereal crops grown in highly productive European countries. The workflow included the statistical post-processing of model outputs aggregated at national level with historical series (1995–2013) of official yields, followed by a cross-validation for forecasting events triggered at flowering, maturity and at an intermediate stage. With the system based on agro-climatic indicators, satisfactory performances were limited to microthermal crops grown in Mediterranean environments (i.e. crop production systems mainly driven by rainfall distribution). Compared to CGMS-standard system, the newly proposed approaches increased the forecasting reliability in 94% of the combinations crop × country × forecasting moment. In particular, the explicit simulation of the impact of extreme events explained a large part of the inter-annual variability (up to +44% for spring barley in Poland), while the addition of agro-climatic indicators to the workflow mostly added accuracy to an already satisfactory forecasting system.},
author = {Pagani, Valentina and Guarneri, Tommaso and Fumagalli, Davide and Movedi, Ermes and Testi, Luca and Klein, Tommy and Calanca, Pierluigi and Villalobos, Francisco and Lopez-Bernal, Alvaro and Niemeyer, Stefan and Bellocchi, Gianni and Confalonieri, Roberto},
doi = {10.1016/j.eja.2017.06.010},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pagani et al. - 2017 - Improving cereal yield forecasts in Europe – The impact of weather extremes.pdf:pdf},
issn = {11610301},
journal = {European Journal of Agronomy},
keywords = {Agro-climatic indicators,CGMS,Crop model,Extreme weather events,WOFOST,Yield forecasting},
number = {February},
pages = {97--106},
publisher = {Elsevier},
title = {{Improving cereal yield forecasts in Europe – The impact of weather extremes}},
url = {http://dx.doi.org/10.1016/j.eja.2017.06.010},
volume = {89},
year = {2017}
}
@article{Robertini2017,
abstract = {This paper presents a novel approach to recover true fine surface detail of deforming meshes reconstructed from multi-view video. Template-based methods for performance capture usually produce a coarse-to-medium scale detail 4D surface reconstruction which does not contain the real high-frequency geometric detail present in the original video footage. Fine scale deformation is often incorporated in a second pass by using stereo constraints, features, or shading-based refinement. In this paper, we propose an alternative solution to this second stage by formulating dense dynamic surface reconstruction as a global optimization problem of the densely deforming surface. Our main contribution is an implicit representation of a deformable mesh that uses a set of Gaussian functions on the surface to represent the initial coarse mesh, and a set of Gaussians for the images to represent the original captured multi-view images. We effectively find the fine scale deformations for all mesh vertices, which maximize photo-temporal-consistency, by densely optimizing our model-to-image consistency energy on all vertex positions. Our formulation yields a smooth closed form energy with implicit occlusion handling and analytic derivatives. Furthermore, it does not require error-prone correspondence finding or discrete sampling of surface displacement values. We demonstrate our approach on a variety of datasets of human subjects wearing loose clothing and performing different motions. We qualitatively and quantitatively demonstrate that our technique successfully reproduces finer detail than the input baseline geometry.},
author = {Robertini, Nadia and Casas, Dan and {De Aguiar}, Edilson and Theobalt, Christian},
doi = {10.1007/s11263-016-0979-1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Robertini et al. - 2017 - Multi-view Performance Capture of Surface Details.pdf:pdf},
issn = {15731405},
journal = {International Journal of Computer Vision},
keywords = {Performance capture,Sums of Gaussian,Surface detail},
number = {1},
pages = {96--113},
publisher = {Springer US},
title = {{Multi-view Performance Capture of Surface Details}},
volume = {124},
year = {2017}
}
@article{Tsonev2015,
abstract = {Potential visible light communication (VLC) data rates at over 10 Gb/s have been recently demonstrated using light emitting diodes (LEDs). The disadvantage is, LEDs have an inherent trade-off between optical efficiency and bandwidth. Consequently, laser diodes (LDs) can be considered as a very promising alternative for better utilization of the visible light spectrum for communication purposes. This work investigates the communication capabilities of off-the-shelf LDs in a number of scenarios with illumination constraints. The results indicate that optical wireless access data rates in the excess of 100 Gb/s are possible at standard indoor illumination levels.},
author = {Tsonev, Dobroslav and Videv, Stefan and Haas, Harald},
doi = {10.1364/OE.23.001627},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tsonev, Videv, Haas - 2015 - Towards a 100 Gbs visible light wireless access network.pdf:pdf},
isbn = {1094-4087},
issn = {1094-4087},
journal = {Optics Express},
number = {2},
pages = {1627},
pmid = {25835920},
title = {{Towards a 100 Gb/s visible light wireless access network}},
url = {https://www.osapublishing.org/abstract.cfm?URI=oe-23-2-1627},
volume = {23},
year = {2015}
}
@article{Bertugli2021,
abstract = {Learning quickly and continually is still an ambitious task for neural networks. Indeed, many real-world applications do not reflect the learning setting where neural networks shine, as data are usually few, mostly unlabelled and come as a stream. To narrow this gap, we introduce FUSION - Few-shot UnSupervIsed cONtinual learning - a novel strategy which aims to deal with neural networks that "learn in the wild", simulating a real distribution and flow of unbalanced tasks. We equip FUSION with MEML - Meta-Example Meta-Learning - a new module that simultaneously alleviates catastrophic forgetting and favours the generalisation and future learning of new tasks. To encourage features reuse during the meta-optimisation, our model exploits a single inner loop per task, taking advantage of an aggregated representation achieved through the use of a self-attention mechanism. To further enhance the generalisation capability of MEML, we extend it by adopting a technique that creates various augmented tasks and optimises over the hardest. Experimental results on few-shot learning benchmarks show that our model exceeds the other baselines in both FUSION and fully supervised case. We also explore how it behaves in standard continual learning consistently outperforming state-of-the-art approaches.},
archivePrefix = {arXiv},
arxivId = {2101.12081},
author = {Bertugli, Alessia and Vincenzi, Stefano and Calderara, Simone and Passerini, Andrea},
eprint = {2101.12081},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bertugli et al. - 2021 - Generalising via Meta-Examples for Continual Learning in the Wild.pdf:pdf},
keywords = {continual learning,few-shot learning,self-attention,unsupervised learning},
mendeley-tags = {continual learning,few-shot learning,self-attention,unsupervised learning},
title = {{Generalising via Meta-Examples for Continual Learning in the Wild}},
url = {http://arxiv.org/abs/2101.12081},
year = {2021}
}
@article{Ahn2020,
abstract = {We consider class incremental learning (CIL) problem, in which a learning agent continuously learns new classes from incrementally arriving training data batches and aims to predict well on all the classes learned so far. The main challenge of the problem is the catastrophic forgetting, and for the exemplar-memory based CIL methods, it is generally known that the forgetting is commonly caused by the prediction score bias that is injected due to the data imbalance between the new classes and the old classes (in the exemplar-memory). While several methods have been proposed to correct such score bias by some additional post-processing, e.g., score re-scaling or balanced fine-tuning, no systematic analysis on the root cause of such bias has been done. To that end, we analyze that computing the softmax probabilities by combining the output scores for all old and new classes could be the main source of the bias and propose a new CIL method, Separated Softmax for Incremental Learning (SS-IL). Our SS-IL consists of separated softmax (SS) output layer and ratio-preserving (RP) mini-batches combined with task-wise knowledge distillation (TKD), and through extensive experimental results, we show our SS-IL achieves very strong state-of-the-art accuracy on several large-scale benchmarks. We also show SS-IL makes much more balanced prediction, without any additional post-processing steps as is done in other baselines.},
archivePrefix = {arXiv},
arxivId = {2003.13947},
author = {Ahn, Hongjoon and Kwak, Jihwan and Lim, Subin and Bang, Hyeonsu and Kim, Hyojun and Moon, Taesup},
eprint = {2003.13947},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ahn et al. - 2020 - SS-IL Separated Softmax for Incremental Learning.pdf:pdf},
journal = {arXiv},
keywords = {Catastrophic forgetting,Class incremental learning,Exemplar-memory,Fine-tuning},
month = {mar},
title = {{SS-IL: Separated Softmax for Incremental Learning}},
url = {http://arxiv.org/abs/2003.13947},
year = {2020}
}
@article{Mai2021,
abstract = {Online continual learning for image classification studies the problem of learning to classify images from an online stream of data and tasks, where tasks may include new classes (class incremental) or data nonstationarity (domain incremental). One of the key challenges of continual learning is to avoid catastrophic forgetting (CF), i.e., forgetting old tasks in the presence of more recent tasks. Over the past few years, many methods and tricks have been introduced to address this problem, but many have not been fairly and systematically compared under a variety of realistic and practical settings. To better understand the relative advantages of various approaches and the settings where they work best, this survey aims to (1) compare state-of-the-art methods such as MIR, iCARL, and GDumb and determine which works best at different experimental settings; (2) determine if the best class incremental methods are also competitive in domain incremental setting; (3) evaluate the performance of 7 simple but effective trick such as "review" trick and nearest class mean (NCM) classifier to assess their relative impact. Regarding (1), we observe earlier proposed iCaRL remains competitive when the memory buffer is small; GDumb outperforms many recently proposed methods in medium-size datasets and MIR performs the best in larger-scale datasets. For (2), we note that GDumb performs quite poorly while MIR -- already competitive for (1) -- is also strongly competitive in this very different but important setting. Overall, this allows us to conclude that MIR is overall a strong and versatile method across a wide variety of settings. For (3), we find that all 7 tricks are beneficial, and when augmented with the "review" trick and NCM classifier, MIR produces performance levels that bring online continual learning much closer to its ultimate goal of matching offline training.},
archivePrefix = {arXiv},
arxivId = {2101.10423},
author = {Mai, Zheda and Li, Ruiwen and Jeong, Jihwan and Quispe, David and Kim, Hyunwoo and Sanner, Scott},
eprint = {2101.10423},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mai et al. - 2021 - Online Continual Learning in Image Classification An Empirical Survey.pdf:pdf},
keywords = {continual learning,image classification,review,survey},
mendeley-tags = {continual learning,image classification,review,survey},
number = {1},
pages = {1--64},
title = {{Online Continual Learning in Image Classification: An Empirical Survey}},
url = {http://arxiv.org/abs/2101.10423},
year = {2021}
}
@article{Caron2020,
abstract = {Unsupervised image representations have significantly reduced the gap with supervised pretraining, notably with the recent achievements of contrastive learning methods. These contrastive methods typically work online and rely on a large number of explicit pairwise feature comparisons, which is computationally challenging. In this paper, we propose an online algorithm, SwAV, that takes advantage of contrastive methods without requiring to compute pairwise comparisons. Specifically, our method simultaneously clusters the data while enforcing consistency between cluster assignments produced for different augmentations (or “views”) of the same image, instead of comparing features directly as in contrastive learning. Simply put, we use a “swapped” prediction mechanism where we predict the cluster assignment of a view from the representation of another view. Our method can be trained with large and small batches and can scale to unlimited amounts of data. Compared to previous contrastive methods, our method is more memory efficient since it does not require a large memory bank or a special momentum network. In addition, we also propose a new data augmentation strategy, multi-crop, that uses a mix of views with different resolutions in place of two full-resolution views, without increasing the memory or compute requirements much. We validate our findings by achieving 75.3% top-1 accuracy on ImageNet with ResNet-50, as well as surpassing supervised pretraining on all the considered transfer tasks.},
archivePrefix = {arXiv},
arxivId = {2006.09882},
author = {Caron, Mathilde and Goyal, Priya and Misra, Ishan and Bojanowski, Piotr and Mairal, Julien and Joulin, Armand},
eprint = {2006.09882},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Caron et al. - 2020 - Unsupervised Learning of Visual Features by Contrasting Cluster Assignments(4).pdf:pdf;:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Caron et al. - 2020 - Unsupervised Learning of Visual Features by Contrasting Cluster Assignments(5).pdf:pdf},
issn = {23318422},
journal = {arXiv},
number = {NeurIPS},
pages = {1--23},
title = {{Unsupervised Learning of Visual Features by Contrasting Cluster Assignments}},
year = {2020}
}
@article{Bisht2016,
abstract = {This study proposes a fuzzy time series forecasting method based on hesitant fuzzy sets for forecasting in the environment of hesitant information. The proposed method addresses the problem of establishing a common membership grade for the situation when multiple fuzzification methods are available to fuzzify time series data. An aggregation operator for aggregating hesitant information is also proposed in the study. The proposed method is implemented to forecast enrollment at University of Alabama and price of state bank of India (SBI) share at Bombay stock exchange (BSE), India. In both time series data are fuzzified with triangular fuzzy sets constructed using intervals of equal and unequal length. The performance of the proposed method in forecasting student enrollments and SBI share price is measured in terms of root mean square and average forecasting errors. Statistical validation and performance analysis is also carried out to validate the proposed forecasting method.},
author = {Bisht, Kamlesh and Kumar, Sanjay},
doi = {10.1016/j.eswa.2016.07.044},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bisht, Kumar - 2016 - Fuzzy time series forecasting method based on hesitant fuzzy sets(2).pdf:pdf},
isbn = {0957-4174},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Aggregation operator,Forecasting,Fuzzy logical relation,Fuzzy time series,Hesitant fuzzy set,Time invariant},
pages = {557--568},
publisher = {Elsevier Ltd},
title = {{Fuzzy time series forecasting method based on hesitant fuzzy sets}},
url = {http://dx.doi.org/10.1016/j.eswa.2016.07.044},
volume = {64},
year = {2016}
}
@article{Dodds2015,
abstract = {The debate on low-carbon heat in Europe has become focused on a narrow range of technological options and has largely neglected hydrogen and fuel cell technologies, despite these receiving strong support towards commercialisation in Asia. This review examines the potential benefits of these technologies across different markets, particularly the current state of development and performance of fuel cell micro-CHP. Fuel cells offer some important benefits over other low-carbon heating technologies, and steady cost reductions through innovation are bringing fuel cells close to commercialisation in several countries. Moreover, fuel cells offer wider energy system benefits for high-latitude countries with peak electricity demands in winter. Hydrogen is a zero-carbon alternative to natural gas, which could be particularly valuable for those countries with extensive natural gas distribution networks, but many national energy system models examine neither hydrogen nor fuel cells for heating. There is a need to include hydrogen and fuel cell heating technologies in future scenario analyses, and for policymakers to take into account the full value of the potential contribution of hydrogen and fuel cells to low-carbon energy systems.},
author = {Dodds, Paul E. and Staffell, Iain and Hawkes, Adam D. and Li, Francis and Gr{\"{u}}newald, Philipp and McDowall, Will and Ekins, Paul},
doi = {10.1016/j.ijhydene.2014.11.059},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dodds et al. - 2015 - Hydrogen and fuel cell technologies for heating A review.pdf:pdf},
isbn = {0360-3199},
issn = {03603199},
journal = {International Journal of Hydrogen Energy},
keywords = {Energy policy,Fuel cell CHP,Hydrogen heating,Low-carbon heat,Systems integration},
number = {5},
pages = {2065--2083},
title = {{Hydrogen and fuel cell technologies for heating: A review}},
volume = {40},
year = {2015}
}
@article{Natekar2020,
archivePrefix = {arXiv},
arxivId = {arXiv:2012.02775v1},
author = {Natekar, Parth},
eprint = {arXiv:2012.02775v1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Natekar - 2020 - Representation Based Complexity Measures for Predicting Generalization on Deep Learning.pdf:pdf},
keywords = {generalization,measurement},
mendeley-tags = {generalization,measurement},
number = {2018},
title = {{Representation Based Complexity Measures for Predicting Generalization on Deep Learning}},
year = {2020}
}
@article{GHOSH-DASTIDAR2009,
abstract = {Most current Artificial Neural Network (ANN) models are based on highly simplified brain dynamics. They have been used as powerful computational tools to solve complex pattern recognition, function estimation, and classification problems. ANNs have been evolving towards more powerful and more biologically realistic models. In the past decade, Spiking Neural Networks (SNNs) have been developed which comprise of spiking neurons. Information transfer in these neurons mimics the information transfer in biological neurons, i.e., via the precise timing of spikes or a sequence of spikes. To facilitate learning in such networks, new learning algorithms based on varying degrees of biological plausibility have also been developed recently. Addition of the temporal dimension for information encoding in SNNs yields new insight into the dynamics of the human brain and could result in compact representations of large neural networks. As such, SNNs have great potential for solving complicated time-dependent pattern recognition problems because of their inherent dynamic representation. This article presents a state-of-the-art review of the development of spiking neurons and SNNs, and provides insight into their evolution as the third generation neural networks.},
author = {GHOSH-DASTIDAR, SAMANWOY and ADELI, HOJJAT},
doi = {10.1142/S0129065709002002},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/GHOSH-DASTIDAR, ADELI - 2009 - SPIKING NEURAL NETWORKS.pdf:pdf},
issn = {0129-0657},
journal = {International Journal of Neural Systems},
keywords = {information encoding,learning algorithm,spiking neural network,spiking neuron,supervised learning,unsuper-,vised learning},
month = {aug},
number = {04},
pages = {295--308},
title = {{SPIKING NEURAL NETWORKS}},
url = {https://www.worldscientific.com/doi/abs/10.1142/S0129065709002002},
volume = {19},
year = {2009}
}
@article{Carreira-Perpinan2018,
abstract = {Pruning a neural net consists of removing weights without degrading its performance. This is an old problem of renewed interest because of the need to compress ever larger nets so they can run in mobile devices. Pruning has been traditionally done by ranking or penalizing weights according to some criterion (such as magnitude), removing low-ranked weights and retraining the remaining ones. We formulate pruning as an optimization problem of finding the weights that minimize the loss while satisfying a pruning cost condition. We give a generic algorithm to solve this which alternates 'learning' steps that optimize a regularized, data-dependent loss and 'compression' steps that mark weights for pruning in a data-independent way. Magnitude thresholding arises naturally in the compression step, but unlike existing magnitude pruning approaches, our algorithm explores subsets of weights rather than committing irrevocably to a specific subset from the beginning. It is also able to learn automatically the best number of weights to prune in each layer of the net without incurring an exponentially costly model selection. Using a single pruning-level user parameter, we achieve state-of-the-art pruning in LeNet and ResNets of various sizes.},
author = {Carreira-Perpi{\~{n}}{\'{a}}n, Miguel A. and Idelbayev, Yerlan},
doi = {10.1109/CVPR.2018.00890},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Carreira-Perpi{\~{n}}{\'{a}}n, Idelbayev - 2018 - 'Learning-Compression' Algorithms for Neural Net Pruning.pdf:pdf},
isbn = {9781538664209},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
number = {Lc},
pages = {8532--8541},
title = {{'Learning-Compression' Algorithms for Neural Net Pruning}},
year = {2018}
}
@article{Ranganathan2020,
abstract = {Gradient descent and backpropagation have enabled neural networks to achieve remarkable results in many real-world applications. Despite ongoing success, training a neural network with gradient descent can be a slow and strenuous affair. We present a simple yet faster training algorithm called Zeroth-Order Relaxed Backpropagation (ZORB). Instead of calculating gradients, ZORB uses the pseudoinverse of targets to backpropagate information. ZORB is designed to reduce the time required to train deep neural networks without penalizing performance. To illustrate the speed up, we trained a feed-forward neural network with 11 layers on MNIST and observed that ZORB converged 300 times faster than Adam while achieving a comparable error rate, without any hyperparameter tuning. We also broaden the scope of ZORB to convolutional neural networks, and apply it to subsamples of the CIFAR-10 dataset. Experiments on standard classification and regression benchmarks demonstrate ZORB's advantage over traditional backpropagation with Gradient Descent.},
archivePrefix = {arXiv},
arxivId = {2011.08895},
author = {Ranganathan, Varun and Lewandowski, Alex},
eprint = {2011.08895},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ranganathan, Lewandowski - 2020 - ZORB A Derivative-Free Backpropagation Algorithm for Neural Networks.pdf:pdf},
number = {NeurIPS},
title = {{ZORB: A Derivative-Free Backpropagation Algorithm for Neural Networks}},
url = {http://arxiv.org/abs/2011.08895 https://github.com/varunranga/zorb-numpy},
year = {2020}
}
@misc{Shirane1952,
abstract = {The dielectric, calorimetric and dilatometric measurements have been made on the solid solutions Pb(Zr-Ti)O_3 which contain small amounts of PbTiO_3 less than 10%. Besides the ordinary Curie point near 220℃, the existence of atlother transition, for example 140℃ in Pb(Zr95-Ti5)O_3, was confirmed. It seems reasonable to interpret these two transitions as phase changes from paraelectric state to ferroelectric one and further to antiferroelectric one. Whereas the upper transition temperature is nearly constant for these concentrations, the lower transition temperature increases with decreasing Ti concentration and both temperatures seem to coincide at pure PbZrO_3. These results suggest that PbZrO_3 may be antiferroelectric below its Curie point 220℃.},
author = {Shirane, Gen and Takeda, Akitsu},
booktitle = {Journal of the Physical Society of Japan},
doi = {10.1143/JPSJ.7.5},
issn = {0031-9015},
number = {1},
pages = {5--11},
title = {{"Phase Transitions in Solid Solutions of PbZrO 3 and PbTiO 3 (I) Small Concentrations of PbTiO 3"}},
url = {http://jpsj.ipap.jp/link?JPSJ/7/5/},
volume = {7},
year = {1952}
}
@article{Ruiz-Perez2015,
abstract = {The aim of this paper was to analyze decisional competence and contextual intelligence in sport among different level of expertise football players. In addition, the relationship between self-perceptions of decisional competence and contextual intelligence was assessed. Participants were 467 football players (M=20,26, DT=5,43). They were assigned three levels of expertise: Autonomic (N = 141), National (N = 253) and International (N = 73), from a group of 46 spanish clubs and several national teams. The Contextual Intelligence in Sport Questionnaire (ICD) and the Decision Making in Sport Questionnaire (CETD) were used to explore self-perceptions of players. Results showed that self-perceptions of Contextual Intelligence and Decision Making increased with the level of expertise. ABSTRACT FROM AUTHOR},
author = {Ruiz-P{\'{e}}rez, Luis Miguel and Navia, Jos{\'{e}} Antonio and Mi{\~{n}}ano-Esp{\'{i}}n, Javier and Garc{\'{i}}a-Coll, Virginia and Palomo-Nieto, Miriam},
doi = {10.1080/0264041031000101809},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ruiz-P{\'{e}}rez et al. - 2015 - Autopercepci{\'{o}}n de inteligencia contextual para jugar y de competencia decisional en el f{\'{u}}tbol.pdf:pdf},
isbn = {0000725620033},
issn = {18853137},
journal = {RICYDE: Revista Internacional de Ciencias del Deporte},
keywords = {Decision making,Expertise,Practical intelligence,Self-perceptions,Soccer},
number = {42},
pages = {329--338},
pmid = {12846532},
title = {{Autopercepci{\'{o}}n de inteligencia contextual para jugar y de competencia decisional en el f{\'{u}}tbol}},
volume = {11},
year = {2015}
}
@article{Ding2019,
abstract = {Deep neural networks (DNNs), as the basis of object detection, will play a key role in the development of future autonomous systems with full autonomy. The autonomous systems have special require- ments of real-time, energy-efficient implementations of DNNs on a power-constrained system. Two research thrusts are dedicated to performance and energy efficiency enhancement of the inference phase ofDNNs. The first one is model compression techniques while the second is efficient hardware implementation. Recent works on extremely-low-bit CNNs such as the binary neural network (BNN) and XNOR-Net replace the traditional floating point operations with binary bit operations which significantly reduces the memory bandwidth and storage requirement. However, it suffers from non- negligible accuracy loss and underutilized digital signal processing (DSP) blocks of FPGAs. To overcome these limitations, this paper proposes REQ-YOLO, a resource aware, systematic weight quantization framework for object detection, considering both algorithm and hardware re- source aspects in object detection. We adopt the block-circulant matrix method and propose a heterogeneous weight quantiza- tion using Alternative Direction Method of Multipliers (ADMM), an effective optimization technique for general, non-convex opti- mization problems. To achieve real-time, highly-efficient imple- mentations on FPGA, we present the detailed hardware imple- mentation of block circulant matrices on CONV layers and de- velop an efficient processing element (PE) structure supporting the heterogeneous weight quantization, CONV dataflow and pipelin- ing techniques, design optimization, and a template-based auto- matic synthesis framework to optimally exploit hardware resource. Experimental results show that our proposed REQ-YOLO frame- work can significantly compress the YOLO model while introduc- ing very small accuracy degradation. The related codes are here: https://github.com/Anonymous788/heterogeneous_ADMM_YOLO. ∗Corresponding author. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. FPGA '19, February 24–26, 2019, Seaside, CA, USA {\textcopyright} 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-6137-8/19/02...$15.00 https://doi.org/10.1145/3289602.3293904 KEYWORDS},
archivePrefix = {arXiv},
arxivId = {1909.13396},
author = {Ding, Caiwen and Wang, Shuo and Liu, Ning and Xu, Kaidi and Wang, Yanzhi and Liang, Yun},
doi = {10.1145/3289602.3293904},
eprint = {1909.13396},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ding et al. - 2019 - REQ-YOLO A resource-aware, efficient quantization framework for object detection on FPGAS.pdf:pdf},
isbn = {9781450361378},
journal = {FPGA 2019 - Proceedings of the 2019 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
keywords = {ADMM,Compression,FPGA,Object detection,YOLO},
pages = {33--42},
title = {{REQ-YOLO: A resource-aware, efficient quantization framework for object detection on FPGAS}},
year = {2019}
}
@article{Srinivas2021,
abstract = {We present BoTNet, a conceptually simple yet powerful backbone architecture that incorporates self-attention for multiple computer vision tasks including image classification, object detection and instance segmentation. By just replacing the spatial convolutions with global self-attention in the final three bottleneck blocks of a ResNet and no other changes, our approach improves upon the baselines significantly on instance segmentation and object detection while also reducing the parameters, with minimal overhead in latency. Through the design of BoTNet, we also point out how ResNet bottleneck blocks with self-attention can be viewed as Transformer blocks. Without any bells and whistles, BoTNet achieves 44.4% Mask AP and 49.7% Box AP on the COCO Instance Segmentation benchmark using the Mask R-CNN framework; surpassing the previous best published single model and single scale results of ResNeSt evaluated on the COCO validation set. Finally, we present a simple adaptation of the BoTNet design for image classification, resulting in models that achieve a strong performance of 84.7% top-1 accuracy on the ImageNet benchmark while being up to 2.33x faster in compute time than the popular EfficientNet models on TPU-v3 hardware. We hope our simple and effective approach will serve as a strong baseline for future research in self-attention models for vision.},
archivePrefix = {arXiv},
arxivId = {2101.11605},
author = {Srinivas, Aravind and Lin, Tsung-Yi and Parmar, Niki and Shlens, Jonathon and Abbeel, Pieter and Vaswani, Ashish},
eprint = {2101.11605},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Srinivas et al. - 2021 - Bottleneck Transformers for Visual Recognition.pdf:pdf},
keywords = {backbone,self-attention,transformer,vision},
mendeley-tags = {backbone,self-attention,transformer,vision},
number = {Figure 1},
title = {{Bottleneck Transformers for Visual Recognition}},
url = {http://arxiv.org/abs/2101.11605},
year = {2021}
}
@article{Federal2005,
author = {Federal, Universidade and Estadual, Rede and Superior, Ensino and Estadual, Rede and Superior, Ensino},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Federal et al. - 2005 - 1 , 2 3.pdf:pdf},
keywords = {method of statisik,parameter of phsycal weather,rainfall},
pages = {1--13},
title = {1 , 2 3},
year = {2005}
}
@article{Zhang2020f,
abstract = {Online depth learning is the problem of consistently adapting a depth estimation model to handle a continuously changing environment. This problem is challenging due to the network easily overfits on the current environment and forgets its past experiences. To address such problem, this paper presents a novel Learning to Prevent Forgetting (LPF) method for online mono-depth adaptation to new target domains in unsupervised manner. Instead of updating the universal parameters, LPF learns adapter modules to efficiently adjust the feature representation and distribution without losing the pre-learned knowledge in online condition. Specifically, to adapt temporal-continuous depth patterns in videos, we introduce a novel meta-learning approach to learn adapter modules by combining online adaptation process into the learning objective. To further avoid overfitting, we propose a novel temporal-consistent regularization to harmonize the gradient descent procedure at each online learning step. Extensive evaluations on real-world datasets demonstrate that the proposed method, with very limited parameters, significantly improves the estimation quality.},
author = {Zhang, Zhenyu and Lathuili{\`{e}}re, St{\'{e}}phane and Ricci, Elisa and Sebe, Nicu and Yan, Yan and Yang, Jian},
doi = {10.1109/CVPR42600.2020.00455},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2020 - Online depth learning against forgetting in monocular videos.pdf:pdf},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
keywords = {continual learning,depth estimation,incremental learning},
mendeley-tags = {continual learning,depth estimation,incremental learning},
pages = {4493--4502},
title = {{Online depth learning against forgetting in monocular videos}},
year = {2020}
}
@article{Caccia2020,
abstract = {Continual learning studies agents that learn from streams of tasks without forgetting previous ones while adapting to new ones. Two recent continual-learning scenarios have opened new avenues of research. In meta-continual learning, the model is pre-trained to minimize catastrophic forgetting of previous tasks. In continual-meta learning, the aim is to train agents for faster remembering of previous tasks through adaptation. In their original formulations, both methods have limitations. We stand on their shoulders to propose a more general scenario, OSAKA, where an agent must quickly solve new (out-of-distribution) tasks, while also requiring fast remembering. We show that current continual learning, meta-learning, meta-continual learning, and continual-meta learning techniques fail in this new scenario. We propose Continual-MAML, an online extension of the popular MAML algorithm as a strong baseline for this scenario. We empirically show that Continual-MAML is better suited to the new scenario than the aforementioned methodologies, as well as standard continual learning and meta-learning approaches.},
archivePrefix = {arXiv},
arxivId = {2003.05856},
author = {Caccia, Massimo and Rodriguez, Pau and Ostapenko, Oleksiy and Normandin, Fabrice and Lin, Min and Caccia, Lucas and Laradji, Issam and Rish, Irina and Lacoste, Alexandre and Vazquez, David and Charlin, Laurent},
eprint = {2003.05856},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Caccia et al. - 2020 - Online Fast Adaptation and Knowledge Accumulation a New Approach to Continual Learning.pdf:pdf},
title = {{Online Fast Adaptation and Knowledge Accumulation: a New Approach to Continual Learning}},
url = {http://arxiv.org/abs/2003.05856 https://github.com/ElementAI/osaka},
year = {2020}
}
@article{Luo2017,
abstract = {We propose an efficient and unified framework, namely ThiNet, to simultaneously accelerate and compress CNN models in both training and inference stages. We focus on the filter level pruning, i.e., the whole filter would be discarded if it is less important. Our method does not change the original network structure, thus it can be perfectly supported by any off-the-shelf deep learning libraries. We formally establish filter pruning as an optimization problem, and reveal that we need to prune filters based on statistics information computed from its next layer, not the current layer, which differentiates ThiNet from existing methods. Experimental results demonstrate the effectiveness of this strategy, which has advanced the state-of-the-art. We also show the performance of ThiNet on ILSVRC-12 benchmark. ThiNet achieves 3.31 x FLOPs reduction and 16.63× compression on VGG-16, with only 0.52% top-5 accuracy drop. Similar experiments with ResNet-50 reveal that even for a compact network, ThiNet can also reduce more than half of the parameters and FLOPs, at the cost of roughly 1% top-5 accuracy drop. Moreover, the original VGG-16 model can be further pruned into a very small model with only 5.05MB model size, preserving AlexNet level accuracy but showing much stronger generalization ability.},
archivePrefix = {arXiv},
arxivId = {1707.06342},
author = {Luo, Jian Hao and Wu, Jianxin and Lin, Weiyao},
doi = {10.1109/ICCV.2017.541},
eprint = {1707.06342},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Luo, Wu, Lin - 2017 - ThiNet A Filter Level Pruning Method for Deep Neural Network Compression.pdf:pdf},
isbn = {9781538610329},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {5068--5076},
title = {{ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression}},
volume = {2017-Octob},
year = {2017}
}
@article{Augustin2020,
abstract = {Deep Learning heavily depends on large labeled datasets which limits further improvements. While unlabeled data is available in large amounts, in particular in image recognition, it does not fulfill the closed world assumption of semi-supervised learning that all unlabeled data are task-related. The goal of this paper is to leverage unlabeled data in an open world setting to further improve prediction performance. For this purpose, we introduce out-distribution aware self-training, which includes a careful sample selection strategy based on the confidence of the classifier. While normal self-training deteriorates prediction performance, our iterative scheme improves using up to 15 times the amount of originally labeled data. Moreover, our classifiers are by design out-distribution aware and can thus distinguish task-related inputs from unrelated ones.},
archivePrefix = {arXiv},
arxivId = {2012.12372},
author = {Augustin, Maximilian and Hein, Matthias},
eprint = {2012.12372},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Augustin, Hein - 2020 - Out-distribution aware Self-training in an Open World Setting.pdf:pdf},
keywords = {open-set recognition,out-of-distribution},
mendeley-tags = {open-set recognition,out-of-distribution},
title = {{Out-distribution aware Self-training in an Open World Setting}},
url = {http://arxiv.org/abs/2012.12372},
year = {2020}
}
@techreport{Nugrahandhita2017,
address = {Surabaya},
author = {Nugrahandhita, Naufal and Ardiansyah, Muhammad and Kurniawan, Rifki and Pendahuluan, I},
doi = {10.13140/RG.2.2.17407.05282},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nugrahandhita et al. - 2017 - Penentuan Tempat Parkir Mobil Terbaik di Institut Teknologi Sepuluh Nopember Surabaya Menggunakan Logika F.pdf:pdf},
institution = {Institut Teknologi Sepuluh Nopember},
pages = {1--6},
title = {{Penentuan Tempat Parkir Mobil Terbaik di Institut Teknologi Sepuluh Nopember Surabaya Menggunakan Logika Fuzzy}},
year = {2017}
}
@article{Bisk2020,
abstract = {Successful linguistic communication relies on a shared experience of the world, and it is this shared experience that makes utterances meaningful. Despite the incredible effectiveness of language processing models trained on text alone, today's best systems still make mistakes that arise from a failure to relate language to the physical world it describes and to the social interactions it facilitates. Natural Language Processing is a diverse field, and progress throughout its development has come from new representational theories, modeling techniques, data collection paradigms, and tasks. We posit that the present success of representation learning approaches trained on large text corpora can be deeply enriched from the parallel tradition of research on the contextual and social nature of language. In this article, we consider work on the contextual foundations of language: grounding, embodiment, and social interaction. We describe a brief history and possible progression of how contextual information can factor into our representations, with an eye towards how this integration can move the field forward and where it is currently being pioneered. We believe this framing will serve as a roadmap for truly contextual language understanding.},
archivePrefix = {arXiv},
arxivId = {2004.10151},
author = {Bisk, Yonatan and Holtzman, Ari and Thomason, Jesse and Andreas, Jacob and Bengio, Yoshua and Chai, Joyce and Lapata, Mirella and Lazaridou, Angeliki and May, Jonathan and Nisnevich, Aleksandr and Pinto, Nicolas and Turian, Joseph},
doi = {10.18653/v1/2020.emnlp-main.703},
eprint = {2004.10151},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bisk et al. - 2020 - Experience grounds language.pdf:pdf},
journal = {arXiv},
title = {{Experience grounds language}},
year = {2020}
}
@article{Sun2017,
abstract = {The success of deep learning in vision can be attributed to: (a) models with high capacity; (b) increased computational power; and (c) availability of large-scale labeled data. Since 2012, there have been significant advances in representation capabilities of the models and computational capabilities of GPUs. But the size of the biggest dataset has surprisingly remained constant. What will happen if we increase the dataset size by 10 × or 100 × ? This paper takes a step towards clearing the clouds of mystery surrounding the relationship between 'enormous data' and visual deep learning. By exploiting the JFT-300M dataset which has more than 375M noisy labels for 300M images, we investigate how the performance of current vision tasks would change if this data was used for representation learning. Our paper delivers some surprising (and some expected) findings. First, we find that the performance on vision tasks increases logarithmically based on volume of training data size. Second, we show that representation learning (or pre-training) still holds a lot of promise. One can improve performance on many vision tasks by just training a better base model. Finally, as expected, we present new state-of-the-art results for different vision tasks including image classification, object detection, semantic segmentation and human pose estimation. Our sincere hope is that this inspires vision community to not undervalue the data and develop collective efforts in building larger datasets.},
archivePrefix = {arXiv},
arxivId = {1707.02968},
author = {Sun, Chen and Shrivastava, Abhinav and Singh, Saurabh and Gupta, Abhinav},
doi = {10.1109/ICCV.2017.97},
eprint = {1707.02968},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sun et al. - 2017 - Revisiting Unreasonable Effectiveness of Data in Deep Learning Era.pdf:pdf},
isbn = {9781538610329},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
keywords = {deep learning,empirical study,neural networks,theory},
mendeley-tags = {deep learning,empirical study,neural networks,theory},
pages = {843--852},
title = {{Revisiting Unreasonable Effectiveness of Data in Deep Learning Era}},
volume = {2017-Octob},
year = {2017}
}
@inproceedings{Kampffmeyer2019,
abstract = {Graph convolutional neural networks have recently shown great potential for the task of zero-shot learning. These models are highly sample efficient as related concepts in the graph structure share statistical strength allowing generalization to new classes when faced with a lack of data. However, multi-layer architectures, which are required to propagate knowledge to distant nodes in the graph, dilute the knowledge by performing extensive Laplacian smoothing at each layer and thereby consequently decrease performance. In order to still enjoy the benefit brought by the graph structure while preventing dilution of knowledge from distant nodes, we propose a Dense Graph Propagation (DGP) module with carefully designed direct links among distant nodes. DGP allows us to exploit the hierarchical graph structure of the knowledge graph through additional connections. These connections are added based on a node's relationship to its ancestors and descendants. A weighting scheme is further used to weigh their contribution depending on the distance to the node to improve information propagation in the graph. Combined with finetuning of the representations in a two-stage training approach our method outperforms state-of-the-art zero-shot learning approaches.},
archivePrefix = {arXiv},
arxivId = {1805.11724},
author = {Kampffmeyer, Michael and Chen, Yinbo and Liang, Xiaodan and Wang, Hao and Zhang, Yujia and Xing, Eric P.},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2019.01175},
eprint = {1805.11724},
isbn = {9781728132938},
issn = {10636919},
keywords = {Categorization,Deep Learning,Recognition: Detection,Retrieval},
title = {{Rethinking knowledge graph propagation for zero-shot learning}},
year = {2019}
}
@article{Shin2021,
abstract = {Meta-learning of shared initialization parameters has shown to be highly effective in solving few-shot learning tasks. However, extending the framework to many-shot scenarios, which may further enhance its practicality, has been relatively overlooked due to the technical difficulties of meta-learning over long chains of inner-gradient steps. In this paper, we first show that allowing the meta-learners to take a larger number of inner gradient steps better captures the structure of heterogeneous and large-scale task distributions, thus results in obtaining better initialization points. Further, in order to increase the frequency of meta-updates even with the excessively long inner-optimization trajectories, we propose to estimate the required shift of the task-specific parameters with respect to the change of the initialization parameters. By doing so, we can arbitrarily increase the frequency of meta-updates and thus greatly improve the meta-level convergence as well as the quality of the learned initializations. We validate our method on a heterogeneous set of large-scale tasks and show that the algorithm largely outperforms the previous first-order meta-learning methods in terms of both generalization performance and convergence, as well as multi-task learning and fine-tuning baselines.},
archivePrefix = {arXiv},
arxivId = {2102.07215},
author = {Shin, Jaewoong and Lee, Hae Beom and Gong, Boqing and Hwang, Sung Ju},
eprint = {2102.07215},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shin et al. - 2021 - Large-Scale Meta-Learning with Continual Trajectory Shifting.pdf:pdf},
keywords = {few-shot learning,large-scale,meta-learning},
mendeley-tags = {few-shot learning,large-scale,meta-learning},
title = {{Large-Scale Meta-Learning with Continual Trajectory Shifting}},
url = {http://arxiv.org/abs/2102.07215},
year = {2021}
}
@article{Zhang2020d,
abstract = {Lifelong or continual learning remains to be a challenge for artificial neural network, as it is required to be both stable for preservation of old knowledge and plastic for acquisition of new knowledge. It is common to see previous experience get overwritten, which leads to the well-known issue of catastrophic forgetting, especially in the scenario of class-incremental learning (Class-IL). Recently, many lifelong learning methods have been proposed to avoid catastrophic forgetting. However, models which learn without replay of the input data, would encounter another problem which has been ignored, and we refer to it as prior information loss (PIL). In training procedure of Class-IL, as the model has no knowledge about following tasks, it would only extract features necessary for tasks learned so far, whose information is insufficient for joint classification. In this paper, our empirical results on several image datasets show that PIL limits the performance of current state-of-the-art method for Class-IL, the orthogonal weights modification (OWM) algorithm. Furthermore, we propose to combine self-supervised learning, which can provide effective representations without requiring labels, with Class-IL to partly get around this problem. Experiments show superiority of proposed method to OWM, as well as other strong baselines.},
archivePrefix = {arXiv},
arxivId = {2006.05882},
author = {Zhang, Song and Shen, Gehui and Deng, Zhi Hong},
eprint = {2006.05882},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Shen, Deng - 2020 - Self-Supervised Learning Aided Class-Incremental Lifelong Learning.pdf:pdf},
journal = {arXiv},
keywords = {continual learning,self-supervised learning},
mendeley-tags = {continual learning,self-supervised learning},
pages = {1--12},
title = {{Self-Supervised Learning Aided Class-Incremental Lifelong Learning}},
year = {2020}
}
@book{Mendel2017,
abstract = {The second edition of this textbook provides a fully updated approach to fuzzy sets and systems that can model uncertainty — i.e., “type-2” fuzzy sets and systems. The author demonstrates how to overcome the limitations of classical fuzzy sets and systems, enabling a wide range of applications from time-series forecasting to knowledge mining to control. In this new edition, a bottom-up approach is presented that begins by introducing classical (type-1) fuzzy sets and systems, and then explains how they can be modified to handle uncertainty. The author covers fuzzy rule-based systems – from type-1 to interval type-2 to general type-2 – in one volume. For hands-on experience, the book provides information on accessing MatLab and Java software to complement the content. The book features a full suite of classroom material.},
author = {Mendel, Jerry M.},
doi = {10.1007/978-3-319-51370-6},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mendel - 2017 - Uncertain Rule-Based Fuzzy Systems.pdf:pdf},
isbn = {978-3-319-51369-0},
title = {{Uncertain Rule-Based Fuzzy Systems}},
url = {http://link.springer.com/10.1007/978-3-319-51370-6},
year = {2017}
}
@article{Ghoroghchian2009,
abstract = {In vivo fluorescence imaging with near-infrared (NIR) light holds enormous potential for a wide variety of molecular diagnostic and therapeutic applications. Because of its quantitative sensitivity, inherent biological safety, and relative ease of use (i.e., with respect to cost, time, mobility, and its familiarity to a diverse population of investigators), fluorescence-based imaging techniques are being increasingly utilized in small-animal research. Moreover, there is substantial interest in the translation of novel optical techniques into the clinic, where they will prospectively aid in noninvasive and quantitative screening, disease diagnosis, and post-treatment monitoring of patients. Effective deep-tissue fluorescence imaging requires the application of exogenous NIR-emissive contrast agents. Currently, available probes fall into two major categories: organic and inorganic NIR fluorophores (NIRFs). In the studies reviewed herein, we utilized polymersomes (50 nm to 50 µm diameter polymer vesicles) for the incorporation and delivery of large numbers of highly emissive oligo (porphyrin)-based, organic NIRFs Copyright {\textcopyright} 2009 John Wiley & Sons, Inc.For further resources related to this article, please visit the .},
author = {Ghoroghchian, P. Peter and Therien, Michael J. and Hammer, Daniel A.},
doi = {10.1002/wnan.7},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghoroghchian, Therien, Hammer - 2009 - In vivo fluorescence imaging A personal perspective.pdf:pdf},
isbn = {1939-0041},
issn = {19395116},
journal = {Wiley Interdisciplinary Reviews: Nanomedicine and Nanobiotechnology},
number = {2},
pages = {156--167},
pmid = {20049787},
title = {{In vivo fluorescence imaging: A personal perspective}},
volume = {1},
year = {2009}
}
@article{Alonso2010,
abstract = {A series of CaO solids have been prepared by means of thermal treatment of the following precursors: carbonate, acetate, oxalate, nitrate, and two hydroxides obtained previously by precipitation of calcium acetate and nitrate in basic medium. These solids show distinct reaction rates in the catalytic transesterification of triglycerides with methanol to obtain biodiesel. An exhaustive characterization study using X-ray diffraction, N2adsorption-desorption isotherms, infrared spectroscopy of pyrrole adsorbed, and temperature-programmed desorption of CO2allowed us to determine the influence of the physicochemical properties (crystallite size, surface area and porosity) and surface basicity (amount and distribution of basic sites with different strength) on the overall catalytic activity. We have found that CaO obtained by decomposition of calcium carbonate, which shows the highest amount and surface density of very strong base sites, catalyzes triglycerides transesterification with higher rates. {\textcopyright} 2010 Elsevier B.V. All rights reserved.},
author = {Alonso, D. Mart{\'{i}}n and Vila, F. and Mariscal, R. and Ojeda, M. and Granados, M. L{\'{o}}pez and Santamar{\'{i}}a-Gonz{\'{a}}lez, J.},
doi = {10.1016/j.cattod.2010.05.003},
isbn = {0920-5861},
issn = {09205861},
journal = {Catalysis Today},
keywords = {Biodiesel,CaO catalysts,Pyrrole,Surface basicity,Transesterification},
number = {1-2},
pages = {114--120},
title = {{Relevance of the physicochemical properties of CaO catalysts for the methanolysis of triglycerides to obtain biodiesel}},
volume = {158},
year = {2010}
}
@article{Wagner2012,
abstract = {Current-generating (exoelectrogenic) bacteria in bioelectrochemical systems (BESs) may not be culturable using standard in vitro agar-plating techniques, making isolation of new microbes a challenge. More in vivo like conditions are needed where bacteria can be grown and directly isolated on an electrode. While colonies can be developed from single cells on an electrode, the cells must be immobilized after being placed on the surface. Here we present a proof-of-concept immobilization approach that allows exoelectrogenic activity of cells on an electrode based on applying a layer of latex to hold bacteria on surfaces. The effectiveness of this procedure to immobilize particles was first demonstrated using fluorescent microspheres as bacterial analogs. The latex coating was then shown to not substantially affect the exoelectrogenic activity of well-developed anode biofilms in two different systems. A single layer of airbrushed coating did not reduce the voltage produced by a biofilm in a microbial fuel cell (MFC), and more easily applied dip-and-blot coating reduced voltage by only 11% in a microbial electrolysis cell (MEC). This latex immobilization procedure will enable future testing of single cells for exoelectrogenic activity on electrodes in BESs.},
author = {Wagner, Rachel C and Porter-Gill, Sikandar and Logan, Bruce E},
doi = {10.1186/2191-0855-2-2},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wagner, Porter-Gill, Logan - 2012 - Immobilization of anode-attached microbes in a microbial fuel cell.pdf:pdf},
isbn = {2191-0855 (Electronic)\r2191-0855 (Linking)},
issn = {2191-0855},
journal = {AMB Express},
keywords = {anode,bioelectrochemical system,immobilization layer,microbial electrolysis cell,microbial fuel cell},
number = {1},
pages = {2},
pmid = {22214379},
title = {{Immobilization of anode-attached microbes in a microbial fuel cell}},
url = {http://amb-express.springeropen.com/articles/10.1186/2191-0855-2-2},
volume = {2},
year = {2012}
}
@article{Frankle2020a,
abstract = {We study whether a neural network optimizes to the same, linearly connected minimum under different samples of SGD noise (e.g., random data order and augmentation). We find that standard vision models become stable to SGD noise in this way early in training. From then on, the outcome of optimization is determined to a linearly connected region. We use this technique to study iterative magnitude pruning (IMP), the procedure used by work on the lottery ticket hypothesis to identify subnetworks that could have trained in isolation to full accuracy. We find that these subnetworks only reach full accuracy when they are stable to SGD noise, which either occurs at initialization for small-scale settings (MNIST) or early in training for large-scale settings (ResNet-50 and Inception-v3 on ImageNet).},
archivePrefix = {arXiv},
arxivId = {1912.05671},
author = {Frankle, Jonathan and Dziugaite, Gintare Karolina and Roy, Daniel M. and Carbin, Michael},
eprint = {1912.05671},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Frankle et al. - 2020 - Linear mode connectivity and the lottery ticket hypothesis.pdf:pdf},
isbn = {9781713821120},
journal = {37th International Conference on Machine Learning, ICML 2020},
keywords = {linear mode connectivity,loss landscape,lottery ticket},
mendeley-tags = {linear mode connectivity,loss landscape,lottery ticket},
pages = {3217--3227},
title = {{Linear mode connectivity and the lottery ticket hypothesis}},
volume = {PartF16814},
year = {2020}
}
@article{Qayyum2015,
abstract = {In this paper, we propose a solution to the problem of scheduling of a smart home appliance operation in a given time range. In addition to power-consuming appliances, we adopt a photovoltaic (PV) panel as a power-producing appliance that acts as a micro-grid. An appliance operation is modeled in terms of uninterruptible sequence phases, given in a load demand profile with a goal of minimizing electricity cost fulfilling duration, energy requirement, and user preference constraints. An optimization algorithm, which can provide a schedule for smart home appliance usage, is proposed based on the mixed-integer programming technique. Simulation results demonstrate the utility of our proposed solution for appliance scheduling. We further show that adding a PV system in the home results in the reduction of electricity bills and the export of energy to the national grid in times when solar energy production is more than the demand of the home.},
author = {Qayyum, F A and Naeem, M and Khwaja, A S and Anpalagan, A and Guan, L and Venkatesh, B},
doi = {10.1109/ACCESS.2015.2496117},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qayyum et al. - 2015 - Appliance Scheduling Optimization in Smart Home Networks.pdf:pdf},
isbn = {9781479976645},
issn = {2169-3536},
journal = {Access, IEEE},
keywords = {domestic appliances,home computing,integer program},
pages = {2176--2190},
title = {{Appliance Scheduling Optimization in Smart Home Networks}},
volume = {3},
year = {2015}
}
@article{Chen2021c,
abstract = {Despite their success in massive engineering applications, deep neural networks are vulnerable to various perturbations due to their black-box nature. Recent study has shown that a deep neural network can misclassify the data even if the input data is perturbed by an imperceptible amount. In this paper, we address the ro- bustness issue of neural networks by a novel close-loop control method from the perspective of dynamic systems. Instead of modifying the parameters in a fixed neural network architecture, a close-loop control process is added to generate con- trol signals adaptively for the perturbed or corrupted data. We connect the robust- ness of neural networks with optimal control using the geometrical information of underlying data to design the control objective. The detailed analysis shows how the embedding manifolds of state trajectory affect error estimation of the proposed method. Our approach can simultaneously maintain the performance on clean data and improve the robustness against many types of data perturbations. It can also further improve the performance of robustly trained neural networks against different perturbations. To the best of our knowledge, this is the first work that improves the robustness of neural networks with close-loop control.},
archivePrefix = {arXiv},
arxivId = {arXiv:2102.01862v1},
author = {Chen, Zhuotong and Li, Qianxiao and Zhang, Zheng},
eprint = {arXiv:2102.01862v1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Li, Zhang - 2021 - Towards Robust Neural Networks Via Close-Loop Control.pdf:pdf},
journal = {Iclr},
keywords = {adversarial learning,close-loop control,robustness},
mendeley-tags = {adversarial learning,close-loop control,robustness},
title = {{Towards Robust Neural Networks Via Close-Loop Control}},
url = {https://github.com/zhuotongchen/Towards-Robust-Neural-Networks-via-Close-loop-Control},
year = {2021}
}
@article{Jones2017,
abstract = {Assimilation of hyperspectral sounder data into numerical weather prediction (NWP) models has proven vital to generating accurate model analyses of tropospheric temperature and humidity where few conventional observations exist. Applications to storm-scale models are limited since the low temporal resolution provided by polar orbiting sensors cannot adequately sample rapidly changing environments associated with high impact weather events. To address this limitation, hyperspectral sounders have been proposed for geostationary orbiting satellites, but these have yet to be built and launched in part due to much higher engineering costs and a lack of a definite requirement for the data. This study uses an Observation System Simulation Experiment (OSSE) approach to simulate temperature and humidity profiles from a hypothetical geostationary-based sounder from a nature run of a high impact weather event on 20 May 2013. The simulated observations are then assimilated using an ensemble adjustment Kalman filter approach, testing both hourly and 15 minute cycling to determine their relative effectiveness at improving the near storm environment. Results indicate that assimilating both temperature and humidity profiles reduced mid-tropospheric both mean and standard deviation of analysis and forecast errors compared to assimilating conventional observations alone. The 15 minute cycling generally produced the lowest errors while also generating the best 2–4 hour updraft helicity forecasts of ongoing convection. This study indicates the potential for significant improvement in short-term forecasting of severe storms from the assimilation of hyperspectral geostationary satellite data. However, more studies are required using improved OSSE designs encompassing multiple storm environments and additional observation types such as radar reflectivity to fully define the effectiveness of assimilating geostationary hyperspectral observations for high impact weather forecasting applications.},
author = {Jones, Thomas A. and Koch, Steven and Li, Zhenglong},
doi = {10.1016/j.atmosres.2016.11.004},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jones, Koch, Li - 2017 - Assimilating synthetic hyperspectral sounder temperature and humidity retrievals to improve severe weather fore.pdf:pdf},
issn = {01698095},
journal = {Atmospheric Research},
keywords = {Ensemble data assimilation,Hyperspectral sounders,OSSE,Storm-scale data assimilation},
pages = {9--25},
publisher = {Elsevier B.V.},
title = {{Assimilating synthetic hyperspectral sounder temperature and humidity retrievals to improve severe weather forecasts}},
url = {http://dx.doi.org/10.1016/j.atmosres.2016.11.004},
volume = {186},
year = {2017}
}
@article{Ferrone2020,
abstract = {Natural language is inherently a discrete symbolic representation of human knowledge. Recent advances in machine learning (ML) and in natural language processing (NLP) seem to contradict the above intuition: discrete symbols are fading away, erased by vectors or tensors called distributed and distributional representations. However, there is a strict link between distributed/distributional representations and discrete symbols, being the first an approximation of the second. A clearer understanding of the strict link between distributed/distributional representations and symbols may certainly lead to radically new deep learning networks. In this paper we make a survey that aims to renew the link between symbolic representations and distributed/distributional representations. This is the right time to revitalize the area of interpreting how discrete symbols are represented inside neural networks.},
archivePrefix = {arXiv},
arxivId = {1702.00764},
author = {Ferrone, Lorenzo and Zanzotto, Fabio Massimo},
doi = {10.3389/frobt.2019.00153},
eprint = {1702.00764},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ferrone, Zanzotto - 2020 - Symbolic, Distributed, and Distributional Representations for Natural Language Processing in the Era of Deep.pdf:pdf},
issn = {22969144},
journal = {Frontiers in Robotics and AI},
keywords = {compositional distributional semantic models,compositionality,concatenative compositionality,deep learning (DL),distributed representation,natural language processing (NLP)},
number = {2018},
pages = {1--28},
title = {{Symbolic, Distributed, and Distributional Representations for Natural Language Processing in the Era of Deep Learning: A Survey}},
volume = {6},
year = {2020}
}
@article{Wang2017a,
abstract = {In this paper, topological characterizations of generalized fuzzy rough sets are investigated in the context of basic rough equalities. Various fuzzy topologies induced by different fuzzy relations are studied with respect to the lower fuzzy rough approximation operator determined by a fuzzy implicator, which is left-continuous in the first argument and right-continuous in the second argument. The relationships among fuzzy topologies induced by fuzzy relations are discussed. The algebraic structures of T-similarity set of fuzzy relations are investigated with respect to different fuzzy implicators, where T is a left-continuous t-norm. Moreover, the T-transitive subset of T-similarity set is proven to be a complete distributive lattice.},
author = {Wang, Chun Yong},
doi = {10.1016/j.fss.2016.02.005},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang - 2017 - Topological characterizations of generalized fuzzy rough sets.pdf:pdf},
issn = {01650114},
journal = {Fuzzy Sets and Systems},
keywords = {Fuzzy implicator,Fuzzy relation,Fuzzy topology,Generalized fuzzy rough set},
pages = {109--125},
publisher = {Elsevier B.V.},
title = {{Topological characterizations of generalized fuzzy rough sets}},
url = {http://dx.doi.org/10.1016/j.fss.2016.02.005},
volume = {312},
year = {2017}
}
@article{Kim2021a,
abstract = {This paper introduces SelfMatch, a semi-supervised learning method that combines the power of contrastive self-supervised learning and consistency regularization. SelfMatch consists of two stages: (1) self-supervised pre-training based on contrastive learning and (2) semi-supervised fine-tuning based on augmentation consistency regularization. We empirically demonstrate that SelfMatch achieves the state-of-the-art results on standard benchmark datasets such as CIFAR-10 and SVHN. For example, for CIFAR-10 with 40 labeled examples, SelfMatch achieves 93.19% accuracy that outperforms the strong previous methods such as MixMatch (52.46%), UDA (70.95%), ReMixMatch (80.9%), and FixMatch (86.19%). We note that SelfMatch can close the gap between supervised learning (95.87%) and semi-supervised learning (93.19%) by using only a few labels for each class.},
archivePrefix = {arXiv},
arxivId = {2101.06480},
author = {Kim, Byoungjip and Choo, Jinho and Kwon, Yeong-Dae and Joe, Seongho and Min, Seungjai and Gwon, Youngjune},
eprint = {2101.06480},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim et al. - 2021 - SelfMatch Combining Contrastive Self-Supervision and Consistency for Semi-Supervised Learning.pdf:pdf},
keywords = {contrastive learning,self-supervised learning,semi-supervised learning},
mendeley-tags = {contrastive learning,self-supervised learning,semi-supervised learning},
number = {NeurIPS},
title = {{SelfMatch: Combining Contrastive Self-Supervision and Consistency for Semi-Supervised Learning}},
url = {http://arxiv.org/abs/2101.06480},
year = {2021}
}
@article{BenMabrouk2018,
abstract = {With the increasing number of surveillance cameras in both indoor and outdoor locations, there is a grown demand for an intelligent system that detects abnormal events. Although human action recognition is a highly reached topic in computer vision, abnormal behavior detection is lately attracting more research attention. Indeed, several systems are proposed in order to ensure human safety. In this paper, we are interested in the study of the two main steps composing a video surveillance system which are the behavior representation and the behavior modeling. Techniques related to feature extraction and description for behavior representation are reviewed. Classification methods and frameworks for behavior modeling are also provided. Moreover, available datasets and metrics for performance evaluation are presented. Finally, examples of existing video surveillance systems used in real world are described.},
author = {{Ben Mabrouk}, Amira and Zagrouba, Ezzeddine},
doi = {10.1016/j.eswa.2017.09.029},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ben Mabrouk, Zagrouba - 2018 - Abnormal behavior recognition for intelligent video surveillance systems A review.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Behavior modeling,Behavior representation,Computer vision,Video surveillance system},
pages = {480--491},
publisher = {Elsevier Ltd},
title = {{Abnormal behavior recognition for intelligent video surveillance systems: A review}},
url = {http://dx.doi.org/10.1016/j.eswa.2017.09.029},
volume = {91},
year = {2018}
}
@article{Mardle2000,
author = {Mardle, Simon and Pascoe, Sean and Tamiz, Mehrdad},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mardle, Pascoe, Tamiz - 2000 - An investigation of genetic algorithms for the optimisation of multi-objective fisheries bioeconomic mode.pdf:pdf},
journal = {International Transactions of Operations Research},
number = {1},
pages = {33--49},
title = {{An investigation of genetic algorithms for the optimisation of multi-objective fisheries bioeconomic models}},
volume = {7},
year = {2000}
}
@article{Ebrahimi2020,
abstract = {The goal of continual learning (CL) is to learn a sequence of tasks without suffering from the phenomenon of catastrophic forgetting. Previous work has shown that leveraging memory in the form of a replay buffer can reduce performance degradation on prior tasks. We hypothesize that forgetting can be further reduced when the model is encouraged to remember the \textit{evidence} for previously made decisions. As a first step towards exploring this hypothesis, we propose a simple novel training paradigm, called Remembering for the Right Reasons (RRR), that additionally stores visual model explanations for each example in the buffer and ensures the model has "the right reasons" for its predictions by encouraging its explanations to remain consistent with those used to make decisions at training time. Without this constraint, there is a drift in explanations and increase in forgetting as conventional continual learning algorithms learn new tasks. We demonstrate how RRR can be easily added to any memory or regularization-based approach and results in reduced forgetting, and more importantly, improved model explanations. We have evaluated our approach in the standard and few-shot settings and observed a consistent improvement across various CL approaches using different architectures and techniques to generate model explanations and demonstrated our approach showing a promising connection between explainability and continual learning. Our code is available at https://github.com/SaynaEbrahimi/Remembering-for-the-Right-Reasons.},
archivePrefix = {arXiv},
arxivId = {2010.01528},
author = {Ebrahimi, Sayna and Petryk, Suzanne and Gokul, Akash and Gan, William and Gonzalez, Joseph E. and Rohrbach, Marcus and Darrell, Trevor},
eprint = {2010.01528},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ebrahimi et al. - 2020 - Remembering for the Right Reasons Explanations Reduce Catastrophic Forgetting.pdf:pdf},
pages = {1--12},
title = {{Remembering for the Right Reasons: Explanations Reduce Catastrophic Forgetting}},
url = {http://arxiv.org/abs/2010.01528},
year = {2020}
}
@article{Luo2021,
abstract = {Conventional semi-supervised learning (SSL) methods, e.g., MixMatch, achieve great performance when both labeled and unlabeled dataset are drawn from the same distribution. However, these methods often suffer severe performance degradation in a more realistic setting, where unlabeled dataset contains out-of-distribution (OOD) samples. Recent approaches mitigate the negative influence of OOD samples by filtering them out from the unlabeled data. Our studies show that it is not necessary to get rid of OOD samples during training. On the contrary, the network can benefit from them if OOD samples are properly utilized. We thoroughly study how OOD samples affect DNN training in both low- and high-dimensional spaces, where two fundamental SSL methods are considered: Pseudo Labeling (PL) and Data Augmentation based Consistency Training (DACT). Conclusion is twofold: (1) unlike PL that suffers performance degradation, DACT brings improvement to model performance; (2) the improvement is closely related to class-wise distribution gap between the labeled and the unlabeled dataset. Motivated by this observation, we further improve the model performance by bridging the gap between the labeled and the unlabeled datasets (containing OOD samples). Compared to previous algorithms paying much attention to distinguishing between ID and OOD samples, our method makes better use of OOD samples and achieves state-of-the-art results.},
archivePrefix = {arXiv},
arxivId = {2101.08237},
author = {Luo, Huixiang and Cheng, Hao and Gao, Yuting and Li, Ke and Zhang, Mengdan and Meng, Fanxu and Guo, Xiaowei and Huang, Feiyue and Sun, Xing},
eprint = {2101.08237},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Luo et al. - 2021 - On The Consistency Training for Open-Set Semi-Supervised Learning.pdf:pdf},
keywords = {open-set recognition,semi-supervised learning},
mendeley-tags = {open-set recognition,semi-supervised learning},
title = {{On The Consistency Training for Open-Set Semi-Supervised Learning}},
url = {http://arxiv.org/abs/2101.08237},
year = {2021}
}
@inproceedings{Chen2021a,
abstract = {The capability of incrementally learning new tasks without forgetting old ones is a challenging problem due to catastrophic forgetting. This challenge becomes greater when novel tasks contain very few labelled training samples. Currently, most methods are dedicated to class-incremental learning and rely on sufficient training data to learn additional weights for newly added classes. Those methods cannot be easily extended to incremental regression tasks and could suffer from severe overfitting when learning few-shot novel tasks. In this study, we propose a nonparametric method in deep embedded space to tackle incremental few-shot learning problems. The knowledge about the learned tasks is compressed into a small number of quantized reference vectors. The proposed method learns new tasks sequentially by adding more reference vectors to the model using few-shot samples in each novel task. For classification problems, we employ the nearest neighbor scheme to make classification on sparsely available data and incorporate intra-class variation, less forgetting regularization and calibration of reference vectors to mitigate catastrophic forgetting. In addition, the proposed learning vector quantization (LVQ) in deep embedded space can be customized as a kernel smoother to handle incremental few-shot regression tasks. Experimental results demonstrate that the proposed method outperforms other state-of-the-art methods in incremental learning.},
author = {Chen, Kuilin and Lee, Chi-guhn},
booktitle = {Iclr 2021},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Lee - 2021 - Incremental few-shot learning via vector quantization in deep embedded space.pdf:pdf},
keywords = {continual learning,few-shot learning,incremental learning},
mendeley-tags = {continual learning,few-shot learning,incremental learning},
pages = {1--16},
title = {{Incremental few-shot learning via vector quantization in deep embedded space}},
year = {2021}
}
@article{Jain2010,
author = {Jain, Amit and Jain, M Babita and Srinivas, E},
isbn = {9781424459391},
pages = {1--7},
title = {{A Novel Hybrid Method for Short Term Load Forecasting using Fuzzy Logic and Particle Swarm Optimization}},
year = {2010}
}
@article{Brust2019,
abstract = {The great success that deep models have achieved in the past is mainly owed to large amounts of labeled training data. However, the acquisition of labeled data for new tasks aside from existing benchmarks is both challenging and costly. Active learning can make the process of labeling new data more efficient by selecting unlabeled samples which, when labeled, are expected to improve the model the most. In this paper, we combine a novel method of active learning for object detection with an incremental learning scheme (K{\"{a}}ding et al., 2016b) to enable continuous exploration of new unlabeled datasets. We propose a set of uncertainty-based active learning metrics suitable for most object detectors. Furthermore, we present an approach to leverage class imbalances during sample selection. All methods are evaluated systematically in a continuous exploration context on the PASCAL VOC 2012 dataset (Everingham et al., 2010).},
archivePrefix = {arXiv},
arxivId = {1809.09875},
author = {Brust, Clemens Alexander and K{\"{a}}ding, Christoph and Denzler, Joachim},
doi = {10.5220/0007248601810190},
eprint = {1809.09875},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brust, K{\"{a}}ding, Denzler - 2019 - Active learning for deep object detection.pdf:pdf},
isbn = {9789897583544},
journal = {VISIGRAPP 2019 - Proceedings of the 14th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
keywords = {Active Learning,Continuous Learning,Deep Learning,Incremental Learning,Object Detection,YOLO,active learning,object detection},
mendeley-tags = {active learning,object detection},
pages = {181--190},
title = {{Active learning for deep object detection}},
volume = {5},
year = {2019}
}
@article{Brunet2017,
abstract = {The distance transform (DT) (also known as distance map or distance field) is a fundamental tool of mathematical morphology. We introduce a generalized DT (GDT) that is smoother than the classical DT. This transform can be used to define a generalized Hausdorff metric that is shown to be more robust to noise while preserving all metric properties. It is also shown to lead to smoother level sets, allowing contour evolution without having to solve a partial differential equation. Two applications in weather analysis and forecasting demonstrate the usefulness of this proposed GDT. In particular, the dilation of sets according to the GDT allows the simplification of numerical weather forecasts and analysis into geometric objects, called MetObjects, and the generalized Hausdorff distance can be used as a forecast verification metric.},
author = {Brunet, Dominique and Sills, David},
doi = {10.1109/TGRS.2016.2632042},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brunet, Sills - 2017 - A Generalized Distance Transform Theory and Applications to Weather Analysis and Forecasting.pdf:pdf},
issn = {01962892},
journal = {IEEE Transactions on Geoscience and Remote Sensing},
keywords = {Distance transform (DT),Hausdorff distance,MetObject,level-set methods (LSMs),meteorological applications,object-based distance,shape processing},
number = {3},
pages = {1752--1764},
title = {{A Generalized Distance Transform: Theory and Applications to Weather Analysis and Forecasting}},
volume = {55},
year = {2017}
}
@article{Yang2013,
abstract = {Stackelberg games have garnered significant attention in recent years given their deployment for real world security. Most of these systems, such as ARMOR, IRIS and GUARDS have adopted the standard game-theoretical assumption that adversaries are perfectly rational, which is standard in the game theory literature. This assumption may not hold in real-world security problems due to the bounded rationality of human adversaries, which could potentially reduce the effectiveness of these systems. In this paper, we focus on relaxing the unrealistic assumption of perfectly rational adversary in Stackelberg security games. In particular, we present new mathematical models of human adversaries' behavior, based on using two fundamental theory/method in human decision making: Prospect Theory (PT) and stochastic discrete choice model. We also provide methods for tuning the parameters of these new models. Additionally, we propose a modification of the standard quantal response based model inspired by rank-dependent expected utility theory. We then develop efficient algorithms to compute the best response of the security forces when playing against the different models of adversaries. In order to evaluate the effectiveness of the new models, we conduct comprehensive experiments with human subjects using a web-based game, comparing them with models previously proposed in the literature to address the perfect rationality assumption on part of the adversary. Our experimental results show that the subjects' responses follow the assumptions of our new models more closely than the previous perfect rationality assumption. We also show that the defender strategy produced by our new stochastic discrete choice model outperform the previous leading contender for relaxing the assumption of perfect rationality. Furthermore, in a separate set of experiments, we show the benefits of our modified stochastic model (QRRU) over the standard model (QR).1{\textcopyright} 2012 Elsevier B.V. All rights reserved.},
author = {Yang, Rong and Kiekintveld, Christopher and Ord{\'{o}}{\~{n}}ez, Fernando and Tambe, Milind and John, Richard},
doi = {10.1016/j.artint.2012.11.004},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2013 - Improving resource allocation strategies against human adversaries in security games An extended study.pdf:pdf},
isbn = {9781577355120},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {Bounded rationality,Decision-making,Stackelberg games},
pages = {440--469},
publisher = {Elsevier B.V.},
title = {{Improving resource allocation strategies against human adversaries in security games: An extended study}},
url = {http://dx.doi.org/10.1016/j.artint.2012.11.004},
volume = {195},
year = {2013}
}
@article{Li2021c,
archivePrefix = {arXiv},
arxivId = {2111.01353v2},
author = {Li, Shanda and He, Di and Chen, Xiangning and Hsieh, Cho-Jui},
eprint = {2111.01353v2},
file = {:home/user/Downloads/2111.01353.pdf:pdf},
keywords = {theory,transformer},
mendeley-tags = {theory,transformer},
number = {2020},
title = {{Can Vision Transformers Perform Convolution?}},
year = {2021}
}
@article{Khemthong2012,
abstract = {Active biodiesel production catalysts were derived from waste eggshells by simple calcination in air. The physicochemical properties of the activated catalysts were characterized by XRD, N2sorption, CO2-TPD, TGA-DTG, XRF, and SEM, while the catalytic activity was tested in producing biodiesel via transesterification on palm oil with methanol under microwave conditions. The effect of microwave power, reaction time, methanol-to-oil ratio, and catalyst loading was investigated. The experimental results revealed that the catalysts exhibited a high content of CaO (99.2 wt%) with a high density of strong base sites. The catalytic testing demonstrated a remarkable enhancement for biodiesel production using microwaves compared to conventional heating. The maximum yield of fatty acid methyl esters reached 96.7% under the optimal condition of reaction time of 4 min with 900 W microwave power, methanol-to-oil ratio of 18:1, and catalyst loading of 15%. The results indicated that the CaO catalysts derived from eggshells showed good reusability and had high potential to be used as biodiesel production catalysts under microwave-assisted transesterification of palm oil. {\textcopyright} 2011 Elsevier B.V. All rights reserved.},
author = {Khemthong, P. and Luadthong, C. and Nualpaeng, W. and Changsuwan, P. and Tongprem, P. and Viriya-Empikul, N. and Faungnawakij, K.},
doi = {10.1016/j.cattod.2011.12.024},
isbn = {0920-5861},
issn = {09205861},
journal = {Catalysis Today},
keywords = {Biodiesel production,CaO,Eggshell,Fatty acid methyl esters,Microwave irradiation,Palm olein oil},
number = {1},
pages = {112--116},
publisher = {Elsevier B.V.},
title = {{Industrial eggshell wastes as the heterogeneous catalysts for microwave-assisted biodiesel production}},
url = {http://dx.doi.org/10.1016/j.cattod.2011.12.024},
volume = {190},
year = {2012}
}
@article{Ali2018,
abstract = {Long-term load forecasting provides vital information about future load and it helps the power industries to make decision regarding electrical energy generation and delivery. In this work, fuzzy – neuro model is developed to forecast a year ahead load in relation to weather parameter (temperature and humidity) in Mubi, Adamawa State. It is observed that: electrical load increased with increase in temperature and relative humidity does not show notable effect on electrical load. The accuracy of the prediction is obtained at 98.78% with the corresponding mean absolute percentage error (MAPE) of 1.22%. This confirms that fuzzy – neuro is a good tool for load forecasting.},
author = {Ali, Danladi and Yohanna, Michael and Ijasini, Puwu Markus and Garkida, Musa Bulus},
doi = {10.1016/j.aej.2016.12.008},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ali et al. - 2018 - Application of fuzzy – Neuro to model weather parameter variability impacts on electrical load based on long-term.pdf:pdf},
issn = {11100168},
journal = {Alexandria Engineering Journal},
keywords = {Back propagation,Electrical load,Fuzzy logic,Load forecasting,Neuro-fuzzy,Weather parameter},
number = {1},
pages = {121--130},
publisher = {Faculty of Engineering, Alexandria University},
title = {{Application of fuzzy – Neuro to model weather parameter variability impacts on electrical load based on long-term forecasting}},
url = {https://doi.org/10.1016/j.aej.2016.12.008},
volume = {57},
year = {2018}
}
@article{Gouda2012,
abstract = {Power transformers represent the largest portion of capital investment in transmission and distribution substations. One of the most important parameters governing a transformer's life expectancy is the hot spot temperature value. The aim of this paper is to introduce hot-spot and top-oil temperature model as top oil and hot spot temperature rise over ambient temperature model and thermal model under liner and non-linear loads. For more accurate temperature calculations, in this paper thermal dynamic model by MATLAB is used to calculate the power transformer temperature. The hot spot, top oil and loss life of power transformer under harmonics load are calculated. The measured temperatures of 25 MVA, 66/11 kV, ONAF cooling temperatures are compared with the suggested dynamic model. {\textcopyright} 2011 Ain Shams University. Production and hosting by Elsevier B.V. All rights reserved.},
author = {Gouda, O. E. and Amer, G. M. and Salem, W. A A},
doi = {10.1016/j.asej.2012.01.003},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gouda, Amer, Salem - 2012 - Predicting transformer temperature rise and loss of life in the presence of harmonic load currents.pdf:pdf},
isbn = {1223416259},
issn = {20904479},
journal = {Ain Shams Engineering Journal},
keywords = {Hot spot temperature,Power transformer,Thermal model,Top oil},
number = {2},
pages = {113--121},
publisher = {Faculty of Engineering, Ain Shams University},
title = {{Predicting transformer temperature rise and loss of life in the presence of harmonic load currents}},
url = {http://dx.doi.org/10.1016/j.asej.2012.01.003},
volume = {3},
year = {2012}
}
@techreport{Kurniawan2017,
address = {Surabaya},
author = {Kurniawan, Muhammad Rifki and Kusumawardhani, Apriani},
doi = {10.13140/RG.2.2.22236.90246},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kurniawan, Kusumawardhani - 2017 - Analysis and Comparison of Image Restoration Algorithms Using MATLAB.pdf:pdf},
institution = {Institut Teknologi Sepuluh Nopember},
keywords = {filter,image restoration,lucy-richardson filter,regularization,wiener filter},
number = {2},
pages = {1--8},
title = {{Analysis and Comparison of Image Restoration Algorithms Using MATLAB}},
year = {2017}
}
@inproceedings{Quincy2021,
author = {Quincy, Jared and Albert, Davis and Krzysztof, Gu and Tri, Choromanski and Christopher, Dao and Chelsea, Re and Liang, Percy},
booktitle = {Proceedings of the 38th International Conference on Machine Learning},
editor = {{Meila, Marina and Zhang}, Tong},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Quincy et al. - 2021 - Catformer Designing Stable Transformers via Sensitivity Analysis.pdf:pdf},
keywords = {module,transformer},
mendeley-tags = {module,transformer},
pages = {2489----2499},
publisher = {PMLR},
title = {{Catformer : Designing Stable Transformers via Sensitivity Analysis}},
year = {2021}
}
@article{Vijayakumar2016,
abstract = {Neural sequence models are widely used to model time-series data. Equally ubiquitous is the usage of beam search (BS) as an approximate inference algorithm to decode output sequences from these models. BS explores the search space in a greedy left-right fashion retaining only the top-B candidates - resulting in sequences that differ only slightly from each other. Producing lists of nearly identical sequences is not only computationally wasteful but also typically fails to capture the inherent ambiguity of complex AI tasks. To overcome this problem, we propose Diverse Beam Search (DBS), an alternative to BS that decodes a list of diverse outputs by optimizing for a diversity-augmented objective. We observe that our method finds better top-1 solutions by controlling for the exploration and exploitation of the search space - implying that DBS is a better search algorithm. Moreover, these gains are achieved with minimal computational or memory over- head as compared to beam search. To demonstrate the broad applicability of our method, we present results on image captioning, machine translation and visual question generation using both standard quantitative metrics and qualitative human studies. Further, we study the role of diversity for image-grounded language generation tasks as the complexity of the image changes. We observe that our method consistently outperforms BS and previously proposed techniques for diverse decoding from neural sequence models.},
archivePrefix = {arXiv},
arxivId = {1610.02424},
author = {Vijayakumar, Ashwin K and Cogswell, Michael and Selvaraju, Ramprasath R. and Sun, Qing and Lee, Stefan and Crandall, David and Batra, Dhruv},
eprint = {1610.02424},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vijayakumar et al. - 2016 - Diverse Beam Search Decoding Diverse Solutions from Neural Sequence Models.pdf:pdf},
keywords = {time series},
mendeley-tags = {time series},
pages = {1--16},
title = {{Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models}},
url = {http://arxiv.org/abs/1610.02424 https://github.com/pytorch/fairseq https://github.com/ashwinkalyan/dbs},
year = {2016}
}
@article{Mirzadeh2020c,
abstract = {In recent years, neural networks have demonstrated an outstanding ability to achieve complex learning tasks across various domains. However, they suffer from the "catastrophic forgetting" problem when they face a sequence of learning tasks, where they forget the old ones as they learn new tasks. This problem is also highly related to the "stability-plasticity dilemma". The more plastic the network, the easier it can learn new tasks, but the faster it also forgets previous ones. Conversely, a stable network cannot learn new tasks as fast as a very plastic network. However, it is more reliable to preserve the knowledge it has learned from the previous tasks. Several solutions have been proposed to overcome the forgetting problem by making the neural network parameters more stable, and some of them have mentioned the significance of dropout in continual learning. However, their relationship has not been sufficiently studied yet. In this paper, we investigate this relationship and show that a stable network with dropout learns a gating mechanism such that for different tasks, different paths of the network are active. Our experiments show that the stability achieved by this implicit gating plays a very critical role in leading to performance comparable to or better than other involved continual learning algorithms to overcome catastrophic forgetting.1},
archivePrefix = {arXiv},
arxivId = {2004.11545},
author = {Mirzadeh, Seyed Iman and Farajtabar, Mehrdad and Ghasemzadeh, Hassan},
doi = {10.1109/CVPRW50498.2020.00124},
eprint = {2004.11545},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mirzadeh, Farajtabar, Ghasemzadeh - 2020 - Dropout as an implicit gating mechanism for continual learning(2).pdf:pdf},
issn = {21607516},
journal = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
keywords = {continual learning,dropout,gating,regularization},
mendeley-tags = {continual learning,dropout,gating,regularization},
pages = {945--951},
title = {{Dropout as an implicit gating mechanism for continual learning}},
volume = {2020-June},
year = {2020}
}
@article{Bartunov2019,
abstract = {We study the problem of learning associative memory -- a system which is able to retrieve a remembered pattern based on its distorted or incomplete version. Attractor networks provide a sound model of associative memory: patterns are stored as attractors of the network dynamics and associative retrieval is performed by running the dynamics starting from a query pattern until it converges to an attractor. In such models the dynamics are often implemented as an optimization procedure that minimizes an energy function, such as in the classical Hopfield network. In general it is difficult to derive a writing rule for a given dynamics and energy that is both compressive and fast. Thus, most research in energy-based memory has been limited either to tractable energy models not expressive enough to handle complex high-dimensional objects such as natural images, or to models that do not offer fast writing. We present a novel meta-learning approach to energy-based memory models (EBMM) that allows one to use an arbitrary neural architecture as an energy model and quickly store patterns in its weights. We demonstrate experimentally that our EBMM approach can build compressed memories for synthetic and natural data, and is capable of associative retrieval that outperforms existing memory systems in terms of the reconstruction error and compression rate.},
archivePrefix = {arXiv},
arxivId = {1910.02720},
author = {Bartunov, Sergey and Rae, Jack W and Osindero, Simon and Lillicrap, Timothy P},
eprint = {1910.02720},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bartunov et al. - 2019 - Meta-Learning Deep Energy-Based Memory Models.pdf:pdf},
pages = {1--18},
title = {{Meta-Learning Deep Energy-Based Memory Models}},
url = {http://arxiv.org/abs/1910.02720},
year = {2019}
}
@article{Yang2019e,
abstract = {The capability of making interpretable and self-explanatory decisions is essential for developing responsible machine learning systems. In this work, we study the learning to explain problem in the scope of inductive logic programming (ILP). We propose Neural Logic Inductive Learning (NLIL), an efficient differentiable ILP framework that learns first-order logic rules that can explain the patterns in the data. In experiments, compared with the state-of-the-art methods, we find NLIL can search for rules that are x10 times longer while remaining x3 times faster. We also show that NLIL can scale to large image datasets, i.e. Visual Genome, with 1M entities.},
archivePrefix = {arXiv},
arxivId = {1910.02481},
author = {Yang, Yuan and Song, Le},
eprint = {1910.02481},
pages = {1--12},
title = {{Learn to Explain Efficiently via Neural Logic Inductive Learning}},
url = {http://arxiv.org/abs/1910.02481},
year = {2019}
}
@book{Allen,
author = {Allen, Jonathan},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Allen - Unknown - Binary Decision Diagrams and Applications for Vlsi Cad the Kluwer International Series in Engineering and Computer Sci.pdf:pdf},
isbn = {9781461285588},
title = {{Binary Decision Diagrams and Applications for Vlsi Cad the Kluwer International Series in Engineering and Computer Science Vlsi , Computer Architecture and}}
}
@article{Schwarz2018,
abstract = {We introduce a conceptually simple and scalable framework for continual learning domains where tasks are learned sequentially. Our method is constant in the number of parameters and is designed to preserve performance on previously encountered tasks while accelerating learning progress on subsequent problems. This is achieved by training a network with two components: A knowledge base, capable of solving previously encountered problems, which is connected to an active column that is employed to efficiently learn the current task. After learning a new task, the active column is distilled into the knowledge base, taking care to protect any previously acquired skills. This cycle of active learning (progression) followed by consolidation (compression) requires no architecture growth, no access to or storing of previous data or tasks, and no task-specific parameters. We demonstrate the progress & compress approach on sequential classification of handwritten alphabets as well as two reinforcement learning domains: Atari games and 3D maze navigation.},
archivePrefix = {arXiv},
arxivId = {1805.06370},
author = {Schwarz, Jonathan and Luketina, Jelena and Czarnecki, Wojciech M. and Grabska-Barwinska, Agnieszka and Teh, Yee Whye and Pascanu, Razvan and Hadsell, Raia},
eprint = {1805.06370},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schwarz et al. - 2018 - Progress & compress A scalable framework for continual learning.pdf:pdf},
isbn = {9781510867963},
journal = {35th International Conference on Machine Learning, ICML 2018},
pages = {7199--7208},
title = {{Progress & compress: A scalable framework for continual learning}},
volume = {10},
year = {2018}
}
@article{Ma2017a,
abstract = {Conceptual design plays an important role in development of new products and redesign of existing products. Morphological matrix is a popular tool for conceptual design. Although the morphological-matrix based conceptual design approaches are effective for generation of conceptual schemes, quantitative evaluation to each of the function solution principle is seldom considered, thus leading to the difficulty to identify the optimal conceptual design by combining these function solution principles. In addition, the uncertainties due to the subjective evaluations from engineers and customers in early design stage are not considered in these morphological-matrix based conceptual design approaches. To solve these problems, a systematic decision making approach is developed in this research for product conceptual design based on fuzzy morphological matrix to quantitatively evaluate function solution principles using knowledge and preferences of engineers and customers with subjective uncertainties. In this research, the morphological matrix is quantified by associating the properties of function solution principles with the information of customer preferences and product failures. Customer preferences for different function solution principles are obtained from multiple customers using fuzzy pairwise comparison (FPC). The fuzzy customer preference degree of each solution principle is then calculated by fuzzy logarithmic least square method (FLLSM). In addition, the product failure data are used to improve product reliability through fuzzy failure mode effects analysis (FMEA). Unlike the traditional FMEA, the causality relationships among failure modes of solution principles are analyzed to use failure information more effectively through constructing a directed failure causality relationship diagram (DFCRD). A fuzzy multi-objective optimization model is also developed to solve the conceptual design problem. The effectiveness of this new approach is demonstrated using a real-world application for conceptual design of a horizontal directional drilling machine (HDDM).},
author = {Ma, Hongzhan and Chu, Xuening and Xue, Deyi and Chen, Dongping},
doi = {10.1016/j.eswa.2017.03.074},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ma et al. - 2017 - A systematic decision making approach for product conceptual design based on fuzzy morphological matrix.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Conceptual design,Customer preference,Directed failure causality relationship diagram,Fuzzy multi-objective optimization,Fuzzy pairwise comparison,Morphological matrix},
pages = {444--456},
publisher = {Elsevier Ltd},
title = {{A systematic decision making approach for product conceptual design based on fuzzy morphological matrix}},
url = {http://dx.doi.org/10.1016/j.eswa.2017.03.074},
volume = {81},
year = {2017}
}
@article{Javid2021,
abstract = {We study the problem of learning without forgetting (LwF) in which a deep learning model learns new tasks without a significant drop in the classification performance on the previously learned tasks. We propose an LwF algorithm for multilayer feedforward neural networks in which we can adapt the number of layers of the network from the old task to the new task. To this end, we limit ourselves to convex loss functions in order to train the network in a layer-wise manner. Layer-wise convex optimization leads to low-computational complexity and provides a more interpretable understanding of the network. We compare the effectiveness of the proposed adaptive LwF algorithm with the standard LwF over image classification datasets.},
author = {Javid, Alireza M. and Liang, Xinyue and Skoglund, Mikael and Chatterjee, Saikat},
doi = {10.23919/Eusipco47968.2020.9287632},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Javid et al. - 2021 - Adaptive learning without forgetting via low-complexity convex networks.pdf:pdf},
isbn = {9789082797053},
issn = {22195491},
journal = {European Signal Processing Conference},
keywords = {Convex neural networks,Learning without forgetting,Low complexity,Size adaptive,continual learning},
mendeley-tags = {continual learning},
pages = {1623--1627},
title = {{Adaptive learning without forgetting via low-complexity convex networks}},
volume = {2021-Janua},
year = {2021}
}
@article{Wang2017,
abstract = {In conventional PID scheme, the ensemble control performance may be unsatisfactory due to limited degrees of freedom under various kinds of uncertainty. To overcome this disadvantage, a novel PID control method that inherits the advantages of fuzzy PID control and the predictive functional control (PFC) is presented and further verified on the temperature model of a coke furnace. Based on the framework of PFC, the prediction of the future process behavior is first obtained using the current process input signal. Then, the fuzzy PID control based on the multi-step prediction is introduced to acquire the optimal control law. Finally, the case study on a temperature model of a coke furnace shows the effectiveness of the fuzzy PID control scheme when compared with conventional PID control and fuzzy self-adaptive PID control.},
author = {Wang, Yuzhong and Jin, Qibing and Zhang, Ridong},
doi = {10.1016/j.isatra.2017.09.005},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Jin, Zhang - 2017 - Improved fuzzy PID controller design using predictive functional control structure.pdf:pdf},
issn = {00190578},
journal = {ISA Transactions},
keywords = {Fuzzy control,PID control,Predictive functional control,Temperature regulation},
pages = {354--363},
publisher = {Elsevier Ltd},
title = {{Improved fuzzy PID controller design using predictive functional control structure}},
url = {http://dx.doi.org/10.1016/j.isatra.2017.09.005},
volume = {71},
year = {2017}
}
@article{Qiu2017,
abstract = {Social media are massive marketplaces in which memes compete for our attention. We investigate the conditions in which the best ideas prevail in a stylized model of online social network, where agents have behavioral limitations in managing a heavy flow of information. We measure the relationship between the quality of an idea and its likelihood to become prevalent at the system level. We find that both information overload and limited attention contribute to a degradation in the market's discriminative power. A good tradeoff between discriminative power and diversity of information is possible according to the model. However, calibration with empirical data characterizing information load and finite attention in real social media reveals a weak correlation between quality and popularity of information. In these realistic conditions, the model predicts that low-quality information is just as likely to go viral, providing an interpretation for the high volume of misinformation we observe online.},
archivePrefix = {arXiv},
arxivId = {1701.02694},
author = {Qiu, Xiaoyan and Oliveira, Diego F.M. and {Sahami Shirazi}, Alireza and Flammini, Alessandro and Menczer, Filippo},
doi = {10.1038/s41562-017-0132},
eprint = {1701.02694},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qiu et al. - 2017 - Limited individual attention and online virality of low-quality information.pdf:pdf},
issn = {23973374},
journal = {Nature Human Behaviour},
number = {7},
pages = {1--7},
title = {{Limited individual attention and online virality of low-quality information}},
volume = {1},
year = {2017}
}
@article{Du2019,
abstract = {Gradient descent finds a global minimum in training deep neural networks despite the objective function being non-convex. The current paper proves gradient descent achieves zero training loss in polynomial time for a deep overparameterized neural network with residual connections (RcsNct). Our analysis relics on the particular structure of the Gram matrix induced by the neural network architecture. This structure allows us to show the Gram matrix is stable throughout the training process and this stability implies the global optimality of the gradient descent algorithm. Wc further extend our analysis to deep residual convolutional neural networks and obtain a similar convergence result.},
archivePrefix = {arXiv},
arxivId = {1811.03804},
author = {Du, Simon S. and Lee, Jason D. and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
eprint = {1811.03804},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Du et al. - 2019 - Gradient descent finds global minima of deep neural networks.pdf:pdf},
isbn = {9781510886988},
journal = {36th International Conference on Machine Learning, ICML 2019},
keywords = {gradient descent,optimization},
mendeley-tags = {gradient descent,optimization},
pages = {3003--3048},
title = {{Gradient descent finds global minima of deep neural networks}},
volume = {2019-June},
year = {2019}
}
@article{Ramsauer2020,
abstract = {The transformer and BERT models pushed the performance on NLP tasks to new levels via their attention mechanism. We show that this attention mechanism is the update rule of a modern Hopfield network with continuous states. This new Hopfield network can store exponentially (with the dimension) many patterns, converges with one update, and has exponentially small retrieval errors. The number of stored patterns must be traded off against convergence speed and retrieval error. The new Hopfield network has three types of energy minima (fixed points of the update): (1) global fixed point averaging over all patterns, (2) metastable states averaging over a subset of patterns, and (3) fixed points which store a single pattern. Transformers learn an attention mechanism by constructing an embedding of patterns and queries into an associative space. Transformer and BERT models operate in their first layers preferably in the global averaging regime, while they operate in higher layers in metastable states. The gradient in transformers is maximal in the regime of metastable states, is uniformly distributed when averaging globally, and vanishes when a fixed point is near a stored pattern. Based on the Hopfield network interpretation, we analyzed learning of transformer and BERT architectures. Learning starts with attention heads that average and then most of them switch to metastable states. However, the majority of heads in the first layers still averages and can be replaced by averaging operations like the Gaussian weighting that we propose. In contrast, heads in the last layers steadily learn and seem to use metastable states to collect information created in lower layers. These heads seem to be a promising target for improving transformers. Neural networks that integrate Hopfield networks, that are equivalent to attention heads, outperform other methods on immune repertoire classification, where the Hopfield net stores several hundreds of thousands of patterns. We provide a new PyTorch layer called “Hopfield” which allows to equip deep learning architectures with modern Hopfield networks as new powerful concept comprising pooling, memory, and attention. The implementation is available at: https://github.com/ml-jku/ hopfield-layers},
archivePrefix = {arXiv},
arxivId = {2008.02217},
author = {Ramsauer, Hubert and Sch{\"{a}}fl, Bernhard and Lehner, Johannes and Seidl, Philipp and Widrich, Michael and Gruber, Lukas and Holzleitner, Markus and Pavlovi{\'{c}}, Milena and Sandve, Geir Kjetil and Greiff, Victor and Kreil, David and Kopp, Michael and Klambauer, G{\"{u}}nter and Brandstetter, Johannes and Hochreiter, Sepp},
eprint = {2008.02217},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramsauer et al. - 2020 - Hopfield networks is all you need.pdf:pdf},
journal = {arXiv},
keywords = {hopfield networks},
mendeley-tags = {hopfield networks},
title = {{Hopfield networks is all you need}},
url = {https://github.com/ml-jku/hopfield-layers},
year = {2020}
}
@article{Delange2021,
abstract = {Artificial neural networks thrive in solving the classification problem for a particular rigid task, acquiring knowledge through generalized learning behaviour from a distinct training phase. The resulting network resembles a static entity of knowledge, with endeavours to extend this knowledge without targeting the original task resulting in a catastrophic forgetting. Continual learning shifts this paradigm towards networks that can continually accumulate knowledge over different tasks without the need to retrain from scratch. We focus on task incremental classification, where tasks arrive sequentially and are delineated by clear boundaries. Our main contributions concern 1) a taxonomy and extensive overview of the state-of-the-art, 2) a novel framework to continually determine the stability-plasticity trade-off of the continual learner, 3) a comprehensive experimental comparison of 11 state-of-the-art continual learning methods and 4 baselines. We empirically scrutinize method strengths and weaknesses on three benchmarks, considering Tiny Imagenet and large-scale unbalanced iNaturalist and a sequence of recognition datasets. We study the influence of model capacity, weight decay and dropout regularization, and the order in which the tasks are presented, and qualitatively compare methods in terms of required memory, computation time, and storage.},
archivePrefix = {arXiv},
arxivId = {1909.08383},
author = {Delange, Matthias and Aljundi, Rahaf and Masana, Marc and Parisot, Sarah and Jia, Xu and Leonardis, Ales and Slabaugh, Gregory and Tuytelaars, Tinne},
doi = {10.1109/TPAMI.2021.3057446},
eprint = {1909.08383},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Delange et al. - 2021 - A continual learning survey Defying forgetting in classification tasks.pdf:pdf},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {classification,continual learning,incremental learning,review,survey},
mendeley-tags = {classification,continual learning,incremental learning,review,survey},
pages = {1--1},
title = {{A continual learning survey: Defying forgetting in classification tasks}},
url = {http://arxiv.org/abs/1909.08383 https://github.com/Mattdl/CLsurvey https://ieeexplore.ieee.org/document/9349197/},
year = {2021}
}
@article{Mahir2008a,
abstract = {This paper proposed a new method to estimate the missing data by using the filtering process. We used datasets without missing data and randomly missing data to evaluate the new method of estimation by using the Box - Jenkins modeling technique to predict monthly average rainfall for site 5504035 Lahar Ikan Mati at Kepala Batas, P. Pinang station in Malaysia. The rainfall data was collected from the $1^{st}$ January 1969 to $31^{st}$ December 1997 in the station. The data used in the development of the model to predict rainfall were represented by an autoregressive integrated moving - average (ARIMA) model. The model for both datasets was ARIMA$(1,0,0)(0,1,1)_s$. The result checked with the Naive test, which is the Thiel's statistic and was found to be equal to $U=0.72086$ for the complete data and $U=0.726352$ for the missing data, which mean they were good models.},
archivePrefix = {arXiv},
arxivId = {0811.0659},
author = {Mahir, R. Ahmad and Al-Khazaleh, A. M. H.},
eprint = {0811.0659},
keywords = {and phrases,arima model,filter-,forecasting method,ing process and,monthly average rainfall},
pages = {1--12},
title = {{Estimation of missing data by using the filtering process in a time series modeling}},
url = {http://arxiv.org/abs/0811.0659},
year = {2008}
}
@article{Scitovski2016,
abstract = {In this paper, a new fast incremental fuzzy partitioning algorithm able to find either a fuzzy globally optimal partition or a fuzzy locally optimal partition of the set A⊂ℝnclose to the global one is proposed. This is the main impact of the paper, which could have an important role in applied research. Since fuzzy k-optimal partitions with k=2,3,...,kmaxclusters are determined successively in the algorithm, it is possible to calculate corresponding validity indices for every obtained partition. The number kmaxis defined in such a way that the objective function value of optimal partition with kmaxclusters is relatively very close to the objective function value of optimal partition with (kmax-1) clusters. Before clustering, the data are normalized and afterwards several validity indices are applied to partitions of the normalized data. Very simple relationships between used validity indices on normalized and original data are given as well. Hence, the proposed algorithm is able to find optimal partitions with the most appropriate number of clusters. The algorithm is tested on numerous synthetic data sets and several real data sets from the UCI data repository.},
archivePrefix = {arXiv},
arxivId = {arXiv:0711.0189v1},
author = {Scitovski, Rudolf and Vidovi{\'{c}}, Ivan and Bajer, Dra{\v{z}}en},
doi = {10.1016/j.eswa.2015.12.034},
eprint = {arXiv:0711.0189v1},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Scitovski, Vidovi{\'{c}}, Bajer - 2016 - A new fast fuzzy partitioning algorithm.pdf:pdf},
isbn = {978-1-4673-0892-2},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {DIRECT,Fuzzy c-means,Fuzzy clustering,Fuzzy globally optimal partition,Fuzzy locally optimal partition,Incremental algorithm},
pages = {143--150},
pmid = {19784854},
title = {{A new fast fuzzy partitioning algorithm}},
volume = {51},
year = {2016}
}
@article{Using2015,
author = {Using, High-pin-count B G A Packages},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Using - 2015 - Pin Assignment Optimization for Large-Scale.pdf:pdf},
number = {2},
pages = {232--244},
title = {{Pin Assignment Optimization for Large-Scale}},
volume = {5},
year = {2015}
}
@article{Mohamed2013,
abstract = {This paper introduces an Effective Differential Evolution (EDE) algorithm for solving real parameter optimization problems over continuous domain. The proposed algorithm proposes a new mutation rule based on the best and the worst individuals among the entire population of a particular generation. The mutation rule is combined with the basic mutation strategy through a linear decreasing probability rule. The proposed mutation rule is shown to promote local search capability of the basic DE and to make it faster. Furthermore, a random mutation scheme and a modified Breeder Genetic Algorithm (BGA) mutation scheme are merged to avoid stagnation and/or premature convergence. Additionally, the scaling factor and crossover of DE are introduced as uniform random numbers to enrich the search behavior and to enhance the diversity of the population. The effectiveness and benefits of the proposed modifications used in EDE has been experimentally investigated. Numerical experiments on a set of bound-constrained problems have shown that the new approach is efficient, effective and robust. The comparison results between the EDE and several classical differential evolution methods and state-of-the-art parameter adaptive differential evolution variants indicate that the proposed EDE algorithm is competitive with, and in some cases superior to, other algorithms in terms of final solution quality, efficiency, convergence rate, and robustness. {\textcopyright} 2013 Faculty of Computers and Information, Cairo University. Production and hosting by Elsevier B.V. All rights reserved.},
author = {Mohamed, Ali Wagdy and Sabry, Hegazy Zaher and Abd-Elaziz, Tareq},
doi = {10.1016/j.eij.2013.01.001},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mohamed, Sabry, Abd-Elaziz - 2013 - Real parameter optimization by an effective differential evolution algorithm.pdf:pdf},
issn = {11108665},
journal = {Egyptian Informatics Journal},
keywords = {Best-worst mutation,Differential evolution,Global optimization,Modified BGA mutation},
number = {1},
pages = {37--53},
publisher = {Ministry of Higher Education and Scientific Research},
title = {{Real parameter optimization by an effective differential evolution algorithm}},
url = {http://dx.doi.org/10.1016/j.eij.2013.01.001},
volume = {14},
year = {2013}
}
@article{Zoph2019,
abstract = {Data augmentation is a critical component of training deep learning models. Although data augmentation has been shown to significantly improve image classification, its potential has not been thoroughly investigated for object detection. Given the additional cost for annotating images for object detection, data augmentation may be of even greater importance for this computer vision task. In this work, we study the impact of data augmentation on object detection. We first demonstrate that data augmentation operations borrowed from image classification may be helpful for training detection models, but the improvement is limited. Thus, we investigate how learned, specialized data augmentation policies improve generalization performance for detection models. Importantly, these augmentation policies only affect training and leave a trained model unchanged during evaluation. Experiments on the COCO dataset indicate that an optimized data augmentation policy improves detection accuracy by more than +2.3 mAP, and allow a single inference model to achieve a state-of-the-art accuracy of 50.7 mAP. Importantly, the best policy found on COCO may be transferred unchanged to other detection datasets and models to improve predictive accuracy. For example, the best augmentation policy identified with COCO improves a strong baseline on PASCAL-VOC by +2.7 mAP. Our results also reveal that a learned augmentation policy is superior to state-of-the-art architecture regularization methods for object detection, even when considering strong baselines. Code for training with the learned policy is available online at https://github.com/tensorflow/tpu/tree/master/models/official/detection},
archivePrefix = {arXiv},
arxivId = {1906.11172},
author = {Zoph, Barret and Cubuk, Ekin D. and Ghiasi, Golnaz and Lin, Tsung-Yi and Shlens, Jonathon and Le, Quoc V.},
eprint = {1906.11172},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zoph et al. - 2019 - Learning Data Augmentation Strategies for Object Detection.pdf:pdf},
title = {{Learning Data Augmentation Strategies for Object Detection}},
url = {http://arxiv.org/abs/1906.11172},
year = {2019}
}
@article{Maurya2014,
abstract = {— Image restoration is an important issue in high level image processing which deals with recovering of an original and sharp image using a degradation and restoration model. During image acquisition process degradation occurs. Image restoration is used to estimate the original image from the degraded data. Aim of this research paper is to provide a concise overview of most useful restoration models .Different types of image restoration techniques like wiener filter, inverse filter, regularized filter, Richardson –Lucy algorithm, neural network approach ,wavelet based approach, blind deconvolution are described and strength and weakness of each approach are identified.},
author = {Maurya, Anamika and Tiwari, Rajinder},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maurya, Tiwari - 2014 - A Novel Method of Image Restoration by using Different Types of Filtering Techniques.pdf:pdf},
journal = {International Journal Engineering Science and Innovative Technology},
number = {4},
pages = {124--129},
title = {{A Novel Method of Image Restoration by using Different Types of Filtering Techniques}},
volume = {3},
year = {2014}
}
@article{Zhang2020b,
abstract = {Most existing few-shot learning methods in computer vision focus on class recognition given a few of still images as the input. In contrast, this paper tackles a more challenging task of few-shot action-recognition from video clips. We propose a simple framework which is both flexible and easy to implement. Our approach exploits joint spatial and temporal attention mechanisms in conjunction with self-supervised representation learning on videos. This design encourages the model to discover and encode spatial and temporal attention hotspots important during the similarity learning between dynamic video sequences for which locations of discriminative patterns vary in the spatio-temporal sense. Our method compares favorably with several state-of-the-art baselines on HMDB51, miniMIT and UCF101 datasets, demonstrating its superior performance.},
archivePrefix = {arXiv},
arxivId = {2001.03905},
author = {Zhang, Hongguang and Zhang, Li and Qi, Xiaojuan and Li, Hongdong and Torr, Philip H. S. and Koniusz, Piotr},
eprint = {2001.03905},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2020 - Few-shot Action Recognition via Improved Attention with Self-supervision.pdf:pdf},
title = {{Few-shot Action Recognition via Improved Attention with Self-supervision}},
url = {http://arxiv.org/abs/2001.03905},
year = {2020}
}
@article{Borsos2020,
abstract = {Coresets are small data summaries that are sufficient for model training. They can be maintained online, enabling efficient handling of large data streams under resource constraints. However, existing constructions are limited to simple models such as k-means and logistic regression. In this work, we propose a novel coreset construction via cardinality-constrained bilevel optimization. We show how our framework can efficiently generate coresets for deep neural networks, and demonstrate its empirical benefits in continual learning and in streaming settings.},
archivePrefix = {arXiv},
arxivId = {2006.03875},
author = {Borsos, Zal{\'{a}}n and Mutn{\'{y}}, Mojm{\'{i}}r and Krause, Andreas},
eprint = {2006.03875},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Borsos, Mutn{\'{y}}, Krause - 2020 - Coresets via Bilevel Optimization for Continual Learning and Streaming(2).pdf:pdf},
keywords = {continual learning},
mendeley-tags = {continual learning},
number = {NeurIPS},
pages = {1--22},
title = {{Coresets via Bilevel Optimization for Continual Learning and Streaming}},
year = {2020}
}
@article{Khanduja2013,
abstract = {Purpose: The purpose of this paper is to deal with the performance modeling and optimization for the stock preparation unit of a paper plant using genetic algorithm. It provides the optimum unit availability level for different combinations of failure and repair rates of the subsystems of the stock preparation unit of the paper plant concerned. Design/methodology/approach: In this paper, efforts have been made to develop performance models based on real situations for the stock preparation unit. The performance in terms of availability has been evaluated on the basis of Markov birth-death process. After that, the performance optimization using genetic algorithm is done, which gives the optimum unit availability levels for different combinations of failure and repair rates of the subsystems of stock preparation units for enhancing the overall performance of the paper plant. Findings: The effect of genetic algorithm parameters, namely number of generations, population size and crossover probability on the unit performance i.e. availability has been analyzed and discussed with the concerned paper plant management. It is found that these results are highly beneficial to the maintenance engineers for the purpose of effective maintenance planning to enhance the overall performance (availability) of the stock preparation unit of the paper plant. Originality/value: Most of the researchers have confined their work to the development and analysis of theoretical models which has little practical significance. To fulfill this deficiency, efforts have been made in the present work to develop a model based on real situations for the stock preparation unit. {\textcopyright} Emerald Group Publishing Limited.},
author = {Khanduja, Rajiv and Tewari, P. C.},
doi = {10.1108/02656711311315477},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khanduja, Tewari - 2013 - Performance modeling and optimization for the stock preparation unit of a paper plant using genetic algorithm.pdf:pdf},
isbn = {0265671111114},
issn = {0265671X},
journal = {International Journal of Quality & Reliability Management},
keywords = {Genetic algorithms,Modelling,Paper industry,Performance optimization,Stock preparation unit},
number = {5},
pages = {480--494},
title = {{Performance modeling and optimization for the stock preparation unit of a paper plant using genetic algorithm}},
volume = {30},
year = {2013}
}
@article{Chaudhry2020a,
abstract = {In continual learning (CL), a learner is faced with a sequence of tasks, arriving one after the other, and the goal is to remember all the tasks once the continual learning experience is finished. The prior art in CL uses episodic memory, parameter regularization or extensible network structures to reduce interference among tasks, but in the end, all the approaches learn different tasks in a joint vector space. We believe this invariably leads to interference among different tasks. We propose to learn tasks in different (low-rank) vector subspaces that are kept orthogonal to each other in order to minimize interference. Further, to keep the gradients of different tasks coming from these subspaces orthogonal to each other, we learn isometric mappings by posing network training as an optimization problem over the Stiefel manifold. To the best of our understanding, we report, for the first time, strong results over experience-replay baseline with and without memory on standard classification benchmarks in continual learning. The code is made publicly available.},
archivePrefix = {arXiv},
arxivId = {2010.11635},
author = {Chaudhry, Arslan and Khan, Naeemullah and Dokania, Puneet K. and Torr, Philip H. S.},
eprint = {2010.11635},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chaudhry et al. - 2020 - Continual Learning in Low-rank Orthogonal Subspaces.pdf:pdf},
keywords = {continual learning,regularization},
mendeley-tags = {continual learning,regularization},
number = {NeurIPS},
pages = {1--16},
title = {{Continual Learning in Low-rank Orthogonal Subspaces}},
year = {2020}
}
@article{Brown2017,
abstract = {Here we present a novel, histogram-based salient point feature detector that may naturally be applied to both images and 3D data. Existing point feature detectors are often modality specific, with 2D and 3D feature detectors typically constructed in separate ways. As such, their applicability in a 2D-3D context is very limited, particularly where the 3D data is obtained by a LiDAR scanner. By contrast, our histogram-based approach is highly generalisable and as such, may be meaningfully applied between 2D and 3D data. Using the generalised approach, we propose salient point detectors for images, and both untextured and textured 3D data. The approach naturally allows for the detection of salient 3D points based jointly on both the geometry and texture of the scene, allowing for broader applicability. The repeatability of the feature detectors is evaluated using a range of datasets including image and LiDAR input from indoor and outdoor scenes. Experimental results demonstrate a significant improvement in terms of 2D-2D and 2D-3D repeatability compared to existing multi-modal feature detectors.},
author = {Brown, Mark and Windridge, David and Guillemaut, Jean Yves},
doi = {10.1016/j.cviu.2016.09.008},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brown, Windridge, Guillemaut - 2017 - A generalised framework for saliency-based point feature detection.pdf:pdf},
issn = {1090235X},
journal = {Computer Vision and Image Understanding},
keywords = {2D-3D registration,Feature detection,Feature matching,Point detection,Saliency},
pages = {117--137},
publisher = {Elsevier Inc.},
title = {{A generalised framework for saliency-based point feature detection}},
url = {http://dx.doi.org/10.1016/j.cviu.2016.09.008},
volume = {157},
year = {2017}
}
@article{Boudhane2016,
abstract = {Object detection is an important process in image processing, it aims to detect instances of semantic objects of a certain class in digital images and videos. Object detection has applications in many areas of computer vision such as underwater fish detection. In this paper we present a method for preprocessing and fish localization in underwater images. We are based on a Poisson-Gauss theory, because it can accurately describe the noise present in a large variety of imaging systems. In the preprocessing step we denoise and restore the raw images. These images are split into regions utilizing the mean shift algorithm. For each region, statistical estimation is done independently in order to combine regions into objects. The method is tested under different underwater conditions. Experimental results show that the proposed approach outperforms state of the art methods.},
author = {Boudhane, Mohcine and Nsiri, Benayad},
doi = {10.1016/j.jvcir.2016.05.017},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boudhane, Nsiri - 2016 - Underwater image processing method for fish localization and detection in submarine environment.pdf:pdf},
issn = {10959076},
journal = {Journal of Visual Communication and Image Representation},
keywords = {Image denoising,Object detection,Scene understanding,Underwater image processing},
pages = {226--238},
title = {{Underwater image processing method for fish localization and detection in submarine environment}},
url = {http://dx.doi.org/10.1016/j.jvcir.2016.05.017},
volume = {39},
year = {2016}
}
@article{Hess1928,
abstract = {• Basic principles - Resonance Raman scattering - Surface Enhanced Raman Scattering (SERS) • Instrumentation -Spectrometer - Excitation sources • Raman in catalysis - In situ cells -},
author = {Hess, Christian},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hess - 1928 - Raman spectroscopy Basic principles and applications.pdf:pdf},
title = {{Raman spectroscopy : Basic principles and applications}},
year = {1928}
}
@article{Mehrpouya2018,
abstract = {NiTi shape memory alloys (SMA) are broadly employed in multifunctional systems in several industrial domains, like aerospace, automotive, biomedical and power plants. Their functional properties, which include shape memory effect (SME) and superelasticity (SE), offer a particular flexibility to design many smart components. However, scientists and practitioners are still facing some restrictions in machining processes and joining techniques of NiTi SMAs to both similar and dissimilar materials. Compared to other procedures, laser welding is an economical and reliable joining technique for NiTi SMAs. Nevertheless, it is considered a challenging technique, with many obstacles still to overcome to achieve welded joints characterized by the necessary strength and the required functionalities. In this respect, the present work investigates the effects of laser welding process on the functional properties of NiTi and related alloys. Mechanical, microstructural, and metallurgical effects of the process are reported, as well. Lastly, the impact of the post-weld heat treatment (PWHT) is studied as an effective solution to improve the downsides of the laser welding process.},
author = {Mehrpouya, Mehrshad and Gisario, Annamaria and Elahinia, Mohammad},
doi = {10.1016/j.jmapro.2017.11.011},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mehrpouya, Gisario, Elahinia - 2018 - Laser welding of NiTi shape memory alloy A review.pdf:pdf},
issn = {15266125},
journal = {Journal of Manufacturing Processes},
keywords = {Fusion zone,Heat affected zone,Laser welding,NiTi shape memory alloys,Shape memory effect,Superelasticity},
pages = {162--186},
publisher = {The Society of Manufacturing Engineers},
title = {{Laser welding of NiTi shape memory alloy: A review}},
url = {http://dx.doi.org/10.1016/j.jmapro.2017.11.011},
volume = {31},
year = {2018}
}
@article{Ma2017,
abstract = {Wind speed forecasting plays a pivotal role in power dispatching and normal operations of power grids. However, it is both a difficult and challenging problem to achieve high-precision forecasting for the wind speed because the original sequence includes many nonlinear stochastic signals. The current conventional forecasting methods are more suitable for capturing linear trends, and artificial neural networks easily fall into a local optimum. This paper proposes a model that combines a denoising method with a dynamic fuzzy neural network to address the problems above. Singular spectrum analysis optimized by brain storm optimization is applied to preprocess the original wind speed data to obtain a smoother sequence, and a generalized dynamic fuzzy neural network is utilized to perform the forecasting. With a smaller and simpler structure of the neural network, the model can effectively achieve a rapid learning rate and accurate forecasting. Three experimental results, which cover 10-min, 30-min and 60-min interval wind speed time series data, demonstrate that the model can both satisfactorily approximates the actual value and be used as an effective and simple tool for the planning of smart grids.},
author = {Ma, Xuejiao and Jin, Yu and Dong, Qingli},
doi = {10.1016/j.asoc.2017.01.033},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ma, Jin, Dong - 2017 - A generalized dynamic fuzzy neural network based on singular spectrum analysis optimized by brain storm optimizat.pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {Brain storm optimization,Generalized dynamic fuzzy neural network,Short-term wind speed forecasting,Singular spectrum analysis},
pages = {296--312},
publisher = {Elsevier B.V.},
title = {{A generalized dynamic fuzzy neural network based on singular spectrum analysis optimized by brain storm optimization for short-term wind speed forecasting}},
url = {http://dx.doi.org/10.1016/j.asoc.2017.01.033},
volume = {54},
year = {2017}
}
@article{Lohit2020,
abstract = {Model compression methods are important to allow for easier deployment of deep learning models in compute, memory and energy-constrained environments such as mobile phones. Knowledge distillation is a class of model compression algorithm where knowledge from a large teacher network is transferred to a smaller student network thereby improving the student's performance. In this paper, we show how optimal transport-based loss functions can be used for training a student network which encourages learning student network parameters that help bring the distribution of student features closer to that of the teacher features. We present image classification results on CIFAR-100, SVHN and ImageNet and show that the proposed optimal transport loss functions perform comparably to or better than other loss functions.},
archivePrefix = {arXiv},
arxivId = {2012.03907},
author = {Lohit, Suhas and Jones, Michael},
eprint = {2012.03907},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lohit, Jones - 2020 - Model Compression Using Optimal Transport.pdf:pdf},
keywords = {model compression,optimal transport},
mendeley-tags = {model compression,optimal transport},
title = {{Model Compression Using Optimal Transport}},
url = {http://arxiv.org/abs/2012.03907},
year = {2020}
}
@article{Pourahmadi1989,
author = {Pourahmadi, Mohsen},
doi = {10.1111/j.1467-9892.1989.tb00021.x},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pourahmadi - 1989 - Estimation and Interpolation of Missing Values of a Stationary Time Series.pdf:pdf},
issn = {14679892},
journal = {Journal of Time Series Analysis},
keywords = {EM algorithm,Stationary time series,autoregressive process,missing‐value problem,moving‐average process,multistep‐ahead predictors},
number = {2},
pages = {149--169},
title = {{Estimation and Interpolation of Missing Values of a Stationary Time Series}},
volume = {10},
year = {1989}
}
@article{Skinner2013,
abstract = {Abstract The importance of understanding how confidence varies across time has been encouraged by sport confidence researchers (Vealey & Chase, 2008). The purpose of this study was to examine the relationship between confidence and performance throughout an entire competitive season. Two levels of confidence consistent to team sports were analyzed. Team and coach confidence were collected through the Collective Efficacy Questionnaire for Sport (CEQS) and Coaching Efficacy Scale (CES) respectively. Two teams, women's soccer and volleyball (n=48) from a college in the western United States, completed their specific questionnaires five times throughout the season. The CEQS measured collective efficacy (team confidence) and the CES measured coaching efficacy (coach confidence) for each team. Simple linear regressions were used to determine the relationship team confidence and coaching confidence had on the success of each team. Pearson's correlation coefficients were taken to determine if team and coach confidence were connected throughout the season. Volleyball was statistically significant for both team and coach confidence at p = 0.033 and p = 0.040 respectively, with a .68 correlation coefficient. Conversely, the soccer team was not statistically significant for both team and coach confidence at p = 0.53 and p = 0.93 for each. There was, however, a strong correlation coefficient at .89 for the two levels. The findings suggest that team and coach confidence may be related and associated with the success of the team. The results also hint, through the correlation coefficients, that team and coach confidence may be connected.},
author = {Skinner, Benjiman R and Gordin, Richard D and Ed, D},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Skinner, Gordin, Ed - 2013 - The Relationship Between Confidence and Performance Throughout a Competitive Season.pdf:pdf},
pages = {2117},
title = {{The Relationship Between Confidence and Performance Throughout a Competitive Season}},
year = {2013}
}
@article{Garnelo2019,
abstract = {In the history of the quest for human-level artificial intelligence, a number of rival paradigms have vied for supremacy. Symbolic artificial intelligence was dominant for much of the 20th century, but currently a connectionist paradigm is in the ascendant, namely machine learning with deep neural networks. However, both paradigms have strengths and weaknesses, and a significant challenge for the field today is to effect a reconciliation. A central tenet of the symbolic paradigm is that intelligence results from the manipulation of abstract compositional representations whose elements stand for objects and relations. If this is correct, then a key objective for deep learning is to develop architectures capable of discovering objects and relations in raw data, and learning how to represent them in ways that are useful for downstream processing. This short review highlights recent progress in this direction.},
author = {Garnelo, Marta and Shanahan, Murray},
doi = {10.1016/j.cobeha.2018.12.010},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garnelo, Shanahan - 2019 - Reconciling deep learning with symbolic artificial intelligence representing objects and relations.pdf:pdf},
issn = {23521546},
journal = {Current Opinion in Behavioral Sciences},
keywords = {reasoning,relational},
mendeley-tags = {reasoning,relational},
pages = {17--23},
publisher = {Elsevier Ltd},
title = {{Reconciling deep learning with symbolic artificial intelligence: representing objects and relations}},
url = {https://doi.org/10.1016/j.cobeha.2018.12.010},
volume = {29},
year = {2019}
}
@article{Guo2020,
abstract = {Human intelligence exhibits compositional generalization (i.e., the capacity to understand and produce unseen combinations of seen components), but current neural seq2seq models lack such ability. In this paper, we revisit iterative back-translation, a simple yet effective semi-supervised method, to investigate whether and how it can improve compositional generalization. In this work: (1) We first empirically show that iterative back-translation substantially improves the performance on compositional generalization benchmarks (CFQ and SCAN). (2) To understand why iterative back-translation is useful, we carefully examine the performance gains and find that iterative back-translation can increasingly correct errors in pseudo-parallel data. (3) To further encourage this mechanism, we propose curriculum iterative back-translation, which better improves the quality of pseudo-parallel data, thus further improving the performance.},
archivePrefix = {arXiv},
arxivId = {2012.04276},
author = {Guo, Yinuo and Zhu, Hualei and Lin, Zeqi and Chen, Bei and Lou, Jian-Guang and Zhang, Dongmei},
eprint = {2012.04276},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guo et al. - 2020 - Revisiting Iterative Back-Translation from the Perspective of Compositional Generalization.pdf:pdf},
keywords = {compositional,generalization},
mendeley-tags = {compositional,generalization},
title = {{Revisiting Iterative Back-Translation from the Perspective of Compositional Generalization}},
url = {http://arxiv.org/abs/2012.04276},
year = {2020}
}
@article{Liu2020a,
abstract = {Multi-Class Incremental Learning (MCIL) aims to learn new concepts by incrementally updating a model trained on previous concepts. However, there is an inherent trade-off to effectively learning new concepts without catastrophic forgetting of previous ones. To alleviate this issue, it has been proposed to keep around a few examples of the previous concepts but the effectiveness of this approach heavily depends on the representativeness of these examples. This paper proposes a novel and automatic framework we call mnemonics, where we parameterize exemplars and make them optimizable in an end-to-end manner. We train the framework through bilevel optimizations, i.e., model-level and exemplar-level. We conduct extensive experiments on three MCIL benchmarks, CIFAR-100, ImageNet-Subset and ImageNet, and show that using mnemonics exemplars can surpass the state-of-the-art by a large margin. Interestingly and quite intriguingly, the mnemonics exemplars tend to be on the boundaries between different classes.},
archivePrefix = {arXiv},
arxivId = {2002.10211},
author = {Liu, Yaoyao and Liu, An-An and Su, Yuting and Schiele, Bernt and Sun, Qianru},
eprint = {2002.10211},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2020 - Mnemonics Training Multi-Class Incremental Learning without Forgetting.pdf:pdf},
journal = {arXiv},
keywords = {continual learning,incremental learning},
mendeley-tags = {continual learning,incremental learning},
month = {feb},
title = {{Mnemonics Training: Multi-Class Incremental Learning without Forgetting}},
url = {http://arxiv.org/abs/2002.10211 https://github.com/yaoyao-liu/class-incremental-learning},
year = {2020}
}
@article{Jaiswal2020,
abstract = {Self-supervised learning has gained popularity because of its ability to avoid the cost of annotating large-scale datasets. It is capable of adopting self-defined pseudolabels as supervision and use the learned representations for several downstream tasks. Specifically, contrastive learning has recently become a dominant component in self-supervised learning for computer vision, natural language processing (NLP), and other domains. It aims at embedding augmented versions of the same sample close to each other while trying to push away embeddings from different samples. This paper provides an extensive review of self-supervised methods that follow the contrastive approach. The work explains commonly used pretext tasks in a contrastive learning setup, followed by different architectures that have been proposed so far. Next, we present a performance comparison of different methods for multiple downstream tasks such as image classification, object detection, and action recognition. Finally, we conclude with the limitations of the current methods and the need for further techniques and future directions to make meaningful progress.},
archivePrefix = {arXiv},
arxivId = {2011.00362},
author = {Jaiswal, Ashish and Babu, Ashwin Ramesh and Zadeh, Mohammad Zaki and Banerjee, Debapriya and Makedon, Fillia},
doi = {10.3390/technologies9010002},
eprint = {2011.00362},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jaiswal et al. - 2020 - A Survey on Contrastive Self-Supervised Learning.pdf:pdf},
issn = {2227-7080},
journal = {Technologies},
keywords = {contrastive learning,review,self-supervised learning,survey},
mendeley-tags = {contrastive learning,review,self-supervised learning,survey},
number = {1},
pages = {2},
title = {{A Survey on Contrastive Self-Supervised Learning}},
volume = {9},
year = {2020}
}
@article{Montufar2014,
abstract = {We study the complexity of functions computable by deep feedforward neural networks with piecewise linear activations in terms of the symmetries and the number of linear regions that they have. Deep networks are able to sequentially map portions of each layer's input-space to the same output. In this way, deep models compute functions that react equally to complicated patterns of different inputs. The compositional structure of these functions enables them to re-use pieces of computation exponentially often in terms of the network's depth. This paper investigates the complexity of such compositional maps and contributes new theoretical results regarding the advantage of depth for neural networks with piecewise linear activation functions. In particular, our analysis is not specific to a single family of models, and as an example, we employ it for rectifier and maxout networks. We improve complexity bounds from pre-existing work and investigate the behavior of units in higher layer.},
archivePrefix = {arXiv},
arxivId = {1402.1869},
author = {Mont{\'{u}}far, Guido and Pascanu, Razvan and Cho, Kyunghyun and Bengio, Yoshua},
eprint = {1402.1869},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mont{\'{u}}far et al. - 2014 - On the number of linear regions of deep neural networks.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
keywords = {Deep learning,Input space partition,Maxout,Neural network,Rectifier},
number = {January},
pages = {2924--2932},
title = {{On the number of linear regions of deep neural networks}},
volume = {4},
year = {2014}
}
@article{Ge2014,
author = {Ge, Tiezheng and He, Kaiming and Ke, Qifa and Sun, Jian},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ge et al. - 2014 - Optimized Product Quantization.pdf:pdf},
number = {X},
pages = {1--12},
title = {{Optimized Product Quantization}},
volume = {36},
year = {2014}
}
@article{Bekoulis2020,
abstract = {Adversarial training (AT) is a regularization method that can be used to improve the robustness of neural network methods by adding small perturbations in the training data. We show how to use AT for the tasks of entity recognition and relation extraction. In particular, we demonstrate that applying AT to a general purpose baseline model for jointly extracting entities and relations, allows improving the state-of-the-art effectiveness on several datasets in different contexts (i.e., news, biomedical, and real estate data) and for different languages (English and Dutch).},
archivePrefix = {arXiv},
arxivId = {1808.06876},
author = {Bekoulis, Giannis and Deleu, Johannes and Demeester, Thomas and Develder, Chris},
doi = {10.18653/v1/d18-1307},
eprint = {1808.06876},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bekoulis et al. - 2020 - Adversarial training for multi-context joint entity and relation extraction.pdf:pdf},
isbn = {9781948087841},
journal = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018},
keywords = {information extraction,joint entity and relation extraction,natural language processing},
mendeley-tags = {information extraction,joint entity and relation extraction,natural language processing},
pages = {2830--2836},
title = {{Adversarial training for multi-context joint entity and relation extraction}},
year = {2020}
}
@article{Pathak2016,
abstract = {We present an unsupervised visual feature learning algorithm driven by context-based pixel prediction. By analogy with auto-encoders, we propose Context Encoders - a convolutional neural network trained to generate the contents of an arbitrary image region conditioned on its surroundings. In order to succeed at this task, context encoders need to both understand the content of the entire image, as well as produce a plausible hypothesis for the missing part(s). When training context encoders, we have experimented with both a standard pixel-wise reconstruction loss, as well as a reconstruction plus an adversarial loss. The latter produces much sharper results because it can better handle multiple modes in the output. We found that a context encoder learns a representation that captures not just appearance but also the semantics of visual structures. We quantitatively demonstrate the effectiveness of our learned features for CNN pre-training on classification, detection, and segmentation tasks. Furthermore, context encoders can be used for semantic inpainting tasks, either stand-alone or as initialization for non-parametric methods.},
archivePrefix = {arXiv},
arxivId = {1604.07379},
author = {Pathak, Deepak and Krahenbuhl, Philipp and Donahue, Jeff and Darrell, Trevor and Efros, Alexei A.},
doi = {10.1109/CVPR.2016.278},
eprint = {1604.07379},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pathak et al. - 2016 - Context Encoders Feature Learning by Inpainting.pdf:pdf},
isbn = {9781467388504},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {2536--2544},
title = {{Context Encoders: Feature Learning by Inpainting}},
volume = {2016-Decem},
year = {2016}
}
@article{Ng2019a,
abstract = {Images are uploaded to the Internet over time which makes concept drifting and distribution change in semantic classes unavoidable. Current hashing methods being trained using a given static database may not be suitable for nonstationary semantic image retrieval problems. Moreover, directly retraining a whole hash table to update knowledge coming from new arriving image data may not be efficient. Therefore, this paper proposes a new incremental hash-bit learning method. At the arrival of new data, hash bits are selected from both existing and newly trained hash bits by an iterative maximization of a 3-component objective function. This objective function is also used to weight selected hash bits to re-rank retrieved images for better semantic image retrieval results. The three components evaluate a hash bit in three different angles: 1) information preservation; 2) partition balancing; and 3) bit angular difference. The proposed method combines knowledge retained from previously trained hash bits and new semantic knowledge learned from the new data by training new hash bits. In comparison to table-based incremental hashing, the proposed method automatically adjusts the number of bits from old data and new data according to the concept drifting in the given data via the maximization of the objective function. Experimental results show that the proposed method outperforms existing stationary hashing methods, table-based incremental hashing, and online hashing methods in 15 different simulated nonstationary data environments.},
author = {Ng, Wing W.Y. and Tian, Xing and Pedrycz, Witold and Wang, Xizhao and Yeung, Daniel S.},
doi = {10.1109/TCYB.2018.2846760},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ng et al. - 2019 - Incremental Hash-Bit Learning for Semantic Image Retrieval in Nonstationary Environments(2).pdf:pdf},
issn = {21682275},
journal = {IEEE Transactions on Cybernetics},
keywords = {Concept drift,continual learning,hash bit learning,hashing,image retrieval,incremental learning,nonstationary environment},
mendeley-tags = {continual learning,image retrieval,incremental learning},
number = {11},
pages = {3844--3858},
title = {{Incremental Hash-Bit Learning for Semantic Image Retrieval in Nonstationary Environments}},
volume = {49},
year = {2019}
}
@article{Maltoni2019,
abstract = {It was recently shown that architectural, regularization and rehearsal strategies can be used to train deep models sequentially on a number of disjoint tasks without forgetting previously acquired knowledge. However, these strategies are still unsatisfactory if the tasks are not disjoint but constitute a single incremental task (e.g., class-incremental learning). In this paper we point out the differences between multi-task and single-incremental-task scenarios and show that well-known approaches such as LWF, EWC and SI are not ideal for incremental task scenarios. A new approach, denoted as AR1, combining architectural and regularization strategies is then specifically proposed. AR1 overhead (in terms of memory and computation) is very small thus making it suitable for online learning. When tested on CORe50 and iCIFAR-100, AR1 outperformed existing regularization strategies by a good margin.},
archivePrefix = {arXiv},
arxivId = {1806.08568},
author = {Maltoni, Davide and Lomonaco, Vincenzo},
doi = {10.1016/j.neunet.2019.03.010},
eprint = {1806.08568},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maltoni, Lomonaco - 2019 - Continuous learning in single-incremental-task scenarios.pdf:pdf},
issn = {18792782},
journal = {Neural Networks},
keywords = {Continuous learning,Deep learning,Incremental class learning,Lifelong learning,Object recognition,Single-incremental-task},
pages = {56--73},
pmid = {31005851},
title = {{Continuous learning in single-incremental-task scenarios}},
volume = {116},
year = {2019}
}
@incollection{Lesort2019,
abstract = {We present a new replay-based method of continual classification learning that we term “conditional replay” which generates samples and labels together by sampling from a distribution conditioned on the class. We compare conditional replay to another replay-based continual learning paradigm (which we term “marginal replay”) that generates samples independently of their class and assigns labels in a separate step. The main improvement in conditional replay is that labels for generated samples need not be inferred, which reduces the margin for error in complex continual classification learning tasks. We demonstrate the effectiveness of this approach using novel and standard benchmarks constructed from MNIST and FashionMNIST data, and compare to the regularization-based elastic weight consolidation (EWC) method [17, 34].},
archivePrefix = {arXiv},
arxivId = {1810.12069},
author = {Lesort, Timoth{\'{e}}e and Gepperth, Alexander and Stoian, Andrei and Filliat, David},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-030-30484-3_38},
eprint = {1810.12069},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lesort et al. - 2019 - Marginal Replay vs Conditional Replay for Continual Learning.pdf:pdf},
isbn = {9783030304836},
issn = {16113349},
keywords = {Continual learning,Generative models,Generative replay},
pages = {466--480},
title = {{Marginal Replay vs Conditional Replay for Continual Learning}},
url = {http://link.springer.com/10.1007/978-3-030-30484-3_38},
volume = {11728 LNCS},
year = {2019}
}
@article{Belkin2019,
abstract = {Breakthroughs in machine learning are rapidly changing science and society, yet our fundamental understanding of this technology has lagged far behind. Indeed, one of the central tenets of the field, the bias–variance trade-off, appears to be at odds with the observed behavior of methods used in modern machine-learning practice. The bias–variance trade-off implies that a model should balance underfitting and overfitting: Rich enough to express underlying structure in data and simple enough to avoid fitting spurious patterns. However, in modern practice, very rich models such as neural networks are trained to exactly fit (i.e., interpolate) the data. Classically, such models would be considered overfitted, and yet they often obtain high accuracy on test data. This apparent contradiction has raised questions about the mathematical foundations of machine learning and their relevance to practitioners. In this paper, we reconcile the classical understanding and the modern practice within a unified performance curve. This “double-descent” curve subsumes the textbook U-shaped bias–variance trade-off curve by showing how increasing model capacity beyond the point of interpolation results in improved performance. We provide evidence for the existence and ubiquity of double descent for a wide spectrum of models and datasets, and we posit a mechanism for its emergence. This connection between the performance and the structure of machine-learning models delineates the limits of classical analyses and has implications for both the theory and the practice of machine learning.},
author = {Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik},
doi = {10.1073/pnas.1903070116},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Belkin et al. - 2019 - Reconciling modern machine-learning practice and the classical bias–variance trade-off.pdf:pdf},
issn = {10916490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Bias–variance trade-off,Machine learning,Neural networks},
number = {32},
pages = {15849--15854},
pmid = {31341078},
title = {{Reconciling modern machine-learning practice and the classical bias–variance trade-off}},
volume = {116},
year = {2019}
}
@article{Xiong2020a,
abstract = {Recent studies on catastrophic forgetting during sequential learning typically focus on fixing the accuracy of the predictions for a previously learned task. In this paper we argue that the outputs of neural networks are subject to rapid changes when learning a new data distribution, and networks that appear to "forget" everything still contain useful representation towards previous tasks. Instead of enforcing the output accuracy to stay the same, we propose to reduce the effect of catastrophic forgetting on the representation level, as the output layer can be quickly recovered later with a small number of examples. Towards this goal, we propose an experimental setup that measures the amount of representational forgetting, and develop a novel meta-learning algorithm to overcome this issue. The proposed meta-learner produces weight updates of a sequential learning network, mimicking a multi-task teacher network's representation. We show that our meta-learner can improve its learned representations on new tasks, while maintaining a good representation for old tasks.},
archivePrefix = {arXiv},
arxivId = {1910.04650},
author = {Xiong, Yuwen and Ren, Mengye and Urtasun, Raquel},
eprint = {1910.04650},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xiong, Ren, Urtasun - 2020 - Learning to Remember from a Multi-Task Teacher.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {continual learning,knowledge distillation,multi-task,multi-task learning},
mendeley-tags = {continual learning,knowledge distillation,multi-task,multi-task learning},
month = {oct},
title = {{Learning to Remember from a Multi-Task Teacher}},
url = {http://arxiv.org/abs/1910.04650},
year = {2020}
}
@article{Chen2015c,
abstract = {In the present study, calcined waste pig bone (CB, a solid waste from animal) derived hydroxyapatite (HAP) was served as the support for K<inf>2</inf>CO<inf>3</inf> to prepare a cost-effective solid base catalyst for biodiesel production. The catalysts were characterized by XRD, FTIR, SEM-EDS, N<inf>2</inf> adsorption-desorption and the Hammett indicator method. The effects of catalyst preparation conditions (such as the loading of K<inf>2</inf>CO<inf>3</inf> on the CB and the calcination temperature), reaction conditions (such as reaction time, methanol/oil molar ratio and catalyst loading) and the catalyst reusability were studied in detail. The experimental results revealed that the highest biodiesel yield of 96.4% was obtained using the 30K/HAP-600 catalyst under the optimum reaction condition (reaction time of 1.5 h, catalyst loading of 8 wt.% and methanol/oil molar ratio of 9:1) due to its highest total basicity. Moreover, after reused for more than 8 cycles, the catalyst can still possess a rather high biodiesel yield (above 90%). A little deactivation was found due to K<sup>+</sup> ions leaching to the product.},
author = {Chen, Guanyi and Shan, Rui and Shi, Jiafu and Liu, Changye and Yan, Beibei},
doi = {10.1016/j.enconman.2015.04.012},
issn = {01968904},
journal = {Energy Conversion and Management},
keywords = {Animal bone,Biodiesel,Hydroxyapatite,K<inf>2</inf>CO<inf>3</inf>,Transesterification},
pages = {463--469},
publisher = {Elsevier Ltd},
title = {{Biodiesel production from palm oil using active and stable K doped hydroxyapatite catalysts}},
url = {http://dx.doi.org/10.1016/j.enconman.2015.04.012},
volume = {98},
year = {2015}
}
@article{Nakatsuji2016,
abstract = {The ability to predict the activities of users is an important one for recommender systems and analyses of social media. User activities can be represented in terms of relationships involving three or more things (e.g. when a user tags items on a webpage or tweets about a location he or she visited). Such relationships can be represented as a tensor, and tensor factorization is becoming an increasingly important means for predicting users' possible activities. However, the prediction accuracy of factorization is poor for ambiguous and/or sparsely observed objects. Our solution, Semantic Sensitive Tensor Factorization (SSTF), incorporates the semantics expressed by an object vocabulary or taxonomy into the tensor factorization. SSTF first links objects to classes in the vocabulary (taxonomy) and resolves the ambiguities of objects that may have several meanings. Next, it lifts sparsely observed objects to their classes to create augmented tensors. Then, it factorizes the original tensor and augmented tensors simultaneously. Since it shares semantic knowledge during the factorization, it can resolve the sparsity problem. Furthermore, as a result of the natural use of semantic information in tensor factorization, SSTF can combine heterogeneous and unbalanced datasets from different Linked Open Data sources. We implemented SSTF in the Bayesian probabilistic tensor factorization framework. Experiments on publicly available large-scale datasets using vocabularies from linked open data and a taxonomy from WordNet show that SSTF has up to 12% higher accuracy in comparison with state-of-the-art tensor factorization methods.},
author = {Nakatsuji, Makoto and Toda, Hiroyuki and Sawada, Hiroshi and Zheng, Jin Guang and Hendler, James A.},
doi = {10.1016/j.artint.2015.09.001},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nakatsuji et al. - 2016 - Semantic sensitive tensor factorization.pdf:pdf},
isbn = {0004-3702},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {Linked open data,Recommendation systems,Tensor factorization},
pages = {224--245},
publisher = {Elsevier B.V.},
title = {{Semantic sensitive tensor factorization}},
url = {http://dx.doi.org/10.1016/j.artint.2015.09.001},
volume = {230},
year = {2016}
}
@article{Bagherinezhad2016,
abstract = {Human vision greatly benefits from the information about sizes of objects. The role of size in several visual reasoning tasks has been thoroughly explored in human perception and cognition. However, the impact of the information about sizes of objects is yet to be determined in AI. We postulate that this is mainly attributed to the lack of a comprehensive repository of size information. In this paper, we introduce a method to automatically infer object sizes, leveraging visual and textual information from web. By maximizing the joint likelihood of textual and visual observations, our method learns reliable relative size estimates, with no explicit human supervision. We introduce the relative size dataset and show that our method outperforms competitive textual and visual baselines in reasoning about size comparisons.},
archivePrefix = {arXiv},
arxivId = {1602.00753},
author = {Bagherinezhad, Hessam and Hajishirzi, Hannaneh and Choi, Yejin and Farhadi, Ali},
doi = {10.5555/3016387.3016389},
eprint = {1602.00753},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bagherinezhad et al. - 2016 - Are Elephants Bigger than Butterflies Reasoning about Sizes of Objects.pdf:pdf},
month = {feb},
title = {{Are Elephants Bigger than Butterflies? Reasoning about Sizes of Objects}},
url = {http://arxiv.org/abs/1602.00753},
year = {2016}
}
@article{Alyafeai2020,
abstract = {Deep learning models usually require a huge amount of data. However, these large datasets are not always attainable. This is common in many challenging NLP tasks. Consider Neural Machine Translation, for instance, where curating such large datasets may not be possible specially for low resource languages. Another limitation of deep learning models is the demand for huge computing resources. These obstacles motivate research to question the possibility of knowledge transfer using large trained models. The demand for transfer learning is increasing as many large models are emerging. In this survey, we feature the recent transfer learning advances in the field of NLP. We also provide a taxonomy for categorizing different transfer learning approaches from the literature.},
archivePrefix = {arXiv},
arxivId = {2007.04239},
author = {Alyafeai, Zaid and {Saeed AlShaibani}, Maged and Ahmad, Irfan},
eprint = {2007.04239},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alyafeai, Saeed AlShaibani, Ahmad - 2020 - A survey on transfer learning in natural language processing.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {NLP,Survey,Transfer Learning,continual learning,natural language processing,review,survey},
mendeley-tags = {continual learning,natural language processing,review,survey},
pages = {6523--6541},
title = {{A survey on transfer learning in natural language processing}},
year = {2020}
}
@article{Herrick2000a,
abstract = {Kartalopoulos, Stamatios V},
author = {Herrick, Robert J},
doi = {10.1109/9780470544990},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Herrick - 2000 - Introduction To Dwdm Technology.pdf:pdf},
isbn = {0780347455},
journal = {Introduction To Dwdm Technology},
number = {6387},
pages = {288},
title = {{Introduction To Dwdm Technology}},
year = {2000}
}
@article{Liu2017a,
abstract = {The deployment of deep convolutional neural networks (CNNs) in many real world applications is largely hindered by their high computational cost. In this paper, we propose a novel learning scheme for CNNs to simultaneously 1) reduce the model size; 2) decrease the run-time memory footprint; and 3) lower the number of computing operations, without compromising accuracy. This is achieved by enforcing channel-level sparsity in the network in a simple but effective way. Different from many existing approaches, the proposed method directly applies to modern CNN architectures, introduces minimum overhead to the training process, and requires no special software/hardware accelerators for the resulting models. We call our approach network slimming, which takes wide and large networks as input models, but during training insignificant channels are automatically identified and pruned afterwards, yielding thin and compact models with comparable accuracy. We empirically demonstrate the effectiveness of our approach with several state-of-the-art CNN models, including VGGNet, ResNet and DenseNet, on various image classification datasets. For VGGNet, a multi-pass version of network slimming gives a 20× reduction in model size and a 5× reduction in computing operations.},
archivePrefix = {arXiv},
arxivId = {1708.06519},
author = {Liu, Zhuang and Li, Jianguo and Shen, Zhiqiang and Huang, Gao and Yan, Shoumeng and Zhang, Changshui},
doi = {10.1109/ICCV.2017.298},
eprint = {1708.06519},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2017 - Learning Efficient Convolutional Networks through Network Slimming.pdf:pdf},
isbn = {9781538610329},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {2755--2763},
title = {{Learning Efficient Convolutional Networks through Network Slimming}},
volume = {2017-Octob},
year = {2017}
}
@article{SriHarshaSuri2020,
abstract = {Deep Neural networks forget previously learnt tasks when they are faced with learning new tasks. This is called catastrophic forgetting. Rehearsing the neural network with the training data of the previous task can protect the network from catastrophic forgetting. Since rehearsing requires the storage of entire previous data, Pseudo rehearsal was proposed, where samples belonging to the previous data are generated synthetically for rehearsal. In an image classification setting, while current techniques try to generate synthetic data that is photo-realistic, we demonstrated that Neural networks can be rehearsed on data that is not photo-realistic and still achieve good retention of the previous task. We also demonstrated that forgoing the constraint of having photo realism in the generated data can result in a significant reduction in the consumption of computational and memory resources for pseudo rehearsal.},
archivePrefix = {arXiv},
arxivId = {2004.13414},
author = {{Sri Harsha Suri}, Bhasker and Yeturu, Kalidas},
eprint = {2004.13414},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sri Harsha Suri, Yeturu - 2020 - Pseudo rehearsal using non photo-realistic images.pdf:pdf},
journal = {arXiv},
title = {{Pseudo rehearsal using non photo-realistic images}},
year = {2020}
}
@article{Maltoni2016a,
abstract = {Recent works demonstrated the usefulness of temporal coherence to regularize supervised training or to learn invariant features with deep architectures. In particular, enforcing a smooth output change while presenting temporally-closed frames from video sequences, proved to be an effective strategy. In this paper we prove the efficacy of temporal coherence for semi-supervised incremental tuning. We show that a deep architecture, just mildly trained in a supervised manner, can progressively improve its classification accuracy, if exposed to video sequences of unlabeled data. The extent to which, in some cases, a semi-supervised tuning allows to improve classification accuracy (approaching the supervised one) is somewhat surprising. A number of control experiments pointed out the fundamental role of temporal coherence.},
archivePrefix = {arXiv},
arxivId = {1511.03163},
author = {Maltoni, Davide and Lomonaco, Vincenzo},
doi = {10.1109/ICPR.2016.7900013},
eprint = {1511.03163},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maltoni, Lomonaco - 2016 - Semi-supervised tuning from temporal coherence.pdf:pdf},
isbn = {9781509048472},
issn = {10514651},
journal = {Proceedings - International Conference on Pattern Recognition},
keywords = {Deep learning,Incremental tuning,Self-training,Temporal coherence,continual learning},
mendeley-tags = {continual learning},
pages = {2509--2514},
title = {{Semi-supervised tuning from temporal coherence}},
year = {2016}
}
@article{Metawa2016,
author = {Metawa, Noura and Elhoseny, Mohamed and Hassan, M. Kabir and Hassanien, Aboul Ella},
doi = {10.1109/ICENCO.2016.7856446},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Metawa et al. - 2016 - Loan portfolio optimization using Genetic Algorithm A case of credit constraints.pdf:pdf},
isbn = {978-1-5090-2863-4},
journal = {2016 12th International Computer Engineering Conference (ICENCO)},
keywords = {- bank lending,bank profit,credit con,genetic algorithm,straints},
pages = {59--64},
title = {{Loan portfolio optimization using Genetic Algorithm: A case of credit constraints}},
url = {http://ieeexplore.ieee.org/document/7856446/},
year = {2016}
}
@article{Li2018,
author = {Li, Wenyan and Buhrow, Jerry and Jolley, Scott and Calle, Luz and Pearman, Benjamin and Zhang, Xuejun and Qna, Esc-team and NASA},
keywords = {corrosion,corrosion control,corrosion detection,corrosion indicator,corrosion inhibitor,corrosion protective coatings,corrosion sensing coating,microcapsule,microencapsulation,microparticle,ph-sensitive microcapsule,smart coating},
title = {{Microencapsulation Technologies for Corrosion Protective Coating Applications}},
year = {2018}
}
@article{Rudajevova,
author = {Rudajevov{\'{a}}, A},
doi = {10.1016/j.ijthermalsci.2007.10.009},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rudajevov{\'{a}} - Unknown - Shape Memory Alloy.pdf:pdf},
keywords = {1 ga 19,1243,1248,2008,3,3v,6 mn 27,com,conductivity of ni 53,elsevier,ernational journal of thermal,ijts,locate,ni 53,p{\'{i}},p{\'{i}}biect,sciences 47,thermal diffusivity and thermal,www,{\"{u}}s},
number = {2008},
pages = {1243--1248},
title = {{Shape Memory Alloy}},
volume = {47}
}
@incollection{Castro2018,
abstract = {Although deep learning approaches have stood out in recent years due to their state-of-the-art results, they continue to suffer from catastrophic forgetting, a dramatic decrease in overall performance when training with new classes added incrementally. This is due to current neural network architectures requiring the entire dataset, consisting of all the samples from the old as well as the new classes, to update the model—a requirement that becomes easily unsustainable as the number of classes grows. We address this issue with our approach to learn deep neural networks incrementally, using new data and only a small exemplar set corresponding to samples from the old classes. This is based on a loss composed of a distillation measure to retain the knowledge acquired from the old classes, and a cross-entropy loss to learn the new classes. Our incremental training is achieved while keeping the entire framework end-to-end, i.e., learning the data representation and the classifier jointly, unlike recent methods with no such guarantees. We evaluate our method extensively on the CIFAR-100 and ImageNet (ILSVRC 2012) image classification datasets, and show state-of-the-art performance.},
archivePrefix = {arXiv},
arxivId = {1807.09536},
author = {Castro, Francisco M. and Mar{\'{i}}n-Jim{\'{e}}nez, Manuel J. and Guil, Nicol{\'{a}}s and Schmid, Cordelia and Alahari, Karteek},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-030-01258-8_15},
eprint = {1807.09536},
file = {:home/user/Downloads/1807.09536.pdf:pdf},
isbn = {9783030012571},
issn = {16113349},
keywords = {CNN,Distillation loss,Image classification,Incremental learning,continual learning,incremental learning,rehearsal,replay},
mendeley-tags = {continual learning,incremental learning,rehearsal,replay},
pages = {241--257},
title = {{End-to-End Incremental Learning}},
url = {http://link.springer.com/10.1007/978-3-030-01258-8_15},
volume = {11216 LNCS},
year = {2018}
}
@article{Zavadskas2017,
abstract = {Managerial decisions should be made by taking into account the priorities and objectives of different stakeholders' groups. Their preferences are usually expressed in words and are fuzzy concepts. This article analyses the peculiarities of companies' work and decision - making within a fuzzy market situation. It also presents a developed fuzzy multi-criteria group decision-making model for practical problem solving by taking into account cost-effective management. This case study presents a selection of rational criteria set to use in the weighted cost-effectiveness analysis for facilities management strategies, in which integrated fuzzy multi-criteria decision-making methods are applied. The main findings are: the model is adopted to real- life; the main criteria groups are identified by a three-step Delphi technique; a rational strategy is determined and integrated in one model by the concept of Minkowski distance and fuzzy TOPSIS method, ARAS-F and fuzzy weighted product method. The proposed model is versatile and therefore can be applied for various problems were the experts' knowledge needed for decision–making.},
author = {Zavadskas, Edmundas Kazimieras and Turskis, Zenonas and Vilutienė, Tatjana and Lepkova, Natalija},
doi = {10.1016/j.eswa.2017.03.072},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zavadskas et al. - 2017 - Integrated group fuzzy multi-criteria model Case of facilities management strategy selection.pdf:pdf},
isbn = {0957-4174},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {ARAS-F,Experts,Facilities management,Fuzzy multi-criteria decision-making,TOPSIS-F,Weighted Product Model},
pages = {317--331},
title = {{Integrated group fuzzy multi-criteria model: Case of facilities management strategy selection}},
volume = {82},
year = {2017}
}
@article{Li2019a,
abstract = {The success of CNNs in various applications is accompanied by a significant increase in the computation and parameter storage costs. Recent efforts toward reducing these overheads involve pruning and compressing the weights of various layers without hurting original accuracy. However, magnitude-based pruning of weights reduces a significant number of parameters from the fully connected layers and may not adequately reduce the computation costs in the convolutional layers due to irregular sparsity in the pruned networks. We present an acceleration method for CNNs, where we prune filters from CNNs that are identified as having a small effect on the output accuracy. By removing whole filters in the network together with their connecting feature maps, the computation costs are reduced significantly. In contrast to pruning weights, this approach does not result in sparse connectivity patterns. Hence, it does not need the support of sparse convolution libraries and can work with existing efficient BLAS libraries for dense matrix multiplications. We show that even simple filter pruning techniques can reduce inference costs for VGG-16 by up to 34% and ResNet-110 by up to 38% on CIFAR10 while regaining close to the original accuracy by retraining the networks.},
archivePrefix = {arXiv},
arxivId = {1608.08710},
author = {Li, Hao and Samet, Hanan and Kadav, Asim and Durdanovic, Igor and Graf, Hans Peter},
eprint = {1608.08710},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2019 - Pruning filters for efficient convnets.pdf:pdf},
journal = {5th International Conference on Learning Representations, ICLR 2017 - Conference Track Proceedings},
number = {2016},
pages = {1--13},
title = {{Pruning filters for efficient convnets}},
year = {2019}
}
@article{Chaquet2013,
abstract = {Vision-based human action and activity recognition has an increasing importance among the computer vision community with applications to visual surveillance, video retrieval and human-computer interaction. In recent years, more and more datasets dedicated to human action and activity recognition have been created. The use of these datasets allows us to compare different recognition systems with the same input data. The survey introduced in this paper tries to cover the lack of a complete description of the most important public datasets for video-based human activity and action recognition and to guide researchers in the election of the most suitable dataset for benchmarking their algorithms. {\textcopyright} 2013 Elsevier Inc. All rights reserved.},
author = {Chaquet, Jose M. and Carmona, Enrique J. and Fern{\'{a}}ndez-Caballero, Antonio},
doi = {10.1016/j.cviu.2013.01.013},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chaquet, Carmona, Fern{\'{a}}ndez-Caballero - 2013 - A survey of video datasets for human action and activity recognition.pdf:pdf},
isbn = {10773142},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
keywords = {Database,Dataset,Human action recognition,Human activity recognition,Review,Survey},
number = {6},
pages = {633--659},
pmid = {115899833},
publisher = {Elsevier Inc.},
title = {{A survey of video datasets for human action and activity recognition}},
url = {http://dx.doi.org/10.1016/j.cviu.2013.01.013},
volume = {117},
year = {2013}
}
@article{Kuttler2019,
abstract = {TorchBeast is a platform for reinforcement learning (RL) research in PyTorch. It implements a version of the popular IMPALA algorithm for fast, asynchronous, parallel training of RL agents. Additionally, TorchBeast has simplicity as an explicit design goal: We provide both a pure-Python implementation ("MonoBeast") as well as a multi-machine high-performance version ("PolyBeast"). In the latter, parts of the implementation are written in C++, but all parts pertaining to machine learning are kept in simple Python using PyTorch, with the environments provided using the OpenAI Gym interface. This enables researchers to conduct scalable RL research using TorchBeast without any programming knowledge beyond Python and PyTorch. In this paper, we describe the TorchBeast design principles and implementation and demonstrate that it performs on-par with IMPALA on Atari. TorchBeast is released as an open-source package under the Apache 2.0 license and is available at \url{https://github.com/facebookresearch/torchbeast}.},
archivePrefix = {arXiv},
arxivId = {1910.03552},
author = {K{\"{u}}ttler, Heinrich and Nardelli, Nantas and Lavril, Thibaut and Selvatici, Marco and Sivakumar, Viswanath and Rockt{\"{a}}schel, Tim and Grefenstette, Edward},
eprint = {1910.03552},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/K{\"{u}}ttler et al. - 2019 - TorchBeast A PyTorch Platform for Distributed RL.pdf:pdf},
pages = {1--10},
title = {{TorchBeast: A PyTorch Platform for Distributed RL}},
url = {http://arxiv.org/abs/1910.03552},
year = {2019}
}
@article{Delchambre-Demoncheaux2011,
abstract = {Experiments and theoretical investigations of surface temperature measurement in the medium and long wavelength infrared range carried out on MAST show that a nonhomogenous surface temperature distribution due to the surface state (micro-metric hot-spots and/or surface roughness) can lead to a significant difference (up to ∼40%) between both wavelengths. The over-estimation of the bulk temperature decreases with wavelength and the discrepancy observed on MAST can be reproduced using a hot-spot simulation model, by varying the dust size and the dust coverage such that a coverage of 0.2‰ with 1 $\mu$m dust size which is consistent with the observations. The over-estimation of the bulk temperature is assessed at medium and long wavelength as a function of dust contribution (coverage/size). The effect is also assessed in different conditions (temperature of the bulk as well as the incident power flux). {\textcopyright} 2010 Elsevier B.V. All rights reserved.},
author = {Delchambre-Demoncheaux, E. and Detemmerman, G. and Loarer, T. and Gauthier, E. and Dunand, G. and Gardarein, J. L. and Kirk, A. and Moncada, V. and Travere, J. M.},
doi = {10.1016/j.jnucmat.2010.11.057},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Delchambre-Demoncheaux et al. - 2011 - Surface temperature measurement in the medium and long wavelength infrared range on MAST.pdf:pdf},
issn = {00223115},
journal = {Journal of Nuclear Materials},
number = {1 SUPPL},
pages = {S1178--S1181},
publisher = {Elsevier B.V.},
title = {{Surface temperature measurement in the medium and long wavelength infrared range on MAST}},
url = {http://dx.doi.org/10.1016/j.jnucmat.2010.11.057},
volume = {415},
year = {2011}
}
@article{Zepeng2017,
abstract = {In order to solve the suspension overshoot phenomenon existing in the static regulation process of the electric vehicle with electric controlled air suspension, firstly, the relevant factors of air spring are analyzed and the characteristics of the gasbag are simulated and verified in AMESim. Secondly, the model of the electric vehicle body is analyzed according to the law of dynamics and the fuzzy control theory is used to set up the electric vehicle body model in Simulink. In the case of unbalanced load, the effectiveness of the fuzzy controller is used to simulate the phenomenon of "overshoot" in the system.},
author = {Zepeng, Gao and Jinrui, Nan and Lian, Liu and Xiaolin, Xu},
doi = {10.1016/j.egypro.2017.03.770},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zepeng et al. - 2017 - Research on Air Suspension Control System Based on Fuzzy Control.pdf:pdf},
isbn = {978-0-7695-5011-4},
issn = {18766102},
journal = {Energy Procedia},
keywords = {Suspension overshoot phenomenon,electronically controlled air suspension,fuzzy controller},
pages = {2653--2659},
publisher = {Elsevier B.V.},
title = {{Research on Air Suspension Control System Based on Fuzzy Control}},
url = {http://dx.doi.org/10.1016/j.egypro.2017.03.770},
volume = {105},
year = {2017}
}
@inproceedings{De2021,
author = {De, Kanjar and Pedersen, Marius},
booktitle = {International Conference on Computer Vision},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De, Pedersen - 2021 - Impact of Colour on Robustness of Deep Neural Networks Kanjar.pdf:pdf},
keywords = {colour impact,robustness},
mendeley-tags = {colour impact,robustness},
pages = {21--30},
title = {{Impact of Colour on Robustness of Deep Neural Networks Kanjar}},
year = {2021}
}
@article{WorldEconomicForum2016,
abstract = {[...]the reality is highly specific to the industry, region and occupation in question as well as the ability of various stakeholders to manage change.},
archivePrefix = {arXiv},
arxivId = {0803.1716},
author = {{World Economic Forum}},
doi = {10.1177/1946756712473437},
eprint = {0803.1716},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/World Economic Forum - 2016 - The Future of Jobs Employment, Skills and Workforce Strategy for the Fourth Industrial Revolution.pdf:pdf},
isbn = {978-0-08-100273-5},
issn = {08941297},
journal = {Growth Strategies},
keywords = {Business And Economics--Economic Situation And Con,Supply chains},
number = {january},
pages = {2--3},
pmid = {502955140},
title = {{The Future of Jobs Employment, Skills and Workforce Strategy for the Fourth Industrial Revolution}},
url = {http://search.proquest.com/docview/1776113790?accountid=26646%5Cnhttp://link.periodicos.capes.gov.br/sfxlcl41?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ:pqrl&atitle=3+-+THE+FUTURE+OF+JOBS&title=Growth+Strategi},
year = {2016}
}
@article{Elektro2005,
author = {Elektro, Jurusan Teknik and Teknik, Fakultas and Nuswantoro, Universitas Dian},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elektro, Teknik, Nuswantoro - 2005 - Audit energi untuk efisiensi listrik di gedung b universitas dian nuswantoro semarang.pdf:pdf},
pages = {1--7},
title = {{Audit energi untuk efisiensi listrik di gedung b universitas dian nuswantoro semarang}},
year = {2005}
}
@article{Camp2020,
abstract = {Neurons in real brains are enormously complex computational units. Among other things, they're responsible for transforming inbound electro-chemical vectors into outbound action potentials, updating the strengths of intermediate synapses, regulating their own internal states, and modulating the behavior of other nearby neurons. One could argue that these cells are the only things exhibiting any semblance of real intelligence. It is odd, therefore, that the machine learning community has, for so long, relied upon the assumption that this complexity can be reduced to a simple sum and fire operation. We ask, might there be some benefit to substantially increasing the computational power of individual neurons in artificial systems? To answer this question, we introduce Deep Artificial Neurons (DANs), which are themselves realized as deep neural networks. Conceptually, we embed DANs inside each node of a traditional neural network, and we connect these neurons at multiple synaptic sites, thereby vectorizing the connections between pairs of cells. We demonstrate that it is possible to meta-learn a single parameter vector, which we dub a neuronal phenotype, shared by all DANs in the network, which facilitates a meta-objective during deployment. Here, we isolate continual learning as our meta-objective, and we show that a suitable neuronal phenotype can endow a single network with an innate ability to update its synapses with minimal forgetting, using standard backpropagation, without experience replay, nor separate wake/sleep phases. We demonstrate this ability on sequential non-linear regression tasks.},
archivePrefix = {arXiv},
arxivId = {2011.07035},
author = {Camp, Blake and Mandivarapu, Jaya Krishna and Estrada, Rolando},
eprint = {2011.07035},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Camp, Mandivarapu, Estrada - 2020 - Continual Learning with Deep Artificial Neurons.pdf:pdf},
title = {{Continual Learning with Deep Artificial Neurons}},
url = {http://arxiv.org/abs/2011.07035},
year = {2020}
}
@article{Yu2020,
abstract = {To learn intrinsic low-dimensional structures from high-dimensional data that most discriminate between classes, we propose the principle of Maximal Coding Rate Reduction (MCR2), an information-theoretic measure that maximizes the coding rate difference between the whole dataset and the sum of each individual class. We clarify its relationships with most existing frameworks such as cross-entropy, information bottleneck, information gain, contractive and contrastive learning, and provide theoretical guarantees for learning diverse and discriminative features. The coding rate can be accurately computed from finite samples of degenerate subspace-like distributions and can learn intrinsic representations in supervised, self-supervised, and unsupervised settings in a unified manner. Empirically, the representations learned using this principle alone are significantly more robust to label corruptions in classification than those using cross-entropy, and can lead to state-of-the-art results in clustering mixed data from self-learned invariant features.},
archivePrefix = {arXiv},
arxivId = {2006.08558},
author = {Yu, Yaodong and Chan, Kwan Ho Ryan and You, Chong and Song, Chaobing and Ma, Yi},
eprint = {2006.08558},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu et al. - 2020 - Learning Diverse and Discriminative Representations via the Principle of Maximal Coding Rate Reduction.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {rate reduction,representation learning},
mendeley-tags = {rate reduction,representation learning},
pages = {1--28},
title = {{Learning Diverse and Discriminative Representations via the Principle of Maximal Coding Rate Reduction}},
url = {https://github.com/ryanchankh/mcr2},
year = {2020}
}
@article{Raghu2019,
abstract = {Transfer learning from natural image datasets, particularly ImageNet, using standard large models and corresponding pretrained weights has become a de-facto method for deep learning applications to medical imaging. However, there are fundamental differences in data sizes, features and task specifications between natural image classification and the target medical tasks, and there is little understanding of the effects of transfer. In this paper, we explore properties of transfer learning for medical imaging. A performance evaluation on two large scale medical imaging tasks shows that surprisingly, transfer offers little benefit to performance, and simple, lightweight models can perform comparably to ImageNet architectures. Investigating the learned representations and features, we find that some of the differences from transfer learning are due to the over-parametrization of standard models rather than sophisticated feature reuse. We isolate where useful feature reuse occurs, and outline the implications for more efficient model exploration. We also explore feature independent benefits of transfer arising from weight scalings.},
archivePrefix = {arXiv},
arxivId = {1902.07208},
author = {Raghu, Maithra and Zhang, Chiyuan and Kleinberg, Jon and Bengio, Samy},
eprint = {1902.07208},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Raghu et al. - 2019 - Transfusion Understanding Transfer Learning for Medical Imaging.pdf:pdf},
number = {NeurIPS},
title = {{Transfusion: Understanding Transfer Learning for Medical Imaging}},
url = {http://arxiv.org/abs/1902.07208},
year = {2019}
}
@article{Yang2017,
abstract = {Deep convolutional neural networks (CNNs) are indispensable to state-of-the-art computer vision algorithms. However, they are still rarely deployed on battery-powered mobile devices, such as smartphones and wearable gadgets, where vision algorithms can enable many revolutionary real-world applications. The key limiting factor is the high energy consumption of CNN processing due to its high computational complexity. While there are many previous efforts that try to reduce the CNN model size or the amount of computation, we find that they do not necessarily result in lower energy consumption. Therefore, these targets do not serve as a good metric for energy cost estimation. To close the gap between CNN design and energy consumption optimization, we propose an energy-aware pruning algorithm for CNNs that directly uses the energy consumption of a CNN to guide the pruning process. The energy estimation methodology uses parameters extrapolated from actual hardware measurements. The proposed layer-by-layer pruning algorithm also prunes more aggressively than previously proposed pruning methods by minimizing the error in the output feature maps instead of the filter weights. For each layer, the weights are first pruned and then locally fine-tuned with a closed-form least-square solution to quickly restore the accuracy. After all layers are pruned, the entire network is globally fine-tuned using back-propagation. With the proposed pruning method, the energy consumption of AlexNet and GoogLeNet is reduced by 3.7× and 1.6×, respectively, with less than 1% top-5 accuracy loss. We also show that reducing the number of target classes in AlexNet greatly decreases the number of weights, but has a limited impact on energy consumption.},
archivePrefix = {arXiv},
arxivId = {1611.05128},
author = {Yang, Tien Ju and Chen, Yu Hsin and Sze, Vivienne},
doi = {10.1109/CVPR.2017.643},
eprint = {1611.05128},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang, Chen, Sze - 2017 - Designing energy-efficient convolutional neural networks using energy-aware pruning.pdf:pdf},
isbn = {9781538604571},
journal = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
pages = {6071--6079},
title = {{Designing energy-efficient convolutional neural networks using energy-aware pruning}},
volume = {2017-Janua},
year = {2017}
}
@article{Heintzman2014,
abstract = {This article synthesizes empirical studies that explain the relation-ship between nature-based recreation and spirituality for persons with disabilities. In order to describe this relationship, a theoret-ical model, which includes the components of antecedent condi-tions, setting, and recreation, is developed. Antecedent conditions include history and current circumstances, motivation, sociodemo-graphic characteristics, and spiritual tradition. Setting components include being in nature, being away to a different environment, and place processes. Recreation components include activity, free time, solitude, and group experiences. The article further explains how these conditions and components may lead to outcomes of spir-itual experiences, spiritual well-being, and leisure-spiritual coping. Leisure-spiritual coping, which is particularly relevant for persons who are experiencing stress, refers to spiritual coping that takes place within the context of a person's leisure. This model illustrates the complexity of the nature-based recreation and spirituality re-lationship. Recommendations for future research and implications for practitioners who work with people who have disabilities are outlined.},
author = {Heintzman, Paul},
doi = {10.1080/15228967.2014.868983},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Heintzman - 2014 - Nature-based recreation, spirituality, and persons with disabilities.pdf:pdf},
isbn = {01490400},
issn = {2331253X},
journal = {Journal of Disability and Religion},
keywords = {Disabilities,Leisure,Nature,Recreation,Spirituality},
number = {1},
pages = {97--116},
pmid = {49151820},
title = {{Nature-based recreation, spirituality, and persons with disabilities}},
volume = {18},
year = {2014}
}
@article{Ngamcharussrivichai2010,
abstract = {Transesterification of palm kernel oil (PKO) with methanol over various natural calciums, including limestone calcite, cuttlebone, dolomite, hydroxyapatite, and dicalcium phosphate, has been investigated at 60 °C and 1 atm. The study showed that dolomite, mainly consisting of CaCO3 and MgCO3, is the most active catalyst. The calcination temperature largely affected the physicochemical properties, as evidenced by N2 adsorption-desorption measurement, TGA, SEM and XRD, and the transesterification performance of the resultant catalysts. It was found that the calcination of dolomite at 800 °C resulted in a highly active mixed oxide. CaO was suggested to be the catalytically active site responsible for the methyl ester formation. Under the suitable reaction conditions, the amount of dolomite calcined at 800 °C = 6 wt.% based on the weight of oil, the methanol/oil molar ratio = 30, and the reaction time = 3 h, the methyl ester content of 98.0% can be achieved. The calcined dolomite can be reused many times. The analyses of some important fuel properties indicated that the biodiesel produced had the properties that meet the standard of biodiesel and diesel fuel issued by the Department of Energy Business, Ministry of Energy, Thailand. {\textcopyright} 2010 Elsevier B.V.},
author = {Ngamcharussrivichai, Chawalit and Nunthasanti, Pramwit and Tanachai, Sithikorn and Bunyakiat, Kunchana},
doi = {10.1016/j.fuproc.2010.05.014},
isbn = {0378-3820},
issn = {03783820},
journal = {Fuel Processing Technology},
keywords = {Biodiesel,Calcium oxide,Dolomite,Transesterification},
number = {11},
pages = {1409--1415},
publisher = {Elsevier B.V.},
title = {{Biodiesel production through transesterification over natural calciums}},
url = {http://dx.doi.org/10.1016/j.fuproc.2010.05.014},
volume = {91},
year = {2010}
}
@article{Liu2017b,
abstract = {Convolutional Neural Networks (CNNs) are compute intensive which limits their application on mobile devices. Their energy is dominated by the number of mul-tiplies needed to perform the convolutions. Winograd's minimal filtering algo-rithm (Lavin (2015)) and network pruning (Han et al. (2015)) reduce the operation count. Unfortunately, these two methods cannot be combined — because applying the Winograd transform fills in the sparsity in both the weights and the activations. We propose two modifications to Winograd-based CNNs to enable these methods to exploit sparsity. First, we prune the weights in the " Winograd domain " (after the transform) to exploit static weight sparsity. Second, we move the ReLU op-eration into the " Winograd domain " to improve the sparsity of the transformed activations. On CIFAR-10, our method reduces the number of multiplications in the VGG-nagadomi model by 10.2× with no loss of accuracy.},
author = {Liu, Xingyu and Han, Song and Mao, Huizi and Dally, William J},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2017 - Workshop track -ICLR 2017 EFFICIENT SPARSE-WINOGRAD CONVOLUTIONAL NEURAL NETWORKS.pdf:pdf},
pages = {2--5},
title = {{Workshop track -ICLR 2017 EFFICIENT SPARSE-WINOGRAD CONVOLUTIONAL NEURAL NETWORKS}},
year = {2017}
}
@article{Madaan2021,
abstract = {Continual learning (CL) aims to learn a sequence of tasks without forgetting the previously acquired knowledge. However, recent advances in continual learning are restricted to supervised continual learning (SCL) scenarios. Consequently, they are not scalable to real-world applications where the data distribution is often biased and unannotated. In this work, we focus on unsupervised continual learning (UCL), where we learn the feature representations on an unlabelled sequence of tasks and show that reliance on annotated data is not necessary for continual learning. We conduct a systematic study analyzing the learned feature representations and show that unsupervised visual representations are surprisingly more robust to catastrophic forgetting, consistently achieve better performance, and generalize better to out-of-distribution tasks than SCL. Furthermore, we find that UCL achieves a smoother loss landscape through qualitative analysis of the learned representations and learns meaningful feature representations. Additionally, we propose Lifelong Unsupervised Mixup (LUMP), a simple yet effective technique that leverages the interpolation between the current task and previous tasks' instances to alleviate catastrophic forgetting for unsupervised representations.},
archivePrefix = {arXiv},
arxivId = {2110.06976},
author = {Madaan, Divyam and Yoon, Jaehong and Li, Yuanchun and Liu, Yunxin and Hwang, Sung Ju},
eprint = {2110.06976},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Madaan et al. - 2021 - Rethinking the Representational Continuity Towards Unsupervised Continual Learning.pdf:pdf},
keywords = {continual learning},
mendeley-tags = {continual learning},
pages = {1--17},
title = {{Rethinking the Representational Continuity: Towards Unsupervised Continual Learning}},
url = {http://arxiv.org/abs/2110.06976},
year = {2021}
}
@book{Fuente2014,
abstract = {In Arabic, as in many languages, the future is “ahead” and the past is “behind.” Yet in the research reported here, we showed that Arabic speakers tend to conceptualize the future as behind and the past as ahead of them, despite using spoken metaphors that suggest the opposite. We propose a new account of how space-time mappings become activated in individuals' minds and entrenched in their cultures, the temporal-focus hypothesis: People should conceptualize either the future or the past as in front of them to the extent that their culture (or subculture) is future oriented or past oriented. Results support the temporal-focus hypothesis, demonstrating that the space-time mappings in people's minds are conditioned by their cultural attitudes toward time, that they depend on attentional focus, and that they can vary independently of the space-time mappings enshrined in language. Keywords},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Fuente, Juanma De La and Santiago, Julio and Rom{\'{a}}n, Antonio and Dumitrache, Cristina and Casasanto, Daniel},
booktitle = {Psychological Science},
doi = {10.1007/s13398-014-0173-7.2},
eprint = {arXiv:1011.1669v3},
isbn = {9780874216561},
issn = {1467-9280},
keywords = {conceptual metaphor,cross-cultural differences,mental models,open data,space,time},
number = {9},
pages = {1682--1690},
pmid = {25052830},
title = {{Handbook of dielectric, piezoelectric and ferroelectric materials Synthesis, properties and applications}},
volume = {25},
year = {2014}
}
@article{Li2017b,
abstract = {In recent years, there has been growing interest in reducing energy consumption and emissions of manufacturing systems. Except for adopting new equipment or techniques, scheduling is crucial to reduce the total energy consumption of manufacturing systems. This paper focuses on the scheduling problem for flexible manufacturing systems (FMSs) with the objective of minimizing the total energy consumption, and proposes a novel scheduling algorithm for FMSs based on Petri net models and genetic algorithm. Considering that energy consumptions in different states of resources are different, this paper takes two ways for calculating total energy consumptions. In the proposed genetic algorithm, a potential schedule is represented by a chromosome consisting of route selection and operation sequence. Crossover and mutation operations are performed on the operation sequence to guarantee the population diversity. For deadlock-prone FMSs, not all chromosomes can be directly decoded to a feasible schedule. To check the feasibility of chromosomes and convert infeasible chromosomes into feasible ones, a repair algorithm is developed with the help of the deadlock avoidance policy. Experiment results on a typical FMS and an industrial stamping system are provided to show the effectiveness of our proposed scheduling algorithm.},
author = {Li, Xiaoling and Xing, Keyi and Wu, Yunchao and Wang, Xinnian and Luo, Jianchao},
doi = {10.1016/j.cie.2016.12.008},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2017 - Total energy consumption optimization via genetic algorithm in flexible manufacturing systems.pdf:pdf},
issn = {03608352},
journal = {Computers and Industrial Engineering},
keywords = {Flexible manufacturing system,Genetic algorithm,Petri net,Scheduling,Total energy consumption optimization},
pages = {188--200},
publisher = {Elsevier Ltd},
title = {{Total energy consumption optimization via genetic algorithm in flexible manufacturing systems}},
url = {http://dx.doi.org/10.1016/j.cie.2016.12.008},
volume = {104},
year = {2017}
}
@article{Vats2017,
abstract = {The unresolved and paramount challenge in bio-imaging and targeted therapy is to clearly define and demarcate the physical margins of tumor tissue. The ability to outline the healthy vital tissues to be carefully navigated with transection while an intraoperative surgery procedure is performed sets up a necessary and under-researched goal. To achieve the aforementioned objectives, there is a need to optimize design considerations in order to not only obtain an effective imaging agent but to also achieve attributes like favorable water solubility, biocompatibility, high molecular brightness, and a tissue specific targeting approach. The emergence of near infra-red fluorescence (NIRF) light for tissue scale imaging owes to the provision of highly specific images of the target organ. The special characteristics of near infra-red window such as minimal auto-fluorescence, low light scattering, and absorption of biomolecules in tissue converge to form an attractive modality for cancer imaging. Imparting molecular fluorescence as an exogenous contrast agent is the most beneficial attribute of NIRF light as a clinical imaging technology. Additionally, many such agents also display therapeutic potentials as photo-thermal agents, thus meeting the dual purpose of imaging and therapy. Here, we primarily discuss molecular imaging and therapeutic potentials of two such classes of materials, i.e., inorganic NIR dyes and metallic gold nanoparticle based materials.},
author = {Vats, Mukti and Mishra, Sumit Kumar and Baghini, Mahdieh Shojaei and Chauhan, Deepak S. and Srivastava, Rohit and De, Abhijit},
doi = {10.3390/ijms18050924},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vats et al. - 2017 - Near infrared fluorescence imaging in nano-therapeutics and photo-thermal evaluation.pdf:pdf},
issn = {14220067},
journal = {International Journal of Molecular Sciences},
keywords = {Cancer,Gold nanoparticle,Molecular imaging,NIR fluorescence,Photothermal therapy},
number = {5},
pmid = {28452928},
title = {{Near infrared fluorescence imaging in nano-therapeutics and photo-thermal evaluation}},
volume = {18},
year = {2017}
}
@article{You2020,
abstract = {Neural networks are often represented as graphs of connections between neurons. However, despite their wide use, there is currently little understanding of the relationship between the graph structure of the neural network and its predictive performance. Here we systematically investigate how does the graph structure of neural networks affect their predictive performance. To this end, we develop a novel graph-based representation of neural networks called relational graph, where layers of neural network computation correspond to rounds of message exchange along the graph structure. Using this representation we show that: (1) a sweet spot of relational graphs leads to neural networks with significantly improved predictive performance; (2) neural networks performance is approximately a smooth function of the clustering coefficient and average path length of its relational graph; (3) our findings are consistent across many different tasks and datasets; (4) the sweet spot can be identified efficiently; (5) top-performing neural networks have graph structure surprisingly similar to those of real biological neural networks. Our work opens new directions for the design of neural architectures and the understanding on neural networks in general.},
archivePrefix = {arXiv},
arxivId = {2007.06559},
author = {You, Jiaxuan and Leskovec, Jure and He, Kaiming and Xie, Saining},
eprint = {2007.06559},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/You et al. - 2020 - Graph Structure of Neural Networks(2).pdf:pdf},
journal = {arXiv},
pages = {3--6},
title = {{Graph Structure of Neural Networks}},
year = {2020}
}
@article{Ranasinghe2021,
abstract = {In this paper, we propose self-supervised training for video transformers using unlabelled video data. From a given video, we create local and global spatiotemporal views with varying spatial sizes and frame rates. Our self-supervised objective seeks to match the features of these different views representing the same video, to be invariant to spatiotemporal variations in actions. To the best of our knowledge, the proposed approach is the first to alleviate the dependency on negative samples or dedicated memory banks in Self-supervised Video Transformer (SVT). Further, owing to the flexibility of Transformer models, SVT supports slow-fast video processing within a single architecture using dynamically adjusted positional encodings and supports long-term relationship modeling along spatiotemporal dimensions. Our approach performs well on four action recognition benchmarks (Kinetics-400, UCF-101, HMDB-51, and SSv2) and converges faster with small batch sizes. Code: https://git.io/J1juJ},
archivePrefix = {arXiv},
arxivId = {2112.01514},
author = {Ranasinghe, Kanchana and Naseer, Muzammal and Khan, Salman and Khan, Fahad Shahbaz and Ryoo, Michael},
eprint = {2112.01514},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ranasinghe et al. - 2021 - Self-supervised Video Transformer.pdf:pdf},
keywords = {self-supervised learning,video understanding},
mendeley-tags = {self-supervised learning,video understanding},
title = {{Self-supervised Video Transformer}},
url = {http://arxiv.org/abs/2112.01514},
year = {2021}
}
@article{Viriya-Empikul2012,
abstract = {The solid oxide catalysts derived from the industrial waste shells of egg, golden apple snail, and meretrix venus were used as biodiesel production catalysts. Their catalytic activity in transesterification of palm olein oils and their physicochemical properties (by TG/DTA, EDX, SEM, N2sorption, CO2-TPD, and XRD) were systematically investigated. The waste materials calcined in air with optimum conditions (temperature of 800 °C, time of 2-4 h) transformed calcium species in the shells into active CaO catalysts. The activity of the catalysts was in line with the basic amount of the strong base sites, surface area, and crystalline phase in the catalysts. All catalysts derived from egg and mollusk shells at 800 °C provided high activity (>90% fatty acid methyl ester (FAME) in 2 h). These abundant wastes showed good potential to be used as biodiesel production catalysts. {\textcopyright} 2011 Elsevier Ltd. All rights reserved.},
author = {Viriya-Empikul, N. and Krasae, P. and Nualpaeng, W. and Yoosuk, B. and Faungnawakij, K.},
doi = {10.1016/j.fuel.2011.07.013},
isbn = {0016-2361},
issn = {00162361},
journal = {Fuel},
keywords = {Basicity,CO2poisoning,Egg and mollusk shells,Heterogeneous catalyst,Transesterification},
number = {1},
pages = {239--244},
publisher = {Elsevier Ltd},
title = {{Biodiesel production over Ca-based solid catalysts derived from industrial wastes}},
url = {http://dx.doi.org/10.1016/j.fuel.2011.07.013},
volume = {92},
year = {2012}
}
@article{Zhu2020,
abstract = {We investigate the representation power of graph neural networks in the semi-supervised node classification task under heterophily or low homophily, i.e., in networks where connected nodes may have different class labels and dissimilar features. Many popular GNNs fail to generalize to this setting, and are even outperformed by models that ignore the graph structure (e.g., multilayer perceptrons). Motivated by this limitation, we identify a set of key designs -- ego- and neighbor-embedding separation, higher-order neighborhoods, and combination of intermediate representations -- that boost learning from the graph structure under heterophily. We combine them into a graph neural network, H2GCN, which we use as the base method to empirically evaluate the effectiveness of the identified designs. Going beyond the traditional benchmarks with strong homophily, our empirical analysis shows that the identified designs increase the accuracy of GNNs by up to 40% and 27% over models without them on synthetic and real networks with heterophily, respectively, and yield competitive performance under homophily.},
archivePrefix = {arXiv},
arxivId = {2006.11468},
author = {Zhu, Jiong and Yan, Yujun and Zhao, Lingxiao and Heimann, Mark and Akoglu, Leman and Koutra, Danai},
eprint = {2006.11468},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu et al. - 2020 - Beyond Homophily in Graph Neural Networks Current Limitations and Effective Designs.pdf:pdf;:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu et al. - 2020 - Beyond Homophily in Graph Neural Networks Current Limitations and Effective Designs(2).pdf:pdf},
number = {NeurIPS},
pages = {13--30},
title = {{Beyond Homophily in Graph Neural Networks: Current Limitations and Effective Designs}},
url = {http://arxiv.org/abs/2006.11468},
year = {2020}
}
@article{Wei2020,
abstract = {Modern deep learning methods have achieved great success in machine learning and computer vision fields by learning a set of pre-defined datasets. Howerver, these methods perform unsatisfactorily when applied into real-world situations. The reason of this phenomenon is that learning new tasks leads the trained model quickly forget the knowledge of old tasks, which is referred to as catastrophic forgetting. Current state-of-the-art incremental learning methods tackle catastrophic forgetting problem in traditional classification networks and ignore the problem existing in embedding networks, which are the basic networks for image retrieval, face recognition, zero-shot learning, etc. Different from traditional incremental classification networks, the semantic gap between the embedding spaces of two adjacent tasks is the main challenge for embedding networks under incremental learning setting. Thus, we propose a novel class-incremental method for embedding network, named as zero-shot translation class-incremental method (ZSTCI), which leverages zero-shot translation to estimate and compensate the semantic gap without any exemplars. Then, we try to learn a unified representation for two adjacent tasks in sequential learning process, which captures the relationships of previous classes and current classes precisely. In addition, ZSTCI can easily be combined with existing regularization-based incremental learning methods to further improve performance of embedding networks. We conduct extensive experiments on CUB-200-2011 and CIFAR100, and the experiment results prove the effectiveness of our method. The code of our method has been released.},
archivePrefix = {arXiv},
arxivId = {2012.15497},
author = {Wei, Kun and Deng, Cheng and Yang, Xu and Li, Maosen},
eprint = {2012.15497},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wei et al. - 2020 - Incremental Embedding Learning via Zero-Shot Translation.pdf:pdf},
keywords = {continual learning,zero-shot learning},
mendeley-tags = {continual learning,zero-shot learning},
title = {{Incremental Embedding Learning via Zero-Shot Translation}},
url = {http://arxiv.org/abs/2012.15497 https://github.com/Drkun/ZSTCI},
year = {2020}
}
@inproceedings{Hu2021,
abstract = {Continual learning (CL) incrementally learns a sequence of tasks while solving the catastrophic forgetting (CF) problem. Existing methods mainly try to deal with CF directly. In this paper, we propose to avoid CF by considering the features of each class holistically rather than only the discriminative information for classifying the classes seen so far. This latter approach is prone to CF because the discriminative informa- tion for old classes may not be sufficiently discriminative for the new class to be learned. Consequently, in learning each new task, the network parameters for previous tasks have to be revised, which causes CF. With the holistic consideration, after adding new tasks, the system can still do well for previous tasks. The proposed technique is called Per-class Continual Learning (PCL). PCL has two key novelties. (1) It proposes a one-class learning based technique for CL, which considers features of each class holistically and represents a new ap- proach to solving the CL problem. (2) It proposes a method to extract discriminative information after training to further improve the accuracy. Empirical evaluation shows that PCL markedly outperforms the state-of-the-art baselines for one or more classes per task. More tasks also result in more gains.},
author = {Hu, Wenpeng and Qin, Qi and Wang, Mengyu and Ma, Jinwen and Liu, Bing},
booktitle = {AAAI 2021},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hu et al. - 2021 - Continual Learning by Using Information of Each Class Holistically.pdf:pdf},
keywords = {continual learning},
mendeley-tags = {continual learning},
title = {{Continual Learning by Using Information of Each Class Holistically}},
year = {2021}
}
@article{Chen2015,
abstract = {In this paper, we report 4 different saturable absorbers based on 4 transition metal dichalcogenides (MoS2, MoSe2, WS2, WSe2) and utilize them to Q-switch a ring-cavity fiber laser with identical cavity configuration. It is found that MoSe2 exhibits highest modulation depth with similar preparation process among four saturable absorbers. Q-switching operation performance is compared from the aspects of RF spectrum, optical spectrum, repetition rate and pulse duration. WS2 Q-switched fiber laser generates the most stable pulse trains compared to other 3 fiber lasers. These results demonstrate the feasibility of TMDs to Q-switch fiber laser effectively and provide a meaningful reference for further research in nonlinear fiber optics with these TMDs materials.},
archivePrefix = {arXiv},
arxivId = {arXiv:1503.08003},
author = {Chen, Bohua and Zhang, Xiaoyan and Wu, Kan and Wang, Hao and Wang, Jun and Chen, Jianping},
doi = {10.1364/OE.23.026723},
eprint = {arXiv:1503.08003},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2015 - Q-switched fiber laser based on transition metal dichalcogenides MoS_2, MoSe_2, WS_2, and WSe_2.pdf:pdf},
isbn = {1094-4087},
issn = {1094-4087},
journal = {Optics Express},
number = {20},
pages = {26723},
title = {{Q-switched fiber laser based on transition metal dichalcogenides MoS_2, MoSe_2, WS_2, and WSe_2}},
url = {https://www.osapublishing.org/abstract.cfm?URI=oe-23-20-26723},
volume = {23},
year = {2015}
}
@inproceedings{ayub2020a,
abstract = {Incremental learning attempts to develop a classifier which learns continuously from a stream of data segregated into different classes. Deep learning approaches suffer from catastrophic forgetting when learning classes incrementally, while most incremental learning approaches require a large amount of training data per class. We examine the problem of incremental learning using only a few training examples, referred to as Few-Shot Incremental Learning (FSIL). To solve this problem, we propose a novel approach inspired by the concept learning model of the hippocampus and the neocortex that represents each image class as centroids and does not suffer from catastrophic forgetting. We evaluate our approach on three class-incremental learning benchmarks: Caltech-101, CUBS-200-2011 and CIFAR-100 for incremental and few-shot incremental learning and show that our approach achieves state-of-the-art results in terms of classification accuracy over all learned classes.},
author = {Ayub, A. and Wagner, A. R.},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ayub, Wagner - 2020 - Cognitively-Inspired Model for Incremental Learning Using a Few Examples.pdf:pdf},
keywords = {catastrophic forgetting,cognitive-inspired,cognitively-inspired learning,continual learning,few-shot learning,incremental learning},
mendeley-tags = {cognitive-inspired,continual learning,few-shot learning,incremental learning},
title = {{Cognitively-Inspired Model for Incremental Learning Using a Few Examples}},
url = {https://openaccess.thecvf.com/content_CVPRW_2020/html/w15/Ayub_Cognitively-Inspired_Model_for_Incremental_Learning_Using_a_Few_Examples_CVPRW_2020_paper.html https://github.com/aliayub7/CBCL},
year = {2020}
}
@article{Krug2007,
abstract = {Many believe the levels of confidence eyewitness' express when identifying crimi- nal suspects in lineups or testifying in trials make good predictors of their memory accu- racy. Traditionally known as the confidence-accuracy (CA) relationship, the assumption is that as one's confidence increases so does thier level of accuracy. The research litera- ture has addressed the CA relationship along three main lines: examining rates of confi- dence and accuracy in memory for general knowledge (factual information), determining if the CA relationship can be divided into subsections in which performance levels are consistent, and developing measures to raise the value of the CA relationship. The lit- erature outlining the role of the CA relationship in criminal suspect identification is in- deed extensive, but there is little mention of a new field of interest in which the CA rela- tionship is applied to eyewitness memory for product brand names. While},
author = {Krug, Kevin},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krug - 2007 - The relationship between confidence and accuracy Current thoughts of the literature and a new area of research.pdf:pdf},
issn = {15503550},
journal = {Applied Psychology in Criminal Justice},
keywords = {confidence ratings,confidence-accuracy,memory},
number = {1},
pages = {7--41},
title = {{The relationship between confidence and accuracy: Current thoughts of the literature and a new area of research}},
url = {http://www.apcj.org/documents/3_1_confidenceandaccuracy.pdf},
volume = {3},
year = {2007}
}
@article{Berger1988,
abstract = {The influence of exercise mode and practice qualities on the stress reduction benefits of exercise was examined. College students in swimming, body conditioning, hatha yoga, fencing, exercise, and lecture-control classes completed the Profile of Mood States and the State Anxiety Inventory before and after class on three occasions. Swimmers had unusually positive initial moods and reported less tension and confusion after swimming only on the first day of testing. Participants in yoga, an anaerobic activity that satisfied three of the four mode requirements, were significantly less anxious, tense, depressed, angry, fatigued, and confused after class than before on all three occasions. Supporting the importance of the four mode characteristics, participants in the exercise control activity of fencing reported improvements only in vigor. A possible influence of practice conditions was observed when members of the body conditioning class reported significant increases in fatigue, but no other mood changes. Results of this study supported the possibility that exercise mode and practice requirements in the proposed taxonomy moderate the stress reduction benefits.},
author = {Berger, Bonnie G. and Owen, David R.},
doi = {10.1080/02701367.1988.10605493},
isbn = {0270-1367},
issn = {21683824},
journal = {Research Quarterly for Exercise and Sport},
number = {2},
pages = {148--159},
title = {{Stress reduction and mood enhancement in four exercise modes: Swimming, body conditioning, hatha yoga, and fencing}},
volume = {59},
year = {1988}
}
@article{Rubio2017,
abstract = {We propose using new weighted operators in fuzzy time series to forecast the future performance of stock market indices. Based on the chronological sequence of weights associated with the original fuzzy logical relationships, we define both chronological-order and trend-order weights, and incorporate our proposals for the ex-post forecast into the classical modeling approach of fuzzy time series. These modifications for the assignation of weights affect the forecasting process, because we use jumps as technical indicators to predict stock trends, and additionally, they provide a trapezoidal fuzzy number as a forecast of the future performance of the stock index value. Working with trapezoidal fuzzy numbers allows us to analyze both the expected value and the ambiguity of the future behavior of the stock index, using a possibilistic interval-valued mean approach. Therefore, using fuzzy logic more useful information is provided to the decision analyst, which should be appropriate in a financial context. We analyze the effectiveness of our approach with respect to other weighted fuzzy time series methods using trading data sets from the Taiwan Stock Index (TAIEX), the Japanese NIKKEI Index, the German Stock Index (DAX) and the Spanish Stock Index (IBEX35). The comparative results indicate the better accuracy of our procedure for point-wise one-step ahead forecasts.},
author = {Rubio, Abel and Berm{\'{u}}dez, Jos{\'{e}} D. and Vercher, Enriqueta},
doi = {10.1016/j.eswa.2017.01.049},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rubio, Berm{\'{u}}dez, Vercher - 2017 - Improving stock index forecasts by using a new weighted fuzzy-trend time series method.pdf:pdf},
isbn = {0957-4174},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Forecasting,Fuzzy numbers,Fuzzy time series,Stock market indices,Trend analysis},
pages = {12--20},
publisher = {Elsevier Ltd},
title = {{Improving stock index forecasts by using a new weighted fuzzy-trend time series method}},
url = {http://dx.doi.org/10.1016/j.eswa.2017.01.049},
volume = {76},
year = {2017}
}
@article{Radhakrishnan2009,
abstract = {Problem statement: Today, inventory management is considered to be an important field in Supply chain management. Once the efficient and effective management of inventory is carried out throughout the supply chain, service provided to the customer ultimately gets enhanced. Hence, to ensure minimal cost for the supply chain, the determination of the level of inventory to be held at various levels in a supply chain is unavoidable. Minimizing the total supply chain cost refers to the reduction of holding and shortage cost in the entire supply chain. Efficient inventory management is a complex process which entails the management of the inventory in the whole supply chain and getting the final solution as an optimal one. In other words, during the process of supply chain management, the stock level at each member of the supply chain should account to minimum total supply chain cost. The dynamic nature of the excess stock level and shortage level over all the periods is a serious issue when implementation was considered. In addition, consideration of multiple products leads to very complex inventory management process. The complexity of the problem increases when more distribution centers and agents were involved. Approach: In present research, the issues of inventory management had been focused and a novel approach based on genetic algorithm had been proposed in which the most probable excess stock level and shortage level required for inventory optimization in the supply chain is distinctively determined so as to achieve minimum total supply chain cost. Results: The analysis provided us with an inventory level that made a remarkable contribution towards the increase of supply chain cost. We predicted the optimal inventory levels in all the supply chain members with the aid of these levels. Conclusion: We concluded that it is possible to minimize the supply chain cost by maintaining the optimal stock levels that we predicted from the inventory analysis. This will make the inventory management further effective and efficient thereby enhancing the customer servicing levels. [ABSTRACT FROM AUTHOR] Copyright of Journal of Computer Science is the property of Science Publications and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
author = {Radhakrishnan, P. and Prasad, V. M. and Gopalan, M. R.},
doi = {10.3844/jcssp.2009.233.241},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Radhakrishnan, Prasad, Gopalan - 2009 - Optimizing inventory using genetic algorithm for efficient supply chain management.pdf:pdf},
isbn = {15493636},
issn = {15493636},
journal = {Journal of Computer Science},
keywords = {Genetic algorithm,Inventory control,Inventory optimization,Supply chain cost,Supply chain management},
number = {3},
pages = {233--241},
pmid = {39241853},
title = {{Optimizing inventory using genetic algorithm for efficient supply chain management}},
volume = {5},
year = {2009}
}
@inproceedings{Douillard2020b,
abstract = {Deep learning approaches are nowadays ubiquitously used to tackle computer vision tasks such as semantic segmentation, requiring large datasets and substantial computational power. Continual learning for semantic segmentation (CSS) is an emerging trend that consists in updating an old model by sequentially adding new classes. However, continual learning methods are usually prone to catastrophic forgetting. This issue is further aggravated in CSS where, at each step, old classes from previous iterations are collapsed into the background. In this paper, we propose Local POD, a multi-scale pooling distillation scheme that preserves long- and short-range spatial relationships at feature level. Furthermore, we design an entropy-based pseudo-labelling of the background w.r.t. classes predicted by the old model to deal with background shift and avoid catastrophic forgetting of the old classes. Our approach, called PLOP, significantly outperforms state-of-the-art methods in existing CSS scenarios, as well as in newly proposed challenging benchmarks.},
archivePrefix = {arXiv},
arxivId = {2011.11390},
author = {Douillard, Arthur and Chen, Yifu and Dapogny, Arnaud and Cord, Matthieu},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
eprint = {2011.11390},
file = {:home/user/Downloads/2011.11390.pdf:pdf},
issn = {23318422},
keywords = {continual learning,incremental learning,semantic segmentation},
mendeley-tags = {continual learning,incremental learning,semantic segmentation},
title = {{PLOP: Learning without forgetting for continual semantic segmentation}},
year = {2021}
}
@article{Daruna2021,
abstract = {In recent years, there has been a resurgence in methods that use distributed (neural) representations to represent and reason about semantic knowledge for robotics applications. However, while robots often observe previously unknown concepts, these representations typically assume that all concepts are known a priori, and incorporating new information requires all concepts to be learned afresh. Our work relaxes the static assumptions of these representations to tackle the incremental knowledge graph embedding problem by leveraging principles of a range of continual learning methods. Through an experimental evaluation with several knowledge graphs and embedding representations, we provide insights about trade-offs for practitioners to match a semantics-driven robotics application to a suitable continual knowledge graph embedding method.},
archivePrefix = {arXiv},
arxivId = {2101.05850},
author = {Daruna, Angel and Gupta, Mehul and Sridharan, Mohan and Chernova, Sonia},
eprint = {2101.05850},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Daruna et al. - 2021 - Continual Learning of Knowledge Graph Embeddings.pdf:pdf},
keywords = {continual learning,graph},
mendeley-tags = {continual learning,graph},
title = {{Continual Learning of Knowledge Graph Embeddings}},
url = {https://arxiv.org/abs/2101.05850?s=09%0Ahttp://arxiv.org/abs/2101.05850},
year = {2021}
}
@article{Craparo2017,
abstract = {Hybrid microgrids that use renewable energy sources can improve energy security and islanding time while reducing costs. One potential beneficiary of these systems is the U.S. military, which can seek to improve energy security when operating in isolated areas by using a microgrid rather than relying on a fragile (or nonexistent) commercial network. Renewable energy sources can be intermittent and unpredictable, making it difficult to plan operations of a microgrid. We describe a scenario-robust mixed-integer linear program designed to utilize ensemble weather forecasts to improve the performance of a hybrid microgrid containing both renewable and traditional power sources. We exercise our model to quantify the benefit of using ensemble weather forecasts, and we predict the optimal performance of a hypothetical grid containing wind turbines by using simulated realistic weather forecast scenarios based on data. Because forecast quality degrades with lead time, we perform a sensitivity analysis to determine which planning horizon results in the best performance. Our results show that, for day-ahead planning, longer planning horizons outperform shorter planning horizons in terms of cost of operations, but this improvement diminishes as the planning horizon lengthens.},
author = {Craparo, Emily and Karatas, Mumtaz and Singham, Dashi I.},
doi = {10.1016/j.apenergy.2017.05.068},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Craparo, Karatas, Singham - 2017 - A robust optimization approach to hybrid microgrid operation using ensemble weather forecasts.pdf:pdf},
issn = {03062619},
journal = {Applied Energy},
keywords = {Microgrid,Renewable energy,Robust optimization},
pages = {135--147},
title = {{A robust optimization approach to hybrid microgrid operation using ensemble weather forecasts}},
url = {http://dx.doi.org/10.1016/j.apenergy.2017.05.068},
volume = {201},
year = {2017}
}
@article{Boran2016,
abstract = {While the rapid development of information technology has made easy to store and access the huge amount of data, it also brings another problem, that of how to extract potentially useful knowledge not only in an efficient way but also in a way that could be easily understandable by humans. One of the solutions to this problem is linguistic summarization, aim of which is to generate explicit and concise summaries from data that is more compatible with human cognitive mechanism. The most crucial step in linguistic summarization is certainly the evaluation of linguistic summaries since they are the most important element of fuzzy rule based systems commonly used in expert systems and intelligent systems. Therefore, the selection of appropriate method for evaluating linguistic summaries in sense of different views such as quality, quantity, relevance and simplicity becomes vital. The aim of this paper is to review the state of art on linguistic summarization in the framework of fuzzy sets, focusing on the methods for evaluating linguistic summaries and the current applications. A taxonomy is proposed to identify the existing methods depending on the type of fuzzy sets (i.e., type-1 fuzzy set and type-2 fuzzy set) and the type of cardinalities (i.e., scalar cardinality and fuzzy cardinality). The recent studies on linguistic summarization are also presented to give a comprehensive framework for the future directions. The paper ends with conclusions, addressing some important issues and open questions which can be subject for future research.},
author = {Boran, Fatih Emre and Akay, Diyar and Yager, Ronald R.},
doi = {10.1016/j.eswa.2016.05.044},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boran, Akay, Yager - 2016 - An overview of methods for linguistic summarization with fuzzy sets.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Fuzzy quantification,Fuzzy set,Knowledge discovery,Linguistic summarization},
pages = {356--377},
publisher = {Elsevier Ltd},
title = {{An overview of methods for linguistic summarization with fuzzy sets}},
url = {http://dx.doi.org/10.1016/j.eswa.2016.05.044},
volume = {61},
year = {2016}
}
@article{Jitkrittum2020,
abstract = {This paper is an in-depth investigation of using kernel methods to immunize optimization solutions against distributional ambiguity. We propose kernel distributionally robust optimization (K-DRO) using insights from the robust optimization theory and functional analysis. Our method uses reproducing kernel Hilbert spaces (RKHS) to construct ambiguity sets. It can be reformulated as a tractable program by using the conic duality of moment problems and an extension of the RKHS representer theorem. Our insights reveal that universal RKHSs are large enough for K-DRO to be effective. This paper provides both theoretical analyses that extend the robustness properties of kernel methods, as well as practical algorithms that can be applied to general optimization problems, not limited to kernelized models.},
archivePrefix = {arXiv},
arxivId = {2006.06981},
author = {Jitkrittum, Wittawat and Zhu, Jia Jie and Diehl, Moritz and Sch{\"{o}}lkopf, Bernhard},
eprint = {2006.06981},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jitkrittum et al. - 2020 - Kernel Distributionally Robust Optimization.pdf:pdf},
journal = {arXiv},
pages = {1--9},
title = {{Kernel Distributionally Robust Optimization}},
year = {2020}
}
@article{Hall2012,
abstract = {An explanation of Pearson's correlation coefficient is given and its suitability for evaluating curve fits to data in the third year lab is discussed.},
author = {Hall, G},
doi = {10.1136/bmj.e4483},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Pearson ' s correlation.pdf:pdf},
isbn = {9780761988540},
issn = {1756-1833},
journal = {Statistics},
pages = {1--4},
title = {{Pearson's Correlation}},
url = {http://www.statstutor.ac.uk/resources/uploaded/pearsons.pdf%0Ahttp://www.statisticshowto.com/what-is-the-pearson-correlation-coefficient/},
volume = {1},
year = {2012}
}
@article{Mondal2005,
author = {Mondal, Partha Pratim and Rajan, Kanhirodan},
doi = {10.1364/AO.44.006345},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mondal, Rajan - 2005 - Neural network-based image reconstruction for positron emission tomography.pdf:pdf},
issn = {0003-6935},
journal = {Applied Optics},
number = {30},
pages = {6345--6352},
title = {{Neural network-based image reconstruction for positron emission tomography}},
url = {https://www.osapublishing.org/abstract.cfm?URI=ao-44-30-6345},
volume = {44},
year = {2005}
}
@article{Margetts2017,
abstract = {Social networks are not a new phenomenon — people have always associated with like-minded others — but the advent of social media has led to a vast increase in the amount of social information that we see. We need data and experiments to understand how this information shapes our political landscape.},
author = {Margetts, Helen},
doi = {10.1038/s41562-017-0086},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Margetts - 2017 - Political behaviour and the acoustics of social media.pdf:pdf},
issn = {23973374},
journal = {Nature Human Behaviour},
number = {4},
pages = {1--3},
publisher = {Macmillan Publishers Limited},
title = {{Political behaviour and the acoustics of social media}},
url = {http://dx.doi.org/10.1038/s41562-017-0086},
volume = {1},
year = {2017}
}
@inproceedings{Jayakumar2020,
abstract = {We explore the role of multiplicative interaction as a unifying framework to describe a range of classical and modern neural network architectural motifs, such as gating, attention layers, hypernetworks, and dynamic convolutions amongst others. Multi- plicative interaction layers as primitive operations have a long-established presence in the literature, though this often not emphasized and thus under-appreciated. We begin by showing that such layers strictly enrich the representable function classes of neural networks. We conjecture that multiplicative interactions offer a particularly powerful inductive bias when fusing multiple streams ofinformation or when conditional computation is required. We therefore argue that they should be considered in many situation where multiple compute or information paths need to be combined, in place of the simple and oft-used concatenation operation. Finally, we back up our claims and demonstrate the potential of multiplicative interactions by applying them in large-scale complex RL and sequence modelling tasks, where their use allows us to deliver state-of-the-art results, and thereby provides new evidence in support of multiplicative interactions playing a more prominent role when designing new neural network architectures.},
author = {Jayakumar, Siddhant M. and Czarnecki, Wojciech M. and Menick, Jacob and Schwarz, Jonathan and Rae, Jack and Osindero, Simon and Teh, Yee Whye and Harley, Tim and Pascanu, Razvan},
booktitle = {International Conference on Learning Representations},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jayakumar et al. - 2020 - Multiplicative Interactions and Where to Find Them.pdf:pdf},
isbn = {0049415425},
title = {{Multiplicative Interactions and Where to Find Them}},
url = {International Conference on Learning Representations},
year = {2020}
}
@article{IBM2014a,
abstract = {About IBM Business Analytics IBM Business Analytics software delivers complete, consistent and accurate information that decision-makers trust to improve business performance. A comprehensive portfolio of business intelligence, predictive analytics, financial performance and strategy management, and analytic applications provides clear, immediate and actionable insights into current performance and the ability to predict future outcomes. Combined with rich industry solutions, proven practices and professional services, organizations of every size can drive the highest productivity, confidently automate decisions and deliver better results. As part of this portfolio, IBM SPSS Predictive Analytics software helps organizations predict future events and proactively act upon that insight to drive better business outcomes. Commercial, government and academic customers worldwide rely on IBM SPSS technology as a competitive advantage in attracting, retaining and growing customers, while reducing fraud and mitigating risk. By incorporating IBM SPSS software into their daily operations, organizations become predictive enterprises – able to direct and automate decisions to meet business goals and achieve measurable competitive advantage. For further information or to reach a representative visit},
author = {IBM},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/IBM - 2014 - IBM SPSS Missing Values 22.pdf:pdf},
pages = {99},
title = {{IBM SPSS Missing Values 22}},
year = {2014}
}
@article{Zoph2020,
abstract = {Pre-training is a dominant paradigm in computer vision. For example, supervised ImageNet pre-training is commonly used to initialize the backbones of object detection and segmentation models. He et al. [1], however, show a surprising result that ImageNet pre-training has limited impact on COCO object detection. Here we investigate self-training as another method to utilize additional data on the same setup and contrast it against ImageNet pre-training. Our study reveals the generality and flexibility of self-training with three additional insights: 1) stronger data augmentation and more labeled data further diminish the value of pre-training, 2) unlike pre-training, self-training is always helpful when using stronger data augmentation, in both low-data and high-data regimes, and 3) in the case that pre-training is helpful, self-training improves upon pre-training. For example, on the COCO object detection dataset, pre-training benefits when we use one fifth of the labeled data, and hurts accuracy when we use all labeled data. Self-training, on the other hand, shows positive improvements from +1.3 to +3.4AP across all dataset sizes. In other words, self-training works well exactly on the same setup that pre-training does not work (using ImageNet to help COCO). On the PASCAL segmentation dataset, which is a much smaller dataset than COCO, though pre-training does help significantly, self-training improves upon the pre-trained model. On COCO object detection, we achieve 54.3AP, an improvement of +1.5AP over the strongest SpineNet model. On PASCAL segmentation, we achieve 90.5 mIOU, an improvement of +1.5% mIOU over the previous state-of-the-art result by DeepLabv3+.},
archivePrefix = {arXiv},
arxivId = {2006.06882},
author = {Zoph, Barret and Ghiasi, Golnaz and Lin, Tsung Yi and Cui, Yin and Liu, Hanxiao and Cubuk, Ekin and Le, Quoc V.},
eprint = {2006.06882},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zoph et al. - 2020 - Rethinking pre-training and self-training.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {pre-training,self-training,transfer learning},
mendeley-tags = {pre-training,self-training,transfer learning},
title = {{Rethinking pre-training and self-training}},
year = {2020}
}
@article{Li2018a,
abstract = {When building a unified vision system or gradually adding new apabilities to a system, the usual assumption is that training data for all tasks is always available. However, as the number of tasks grows, storing and retraining on such data becomes infeasible. A new problem arises where we add new capabilities to a Convolutional Neural Network (CNN), but the training data for its existing capabilities are unavailable. We propose our Learning without Forgetting method, which uses only new task data to train the network while preserving the original capabilities. Our method performs favorably compared to commonly used feature extraction and fine-tuning adaption techniques and performs similarly to multitask learning that uses original task data we assume unavailable. A more surprising observation is that Learning without Forgetting may be able to replace fine-tuning with similar old and new task datasets for improved new task performance.},
archivePrefix = {arXiv},
arxivId = {1606.09282},
author = {Li, Zhizhong and Hoiem, Derek},
doi = {10.1109/TPAMI.2017.2773081},
eprint = {1606.09282},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Hoiem - 2018 - Learning without Forgetting.pdf:pdf},
issn = {19393539},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Convolutional neural networks,deep learning,multi-task learning,transfer learning,visual recognition},
number = {12},
pages = {2935--2947},
pmid = {29990101},
title = {{Learning without Forgetting}},
volume = {40},
year = {2018}
}
@article{Lowndes2010,
abstract = {The optical touch pointer (OTP), a fluorescence spectroscopy based system, assists brain surgeons during guided brain tumor resection in patients with glioblastoma multi- forme (GBM). After recording and analyzing the autofluorescence spectrum of the tis- sue, it is possible to distinguish malignant from healthy brain tissue. A challenge during the intraoperative measurements is the interference of blood. If it gets in contact with the laser pointer, the blood blocks the light transmission to and from the tissue. The purpos- es of the project were to study and categorize patterns of blood interference and to present possible solutions to avoid signal blocking by blood. To measure fluorescence and reflection two devices were used respectively, the OTP which has a spectrometer and a blue laser, and the diffused reflection spectroscopy sys- tem (DRS) which has a spectrometer and a white light source. Both operate indepen- dently from each other and are connected to a fiber optical probe. A similar scenario to the one in the operation theater was simulated in the lab. Fluorescence and diffuse ref- lection measurements with and without blood were realized on skin and on two different plastic fluorescent standards. The results were analyzed with the aid of MatLAB, and compared with data collected in the hospital during brain tumor resection. The highest autofluorescence of brain tissue and skin is reached at approximately 506 nm. Although skin and both plastic standards have different optical properties re- garding color or rather fluorescence, all of them presented very similar curves when blood on them blocked partially or completely the light transmission. A blood layer of more than 0.1 mm thickness blocks the blue laser light. Blood absorption happens at 541 and 577 nm due to oxy-hemoglobin (HbO2) in both liquid and dried blood. When the fluorescence spectrum is available but weak, the reflection spectrum contains two dips (traces of HbO2 at 541 and 577 nm). In brain there were cases in which light absorption occurred additionally at other wavelengths than the absorption peaks of deoxy- hemoglobin (Hb) and HbO2. Blood interference during the OP can be prevented if the probe rests in a saline solution after every measurement. In this way the fresh blood sticking on the probe dissolves in the solution. For dried or coagulated blood, additional manual cleansing is needed.},
author = {Lowndes, Shannely},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lowndes - 2010 - Blood interference in fluorescence spectrum – Experiment , analysis and comparison with intra- operative measurements.pdf:pdf},
pages = {42},
title = {{Blood interference in fluorescence spectrum – Experiment , analysis and comparison with intra- operative measurements on brain tumor}},
year = {2010}
}
@article{Yao2014a,
abstract = {Recently, antireflective coatings (ARCs) with self-cleaning properties have attracted significant attention for both their fundamental aspects and wide practical applications. In the current review, the basic principles of antireflection and self-cleaning are briefly discussed first. Then, fabrication strategies with particular emphasis on silicon and silica substrates are reviewed in detail. Meanwhile, ARCs and self-cleaning coatings on polymer and metal foil are also briefly described. Afterwards, progresses in antireflective self-cleaning coatings and some multifunctional ARCs in the latest five years are presented in detail. The applications of ARCs are discussed in terms of architectural glasses, solar collectors, photovoltaic modules, and display devices. Finally, current challenges faced in practical applications and the trend of future development are presented and discussed to facilitate a universal understanding of ARCs and self-cleaning coatings. {\textcopyright} 2013 Elsevier Ltd. All rights reserved.},
author = {Yao, Lin and He, Junhui},
doi = {10.1016/j.pmatsci.2013.12.003},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yao, He - 2014 - Recent progress in antireflection and self-cleaning technology - From surface engineering to functional surfaces.pdf:pdf},
isbn = {0079-6425},
issn = {00796425},
journal = {Progress in Materials Science},
pages = {94--143},
publisher = {Elsevier Ltd},
title = {{Recent progress in antireflection and self-cleaning technology - From surface engineering to functional surfaces}},
url = {http://dx.doi.org/10.1016/j.pmatsci.2013.12.003},
volume = {61},
year = {2014}
}
@article{Majumder2021,
abstract = {Instance discrimination based contrastive learning has emerged as a leading approach for self-supervised learning of visual representations. Yet, its generalization to novel tasks remains elusive when compared to representations learned with supervision, especially in the few-shot setting. We demonstrate how one can incorporate supervision in the instance discrimination based contrastive self-supervised learning framework to learn representations that generalize better to novel tasks. We call our approach CIDS (Contrastive Instance Discrimination with Supervision). CIDS performs favorably compared to existing algorithms on popular few-shot benchmarks like Mini-ImageNet or Tiered-ImageNet. We also propose a novel model selection algorithm that can be used in conjunction with a universal embedding trained using CIDS to outperform state-of-the-art algorithms on the challenging Meta-Dataset benchmark.},
archivePrefix = {arXiv},
arxivId = {2101.11058},
author = {Majumder, Orchid and Ravichandran, Avinash and Maji, Subhransu and Polito, Marzia and Bhotika, Rahul and Soatto, Stefano},
eprint = {2101.11058},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Majumder et al. - 2021 - Revisiting Contrastive Learning for Few-Shot Classification.pdf:pdf},
keywords = {classification,contrastive learning,few-shot learning,self-supervised learning},
mendeley-tags = {classification,contrastive learning,few-shot learning,self-supervised learning},
title = {{Revisiting Contrastive Learning for Few-Shot Classification}},
url = {http://arxiv.org/abs/2101.11058},
year = {2021}
}
@article{Subehi2013,
author = {Subehi, Rakhman Gusti and Sari, Dini Nurmala and Rachmawati, Heni},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Subehi, Sari, Rachmawati - 2013 - Perancangan Sistem Informasi Manajemen Parkir Dengan Pendekatan Algoritma Hill Climbing di Pusat Perbe.pdf:pdf},
isbn = {9792602666},
number = {November},
pages = {291--297},
title = {{Perancangan Sistem Informasi Manajemen Parkir Dengan Pendekatan Algoritma Hill Climbing di Pusat Perbelanjaan ( Studi Kasus : Mal Ska-Pekanbaru )}},
volume = {2013},
year = {2013}
}
@inproceedings{Lomonaco2020,
abstract = {Robotic vision is a field where continual learning can play a significant role. An embodied agent operating in a complex environment subject to frequent and unpredictable changes is required to learn and adapt continuously. In the context of object recognition, for example, a robot should be able to learn (without forgetting) objects of never before seen classes as well as improving its recognition capabilities as new instances of already known classes are discovered. Ideally, continual learning should be triggered by the availability of short videos of single objects and performed on-line on on-board hardware with fine-grained updates. In this paper, we introduce a novel continual learning protocol based on the CORe50 benchmark and propose two rehearsal-free continual learning techniques, CWR∗ and AR1∗, that can learn effectively even in the challenging case of nearly 400 small non-i.i.d. incremental batches. In particular, our experiments show that AR1∗ can outperform other state-of-the-art rehearsal-free techniques by more than 15% accuracy in some cases, with a very light and constant computational and memory overhead across training batches.},
archivePrefix = {arXiv},
arxivId = {1907.03799},
author = {Lomonaco, Vincenzo and Maltoni, Davide and Pellegrini, Lorenzo},
booktitle = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
doi = {10.1109/CVPRW50498.2020.00131},
eprint = {1907.03799},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lomonaco, Maltoni, Pellegrini - 2020 - Rehearsal-free continual learning over small Non-I.I.D. batches.pdf:pdf},
isbn = {9781728193601},
issn = {21607516},
pages = {989--998},
title = {{Rehearsal-free continual learning over small Non-I.I.D. batches}},
volume = {2020-June},
year = {2020}
}
@article{Taori2020,
abstract = {We study how robust current ImageNet models are to distribution shifts arising from natural variations in datasets. Most research on robustness focuses on synthetic image perturbations (noise, simulated weather artifacts, adversarial examples, etc.), which leaves open how robustness on synthetic distribution shift relates to distribution shift arising in real data. Informed by an evaluation of 204 ImageNet models in 213 different test conditions, we find that there is often little to no transfer of robustness from current synthetic to natural distribution shift. Moreover, most current techniques provide no robustness to the natural distribution shifts in our testbed. The main exception is training on larger and more diverse datasets, which in multiple cases increases robustness, but is still far from closing the performance gaps. Our results indicate that distribution shifts arising in real data are currently an open research problem. We provide our testbed and data as a resource for future work at https://modestyachts.github.io/imagenet-testbed/ .},
archivePrefix = {arXiv},
arxivId = {2007.00644},
author = {Taori, Rohan and Dave, Achal and Shankar, Vaishaal and Carlini, Nicholas and Recht, Benjamin and Schmidt, Ludwig},
eprint = {2007.00644},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Taori et al. - 2020 - Measuring Robustness to Natural Distribution Shifts in Image Classification.pdf:pdf;:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Taori et al. - 2020 - Measuring Robustness to Natural Distribution Shifts in Image Classification(2).pdf:pdf},
journal = {arXiv},
keywords = {measurement,robustness},
mendeley-tags = {measurement,robustness},
month = {jul},
number = {NeurIPS},
title = {{Measuring Robustness to Natural Distribution Shifts in Image Classification}},
url = {http://arxiv.org/abs/2007.00644},
year = {2020}
}
@article{Gupta2014,
author = {Gupta, Chanchal and Maheshwari, Priyanka H. and Sasikala, S. and Mathur, R. B.},
doi = {10.1007/s40243-014-0036-3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gupta et al. - 2014 - Processing of pristine carbon nanotube supported platinum as catalyst for PEM fuel cell.pdf:pdf},
issn = {21941467},
journal = {Materials for Renewable and Sustainable Energy},
keywords = {Carbon,Catalyst,Fuel cell,Mid-wave potential,Nanotubes,Polarization},
number = {4},
title = {{Processing of pristine carbon nanotube supported platinum as catalyst for PEM fuel cell}},
volume = {3},
year = {2014}
}
@inproceedings{Kim2018c,
abstract = {Continual learning has been a major problem in the deep learning community, where the main challenge is how to effectively learn a series of newly arriving tasks without forgetting the knowledge of previous tasks. Initiated by Learning with- out Forgetting (LwF), many of the existing works report that knowledge distillation is effective to preserve the previous knowledge, and hence they commonly use a soft label for the old task, namely a knowledge distillation (KD) loss, together with a class label for the new task, namely a cross entropy (CE) loss, to form a composite loss for a single neural network. However, this approach suffers from learning the knowledge by a CE loss as a KD loss often more strongly influences the objective function when they are in a competitive situation within a single network. This could be a critical problem par- ticularly in a class incremental scenario, where the knowledge across tasks as well as within the new task, both of which can only be acquired by a CE loss, is essentially learned due to the existence of a unified classifier. In this paper, we propose a novel continual learning method, called Split-and-Bridge, which can successfully address the above problem by partially splitting a neural network into two partitions for training the new task separated from the old task and re-connecting them for learning the knowledge across tasks. In our thorough exper- imental analysis, our Split-and-Bridge method outperforms the state-of-the-art competitors in KD-based continual learning.},
author = {Kim, Jong-yeong and Choi, Dong-wan},
booktitle = {35th AAAI Conference on Artificial Intelligence, AAAI 2021},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim, Choi - 2018 - Split-and-Bridge Adaptable Class Incremental Learning within a Single Neural Network(2).pdf:pdf},
keywords = {continual learning,knowledge distillation},
mendeley-tags = {continual learning,knowledge distillation},
title = {{Split-and-Bridge : Adaptable Class Incremental Learning within a Single Neural Network}},
year = {2018}
}
@article{Sahu2017,
abstract = {Reason and inference require process as well as memory skills by humans. Neural networks are able to process tasks like image recognition (better than humans) but in memory aspects are still limited (by attention mechanism, size). Recurrent Neural Network (RNN) and it's modified version LSTM are able to solve small memory contexts, but as context becomes larger than a threshold, it is difficult to use them. The Solution is to use large external memory. Still, it poses many challenges like, how to train neural networks for discrete memory representation, how to describe long term dependencies in sequential data etc. Most prominent neural architectures for such tasks are Memory networks: inference components combined with long term memory and Neural Turing Machines: neural networks using external memory resources. Also, additional techniques like attention mechanism, end to end gradient descent on discrete memory representation are needed to support these solutions. Preliminary results of above neural architectures on simple algorithms (sorting, copying) and Question Answering (based on story, dialogs) application are comparable with the state of the art. In this paper, I explain these architectures (in general), the additional techniques used and the results of their application.},
archivePrefix = {arXiv},
arxivId = {1702.06186},
author = {Sahu, Amit},
eprint = {1702.06186},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sahu - 2017 - Survey of reasoning using Neural Networks.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {Discrete memory,External memory,Gradient descent,LSTM,Long term memory,Neural Networks,RNN,Sorting,Turing Machine,neural networks,reasoning,review,survey},
mendeley-tags = {neural networks,reasoning,review,survey},
title = {{Survey of reasoning using Neural Networks}},
year = {2017}
}
@inproceedings{Doshi2020ContinualLF,
abstract = {Anomaly detection in surveillance videos has been recently gaining attention. A challenging aspect of high-dimensional applications such as video surveillance is continual learning. While current state-of-the-art deep learning approaches perform well on existing public datasets, they fail to work in a continual learning framework due to computational and storage issues. Furthermore, online decision making is an important but mostly neglected factor in this domain. Motivated by these research gaps, we propose an online anomaly detection method for surveillance videos using transfer learning and continual learning, which in turn significantly reduces the training complexity and provides a mechanism for continually learning from recent data without suffering from catastrophic forgetting. Our proposed algorithm leverages the feature extraction power of neural network-based models for transfer learning, and the continual learning capability of statistical detection methods.},
author = {Doshi, Keval and Yilmaz, Yasin},
booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Doshi, Yilmaz - 2020 - Continual Learning for Anomaly Detection in Surveillance Videos.pdf:pdf},
issn = {23318422},
keywords = {anomaly detection,continual learning,incremental learning},
mendeley-tags = {anomaly detection,continual learning,incremental learning},
pages = {1025--1034},
title = {{Continual Learning for Anomaly Detection in Surveillance Videos}},
year = {2020}
}
@article{Huynh2020a,
abstract = {In this work, we develop a shared multi-Attention model for multi-label zero-shot learning. We argue that designing attention mechanism for recognizing multiple seen and unseen labels in an image is a non-Trivial task as there is no training signal to localize unseen labels and an image only contains a few present labels that need attentions out of thousands of possible labels. Therefore, instead of generating attentions for unseen labels which have unknown behaviors and could focus on irrelevant regions due to the lack of any training sample, we let the unseen labels select among a set of shared attentions which are trained to be label-Agnostic and to focus on only relevant/foreground regions through our novel loss. Finally, we learn a compatibility function to distinguish labels based on the selected attention. We further propose a novel loss function that consists of three components guiding the attention to focus on diverse and relevant image regions while utilizing all attention features. By extensive experiments, we show that our method improves the state of the art by 2.9% and 1.4% F1 score on the NUS-WIDE and the large scale Open Images datasets, respectively.},
author = {Huynh, Dat and Elhamifar, Ehsan},
doi = {10.1109/CVPR42600.2020.00880},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huynh, Elhamifar - 2020 - A Shared Multi-Attention Framework for Multi-Label Zero-Shot Learning.pdf:pdf},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {8773--8783},
title = {{A Shared Multi-Attention Framework for Multi-Label Zero-Shot Learning}},
year = {2020}
}
@book{Buckle1985,
address = {Jakarta},
author = {Buckle, K. A. (Kenneth A.) and Purnomo, Hari. and Adiono. and Tinggi, Indonesia. Direktorat Jenderal Pendidikan and and Colleges, International Development Program of Australian Universities},
isbn = {0864031602},
pages = {365},
publisher = {Penerbit Universitas Indonesia},
title = {{Ilmu pangan}},
year = {1985}
}
@article{Zhang2020g,
abstract = {Deep neural networks (DNNs) often suffer from "catastrophic forgetting" during incremental learning (IL) - an abrupt degradation of performance on the original set of classes when the training objective is adapted to a newly added set of classes. Existing IL approaches tend to produce a model that is biased towards either the old classes or new classes, unless with the help of exemplars of the old data. To address this issue, we propose a class-incremental learning paradigm called Deep Model Consolidation (DMC), which works well even when the original training data is not available. The idea is to first train a separate model only for the new classes, and then combine the two individual models trained on data of two distinct set of classes (old classes and new classes) via a novel double distillation training objective. The two existing models are consolidated by exploiting publicly available unlabeled auxiliary data. This overcomes the potential difficulties due to unavailability of original training data. Compared to the state-of-the-art techniques, DMC demonstrates significantly better performance in image classification (CIFAR-100 and CUB-200) and object detection (PASCAL VOC 2007) in the single-headed IL setting.},
archivePrefix = {arXiv},
arxivId = {1903.07864},
author = {Zhang, Junting and Zhang, Jie and Ghosh, Shalini and Li, Dawei and Tasci, Serafettin and Heck, Larry and Zhang, Heming and {Jay Kuo}, C. C.},
doi = {10.1109/WACV45572.2020.9093365},
eprint = {1903.07864},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2020 - Class-incremental learning via deep model consolidation.pdf:pdf},
isbn = {9781728165530},
journal = {Proceedings - 2020 IEEE Winter Conference on Applications of Computer Vision, WACV 2020},
keywords = {architectural,class incremental learning,continual learning},
mendeley-tags = {architectural,class incremental learning,continual learning},
pages = {1120--1129},
title = {{Class-incremental learning via deep model consolidation}},
year = {2020}
}
@inproceedings{Wang2021a,
abstract = {Recognizing new objects by learning from a few labeled examples in an evolving environment is crucial to obtain excellent generalization ability for real-world machine learning systems. A typical setting across current meta learning algorithms assumes a stationary task distribution during meta training. In this paper, we explore a more practical and challenging setting where task distribution changes over time with domain shift. Particularly, we consider realistic scenarios where task distribution is highly imbalanced with domain labels unavailable in nature. We propose a kernel-based method for domain change detection and a difficulty-aware memory management mechanism that jointly considers the imbalanced domain size and domain importance to learn across domains continuously. Furthermore, we introduce an efficient adaptive task sampling method during meta training, which significantly reduces task gradient variance with theoretical guarantees. Finally, we propose a challenging benchmark with imbalanced domain sequences and varied domain difficulty. We have performed extensive evaluations on the proposed benchmark, demonstrating the effectiveness of our method. We made our code publicly available.},
archivePrefix = {arXiv},
arxivId = {2109.14120},
author = {Wang, Zhenyi and Duan, Tiehang and Fang, Le and Suo, Qiuling and Gao, Mingchen},
booktitle = {International Conference on Computer Vision},
eprint = {2109.14120},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2021 - Meta Learning on a Sequence of Imbalanced Domains with Difficulty Awareness.pdf:pdf},
keywords = {i,meta-learning},
mendeley-tags = {i,meta-learning},
number = {4},
pages = {8947--8957},
title = {{Meta Learning on a Sequence of Imbalanced Domains with Difficulty Awareness}},
url = {http://arxiv.org/abs/2109.14120},
year = {2021}
}
@article{Long2013,
abstract = {Transfer learning is established as an effective technology in computer vision for leveraging rich labeled data in the source domain to build an accurate classifier for the target domain. However, most prior methods have not simultaneously reduced the difference in both the marginal distribution and conditional distribution between domains. In this paper, we put forward a novel transfer learning approach, referred to as Joint Distribution Adaptation (JDA). Specifically, JDA aims to jointly adapt both the marginal distribution and conditional distribution in a principled dimensionality reduction procedure, and construct new feature representation that is effective and robust for substantial distribution difference. Extensive experiments verify that JDA can significantly outperform several state-of-the-art methods on four types of cross-domain image classification problems. {\textcopyright} 2013 IEEE.},
author = {Long, Mingsheng and Wang, Jianmin and Ding, Guiguang and Sun, Jiaguang and Yu, Philip S.},
doi = {10.1109/ICCV.2013.274},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Long et al. - 2013 - Transfer feature learning with joint distribution adaptation.pdf:pdf},
isbn = {9781479928392},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
keywords = {Transfer learning,feature learning,joint distribution adaptation,transfer learning},
mendeley-tags = {transfer learning},
pages = {2200--2207},
title = {{Transfer feature learning with joint distribution adaptation}},
year = {2013}
}
@article{Peng2020b,
abstract = {The human vision and perception system is inherently incremental where new knowledge is continually learned over time whilst existing knowledge is retained. On the other hand, deep learning networks are ill-equipped for incremental learning. When a well-trained network is adapted to new categories, its performance on the old categories will dramatically degrade. To address this problem, incremental learning methods have been explored which preserve the old knowledge of deep learning models. However, the state-of-the-art incremental object detector employs an external fixed region proposal method that increases overall computation time and reduces accuracy comparing to Region Proposal Network (RPN) based object detectors such as Faster RCNN. The purpose of this paper is to design an efficient end-to-end incremental object detector using knowledge distillation. We first evaluate and analyze the performance of the RPN-based detector with classic distillation on incremental detection tasks. Then, we introduce multi-network adaptive distillation that properly retains knowledge from the old categories when fine-tuning the model for new task. Experiments on the benchmark datasets, PASCAL VOC and COCO, demonstrate that the proposed incremental detector based on Faster RCNN is more accurate as well as being 13 times faster than the baseline detector.},
archivePrefix = {arXiv},
arxivId = {2003.03901},
author = {Peng, Can and Zhao, Kun and Lovell, Brian C.},
doi = {10.1016/j.patrec.2020.09.030},
eprint = {2003.03901},
file = {:home/user/Downloads/10.1016@j.patrec.2020.09.030.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Deep learning,Incremental learning,Object detection,continual learning,object detection},
mendeley-tags = {continual learning,object detection},
pages = {109--115},
publisher = {Elsevier B.V.},
title = {{Faster ILOD: Incremental learning for object detectors based on faster RCNN}},
url = {https://doi.org/10.1016/j.patrec.2020.09.030},
volume = {140},
year = {2020}
}
@article{Douillard2020,
abstract = {Lifelong learning has attracted much attention, but existing works still struggle to fight catastrophic forgetting and accumulate knowledge over long stretches of incremental learning. In this work, we propose PODNet, a model inspired by representation learning. By carefully balancing the compromise between remembering the old classes and learning new ones, PODNet fights catastrophic forgetting, even over very long runs of small incremental tasks --a setting so far unexplored by current works. PODNet innovates on existing art with an efficient spatial-based distillation-loss applied throughout the model and a representation comprising multiple proxy vectors for each class. We validate those innovations thoroughly, comparing PODNet with three state-of-the-art models on three datasets: CIFAR100, ImageNet100, and ImageNet1000. Our results showcase a significant advantage of PODNet over existing art, with accuracy gains of 12.10, 6.51, and 2.85 percentage points, respectively. Code is available at https://github.com/arthurdouillard/incremental_learning.pytorch},
archivePrefix = {arXiv},
arxivId = {2004.13513},
author = {Douillard, Arthur and Cord, Matthieu and Ollion, Charles and Robert, Thomas and Valle, Eduardo},
doi = {10.1007/978-3-030-58565-5_6},
eprint = {2004.13513},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Douillard et al. - 2020 - PODNet Pooled Outputs Distillation for Small-Tasks Incremental Learning.pdf:pdf},
keywords = {incremental-learning,representation-learning pooling},
pages = {86--102},
title = {{PODNet: Pooled Outputs Distillation for Small-Tasks Incremental Learning}},
year = {2020}
}
@article{Lu2015,
abstract = {Black phosphorous (BP), the most thermodynamically stable allotrope of phosphorus, is a high-mobility layered semiconductor with direct band-gap determined by the number of layers from 0.3 eV (bulk) to 2.0 eV (single layer). Therefore, BP is considered as a natural candidate for broadband optical applications, particularly in the infrared (IR) and mid-IR part of the spectrum. The strong light-matter interaction, narrow direct band-gap, and wide range of tunable optical response make BP as a promising nonlinear optical material, particularly with great potentials for infrared and mid-infrared opto-electronics. Herein, we experimentally verified its broadband and enhanced saturable absorption of multi-layer BP (with a thickness of $\sim$10 nm) by wide-band Z-scan measurement technique, and anticipated that multi-layer BPs could be developed as another new type of two-dimensional saturable absorber with operation bandwidth ranging from the visible (400 nm) towards mid-IR (at least 1930 nm). Our results might suggest that ultra-thin multi-layer BP films could be potentially developed as broadband ultra-fast photonics devices, such as passive Q-switcher, mode-locker, optical switcher etc.},
author = {Lu, S. B. and Miao, L. L. and Guo, Z. N. and Qi, X. and Zhao, C. J. and Zhang, H. and Wen, S. C. and Tang, D. Y. and Fan, D. Y.},
doi = {10.1364/OE.23.011183},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu et al. - 2015 - Broadband nonlinear optical response in multi-layer black phosphorus an emerging infrared and mid-infrared optical ma.pdf:pdf},
isbn = {1094-4087 (Electronic)\r1094-4087 (Linking)},
issn = {1094-4087},
journal = {Optics Express},
number = {9},
pages = {11183},
pmid = {25969214},
title = {{Broadband nonlinear optical response in multi-layer black phosphorus: an emerging infrared and mid-infrared optical material}},
url = {https://www.osapublishing.org/abstract.cfm?URI=oe-23-9-11183},
volume = {23},
year = {2015}
}
@article{Lakowicz2009,
abstract = {Fluorescence probes represent the most important area of fluorescence spectroscopy. The wavelength and time resolution required of the instruments is determined by the spectral properties of the fluorophores. Furthermore, the information available from the experiments is determined by the properties of the probes. Only probes with non-zero anisotropies can be used to measure rotational diffusion, and the lifetime of the fluorophore must be comparable to the timescale of interest in the experiment. Only probes that are sensitive to pH can be used to measure pH. And only probes with reasonably long excitation and emission wavelengths can be used in tissues, which display autofluorescence at short excitation wavelengths. Thousands of fluorescent probes are known, and it is not practical to describe them all. This chapter contains an overview of the various types of fluorophores, their spectral properties, and applications. Fluorophores can be broadly divided into two main classes—intrinsic and extrinsic. Intrinsic fluorophores are those that occur naturally. These include the aromatic amino acids, NADH, flavins, derivatives of pyridoxyl, and chlorophyll. Extrinsic fluorophores are added to the sample to provide fluorescence when none exists, or to change the spectral properties of the sample. Extrinsic fluorophores include dansyl, fluorescein, rho-damine, and numerous other substances.},
author = {Lakowicz, Joseph R.},
doi = {10.1002/smll.201090041},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lakowicz - 2009 - 3. Fluorophores.pdf:pdf},
isbn = {978-0-387-31278-1, 978-0-387-46312-4},
issn = {1613-6829},
journal = {Principles of Fluorescence Spectroscopy},
pages = {954},
pmid = {20589865},
title = {{3. Fluorophores}},
year = {2009}
}
@article{Kofinas2016,
abstract = {{\textcopyright} 2016 IEEE.Water demand forecast has emerged as an imperative component of intelligent Internet and Communication Technologies based methodologies of water management. The need of increased time resolution of forecast in order to implement such methodologies is driving stakeholders to long for new more specialized forecast approaches that will take into account the special drivers of water demand in each case study. Advanced techniques have the ability to overcome the nonlinearity issues commonly met when investigating the complex relationship of water demand and weather, socioeconomic and other variables. In this article we present two approaches, an Artificial Neural Network and an Adaptive Neuro-Fuzzy Inference System, for forecasting a Mediterranean touristic resort daily water demand based on weather variables, tourism and leakage. Both models seem to have an adequate response, though ANFIS can more smoothly catch winter non-touristic water demand profile.},
author = {Kofinas, D. and Papageorgiou, E. and Laspidou, C. and Mellios, N. and Kokkinos, K.},
doi = {10.1109/CySWater.2016.7469061},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kofinas et al. - 2016 - Daily multivariate forecasting of water demand in a touristic island with the use of artificial neural network a.pdf:pdf},
isbn = {9781509011612},
journal = {2016 International Workshop on Cyber-physical Systems for Smart Water Networks, CySWater 2016},
keywords = {ANFIS,ANN,ICT,water demand forecasting},
pages = {37--42},
title = {{Daily multivariate forecasting of water demand in a touristic island with the use of artificial neural network and adaptive neuro-fuzzy inference system}},
year = {2016}
}
@article{Fan2020a,
abstract = {Self-supervised learning achieves superior performance in many domains by extracting useful representations from the unlabeled data. However, most of traditional self-supervised methods mainly focus on exploring the inter-sample structure while less efforts have been concentrated on the underlying intra-temporal structure, which is important for time series data. In this paper, we present SelfTime: a general self-supervised time series representation learning framework, by exploring the inter-sample relation and intra-temporal relation of time series to learn the underlying structure feature on the unlabeled time series. Specifically, we first generate the inter-sample relation by sampling positive and negative samples of a given anchor sample, and intra-temporal relation by sampling time pieces from this anchor. Then, based on the sampled relation, a shared feature extraction backbone combined with two separate relation reasoning heads are employed to quantify the relationships of the sample pairs for inter-sample relation reasoning, and the relationships of the time piece pairs for intra-temporal relation reasoning, respectively. Finally, the useful representations of time series are extracted from the backbone under the supervision of relation reasoning heads. Experimental results on multiple real-world time series datasets for time series classification task demonstrate the effectiveness of the proposed method. Code and data are publicly available at https://haoyfan.github.io/.},
archivePrefix = {arXiv},
arxivId = {2011.13548},
author = {Fan, Haoyi and Zhang, Fengbin and Gao, Yue},
eprint = {2011.13548},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fan, Zhang, Gao - 2020 - Self-Supervised Time Series Representation Learning by Inter-Intra Relational Reasoning.pdf:pdf},
keywords = {time series},
mendeley-tags = {time series},
title = {{Self-Supervised Time Series Representation Learning by Inter-Intra Relational Reasoning}},
url = {http://arxiv.org/abs/2011.13548 https://github.com/haoyfan/SelfTime},
year = {2020}
}
@article{Macan2009,
abstract = {The employment interview continues to be a prevalent device used by organizations and a popular topic of study among researchers. In fact, over 100 new articles have been published since Posthuma, Morgeson and Campion's [Posthuma, R. A., Morgeson, F. P., & Campion, M. A. (2002). Beyond employment interview validity: A comprehensive narrative review of recent research and trends over time. Personnel Psychology, 55, 1-81] review that are selectively examined and critiqued. During this timeframe, three main areas that have received considerable research attention are discussed: (1) understanding why "structured" interviews predict, (2) examining the constructs interviews may measure, and (3) investigating the applicant and interview factors that may affect the interview process. Despite advances made in our knowledge of employment interviews, numerous ideas for future research are advanced. Three key areas that deserve immediate research attention are: (1) establishing a common model and measurement of interview structure, (2) focusing on what constructs could be or are best measured, and (3) formulating consistent definitions, labeling and measurement of applicant factors. In this way, employment interview research can be advanced. {\textcopyright} 2009 Elsevier Inc. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Macan, Therese},
doi = {10.1016/j.hrmr.2009.03.006},
eprint = {arXiv:1011.1669v3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Macan - 2009 - The employment interview A review of current studies and directions for future research.pdf:pdf},
isbn = {1053-4822},
issn = {10534822},
journal = {Human Resource Management Review},
keywords = {Employment interviews,Personnel selection,Structured interviews},
number = {3},
pages = {203--218},
pmid = {598},
publisher = {Elsevier Inc.},
title = {{The employment interview: A review of current studies and directions for future research}},
url = {http://dx.doi.org/10.1016/j.hrmr.2009.03.006},
volume = {19},
year = {2009}
}
@article{Hukkelas2019,
abstract = {We propose a novel architecture which is able to automatically anonymize faces in images while retaining the original data distribution. We ensure total anonymization of all faces in an image by generating images exclusively on privacy-safe information. Our model is based on a conditional generative adversarial network, generating images considering the original pose and image background. The conditional information enables us to generate highly realistic faces with a seamless transition between the generated face and the existing background. Furthermore, we introduce a diverse dataset of human faces, including unconventional poses, occluded faces, and a vast variability in backgrounds. Finally, we present experimental results reflecting the capability of our model to anonymize images while preserving the data distribution, making the data suitable for further training of deep learning models. As far as we know, no other solution has been proposed that guarantees the anonymization of faces while generating realistic images.},
archivePrefix = {arXiv},
arxivId = {1909.04538},
author = {Hukkel{\aa}s, H{\aa}kon and Mester, Rudolf and Lindseth, Frank},
eprint = {1909.04538},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hukkel{\aa}s, Mester, Lindseth - 2019 - DeepPrivacy A Generative Adversarial Network for Face Anonymization.pdf:pdf},
keywords = {1,adversarial networks,bounding box and keypoints,deepprivacy results on a,diverse set of images,face de-identification,fig,generative,image anonymization,original image annotated with,the,the left image is,the middle image is},
pages = {1--14},
title = {{DeepPrivacy: A Generative Adversarial Network for Face Anonymization}},
url = {http://arxiv.org/abs/1909.04538},
year = {2019}
}
@article{Reyero2014,
abstract = {Although CaO is one of the most studied basic heterogeneous catalysts for the synthesis of biodiesel, there are important issues that have been addressed by only a few research groups and that deserve further investigation. This is the case of the difficulties introduced by the poisoning of CaO upon exposure to ambient air and the role played by CaO-glycerol complexes on the catalytic performance. The purpose of this work is to provide new information on these issues in order to contribute to a better understanding of the underlying phenomena. Four commercial CaO samples have been considered to investigate their activation and stability under reaction conditions. In addition, calcium glyceroxide, and, for the first time, calcium glycerolate, have been synthesized and compared with the materials obtained from the commercial samples. The solids have been characterized with special emphasis on the assessment of their basic properties. The catalytic tests revealed big differences between the performance of the commercial solids that were substantially reduced after calcination and, specially, Ca-glyceroxide formation during reaction. Ca-glycerolate was the most resistant catalyst to ambient air although it was characterized by a low initial activity. Ca-glyceroxide could be reutilized for at least 5 reaction cycles without activity loss. {\textcopyright} 2013 The Institution of Chemical Engineers.},
author = {Reyero, In{\'{e}}s and Arzamendi, Gurutze and Gand{\'{i}}a, Luis M.},
doi = {10.1016/j.cherd.2013.11.017},
isbn = {0263-8762},
issn = {02638762},
journal = {Chemical Engineering Research and Design},
keywords = {Biodiesel,Calcium glycerolate,Calcium glyceroxide,Calcium oxide,Methanolysis,Transesterification},
number = {8},
pages = {1519--1530},
pmid = {24240148},
publisher = {Institution of Chemical Engineers},
title = {{Heterogenization of the biodiesel synthesis catalysis: CaO and novel calcium compounds as transesterification catalysts}},
url = {http://dx.doi.org/10.1016/j.cherd.2013.11.017},
volume = {92},
year = {2014}
}
@article{Karnik1998a,
abstract = {This paper introduces a robust fuzzy logic system, one that can handle rule uncertainties. We make use of type-2 fuzzy sets for this purpose. The development of a type-2 fuzzy logic system has led to a new operation that we call type-reduction. In the course of this development, we also study set operations on type-2 sets, properties of membership grades of type-2 sets, type-2 relations and their compositions, and defuzzification},
author = {Karnik, N.N. and Mendel, J.M.},
doi = {10.1109/FUZZY.1998.686240},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Karnik, Mendel - 1998 - Introduction to type-2 fuzzy logic systems.pdf:pdf},
isbn = {0-7803-4863-X},
issn = {2152-7806},
journal = {1998 IEEE International Conference on Fuzzy Systems Proceedings. IEEE World Congress on Computational Intelligence (Cat. No.98CH36228)},
keywords = {Fuzzy sets,Marine vehicles,Measurement uncertainty,Robustness,Shape,Terminology,defuzzification,fuzzy logic,fuzzy set theory,inference engines,inference mechanisms,membership grades,type-2 fuzzy logic systems,type-reduction,uncertainty handling},
pages = {915--920},
pmid = {21541006},
title = {{Introduction to type-2 fuzzy logic systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=686240},
volume = {2},
year = {1998}
}
@article{Lovu2007,
abstract = {The potocurrent spectra and transient current-voltage characteristics for amorphous As<sub>2</sub>Se<sub>3</sub> film sandwiched between two aluminum electrodes are presented. During the measurements, the sample was illuminated with the light from the spectral range 0.8 to 4 $\mu$m. The origin of photoresponse related to the involvement in the process of the deep defect centers is discussed. {\textcopyright} 2006 IEEE.},
author = {Lovu, M. S. and Vasiliev, I. A. and Colomeiko, E. P.},
doi = {10.1109/SMICND.2006.283953},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lovu, Vasiliev, Colomeiko - 2007 - Photoconductivity of the amorphous As2Se3 film in the medium infrared range.pdf:pdf},
isbn = {1424401097},
journal = {Proceedings of the International Semiconductor Conference, CAS},
keywords = {Chalcogenide film,Deep centers,Medium infrared range,Photoconductivity},
pages = {145--148},
title = {{Photoconductivity of the amorphous As2Se3 film in the medium infrared range}},
volume = {1},
year = {2007}
}
@article{Roblyer2011,
abstract = {Approximately 8-20% of breast cancer patients receiving neoadjuvant chemotherapy fail to achieve a measurable response and endure toxic side effects without benefit. Most clinical and imaging measures of response are obtained several weeks after the start of therapy. Here, we report that functional hemodynamic and metabolic information acquired using a noninvasive optical imaging method on the first day after neoadjuvant chemotherapy treatment can discriminate nonresponding from responding patients. Diffuse optical spectroscopic imaging was used to measure absolute concentrations of oxyhemoglobin, deoxyhemoglobin, water, and lipid in tumor and normal breast tissue of 24 tumors in 23 patients with untreated primary breast cancer. Measurements were made before chemotherapy, on day 1 after the first infusion, and frequently during the first week of therapy. Various multidrug, multicycle regimens were used to treat patients. Diffuse optical spectroscopic imaging measurements were compared with final postsurgical pathologic response. A statistically significant increase, or flare, in oxyhemoglobin was observed in partial responding (n = 11) and pathologic complete responding tumors (n = 8) on day 1, whereas nonresponders (n = 5) showed no flare and a subsequent decrease in oxyhemoglobin on day 1. Oxyhemoglobin flare on day 1 was adequate to discriminate nonresponding tumors from responding tumors. Very early measures of chemotherapy response are clinically convenient and offer the potential to alter treatment strategies, resulting in improved patient outcomes.},
author = {Roblyer, D. and Ueda, S. and Cerussi, A. and Tanamai, W. and Durkin, A. and Mehta, R. and Hsiang, D. and Butler, J. A. and McLaren, C. and Chen, W.-P. and Tromberg, B.},
doi = {10.1073/pnas.1013103108},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roblyer et al. - 2011 - Optical imaging of breast cancer oxyhemoglobin flare correlates with neoadjuvant chemotherapy response one day a.pdf:pdf},
isbn = {1091-6490 (Electronic)\r0027-8424 (Linking)},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
number = {35},
pages = {14626--14631},
pmid = {21852577},
title = {{Optical imaging of breast cancer oxyhemoglobin flare correlates with neoadjuvant chemotherapy response one day after starting treatment}},
url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1013103108},
volume = {108},
year = {2011}
}
@article{Azimi2016,
abstract = {Accurate forecasting of renewable energy sources plays a key role in their integration into the grid. This paper proposes a hybrid solar irradiance forecasting framework using a Transformation based K-means algorithm, named TB K-means, to increase the forecast accuracy. The proposed clustering method is a combination of a new initialization technique, K-means algorithm and a new gradual data transformation approach. Unlike the other K-means based clustering methods which are not capable of providing a fixed and definitive answer due to the selection of different cluster centroids for each run, the proposed clustering provides constant results for different runs of the algorithm. The proposed clustering is combined with a time-series analysis, a novel cluster selection algorithm and a multilayer perceptron neural network (MLPNN) to develop the hybrid solar radiation forecasting method for different time horizons (1 h ahead, 2 h ahead, ..., 48 h ahead). The performance of the proposed TB K-means clustering is evaluated using several different datasets and compared with different variants of K-means algorithm. Solar datasets with different solar radiation characteristics are also used to determine the accuracy and processing speed of the developed forecasting method with the proposed TB K-means and other clustering techniques. The results of direct comparison with other well-established forecasting models demonstrate the superior performance of the proposed hybrid forecasting method. Furthermore, a comparative analysis with the benchmark solar radiation forecasting models shows that the proposed model gives better forecasting results.},
author = {Azimi, R. and Ghayekhloo, M. and Ghofrani, M.},
doi = {10.1016/j.enconman.2016.04.009},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Azimi, Ghayekhloo, Ghofrani - 2016 - A hybrid method based on a new clustering technique and multilayer perceptron neural networks for h.pdf:pdf},
issn = {01968904},
journal = {Energy Conversion and Management},
keywords = {Clustering,Data preprocessing,Forecasting,Solar radiation,TB K-means},
pages = {331--344},
publisher = {Elsevier Ltd},
title = {{A hybrid method based on a new clustering technique and multilayer perceptron neural networks for hourly solar radiation forecasting}},
url = {http://dx.doi.org/10.1016/j.enconman.2016.04.009},
volume = {118},
year = {2016}
}
@article{Bussmann2020,
abstract = {Causal structure discovery in complex dynamical systems is an important challenge for many scientific domains. Although data from (interventional) experiments is usually limited, large amounts of observational time series data sets are usually available. Current methods that learn causal structure from time series often assume linear relationships. Hence, they may fail in realistic settings that contain nonlinear relations between the variables. We propose Neural Additive Vector Autoregression (NAVAR) models, a neural approach to causal structure learning that can discover nonlinear relationships. We train deep neural networks that extract the (additive) Granger causal influences from the time evolution in multi-variate time series. The method achieves state-of-the-art results on various benchmark data sets for causal discovery, while providing clear interpretations of the mapped causal relations.},
archivePrefix = {arXiv},
arxivId = {2010.09429},
author = {Bussmann, Bart and Nys, Jannes and Latr{\'{e}}, Steven},
eprint = {2010.09429},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bussmann, Nys, Latr{\'{e}} - 2020 - Neural Additive Vector Autoregression Models for Causal Discovery in Time Series Data.pdf:pdf},
keywords = {time series},
mendeley-tags = {time series},
title = {{Neural Additive Vector Autoregression Models for Causal Discovery in Time Series Data}},
url = {http://arxiv.org/abs/2010.09429 https://github.com/bartbussmann/NAVAR},
year = {2020}
}
@inproceedings{Ibrahim2020,
abstract = {The problem of multi-label classification with missing labels (MLML) is a common challenge that is prevalent in several domains, e.g. image annotation and auto-tagging. In multi-label classification, each instance may belong to multiple class labels simultaneously. Due to the nature of the dataset collection and labelling procedure, it is common to have incomplete annotations in the dataset, i.e. not all samples are labelled with all the corresponding labels. However, the incomplete data labelling hinders the training of classification models. MLML has received much attention from the research community. However, in cases where a pre-trained model is fine-tuned on an MLML dataset, there has been no straightforward approach to tackle the missing labels, specifically when there is no information about which are the missing ones. In this paper, we propose a weighted loss function to account for the confidence in each label/sample pair that can easily be incorporated to fine-tune a pre-trained model on an incomplete dataset. Our experiment results show that using the proposed loss function improves the performance of the model as the ratio of missing labels increases.},
address = {New York, NY, USA},
author = {Ibrahim, Karim M. and Epure, Elena V. and Peeters, Geoffroy and Richard, Ga{\"{e}}l},
booktitle = {Proceedings of the 2020 International Conference on Multimedia Retrieval},
doi = {10.1145/3372278.3390728},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ibrahim et al. - 2020 - Confidence-based Weighted Loss for Multi-label Classification with Missing Labels.pdf:pdf},
isbn = {9781450370875},
keywords = {Missing labels,Multi-label classification,Neural networks},
month = {jun},
pages = {291--295},
publisher = {ACM},
title = {{Confidence-based Weighted Loss for Multi-label Classification with Missing Labels}},
url = {https://dl.acm.org/doi/10.1145/3372278.3390728},
year = {2020}
}
@article{Xing2017,
abstract = {Higher education in the fourth industrial revolution, HE 4.0, is a complex, dialectical and exciting opportunity which can potentially transform society for the better. The fourth industrial revolution is powered by artificial intelligence and it will transform the workplace from tasks based characteristics to the human centred characteristics. Because of the convergence of man and machine, it will reduce the subject distance between humanities and social science as well as science and technology. This will necessarily require much more interdisciplinary teaching, research and innovation. This paper explores the impact of HE 4.0 on the mission of a university which is teaching, research (including innovation) and service.},
archivePrefix = {arXiv},
arxivId = {1703.09643},
author = {Xing, Bo and Marwala, Tshilidzi},
doi = {arXiv preprint arXiv:1703.09643.},
eprint = {1703.09643},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xing, Marwala - 2017 - Implications of the Fourth Industrial Age on Higher Education.pdf:pdf},
title = {{Implications of the Fourth Industrial Age on Higher Education}},
url = {http://arxiv.org/abs/1703.09643},
year = {2017}
}
@article{Zhang2019b,
abstract = {Lifelong learning, the problem of continual learning where tasks arrive in sequence, has been lately attracting more attention in the computer vision community. The aim of lifelong learning is to develop a system that can learn new tasks while maintaining the performance on the previously learned tasks. However, there are two obstacles for lifelong learning of deep neural networks: catastrophic forgetting and capacity limitation. To solve the above issues, inspired by the recent breakthroughs in automatically learning good neural network architectures, we develop a Multi-task based lifelong learning via nonexpansive AutoML framework termed Regularize, Expand and Compress (REC). REC is composed of three stages: 1) continually learns the sequential tasks without the learned tasks' data via a newly proposed multi-task weight consolidation (MWC) algorithm; 2) expands the network to help the lifelong learning with potentially improved model capability and performance by network-transformation based AutoML; 3) compresses the expanded model after learning every new task to maintain model efficiency and performance. The proposed MWC and REC algorithms achieve superior performance over other lifelong learning algorithms on four different datasets.},
archivePrefix = {arXiv},
arxivId = {1903.08362},
author = {Zhang, Jie and Zhang, Junting and Ghosh, Shalini and Li, Dawei and Zhu, Jingwen and Zhang, Heming and Wang, Yalin},
eprint = {1903.08362},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2019 - Regularize, expand and compress Multi-task based lifelong learning via NonExpansive AutoML.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {architectural,compression,continual learning,pruning,regularization},
mendeley-tags = {architectural,compression,continual learning,pruning,regularization},
title = {{Regularize, expand and compress: Multi-task based lifelong learning via NonExpansive AutoML}},
year = {2019}
}
@article{Perugachi-Diaz2020,
abstract = {We introduce Invertible Dense Networks (i-DenseNets), a more parameter efficient alternative to Residual Flows. The method relies on an analysis of the Lipschitz continuity of the concatenation in DenseNets, where we enforce the invertibility of the network by satisfying the Lipschitz constraint. Additionally, we extend this method by proposing a learnable concatenation, which not only improves the model performance but also indicates the importance of the concatenated representation. We demonstrate the performance of i-DenseNets and Residual Flows on toy, MNIST, and CIFAR10 data. Both i-DenseNets outperform Residual Flows evaluated in negative log-likelihood, on all considered datasets under an equal parameter budget.},
archivePrefix = {arXiv},
arxivId = {2010.02125},
author = {Perugachi-Diaz, Yura and Tomczak, Jakub M. and Bhulai, Sandjai},
eprint = {2010.02125},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Perugachi-Diaz, Tomczak, Bhulai - 2020 - Invertible DenseNets.pdf:pdf},
keywords = {architecture,backbone,convolutional neural networks},
mendeley-tags = {architecture,backbone,convolutional neural networks},
pages = {2020--2021},
title = {{Invertible DenseNets}},
url = {http://arxiv.org/abs/2010.02125 https://github.com/ yperugachidiaz/invertible_densenets},
year = {2020}
}
@article{McQuivey2013,
abstract = {When companies technology, they do old things in new ways; when companies iinternalliize technology, they find disruptive new things to do},
author = {McQuivey, James},
doi = {1477800123},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/McQuivey - 2013 - Digital Disruption Unleashing The Next Wave Of Innovation.pdf:pdf},
isbn = {9781477800126},
journal = {Forrester Research},
keywords = {Business},
number = {February},
title = {{Digital Disruption: Unleashing The Next Wave Of Innovation}},
url = {A019},
year = {2013}
}
@article{Li2010a,
author = {Li, Yifeng and Ngom, Alioune and Rueda, Luis},
doi = {10.1109/CIBCB.2010.5510349},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Ngom, Rueda - 2010 - Missing value imputation methods for gene-sample-time microarray data analysis.pdf:pdf},
isbn = {978-1-4244-6766-2},
journal = {2010 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology},
number = {2},
pages = {1--7},
title = {{Missing value imputation methods for gene-sample-time microarray data analysis}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5510349},
year = {2010}
}
@article{Sridevi2011,
author = {Sridevi, S. and Rajaram, S. and Parthiban, C. and SibiArasan, S. and Swadhikar, C.},
doi = {10.1109/ICRTIT.2011.5972466},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sridevi et al. - 2011 - Imputation for the analysis of missing values and prediction of time series data.pdf:pdf},
isbn = {978-1-4577-0588-5},
journal = {2011 International Conference on Recent Trends in Information Technology (ICRTIT)},
keywords = {ar,auto-regressive,model,prediction,temporal databases,time series analysis},
pages = {1158--1163},
title = {{Imputation for the analysis of missing values and prediction of time series data}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5972466},
year = {2011}
}
@inproceedings{Ben-Baruch2020,
abstract = {In a typical multi-label setting, a picture contains on average few positive labels, and many negative ones. This positive-negative imbalance dominates the optimization process, and can lead to under-emphasizing gradients from positive labels during training, resulting in poor accuracy. In this paper, we introduce a novel asymmetric loss ("ASL"), which operates differently on positive and negative samples. The loss enables to dynamically down-weights and hard-thresholds easy negative samples, while also discarding possibly mislabeled samples. We demonstrate how ASL can balance the probabilities of different samples, and how this balancing is translated to better mAP scores. With ASL, we reach state-of-the-art results on multiple popular multi-label datasets: MS-COCO, Pascal-VOC, NUS-WIDE and Open Images. We also demonstrate ASL applicability for other tasks, such as single-label classification and object detection. ASL is effective, easy to implement, and does not increase the training time or complexity. Implementation is available at: https://github.com/Alibaba-MIIL/ASL.},
archivePrefix = {arXiv},
arxivId = {2009.14119},
author = {Ben-Baruch, Emanuel and Ridnik, Tal and Zamir, Nadav and Noy, Asaf and Friedman, Itamar and Protter, Matan and Zelnik-Manor, Lihi},
booktitle = {International Conference on Computer Vision},
eprint = {2009.14119},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ben-Baruch et al. - 2021 - Asymmetric Loss For Multi-Label Classification.pdf:pdf},
keywords = {metric learning},
mendeley-tags = {metric learning},
pages = {82--91},
title = {{Asymmetric Loss For Multi-Label Classification}},
url = {http://arxiv.org/abs/2009.14119},
year = {2021}
}
@article{Allen-Zhu2019a,
abstract = {Deep neural networks (DNNs) have demonstrated dominating performance in many fields; since AlexNet, networks used in practice are going wider and deeper. On the theoretical side, a long line of works have been focusing on why we can train neural networks when there is only one hidden layer. The theory of multi-layer networks remains unsettled. In this work, we prove simple algorithms such as stochastic gradient descent (SGD) can find global minima on the training objective of DNNs in polynomial time. We only make two assumptions: the inputs do not degenerate and the network is over-parameterized. The latter means the number of hidden neurons is sufficiently large: polynomial in L, the number of DNN layers and in n, the number of training samples. As concrete examples, starting from randomly initialized weights, we show that SGD attains 100% training accuracy in classification tasks, or minimizes regression loss in linear convergence speed $\epsilon$ e-$\Omega$(T) with running time polynomial in n and L. Our theory applies to the widely-used but non-smooth ReLU activation, and to any smooth and possibly non-convex loss functions. In terms of network architectures, our theory at least applies to fully-connected neural networks, convolutional neural networks (CNN), and residual neural networks (ResNet).},
archivePrefix = {arXiv},
arxivId = {1811.03962},
author = {Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
eprint = {1811.03962},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Allen-Zhu, Li, Song - 2019 - A convergence theory for deep learning via over-parameterization(2).pdf:pdf},
isbn = {9781510886988},
journal = {36th International Conference on Machine Learning, ICML 2019},
keywords = {convergence,optimization,over,theory},
mendeley-tags = {convergence,optimization,over,theory},
pages = {362--372},
title = {{A convergence theory for deep learning via over-parameterization}},
volume = {2019-June},
year = {2019}
}
@article{Bella2005,
abstract = {Little is known about researchers' understanding of confidence intervals (CIs) and standard error (SE) bars. Authors of journal articles in psychology, behavioral neuroscience, and medicine were invited to visit a Web site where they adjusted a figure until they judged 2 means, with error bars, to be just statistically significantly different (p < .05). Results from 473 respondents suggest that many leading researchers have severe misconceptions about how error bars relate to statistical significance, do not adequately distinguish CIs and SE bars, and do not appreciate the importance of whether the 2 means are independent or come from a repeated measures design. Better guidelines for researchers and less ambiguous graphical conventions are needed before the advantages of CIs for research communication can be realized.},
author = {Bella, Sarah and Fidler, Fiona and Williams, Jennifer and Cumming, Geoff},
doi = {10.1037/1082-989X.10.4.389},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bella et al. - 2005 - Researchers misunderstand confidence intervals and standard error bars.pdf:pdf},
isbn = {1082-989X (Print)\r1082-989X (Linking)},
issn = {1082989X},
journal = {Psychological Methods},
keywords = {Confidence intervals,Error bars,Standard error,Statistical cognition,Statistical reform},
number = {4},
pages = {389--396},
pmid = {16392994},
title = {{Researchers misunderstand confidence intervals and standard error bars}},
volume = {10},
year = {2005}
}
@article{Raharjo,
author = {Raharjo, Budi Agung and Wibawa, Unggul and Suyono, Hadi},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Raharjo, Wibawa, Suyono - Unknown - Studi Analisis Konsumsi dan Penghematan Energi di PT. P.G. Krebet Baru I.pdf:pdf},
journal = {Tan},
keywords = {consumption energy,dan,electric motor,energy audit,energy saving,lighting,sec,specific},
title = {{Studi Analisis Konsumsi dan Penghematan Energi di PT. P.G. Krebet Baru I}}
}
@article{Scarselli2009,
abstract = {Catalysts of high activity and stability for the preparation of chlorophthalic anhydride has been investigated. The 3(4)-chloro-1,2-dimethyl benzene was used as raw material. Catalytic oxidation in the gas phase was carried out under the following conditions (concentration of Cl{\textperiodcentered}C 6H 3{\textperiodcentered} (CH 3) 20. 7%∼1. 73%(mol);specific velocity 1 300∼6 000 h -1;temperature 410∼500 °C. Neither phthalic anhydride nor polychlorophthalic anhydride was found in the reaction product. The weight yield of chlorophthalic anhydride was 98%. It is easy to purify the product to a purity of above 98% chlorophthalic anhydride.},
author = {Scarselli, F. and Gori, M. and {Ah Chung Tsoi} and Hagenbuchner, M. and Monfardini, G.},
doi = {10.1109/TNN.2008.2005605},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Scarselli et al. - 2009 - The Graph Neural Network Model.pdf:pdf},
issn = {1045-9227},
journal = {IEEE Transactions on Neural Networks},
keywords = {Chlorophthalic anhydride,Chloroxylene,Oxidation in gas phase},
month = {jan},
number = {1},
pages = {61--80},
title = {{The Graph Neural Network Model}},
url = {http://ieeexplore.ieee.org/document/4700287/},
volume = {20},
year = {2009}
}
@article{Bottomley2014,
abstract = {There are two competing accounts for explaining Britain's technological transformation during the Industrial Revolution. One sees it as the inevitable outcome of a largely exogenous increase in the supply of new ideas and ways of thinking. The other sees it as a demand side response to economic incentives-that in Britain, it paid to invent the technology of the Industrial Revolution. However, this second interpretation relies on the assumption that inventors were sufficiently responsive to new commercial opportunities. This paper tests this assumption, using a new dataset of Scottish and Irish patents. It finds that the propensity of inventors to extend patent protection into Scotland and/or Ireland was indeed closely correlated with the relative market opportunity of the patented invention.},
author = {Bottomley, Sean},
doi = {10.1016/j.eeh.2014.08.002},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bottomley - 2014 - Patenting in England, Scotland and Ireland during the Industrial Revolution, 1700-1852.pdf:pdf},
issn = {10902457},
journal = {Explorations in Economic History},
keywords = {Industrial Revolution,Invention,Ireland,Patents,Scotland},
pages = {48--63},
publisher = {Elsevier Inc.},
title = {{Patenting in England, Scotland and Ireland during the Industrial Revolution, 1700-1852}},
url = {http://dx.doi.org/10.1016/j.eeh.2014.08.002},
volume = {54},
year = {2014}
}
@article{Olabi2007,
abstract = {Magneto-rheological fluid (MRF) technology is an old "newcomers" coming to the market at high speed. Various industries including the automotive industry are full of potential MRF applications. Magneto-rheological fluid technology has been successfully employed already in various low and high volume applications. A structure based on MRF might be the next generation in design for products where power density, accuracy and dynamic performance are the key features. Additionally, for products where is a need to control fluid motion by varying the viscosity, a structure based on MRF might be an improvement in functionality and costs. Two aspects of this technology, direct shear mode (used in brakes and clutches) and valve mode (used in dampers) have been studied thoroughly and several applications are already present on the market. Excellent features like fast response, simple interface between electrical power input and mechanical power output, and precise controllability make MRF technology attractive for many applications. This paper presents the state of the art of an actuator with a control arrangement based on MRF technology. The study shows that excellent features like fast response, simple interface between electrical power input and the mechanical power output, and controllability make MRF the next technology of choice for many applications. {\textcopyright} 2006 Elsevier Ltd. All rights reserved.},
author = {Olabi, A. G. and Grunwald, A.},
doi = {10.1016/j.matdes.2006.10.009},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Olabi, Grunwald - 2007 - Design and application of magneto-rheological fluid.pdf:pdf},
issn = {18734197},
journal = {Materials and Design},
number = {10},
pages = {2658--2664},
title = {{Design and application of magneto-rheological fluid}},
volume = {28},
year = {2007}
}
@book{Bosart2008,
abstract = {Advances in computer power, new forecasting challenges, and new diagnostic\ntechniques have brought about\n\nchanges in the way atmospheric development and vert ical motion are\ndiagnosed in an operational sening. Many\n\nof these changes, such as improved model sk ill, model resolution,\nand ensemble forecasting, have arguably been\n\ndetrimental to the ability of forecasters 10 understand and respond\nto the evolving atmosphere. The use of\n\nnondivergent wind in place of geostrophic wind would be a step in\nthe right direction, but the advantages of\n\npotential vorticity suggest that its widespread adoption as a diagnostic\n1001 on the west side of the Atlantic is\n\noverdue. Ertel potential vorticity (PV), when sca led to be compatible\nwith pseudopotential vorticity, is generally\n\nsimilar to pseudopotential vonicity, so fo recasters accustomed to\nquasigeostrophic reasoning through the height\n\ntendency equation can transfer some of their intuition into the Ertel-PV\nframework. Indeed, many of the differences\n\nbetween pseudopotential vort icity and Ertel potential vort icity\nare consequences of the choice of definition\n\nof quas igeostrophic PV and are not fundamenta l to the quasigeostrophic\nsystem. Thus, al ils core, PV\n\nthinki ng is co nsistent with commonly used quasigeost rophic diagnoslic\ntechniques.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Bosart, Lance F. and Sanders, Fred},
booktitle = {Meteorological monographs},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bosart, Sanders - 2008 - Synoptic-dynamic meteorology and weather analysis and forecasting a tribute to Fred Sanders.pdf:pdf},
isbn = {978-1-878220-84-4},
issn = {19454589},
keywords = {charts and diagrams,for up to 3,local forecasts + single observer forecasts (meteo,meteorological reports/weather-forecast (meteorolo,meteorology/historical aspects,synoptic reports},
number = {33 = no 55},
pages = {423 S.},
pmid = {25246403},
title = {{Synoptic-dynamic meteorology and weather analysis and forecasting a tribute to Fred Sanders}},
year = {2008}
}
@article{Dai2020,
abstract = {Object detection with transformers (DETR) reaches competitive performance with Faster R-CNN via a transformer encoder-decoder architecture. Inspired by the great success of pre-training transformers in natural language processing, we propose a pretext task named random query patch detection to unsupervisedly pre-train DETR (UP-DETR) for object detection. Specifically, we randomly crop patches from the given image and then feed them as queries to the decoder. The model is pre-trained to detect these query patches from the original image. During the pre-training, we address two critical issues: multi-task learning and multi-query localization. (1) To trade-off multi-task learning of classification and localization in the pretext task, we freeze the CNN backbone and propose a patch feature reconstruction branch which is jointly optimized with patch detection. (2) To perform multi-query localization, we introduce UP-DETR from single-query patch and extend it to multi-query patches with object query shuffle and attention mask. In our experiments, UP-DETR significantly boosts the performance of DETR with faster convergence and higher precision on PASCAL VOC and COCO datasets. The code will be available soon.},
archivePrefix = {arXiv},
arxivId = {2011.09094},
author = {Dai, Zhigang and Cai, Bolun and Lin, Yugeng and Chen, Junying},
eprint = {2011.09094},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dai et al. - 2020 - UP-DETR Unsupervised Pre-training for Object Detection with Transformers.pdf:pdf},
month = {nov},
title = {{UP-DETR: Unsupervised Pre-training for Object Detection with Transformers}},
url = {http://arxiv.org/abs/2011.09094},
year = {2020}
}
@article{GhassemiTari2016,
abstract = {In this manuscript, a vehicle allocation problem involving a heterogeneous fleet of vehicles for delivering products from a manufacturing firm to a set of depots is considered. Each depot has a specific order quantity and transportation costs consist of fixed and variable transportation cost. The objective is to assign the proper type and number of vehicle to each depot route to minimize the total transportation costs. It is assumed that the number of chartering vehicle types is limited. It is also assumed that a discount mechanism is applied to the vehicles renting cost. The discount mechanism is applied to the fixed cost, based on the number of vehicles to be rented. A mathematical programming model is proposed which is then converted to a mixed 0-1 integer programming model. Due to the computational complexity of the proposed mathematical model, a priority based genetic algorithm capable of solving the real world size problems was proposed. A computational experiment is conducted through which, the performance of the proposed algorithm is evaluated. The results reveal that the proposed algorithm is capable of providing the astonishing solutions with minimal computational effort, comparing with the CPLEX solutions.},
author = {{Ghassemi Tari}, Farhad and Hashemi, Zahra},
doi = {10.1016/j.cie.2016.03.010},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghassemi Tari, Hashemi - 2016 - A priority based genetic algorithm for nonlinear transportation costs problems.pdf:pdf},
issn = {03608352},
journal = {Computers and Industrial Engineering},
keywords = {Discounted transportation costs,Fixed cost transportation,Nonlinear combinatorial optimization,Priority genetic algorithm},
pages = {86--95},
publisher = {Elsevier Ltd},
title = {{A priority based genetic algorithm for nonlinear transportation costs problems}},
url = {http://dx.doi.org/10.1016/j.cie.2016.03.010},
volume = {96},
year = {2016}
}
@article{Steinmetz2017a,
abstract = {Physical temperature can fundamentally affect psychological processes. Among other things, physical warmth typically fosters the motivation to affiliate. We argue that physical warmth can increase affirmative and acquiescent response behavior in psychological surveys and experiments as a result of such an affiliative motive. In Study 1, we find that participants give more biased answers in a memory test in warmer, compared to colder, environments. In Studies 2–3b, physical warmth fosters a response bias toward the affirmation of unrelated items in questionnaires. In Study 4, the effect of physical warmth on the affirmation bias is amplified when the person reading a participant's answers is a friend (stronger affiliation prime) compared to a stranger. Taken together, temperature affects general response behavior by fostering affirmation. Thereby, physical temperature has deeper psychological as well as methodological consequences than previously thought.},
author = {Steinmetz, Janina and Posten, Ann Christin},
doi = {10.1016/j.jesp.2016.12.001},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Steinmetz, Posten - 2017 - Physical temperature affects response behavior.pdf:pdf},
issn = {10960465},
journal = {Journal of Experimental Social Psychology},
keywords = {Affiliation,Physical warmth,Response bias,Temperature},
pages = {294--300},
publisher = {Elsevier B.V.},
title = {{Physical temperature affects response behavior}},
url = {http://dx.doi.org/10.1016/j.jesp.2016.12.001},
volume = {70},
year = {2017}
}
@article{Ramesh2021,
abstract = {This paper argues that continual learning methods can benefit by splitting the capacity of the learner across multiple models. We use statistical learning theory and experimental analysis to show how multiple tasks can interact with each other in a non-trivial fashion when a single model is trained on them. The generalization error on a particular task can improve when it is trained with synergistic tasks, but can also deteriorate when trained with competing tasks. This theory motivates our method named Model Zoo which, inspired from the boosting literature, grows an ensemble of small models, each of which is trained during one episode of continual learning. We demonstrate that Model Zoo obtains large gains in accuracy on a variety of continual learning benchmark problems.},
archivePrefix = {arXiv},
arxivId = {2106.03027},
author = {Ramesh, Rahul and Chaudhari, Pratik},
eprint = {2106.03027},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramesh, Chaudhari - 2021 - Model Zoo A Growing Brain That Learns Continually.pdf:pdf},
keywords = {continual learning},
mendeley-tags = {continual learning},
title = {{Model Zoo: A Growing "Brain" That Learns Continually}},
url = {http://arxiv.org/abs/2106.03027},
year = {2021}
}
@article{Saruhan2014a,
abstract = {In this study, nature inspired algorithms – the Differential Evolution (DE) and the Simulated Annealing (SA) – are utilized to seek a global optimum solution for ball bearings link system assembly weight with constraints and mixed design variables. The Genetic Algorithm (GA) and the Evolution Strategy (ES) will be a reference for the examination and validation of the DE and the SA. The main purpose is to minimize the weight of an assembly system composed of a shaft and two ball bearings. Ball bearings link system is used extensively in many machinery applications. Among mechanical systems, designers pay great attention to the ball bearings link system because of its significant industrial importance. The problem is complex and a time consuming process due to mixed design variables and inequality constraints imposed on the objective function. The results showed that the DE and the SA performed and obtained convergence reliability on the global optimum solution. So the contribution of the DE and the SA application to the mechanical system design can be very useful in many real-world mechanical system design problems. Beside, the comparison confirms the effectiveness and the superiority of the DE over the others algorithms – the SA, the GA, and the ES – in terms of solution quality. The ball bearings link system assembly weight of 634,099 gr was obtained using the DE while 671,616 gr, 728213.8 gr, and 729445.5 gr were obtained using the SA, the ES, and the GA respectively.},
author = {Saruhan, H.},
doi = {10.1016/j.jestch.2014.04.006},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saruhan - 2014 - Differential evolution and simulated annealing algorithms for mechanical systems design.pdf:pdf},
issn = {22150986},
journal = {Engineering Science and Technology, an International Journal},
keywords = {Design optimization,Differential evolution,Genetic algorithm,Simulated annealing},
number = {3},
pages = {131--136},
publisher = {Elsevier Ltd},
title = {{Differential evolution and simulated annealing algorithms for mechanical systems design}},
url = {http://dx.doi.org/10.1016/j.jestch.2014.04.006},
volume = {17},
year = {2014}
}
@article{Mrugalska2017,
abstract = {Lean Production is widely recognized and accepted in the industrial setting. It concerns the strict integration of humans in the manufacturing process, a continuous improvement and focus on value-adding activities by avoiding waste. However, a new paradigm called Industry 4.0 or the fourth industrial revolution has recently emerged in the manufacturing sector. It allows creating a smart network of machines, products, components, properties, individuals and ICT systems in the entire value chain to have an intelligent factory. So, now a question arises if, and how these two approaches can coexist and support each other.},
author = {Mrugalska, Beata and Wyrwicka, Magdalena K.},
doi = {10.1016/j.proeng.2017.03.135},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mrugalska, Wyrwicka - 2017 - Towards Lean Production in Industry 4.0.pdf:pdf},
isbn = {4861665337},
issn = {18777058},
journal = {Procedia Engineering},
keywords = {industry 4.0,lean automation,lean production,production management},
pages = {466--473},
publisher = {The Author(s)},
title = {{Towards Lean Production in Industry 4.0}},
url = {http://dx.doi.org/10.1016/j.proeng.2017.03.135},
volume = {182},
year = {2017}
}
@article{Ghiassian2020,
abstract = {Reinforcement learning systems require good representations to work well. For decades practical success in reinforcement learning was limited to small domains. Deep reinforcement learning systems, on the other hand, are scalable, not dependent on domain specific prior knowledge and have been successfully used to play Atari, in 3D navigation from pixels, and to control high degree of freedom robots. Unfortunately, the performance of deep reinforcement learning systems is sensitive to hyper-parameter settings and architecture choices. Even well tuned systems exhibit significant instability both within a trial and across experiment replications. In practice, significant expertise and trial and error are usually required to achieve good performance. One potential source of the problem is known as catastrophic interference: when later training decreases performance by overriding previous learning. Interestingly, the powerful generalization that makes Neural Networks (NN) so effective in batch supervised learning might explain the challenges when applying them in reinforcement learning tasks. In this paper, we explore how online NN training and interference interact in reinforcement learning. We find that simply re-mapping the input observations to a high-dimensional space improves learning speed and parameter sensitivity. We also show this preprocessing reduces interference in prediction tasks. More practically, we provide a simple approach to NN training that is easy to implement, and requires little additional computation. We demonstrate that our approach improves performance in both prediction and control with an extensive batch of experiments in classic control domains.},
archivePrefix = {arXiv},
arxivId = {2003.07417},
author = {Ghiassian, Sina and Rafiee, Banafsheh and Lo, Yat Long and White, Adam},
eprint = {2003.07417},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghiassian et al. - 2020 - Improving performance in reinforcement learning by breaking generalization in neural networks.pdf:pdf},
isbn = {9781450375184},
issn = {15582914},
journal = {Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS},
keywords = {Interference,Neural networks,Reinforcement learning,continual learning,reinforcement learning},
mendeley-tags = {continual learning,reinforcement learning},
number = {1},
pages = {438--446},
title = {{Improving performance in reinforcement learning by breaking generalization in neural networks}},
volume = {2020-May},
year = {2020}
}
@article{Triebe2019,
abstract = {In this paper we present a new framework for time-series modeling that combines the best of traditional statistical models and neural networks. We focus on time-series with long-range dependencies, needed for monitoring fine granularity data (e.g. minutes, seconds, milliseconds), prevalent in operational use-cases. Traditional models, such as auto-regression fitted with least squares (Classic-AR) can model time-series with a concise and interpretable model. When dealing with long-range dependencies, Classic-AR models can become intractably slow to fit for large data. Recently, sequence-to-sequence models, such as Recurrent Neural Networks, which were originally intended for natural language processing, have become popular for time-series. However, they can be overly complex for typical time-series data and lack interpretability. A scalable and interpretable model is needed to bridge the statistical and deep learning-based approaches. As a first step towards this goal, we propose modelling AR-process dynamics using a feed-forward neural network approach, termed AR-Net. We show that AR-Net is as interpretable as Classic-AR but also scales to long-range dependencies. Our results lead to three major conclusions: First, AR-Net learns identical AR-coefficients as Classic-AR, thus being equally interpretable. Second, the computational complexity with respect to the order of the AR process, is linear for AR-Net as compared to a quadratic for Classic-AR. This makes it possible to model long-range dependencies within fine granularity data. Third, by introducing regularization, AR-Net automatically selects and learns sparse AR-coefficients. This eliminates the need to know the exact order of the AR-process and allows to learn sparse weights for a model with long-range dependencies.},
archivePrefix = {arXiv},
arxivId = {1911.12436},
author = {Triebe, Oskar J. and Laptev, Nikolay and Rajagopal, Ram},
eprint = {1911.12436},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Triebe, Laptev, Rajagopal - 2019 - AR-net A simple auto-regressive neural network for time-series.pdf:pdf},
journal = {arXiv},
keywords = {Auto-Regression,Long-Range,Neural Networks,Sparsity,Time-Series,time series},
mendeley-tags = {time series},
pages = {1--12},
title = {{AR-net: A simple auto-regressive neural network for time-series}},
url = {https://arxiv.org/pdf/1911.12436v1.pdf https://github.com/ourownstory/AR-Net https://github.com/ourownstory/neural_prophet},
volume = {d},
year = {2019}
}
@article{Jung2017,
abstract = {Interest in energy harvesters has grown rapidly over the last decade. The research effort in large-scale energy harvesting has mainly focused on piezoelectric ceramic based devices, due to its high piezoelectric constants. In this study, we demonstrate a piezoelectric energy harvester module based on polyvinylidene fluoride (PVDF) polymer for roadway applications. Flexible energy harvesters are fabricated with PVDF films and it exhibited stable performance and durability over the repeated number of bending cycles. In order to structurally optimize the design, finite element analysis was performed on two possible module configuration, with detailed input conditions on how the flexible energy harvester must be bent. A piezoelectric energy harvester module is then constructed with the fabricated unit energy harvesters inserted in the vertical direction, with initial radii of curvature as high as possible. The module was tested with a model mobile load system (MMLS3) and exhibited up to 200 mW instantaneous power output across a 40 k$\Omega$ resistor. The power output scaled linearly with the number of parallel connected harvesters. The calculated power density at this impedance reaches up to 8.9 W/m2, suggesting that the flexible energy harvesters based on the piezoelectric polymers may provide energy density as high as those based on piezoelectric ceramics.},
author = {Jung, Inki and Shin, Youn Hwan and Kim, Sangtae and young Choi, Ji and Kang, Chong Yun},
doi = {10.1016/j.apenergy.2017.04.020},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jung et al. - 2017 - Flexible piezoelectric polymer-based energy harvesting system for roadway applications.pdf:pdf},
issn = {03062619},
journal = {Applied Energy},
keywords = {Piezoelectric energy harvesting,Piezoelectric polymer,Smart highway,Traffic induced energy},
pages = {222--229},
publisher = {Elsevier Ltd},
title = {{Flexible piezoelectric polymer-based energy harvesting system for roadway applications}},
url = {http://dx.doi.org/10.1016/j.apenergy.2017.04.020},
volume = {197},
year = {2017}
}
@article{Sovann2014,
author = {Sovann, N and Nallagownden, P and Baharudin, Z},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sovann, Nallagownden, Baharudin - 2014 - A method to determine the input variable for the neural network model of the electrical system.pdf:pdf},
isbn = {1479946532},
journal = {Intelligent and Advanced Systems (ICIAS), 2014 5th International Conference on},
keywords = {acf,ann,artificial neural network,autocorrelation seasonality were not,ccf,choose,cross correlation function,exploration on how to,function,however,included in the study,it still needs more,pacf,partial autocorrelation function},
pages = {1--6},
title = {{A method to determine the input variable for the neural network model of the electrical system}},
year = {2014}
}
@article{Garcez2020,
abstract = {Current advances in Artificial Intelligence (AI) and Machine Learning (ML) have achieved unprecedented impact across research communities and industry. Nevertheless, concerns about trust, safety, interpretability and accountability of AI were raised by influential thinkers. Many have identified the need for well-founded knowledge representation and reasoning to be integrated with deep learning and for sound explainability. Neural-symbolic computing has been an active area of research for many years seeking to bring together robust learning in neural networks with reasoning and explainability via symbolic representations for network models. In this paper, we relate recent and early research results in neurosymbolic AI with the objective of identifying the key ingredients of the next wave of AI systems. We focus on research that integrates in a principled way neural network-based learning with symbolic knowledge representation and logical reasoning. The insights provided by 20 years of neural-symbolic computing are shown to shed new light onto the increasingly prominent role of trust, safety, interpretability and accountability of AI. We also identify promising directions and challenges for the next decade of AI research from the perspective of neural-symbolic systems.},
archivePrefix = {arXiv},
arxivId = {2012.05876},
author = {d'Avila Garcez, Artur and Lamb, Luis C.},
eprint = {2012.05876},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garcez, Lamb - 2020 - Neurosymbolic AI The 3rd Wave.pdf:pdf},
keywords = {ai fast and slow,deep learning,explainable ai,machine learning and reasoning,neuro-symbolic ai,neurosymbolic computing},
mendeley-tags = {neuro-symbolic ai},
pages = {1--37},
title = {{Neurosymbolic AI: The 3rd Wave}},
url = {http://arxiv.org/abs/2012.05876},
year = {2020}
}
@book{Castillo2003,
author = {Castillo, Oscar and Melin, P.},
booktitle = {Comparative and General Pharmacology},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Castillo, Melin - 2003 - Soft computing and fractal theory for intelligent manufacturing.pdf:pdf},
isbn = {9783662002964},
title = {{Soft computing and fractal theory for intelligent manufacturing}},
url = {http://books.google.com/books?hl=en&lr=&id=rlNCFPIBi-MC&oi=fnd&pg=PR5&dq=Soft+Computing+and+Fractal+Theory+for+Intelligent+Control+and+Manufacturing&ots=g76_uOHTBK&sig=EAUrNhoZ0aUKoHjzZh07bMekEYo%5Cnhttp://books.google.com/book},
volume = {117},
year = {2003}
}
@article{Zhang2016a,
abstract = {? 2016 IEEE.In this paper, we propose a hybrid high order Type 2 fuzzy time series model by combining support vector machine (SVM) with adaptive expectation model. We use SVM model to forecast the index of the fuzzy set of the predicted time. Particle swarm optimization (PSO) algorithm is used to adjust the lengths of intervals of the universe of discourse which are employed in forecasting. Moreover, we also propose a new method to calculate the weights of fuzzy sets for compensating the presence of bias in the forecasting. Further, we apply an modified adaptive model to adjust the forecasting value in the defuzzification stage. We utilize the proposed model to forecast the daily Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX) and Index 100 for the stocks and bonds exchange market of Istanbul (IMKB). The experimental results illustrate the validity of the method.},
author = {Zhang, E. and Wang, D. and Li, H.},
doi = {10.1109/CCDC.2016.7532199},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Wang, Li - 2016 - A comprehensive high order Type 2 fuzzy time series forecasting model.pdf:pdf},
isbn = {9781467397148},
journal = {Proceedings of the 28th Chinese Control and Decision Conference, CCDC 2016},
keywords = {Support vector machine,Type 2,[Fuzzy time series},
number = {1},
pages = {1--6},
title = {{A comprehensive high order Type 2 fuzzy time series forecasting model}},
year = {2016}
}
@article{Sutskever2013,
abstract = {Deep and recurrent neural networks (DNNs and RNNs respectively) are powerful models that were considered to be almost impossible to train using stochastic gradient descent with momentum. In this paper, we show that when stochastic gradient descent with momentum uses a well-designed random initialization and a particular type of slowly increasing schedule for the momentum parameter, it can train both DNNs and RNNs (on datasets with long-term dependencies) to levels of performance that were previously achievable only with Hessian-Free optimization. We find that both the initialization and the momentum are crucial since poorly initialized networks cannot be trained with momentum and well-initialized networks perform markedly worse when the momentum is absent or poorly tuned. Our success training these models suggests that previous attempts to train deep and recurrent neural networks from random initializations have likely failed due to poor initialization schemes. Furthermore, carefully tuned momentum methods suffice for dealing with the curvature issues in deep and recurrent network training objectives without the need for sophisticated second-order methods. Copyright 2013 by the author(s).},
author = {Sutskever, Ilya and Martens, James and Dahl, George and Hinton, Geoffrey},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sutskever et al. - 2013 - On the importance of initialization and momentum in deep learning.pdf:pdf;:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/See - Unknown - Appendix A . 1 Derivation of Nesterov ' s Accelerated Gradient as a Momentum Method A . 3 . Autoencoder Problem Detail.pdf:pdf},
isbn = {7841000500250},
journal = {30th International Conference on Machine Learning, ICML 2013},
number = {PART 3},
pages = {2176--2184},
title = {{On the importance of initialization and momentum in deep learning}},
year = {2013}
}
@article{Michieli2021,
abstract = {Deep learning architectures have shown remarkable results in scene understanding problems, however they exhibit a critical drop of performances when they are required to learn incrementally new tasks without forgetting old ones. This catastrophic forgetting phenomenon impacts on the deployment of artificial intelligence in real world scenarios where systems need to learn new and different representations over time. Current approaches for incremental learning deal only with image classification and object detection tasks, while in this work we formally introduce incremental learning for semantic segmentation. We tackle the problem applying various knowledge distillation techniques on the previous model. In this way, we retain the information about learned classes, whilst updating the current model to learn the new ones. We developed four main methodologies of knowledge distillation working on both output layers and internal feature representations. We do not store any image belonging to previous training stages and only the last model is used to preserve high accuracy on previously learned classes. Extensive experimental results on the Pascal VOC2012 and MSRC-v2 datasets show the effectiveness of the proposed approaches in several incremental learning scenarios.},
archivePrefix = {arXiv},
arxivId = {1911.03462},
author = {Michieli, Umberto and Zanuttigh, Pietro},
doi = {10.1016/j.cviu.2021.103167},
eprint = {1911.03462},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Michieli, Zanuttigh - 2021 - Knowledge distillation for incremental learning in semantic segmentation.pdf:pdf},
issn = {1090235X},
journal = {Computer Vision and Image Understanding},
keywords = {Catastrophic forgetting,Continual learning,Incremental learning,Knowledge distillation,Semantic segmentation,continual learning,incremental learning,semantic segmentation},
mendeley-tags = {continual learning,incremental learning,semantic segmentation},
title = {{Knowledge distillation for incremental learning in semantic segmentation}},
volume = {205},
year = {2021}
}
@book{Fausett1994,
abstract = {Mycotoxins are small (MW approximately 700), toxic chemical products formed as secondary metabolites by a few fungal species that readily colonise crops and contaminate them with toxins in the field or after harvest. Ochratoxins and Aflatoxins are mycotoxins of major significance and hence there has been significant research on broad range of analytical and detection techniques that could be useful and practical. Due to the variety of structures of these toxins, it is impossible to use one standard technique for analysis and/or detection. Practical requirements for high-sensitivity analysis and the need for a specialist laboratory setting create challenges for routine analysis. Several existing analytical techniques, which offer flexible and broad-based methods of analysis and in some cases detection, have been discussed in this manuscript. There are a number of methods used, of which many are lab-based, but to our knowledge there seems to be no single technique that stands out above the rest, although analytical liquid chromatography, commonly linked with mass spectroscopy is likely to be popular. This review manuscript discusses (a) sample pre-treatment methods such as liquid-liquid extraction (LLE), supercritical fluid extraction (SFE), solid phase extraction (SPE), (b) separation methods such as (TLC), high performance liquid chromatography (HPLC), gas chromatography (GC), and capillary electrophoresis (CE) and (c) others such as ELISA. Further currents trends, advantages and disadvantages and future prospects of these methods have been discussed.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Fausett, Laurene},
booktitle = {Igarss 2014},
doi = {10.1007/s13398-014-0173-7.2},
eprint = {arXiv:1011.1669v3},
isbn = {9780874216561},
issn = {0717-6163},
keywords = {Bott},
number = {1},
pages = {1--5},
pmid = {15003161},
title = {{Fundamentals of Neural Networks}},
year = {1994}
}
@article{Mori2017,
author = {Mori, Hiroyuki and Itaba, Satoshi},
doi = {10.1109/IFSA-SCIS.2017.8023270},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mori, Itaba - 2017 - Integration of improved GRBFN with fuzzy clustering for electricity price forecasting.pdf:pdf},
isbn = {9781509049172},
journal = {IFSA-SCIS 2017 - Joint 17th World Congress of International Fuzzy Systems Association and 9th International Conference on Soft Computing and Intelligent Systems},
keywords = {DAclustering,GRBFN,clustering,electricity price,forecasting model,fuzzy c-Varieties,neural network,power market,pre-filtering},
title = {{Integration of improved GRBFN with fuzzy clustering for electricity price forecasting}},
year = {2017}
}
@article{Sciancalepore2014b,
author = {Sciancalepore, Corrado and Manfredini, Tiziano and Bondioli, Federica},
doi = {10.4028/www.scientific.net/AST.92.90},
isbn = {3038353043},
issn = {1662-0356},
journal = {Advances in Science and Technology},
number = {October},
pages = {90--99},
title = {{Antibacterial and Self-Cleaning Coatings for Silicate Ceramics: A Review}},
url = {http://www.scientific.net/AST.92.90},
volume = {92},
year = {2014}
}
@article{Xu2019,
abstract = {Deep neural networks (DNN) have achieved unprecedented success in numerous machine learning tasks in various domains. However, the existence of adversarial examples raises our concerns in adopting deep learning to safety-critical applications. As a result, we have witnessed increasing interests in studying attack and defense mechanisms for DNN models on different data types, such as images, graphs and text. Thus, it is necessary to provide a systematic and comprehensive overview of the main threats of attacks and the success of corresponding countermeasures. In this survey, we review the state of the art algorithms for generating adversarial examples and the countermeasures against adversarial examples, for three most popular data types, including images, graphs and text.},
archivePrefix = {arXiv},
arxivId = {1909.08072},
author = {Xu, Han and Ma, Yao and Liu, Haochen and Deb, Debayan and Liu, Hui and Tang, Jiliang and Jain, Anil},
eprint = {1909.08072},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu et al. - 2019 - Adversarial Attacks and Defenses in Images, Graphs and Text A Review.pdf:pdf},
title = {{Adversarial Attacks and Defenses in Images, Graphs and Text: A Review}},
url = {http://arxiv.org/abs/1909.08072},
year = {2019}
}
@article{Fadeyev2017,
abstract = {Parking policy determined and carried out in today's cities is based on a system of priorities. The main of them is the formation of a comfortable, favorable, safe and environmentally friendly city space. The goal can be reached if a certain city area is forbidden for cars. This study is aimed at economic evaluation of parking management tools, and analysis of users' behavior with a glance to applied management tools. The study allowed obtaining comparative evaluations of efficiency of paid parking and time constraint by the example of Irkutsk. Besides, the study determined the optimum rate and the way how costs of searching for a parking spot influence the efficiency of management tools.},
author = {Fadeyev, Dmitriy},
doi = {10.1016/j.trpro.2017.01.050},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fadeyev - 2017 - Method for Evaluating Economic Efficiency of Parking Management Tools.pdf:pdf},
isbn = {0000000000},
issn = {23521465},
journal = {Transportation Research Procedia},
keywords = {economic efficiency,parking,parking duration,parking policy,parking time constraint,payment for parking},
number = {September 2016},
pages = {193--199},
publisher = {The Author(s)},
title = {{Method for Evaluating Economic Efficiency of Parking Management Tools}},
url = {http://dx.doi.org/10.1016/j.trpro.2017.01.050},
volume = {20},
year = {2017}
}
@article{Phelps2004,
abstract = {The amygdala and hippocampal complex, two medial temporal lobe structures, are linked to two independent memory systems, each with unique characteristic functions. In emotional situations, these two systems interact in subtle but important ways. Specifically, the amygdala can modulate both the encoding and the storage of hippocampal-dependent memories. The hippocampal complex, by forming episodic representations of the emotional significance and interpretation of events, can influence the amygdala response when emotional stimuli are encountered. Although these are independent memory systems, they act in concert when emotion meets memory.},
author = {Phelps, Elizabeth A.},
doi = {10.1016/j.conb.2004.03.015},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Phelps - 2004 - Human emotion and memory Interactions of the amygdala and hippocampal complex.pdf:pdf},
isbn = {0959-4388 (Print)\n0959-4388 (Linking)},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
keywords = {Functional magnetic resonance imaging,fMRI},
number = {2},
pages = {198--202},
pmid = {15082325},
title = {{Human emotion and memory: Interactions of the amygdala and hippocampal complex}},
volume = {14},
year = {2004}
}
@article{Rebekic2015a,
abstract = {{\textcopyright} 2015, Faculty of Agriculture in Osijek. All rights Reserved. Most commonly used correlation coefficients are Pearson's product moment correlation coefficient and Spearman's rank correlation coefficient. The aim of this paper is to compare a Pearson's and Spearman's coefficient of correlation on the same data set. The winter wheat grain cadmium (Cd) concentration was correlated to grain zinc (Zn) concentration, plant height, plant weight, number of spikelets per spike and 1000 kernel weight. Data were collected from the experiment carried out in semi controlled conditions, where genotypic specificity of winter wheat varieties was tested on the grain Cd and Zn accumulation on uncontaminated and Cd contaminated soil. Results showed that selection of most convenient correlation coefficient mostly depends on the type of variables, presence of outliers normality and linearity of relationship.},
author = {Rebeki{\'{c}}, A. and Lon{\v{c}}ari{\'{c}}, Z. and Petrovi{\'{c}}, S. and Mari{\'{c}}, S.},
doi = {http://dx.doi.org/10.18047/poljo.21.2.8},
issn = {13307142},
journal = {Poljoprivreda},
number = {2},
pages = {47--54},
title = {{Pearson's or spearman's correlation coefficient – which one to use ?}},
volume = {21},
year = {2015}
}
@article{Ayub2020,
abstract = {For many applications, robots will need to be incrementally trained to recognize the specific objects needed for an application. This paper presents a practical system for incrementally training a robot to recognize different object categories using only a small set of visual examples provided by a human. The paper uses a recently developed state-of-the-art method for few-shot incremental learning of objects. After learning the object classes incrementally, the robot performs a table cleaning task organizing objects into categories specified by the human. We also demonstrate the system's ability to learn arrangements of objects and predict missing or incorrectly placed objects. Experimental evaluations demonstrate that our approach achieves nearly the same performance as a system trained with all examples at one time (batch training), which constitutes a theoretical upper bound.},
archivePrefix = {arXiv},
arxivId = {2008.00819},
author = {Ayub, Ali and Wagner, Alan R.},
eprint = {2008.00819},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ayub, Wagner - 2020 - Tell me what this is Few-shot incremental object learning by a robot.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {continual learning,few-shot learning,robotics},
mendeley-tags = {continual learning,few-shot learning,robotics},
title = {{Tell me what this is: Few-shot incremental object learning by a robot}},
year = {2020}
}
@article{Miller2014,
author = {Miller, Rowland and Leary, Mark R},
doi = {10.1207/S15327965PLI1403&4_15},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Miller, Leary - 2014 - Monitor as an Interpersonal on Self-Esteem Commentary Hypothesis The Sociometer.pdf:pdf},
isbn = {1532-7965 (Electronic); 1047-840X (Print)},
issn = {1047-840X},
number = {3},
pages = {270--274},
title = {{Monitor : as an Interpersonal on Self-Esteem Commentary Hypothesis The Sociometer}},
volume = {14},
year = {2014}
}
@article{Dennis2019,
abstract = {Recurrent Neural Networks (RNNs) capture long dependencies and context, and hence are the key component of typical sequential data based tasks. However, the sequential nature of RNNs dictates a large inference cost for long sequences even if the hardware supports parallelization. To induce long-term dependencies, and yet admit parallelization, we introduce novel shallow RNNs. In this architecture, the first layer splits the input sequence and runs several independent RNNs. The second layer consumes the output of the first layer using a second RNN thus capturing long dependencies. We provide theoretical justification for our architecture under weak assumptions that we verify on real-world benchmarks. Furthermore, we show that for time-series classification, our technique leads to substantially improved inference time over standard RNNs without compromising accuracy. For example, we can deploy audio-keyword classification on tiny Cortex M4 devices (100MHz processor, 256KB RAM, no DSP available) which was not possible using standard RNN models. Similarly, using ShaRNN in the popular Listen-Attend-Spell (LAS) architecture for phoneme classification [4], we can reduce the lag in phoneme classification by 10-12x while maintaining state-of-the-art accuracy.},
author = {Dennis, Don Kurian and Acar, Durmus Alp Emre and Mandikal, Vikram and Sadasivan, Vinu Sankar and Simhadri, Harsha Vardhan and Saligrama, Venkatesh and Jain, Prateek},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dennis et al. - 2019 - Shallow RNNs A method for accurate time-series classification on tiny devices.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
keywords = {time series},
mendeley-tags = {time series},
number = {NeurIPS},
title = {{Shallow RNNs: A method for accurate time-series classification on tiny devices}},
url = {https://github.com/Microsoft/EdgeML https://github.com/sevakon/shallow-rnns http://papers.nips.cc/paper/9451-shallow-rnn-accurate-time-series-classification-on-resource-constrained-devices.pdf},
volume = {32},
year = {2019}
}
@article{TutHaklidir2017,
abstract = {Calcium carbonate scaling and silica scaling are critical challenges directly affecting the efficiency of production during operational periods for geothermal power plants or geothermal district heating systems. Although their precipitation mechanisms are different from each other, both can be observed in varied proportions in production and reinjection wells as well as surface equipment in geothermal systems. Thus, scale prevention and control systems are essential, as abatement of scaling is more efficient than removal from wells and equipment after precipitation in a geothermal system. There are a few methods for control of silica and calcium carbonate precipitation in geothermal wells and surface equipment. Most production and reinjection wells require the implementation of a silica/calcium carbonate inhibition system to prevent silica/calcite precipitation inside casings, pipes, separators and other surface equipment in geothermal power systems. Installation of inhibitor systems are the most effective and practical solution for prevention of scaling problems and production loss, if the optimum inhibitor dosages are determined and applied effectively in geothermal systems. Less than optimum ratios of inhibitors may result in product overfeed, increased costs, and in some cases, inhibitor-induced fouling. The system is nonlinear and has multiple dependent and independent variables thus, it is difficult to obtain a mathematical model that describes the relation of geothermal fluid characteristic and inhibitors and with this reason, a fuzzy controller may be good option to resolve it in geothermal systems. Fuzzy control may replace the role of the mathematical model in conservative controllers, substituting it with a different model that is built from a number of smaller rules that only describe a sub-section of the complete system. In this study, two fuzzy logic controllers have been designed to control precipitation of silica and calcium carbonate by using scale inhibitors.},
author = {{Tut Haklidir}, Fusun and Haklidir, Mehmet},
doi = {10.1016/j.geothermics.2017.07.003},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tut Haklidir, Haklidir - 2017 - Fuzzy control of calcium carbonate and silica scales in geothermal systems.pdf:pdf},
issn = {03756505},
journal = {Geothermics},
keywords = {Fuzzy control,Geothermal systems,Scaling},
number = {April},
pages = {230--238},
publisher = {Elsevier},
title = {{Fuzzy control of calcium carbonate and silica scales in geothermal systems}},
url = {http://dx.doi.org/10.1016/j.geothermics.2017.07.003},
volume = {70},
year = {2017}
}
@book{EmilyM.Bender2020,
abstract = {Keyphrase extraction models are usually evaluated under different, not directly comparable, experimental setups. As a result, it remains unclear how well proposed models actually perform, and how they compare to each other. In this work, we address this issue by presenting a systematic large-scale analysis of state-ofthe- art keyphrase extraction models involving multiple benchmark datasets from various sources and domains. Our main results reveal that state-of-the-art models are in fact still challenged by simple baselines on some datasets. We also present new insights about the impact of using author- or reader-assigned keyphrases as a proxy for gold standard, and give recommendations for strong baselines and reliable benchmark datasets.},
archivePrefix = {arXiv},
arxivId = {2003.04628},
author = {{Emily M. Bender} and McMillan-Major, Angelina and Gebru, Timnit and Shmitchell, Shmargaret},
booktitle = {Proceedings of the ACM/IEEE Joint Conference on Digital Libraries},
doi = {10.1145/3442188.3445922},
eprint = {2003.04628},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Emily M. Bender et al. - 2020 - On the dangers of stochastic parrots can language models be too big.pdf:pdf},
isbn = {9781450375856},
issn = {15525996},
keywords = {Evaluation,Keyphrase generation,Natural language processing,evaluation,large-scale,natural language processing},
mendeley-tags = {evaluation,large-scale,natural language processing},
number = {1},
pages = {271--278},
publisher = {Association for Computing Machinery},
title = {{On the dangers of stochastic parrots: can language models be too big?}},
volume = {1},
year = {2020}
}
@article{Enke2013,
author = {Enke, David and Mehdiyev, Nijat},
doi = {10.1016/j.procs.2013.09.248},
pages = {115--120},
title = {{Type-2 Fuzzy Clustering and a Type-2 Fuzzy Inference Neural Network for the Prediction of Short-Term Interest Rates}},
volume = {20},
year = {2013}
}
@article{Xie2021,
abstract = {Unsupervised contrastive learning achieves great success in learning image representations with CNN. Unlike most recent methods that focused on improving accuracy of image classification, we present a novel contrastive learning approach, named DetCo, which fully explores the contrasts between global image and local image patches to learn discriminative representations for object detection. DetCo has several appealing benefits. (1) It is carefully designed by investigating the weaknesses of current self-supervised methods, which discard important representations for object detection. (2) DetCo builds hierarchical intermediate contrastive losses between global image and local patches to improve object detection, while maintaining global representations for image recognition. Theoretical analysis shows that the local patches actually remove the contextual information of an image, improving the lower bound of mutual information for better contrastive learning. (3) Extensive experiments on PASCAL VOC, COCO and Cityscapes demonstrate that DetCo not only outperforms state-of-the-art methods on object detection, but also on segmentation, pose estimation, and 3D shape prediction, while it is still competitive on image classification. For example, on PASCAL VOC, DetCo-100ep achieves 57.4 mAP, which is on par with the result of MoCov2-800ep. Moreover, DetCo consistently outperforms supervised method by 1.6/1.2/1.0 AP on Mask RCNN-C4/FPN/RetinaNet with 1x schedule. Code will be released at \href{https://github.com/xieenze/DetCo}{\color{blue}{\tt github.com/xieenze/DetCo}} and \href{https://github.com/open-mmlab/OpenSelfSup}{\color{blue}{\tt github.com/open-mmlab/OpenSelfSup}}.},
archivePrefix = {arXiv},
arxivId = {2102.04803},
author = {Xie, Enze and Ding, Jian and Wang, Wenhai and Zhan, Xiaohang and Xu, Hang and Li, Zhenguo and Luo, Ping},
eprint = {2102.04803},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xie et al. - 2021 - DetCo Unsupervised Contrastive Learning for Object Detection.pdf:pdf},
keywords = {contrastive learning,object detection,unsupervised learning},
mendeley-tags = {contrastive learning,object detection,unsupervised learning},
title = {{DetCo: Unsupervised Contrastive Learning for Object Detection}},
url = {http://arxiv.org/abs/2102.04803 https://github.com/xieenze/DetCo},
year = {2021}
}
@article{Zhang2020e,
abstract = {The essence of multivariate sequential learning is all about how to extract dependencies in data. These data sets, such as hourly medical records in intensive care units and multi-frequency phonetic time series, often time exhibit not only strong serial dependencies in the individual components (the "marginal" memory) but also non-negligible memories in the cross-sectional dependencies (the "joint" memory). Because of the multivariate complexity in the evolution of the joint distribution that underlies the data generating process, we take a data-driven approach and construct a novel recurrent network architecture, termed Memory-Gated Recurrent Networks (mGRN), with gates explicitly regulating two distinct types of memories: the marginal memory and the joint memory. Through a combination of comprehensive simulation studies and empirical experiments on a range of public datasets, we show that our proposed mGRN architecture consistently outperforms state-of-the-art architectures targeting multivariate time series.},
archivePrefix = {arXiv},
arxivId = {2012.13121},
author = {Zhang, Yaquan and Wu, Qi and Peng, Nanbo and Dai, Min and Zhang, Jing and Wang, Hu},
eprint = {2012.13121},
file = {:home/user/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2020 - Memory-Gated Recurrent Networks.pdf:pdf},
keywords = {time series},
mendeley-tags = {time series},
title = {{Memory-Gated Recurrent Networks}},
url = {http://arxiv.org/abs/2012.13121 https://github.com/yaquanzhang/mGRN},
year = {2020}
}
